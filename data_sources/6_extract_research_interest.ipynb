{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "load_dotenv()\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dr_ntu_dir='./raw_dr_ntu'\n",
    "raw_faculty_db = 'scse_profile'\n",
    "\n",
    "process_faculty_db_dir ='./processed'\n",
    "process_faculty_db = 'scse_profile'\n",
    "process_co_author_db = 'google_scholar_co_author'\n",
    "\n",
    "raw_google_scholar_dir = './raw_google_scholar'\n",
    "raw_google_search_dir = './google_search'\n",
    "\n",
    "process_publications_dir = './processed_google_scholar_publications'\n",
    "\n",
    "research_interest_dir = './research_interest'\n",
    "\n",
    "cur_year = datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculties = pd.read_csv(os.path.join(process_faculty_db_dir, process_faculty_db+'.csv'))\n",
    "google_scholar_faculties = faculties[faculties['google_scholar'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def extract_topics(title, description):\n",
    "    system_msg = \"I am an AI assistant designed to help you extract the related field of computer science from a given text. \\\n",
    "    I understand that the text contains a title and a description of an academic paper and I am capable of identifying the field of computer science the paper is addressing. \\\n",
    "    I understand that I am only allowed to extract topics related to in the field of computer science and the topics must be generic. \\\n",
    "    Examples of generic fields of computer science are 'Distributed Systems', 'Computer Vision', 'Graph Mining', 'Erasure Coding', 'Bioinformatics', 'Operating Systems', 'Information Retrieval'. \\\n",
    "    The topics must be related to computer science. \\\n",
    "    I also understand that after extracting the topic, \\\n",
    "    My response must be a must be wrapped in `<result>`, eg: `<result>topic<result>` replace topic with the topic that sums up the academic paper.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the title and description below, label the academic paper with the main field of computer science that it is addressing. \n",
    "    Your responsemust be a must be wrapped in `<result>`, eg: `<result>topic<result>` replace topic with the topic that sums up the academic paper.\n",
    "\n",
    "    Title:\n",
    "\n",
    "    {title}\n",
    "\n",
    "    Description:\n",
    "\n",
    "    {description}\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                request_timeout=10\n",
    "            ) \n",
    "            output = response['choices'][0]['message']['content']\n",
    "            if output.startswith('<result>') and output.endswith('<result>'):\n",
    "                output = output.strip('<result>')\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def group_topics(keywords):\n",
    "    system_msg = \"I am an AI assistant designed to help you group related keywords together. \\\n",
    "    I understand that I will receive a list of computer science realted keywords and I am able to understand each keyword. \\\n",
    "    My response be a must a list of lists eg: `[1,2,3,4],[q,w,e]` where within each list consist of keywords that are related to each other \"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the list of keywords provided below, help me to group them. \n",
    "    Your response must be a list of list where within each list are keywords that are related to each other.\n",
    "    Wrap the list of list in `<result>`. eg `<result>[[1,2,3,4],[q,w,e]]<result>`.\n",
    "\n",
    "    Keywords:\n",
    "\n",
    "    {keywords}\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                request_timeout=60*15,\n",
    "                temperature=0.2\n",
    "            ) \n",
    "            output = response['choices'][0]['message']['content']\n",
    "            if output.startswith('<result>') and output.endswith('<result>'):\n",
    "                output = output.strip('<result>')\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_1_topic(keywords):\n",
    "    system_msg = \"I am an AI assistant designed to help you identify keyword for a list of words. \\\n",
    "    I understand that I will receive a list of computer science related keywords and I am able to understand each keyword. \\\n",
    "    My response be a must be wrapped in <result>, eg: <result>topic<result> replace topic with the topic that sums up the list of keywords. \"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the list of keywords provided below, help me to extract the main keyword. \n",
    "    Your response be a must be wrapped in <result>, eg: <result>topic<result> replace topic with the topic that sums up the list of keywords.\n",
    "\n",
    "    Keywords:\n",
    "\n",
    "    {','.join(keywords)}\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                # request_timeout=10,\n",
    "                temperature=1\n",
    "            ) \n",
    "            output = response['choices'][0]['message']['content']\n",
    "            if output.startswith('<result>') and output.endswith('<result>'):\n",
    "                output = output.strip('<result>')\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, row in tqdm(google_scholar_faculties.iterrows()):\n",
    "    name, url, id = row['full_name'], row['google_scholar'], row['google_scholar_id']\n",
    "\n",
    "    pub_file = f\"{process_publications_dir}/{id}.json\"\n",
    "    \n",
    "    if os.path.exists(pub_file):\n",
    "        with open(pub_file, 'r') as f:\n",
    "            pubs = json.load(f)\n",
    "\n",
    "        topics = []\n",
    "        for pub in tqdm(pubs):\n",
    "            if pub['description'] is not None and pub['publication_year'] is not None and int(pub['publication_year'])>=min_year:\n",
    "                topic = extract_topics(pub['title'], pub['description'])\n",
    "\n",
    "                results = {\n",
    "                    'link': pub['link'],\n",
    "                    'topic': topic,\n",
    "                }\n",
    "                topics.append(results)\n",
    "\n",
    "        \n",
    "            with open(f\"{research_interest_dir}/{id}.json  \", 'w') as f:\n",
    "                json.dump(topics, f)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_topics = {}\n",
    "for i, row in tqdm(google_scholar_faculties.iterrows()):\n",
    "    name, url, id = row['full_name'], row['google_scholar'], row['google_scholar_id']\n",
    "\n",
    "    topics_file = f\"{research_interest_dir}/{id}.json\"\n",
    "    \n",
    "    if os.path.exists(topics_file):\n",
    "        with open(topics_file, 'r') as f:\n",
    "            topics = json.load(f)\n",
    "        \n",
    "        for topic in topics:\n",
    "            all_topics[topic['topic']] = all_topics.get(topic['topic'], 0) + 1\n",
    "\n",
    "len(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def group_topics(keywords):\n",
    "    system_msg = \"I am an AI assistant designed to help you group related keywords together. \\\n",
    "    I understand that I will receive a list of computer science realted keywords and I am able to understand each keyword. \\\n",
    "    My response be a must a list of lists eg: `[1,2,3,4],[q,w,e]` where within each list consist of keywords that are related to each other \"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the list of keywords provided below, help me to group them. \n",
    "    Your response must be a list of list where within each list are keywords that are related to each other.\n",
    "    Wrap the list of list in `<result>`. eg `<result>[[1,2,3,4],[q,w,e]]<result>`.\n",
    "\n",
    "    Keywords:\n",
    "\n",
    "    {keywords}\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                request_timeout=60*15,\n",
    "                temperature=0.2\n",
    "            ) \n",
    "            output = response['choices'][0]['message']['content']\n",
    "            if output.startswith('<result>') and output.endswith('<result>'):\n",
    "                output = output.strip('<result>')\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = []\n",
    "topics = list(all_topics.keys())\n",
    "for i in tqdm(range(0, len(topics)-50, 50)):\n",
    "    output = group_topics(topics[i:i+50])\n",
    "    all_outputs.append(output)\n",
    "\n",
    "all_outputs.append(group_topics(topics[len(topics)-50-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = [x.strip('[').strip(']') for x in all_outputs]\n",
    "all_outputs = [x.split('],')for x in all_outputs]\n",
    "\n",
    "groupings = []\n",
    "for x in all_outputs:\n",
    "    for y in x:\n",
    "        z = y.strip()\n",
    "        z = z.strip('[').strip(']').split(',')\n",
    "        group = []\n",
    "        for a in z:\n",
    "            b = a.strip().strip(\"'\")\n",
    "            group.append(b)\n",
    "        groupings.append(group)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_1_topic(keywords):\n",
    "    system_msg = \"I am an AI assistant designed to help you identify keyword for a list of words. \\\n",
    "    I understand that I will receive a list of computer science related keywords and I am able to understand each keyword. \\\n",
    "    My response be a must be wrapped in <result>, eg: <result>topic<result> replace topic with the topic that sums up the list of keywords. \"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the list of keywords provided below, help me to extract the main keyword. \n",
    "    Your response be a must be wrapped in <result>, eg: <result>topic<result> replace topic with the topic that sums up the list of keywords.\n",
    "\n",
    "    Keywords:\n",
    "\n",
    "    {','.join(keywords)}\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"system\", \"content\": system_msg },\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                # request_timeout=10,\n",
    "                temperature=1\n",
    "            ) \n",
    "            output = response['choices'][0]['message']['content']\n",
    "            if output.startswith('<result>') and output.endswith('<result>'):\n",
    "                output = output.strip('<result>')\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<result>Advanced Computer Sciences</result>\n",
      "<result>Geospatial Technology</result>\n",
      "<result>Federated Learning</result>\n",
      "<result>Spatial Data Processing</result>\n",
      "<result>Natural Language Processing</result>\n",
      "<result>Multimodal Fusion</result>\n"
     ]
    }
   ],
   "source": [
    "keyword = []\n",
    "\n",
    "for group in groupings:\n",
    "    if len(group)==1:\n",
    "        output = group[0]\n",
    "    else:\n",
    "        output = get_1_topic(group)\n",
    "    keyword.append(tuple([output, group]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(google_scholar_faculties.iterrows()):\n",
    "    name, url, id = row['full_name'], row['google_scholar'], row['google_scholar_id']\n",
    "\n",
    "    topics_file = f\"{research_interest_dir}/{id}.json\"\n",
    "    \n",
    "    if os.path.exists(topics_file):\n",
    "        with open(topics_file, 'r') as f:\n",
    "            pubs = json.load(f)\n",
    "        \n",
    "        for pub in pubs:\n",
    "            topic = pub['topic']\n",
    "            for key in keyword:\n",
    "                for interest in key[1]:\n",
    "                    if topic in interest:\n",
    "                        pub['topic'] = key[0]\n",
    "        \n",
    "        with open(topics_file, 'w') as f:\n",
    "            json.dump(pubs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics = {}\n",
    "for i, row in tqdm(google_scholar_faculties.iterrows()):\n",
    "    name, url, id = row['full_name'], row['google_scholar'], row['google_scholar_id']\n",
    "\n",
    "    topics_file = f\"{research_interest_dir}/{id}.json\"\n",
    "    \n",
    "    if os.path.exists(topics_file):\n",
    "        with open(topics_file, 'r') as f:\n",
    "            topics = json.load(f)\n",
    "        \n",
    "        for topic in topics:\n",
    "            all_topics[topic['topic']] = all_topics.get(topic['topic'], 0) + 1\n",
    "\n",
    "len(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_topic = group_topics(list(all_topics.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agg_topic\n",
    "output = output.strip('[').strip(']')\n",
    "output = output.split('],')\n",
    "groupings = []\n",
    "for x in output:\n",
    "    z = x.strip()\n",
    "    z = z.strip('[').strip(']').split(',')\n",
    "    group = []\n",
    "    for a in z:\n",
    "        b = a.strip().strip(\"'\")\n",
    "        group.append(b)\n",
    "    groupings.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<result>Computing</result>\n",
      "<result>Federated Learning</result>\n"
     ]
    }
   ],
   "source": [
    "keyword = []\n",
    "\n",
    "for group in groupings:\n",
    "    if len(group)==1:\n",
    "        output = group[0]\n",
    "    else:\n",
    "        output = get_1_topic(group)\n",
    "    keyword.append(tuple([output, group]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(google_scholar_faculties.iterrows()):\n",
    "    name, url, id = row['full_name'], row['google_scholar'], row['google_scholar_id']\n",
    "\n",
    "    topics_file = f\"{research_interest_dir}/{id}.json\"\n",
    "    \n",
    "    if os.path.exists(topics_file):\n",
    "        with open(topics_file, 'r') as f:\n",
    "            pubs = json.load(f)\n",
    "        \n",
    "        for pub in pubs:\n",
    "            topic = pub['topic']\n",
    "            for key in keyword:\n",
    "                for interest in key[1]:\n",
    "                    if topic in interest:\n",
    "                        pub['topic'] = key[0]\n",
    "        \n",
    "        with open(topics_file, 'w') as f:\n",
    "            json.dump(pubs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scse_dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
