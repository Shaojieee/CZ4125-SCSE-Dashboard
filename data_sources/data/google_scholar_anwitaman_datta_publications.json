{"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:g3aElNc5_aQC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2831347.2831354", "authors": ["Pedro Garcia Lopez", "Alberto Montresor", "Dick Epema", "Anwitaman Datta", "Teruo Higashino", "Adriana Iamnitchi", "Marinho Barcellos", "Pascal Felber", "Etienne Riviere"], "publication_date": "2015/9/30", "source": "ACM SIGCOMM Computer Communication Review", "volume": "45", "issue": "5", "pages": "37-42", "publisher": "ACM", "description": "In many aspects of human activity, there has been a continuous struggle between the forces of centralization and decentralization. Computing exhibits the same phenomenon; we have gone from mainframes to PCs and local networks in the past, and over the last decade we have seen a centralization and consolidation of services and applications in data centers and clouds. We position that a new shift is necessary. Technological advances such as powerful dedicated connection boxes deployed in most homes, high capacity mobile end-user devices and powerful wireless networks, along with growing user concerns about trust, privacy, and autonomy requires taking the control of computing applications, data, and services away from some central nodes (the \"core\") to the other logical extreme (the \"edge\") of the Internet. We also position that this development can help blurring the boundary between man and\u00a0\u2026", "total_citations": {"2016": 52, "2017": 147, "2018": 216, "2019": 221, "2020": 151, "2021": 153, "2022": 78, "2023": 46}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:9yKSN-GCB0IC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1578002.1578010", "authors": ["Sonja Buchegger", "Doris Schi\u00f6berg", "Le-Hung Vu", "Anwitaman Datta"], "publication_date": "2009/3/31", "book": "Proceedings of the Second ACM EuroSys Workshop on Social Network Systems", "pages": "46-52", "description": "To address privacy concerns over Online Social Networks (OSNs), we propose a distributed, peer-to-peer approach coupled with encryption. Moreover, extending this distributed approach by direct data exchange between user devices removes the strict Internet-connectivity requirements of web-based OSNs. In order to verify the feasibility of this approach, we designed a two-tiered architecture and protocols that recreate the core features of OSNs in a decentralized way. This paper focuses on the description of the prototype built for the P2P infrastructure for social networks, as a first step without the encryption part, and shares early experiences from the prototype and insights gained since first outlining the challenges and possibilities of decentralized alternatives to OSNs.", "total_citations": {"2009": 11, "2010": 46, "2011": 61, "2012": 80, "2013": 76, "2014": 66, "2015": 58, "2016": 52, "2017": 49, "2018": 25, "2019": 23, "2020": 18, "2021": 18, "2022": 16, "2023": 8}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:u5HHmVD_uO8C": {"external_link": "https://dl.acm.org/doi/pdf/10.1145/945721.945729", "authors": ["Karl Aberer", "Philippe Cudr\u00e9-Mauroux", "Anwitaman Datta", "Zoran Despotovic", "Manfred Hauswirth", "Magdalena Punceva", "Roman Schmidt"], "publication_date": "2003/9/1", "journal": "ACM SiGMOD Record", "volume": "32", "issue": "3", "pages": "29-33", "publisher": "ACM", "description": "In the P2P community a fundamental distinction is made among unstructured and structured P2P systems for resource location. In unstructured P2P systems in principle peers are unaware of the resources that neighboring peers in the overlay networks maintain. Typically they resolve search requests by flooding techniques. Gnutella [9] is the most prominent example of this class. In contrast, in structured P2P systems peers maintain information about what resources neighboring peers offer. Thus queries can be directed and in consequence substantially fewer messages are needed. This comes at the cost of increased maintenance efforts during changes in the overlay network as a result of peers joining or leaving. The most prominent class of approaches to structured P2P systems are distributed hash tables (DHT), for example Chord [17]. Unstructured P2P systems have generated substantial interest because of\u00a0\u2026", "total_citations": {"2003": 2, "2004": 26, "2005": 32, "2006": 63, "2007": 60, "2008": 51, "2009": 50, "2010": 63, "2011": 55, "2012": 33, "2013": 26, "2014": 23, "2015": 23, "2016": 12, "2017": 17, "2018": 10, "2019": 5, "2020": 12, "2021": 3, "2022": 3, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:fQNAKQ3IYiAC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2396761.2396785", "authors": ["Chenliang Li", "Aixin Sun", "Anwitaman Datta"], "publication_date": "2012/10/29", "book": "Proceedings of the 21st ACM international conference on Information and knowledge management", "pages": "155-164", "description": "Event detection from tweets is an important task to understand the current events/topics attracting a large number of common users. However, the unique characteristics of tweets (e.g. short and noisy content, diverse and fast changing topics, and large data volume) make event detection a challenging task. Most existing techniques proposed for well written documents (e.g. news articles) cannot be directly adopted. In this paper, we propose a segment-based event detection system for tweets, called Twevent. Twevent first detects bursty tweet segments as event segments and then clusters the event segments into events considering both their frequency distribution and content similarity. More specifically, each tweet is split into non-overlapping segments (i.e. phrases possibly refer to named entities or semantically meaningful information units). The bursty segments are identified within a fixed time window based on\u00a0\u2026", "total_citations": {"2012": 3, "2013": 21, "2014": 33, "2015": 47, "2016": 69, "2017": 78, "2018": 58, "2019": 47, "2020": 30, "2021": 27, "2022": 27, "2023": 12}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:sSrBHYA8nusC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2348283.2348380", "authors": ["Chenliang Li", "Jianshu Weng", "Qi He", "Yuxia Yao", "Anwitaman Datta", "Aixin Sun", "Bu-Sung Lee"], "publication_date": "2012/8/12", "book": "Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval", "pages": "721-730", "description": "Many private and/or public organizations have been reported to create and monitor targeted Twitter streams to collect and understand users' opinions about the organizations. Targeted Twitter stream is usually constructed by filtering tweets with user-defined selection criteria e.g. tweets published by users from a selected region, or tweets that match one or more predefined keywords. Targeted Twitter stream is then monitored to collect and understand users' opinions about the organizations. There is an emerging need for early crisis detection and response with such target stream. Such applications require a good named entity recognition (NER) system for Twitter, which is able to automatically discover emerging named entities that is potentially linked to the crisis. In this paper, we present a novel 2-step unsupervised NER system for targeted Twitter stream, called TwiNER. In the first step, it leverages on the global\u00a0\u2026", "total_citations": {"2011": 1, "2012": 4, "2013": 29, "2014": 44, "2015": 43, "2016": 59, "2017": 42, "2018": 32, "2019": 27, "2020": 17, "2021": 22, "2022": 16, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:u-x6o8ySG0sC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1203454/", "authors": ["Anwitaman Datta", "Manfred Hauswirth", "Karl Aberer"], "publication_date": "2003/5/19", "conference": "23rd International Conference on Distributed Computing Systems, 2003. Proceedings.", "pages": "76-85", "publisher": "IEEE", "description": "This paper studies the problem of updates in decentralised and self-organising P2P systems in which peers have low online probabilities and only local knowledge. The update strategy we propose for this environment is based on a hybrid push/pull rumor spreading algorithm and provides a fully decentralised, efficient and robust communication scheme which offers probabilistic guarantees rather than ensuring strict consistency. We describe a generic analytical model to investigate the utility of our hybrid update propagation scheme from the perspective of communication overhead.", "total_citations": {"2002": 1, "2003": 17, "2004": 24, "2005": 32, "2006": 32, "2007": 29, "2008": 30, "2009": 24, "2010": 22, "2011": 17, "2012": 13, "2013": 8, "2014": 6, "2015": 7, "2016": 5, "2017": 9, "2018": 3, "2019": 0, "2020": 0, "2021": 1, "2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:5nxA0vEk-isC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5934901/", "authors": ["Frederique Oggier", "Anwitaman Datta"], "publication_date": "2011/4/10", "conference": "2011 Proceedings IEEE INFOCOM", "pages": "1215-1223", "publisher": "IEEE", "description": "Erasure codes provide a storage efficient alternative to replication based redundancy in (networked) storage systems. They however entail high communication overhead for maintenance, when some of the encoded fragments are lost and need to be replenished. Such overheads arise from the fundamental need to recreate (or keep separately) first a copy of the whole object before any individual encoded fragment can be generated and replenished. There has recently been intense interest to explore alternatives, most prominent ones being regenerating codes (RGC) and hierarchical codes (HC). We propose as an alternative a new family of codes to improve the maintenance process, called self-repairing codes (SRC), with the following salient features: (a) encoded fragments can be repaired directly from other subsets of encoded fragments by downloading less data than the size of the complete object, ensuring\u00a0\u2026", "total_citations": {"2010": 4, "2011": 11, "2012": 17, "2013": 38, "2014": 34, "2015": 31, "2016": 32, "2017": 35, "2018": 19, "2019": 23, "2020": 14, "2021": 10, "2022": 4, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:d1gkVwhDpl0C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-540-30145-5_8", "authors": ["Anwitaman Datta", "Silvia Quarteroni", "Karl Aberer"], "publication_date": "2004/6/17", "book": "International Conference on Semantics for the Networked World", "pages": "126-143", "publisher": "Springer Berlin Heidelberg", "description": "We introduce autonomous gossiping (A/G), a new genre epidemic algorithm for selective dissemination of information in contrast to previous usage of epidemic algorithms which flood the whole network. A/G is a paradigm which suits well in a mobile ad-hoc networking (MANET) environment because it does not require any infrastructure or middleware like multicast tree and (un)subscription maintenance for publish/subscribe, but uses ecological and economic principles in a self-organizing manner in order to achieve any arbitrary selectivity (flexible casting). The trade-off of using a stateless self-organizing mechanism like A/G is that it does not guarantee completeness deterministically as is one of the original objectives of alternate selective dissemination schemes like publish/subscribe. We argue that such incompleteness is not a problem in many non-critical real-life civilian application scenarios and\u00a0\u2026", "total_citations": {"2003": 2, "2004": 1, "2005": 9, "2006": 19, "2007": 23, "2008": 20, "2009": 17, "2010": 25, "2011": 17, "2012": 16, "2013": 14, "2014": 7, "2015": 8, "2016": 4, "2017": 5, "2018": 6, "2019": 3, "2020": 0, "2021": 5, "2022": 4, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:tuHXwOkdijsC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7463523/", "authors": ["Lichun Li", "Rongxing Lu", "Kim-Kwang Raymond Choo", "Anwitaman Datta", "Jun Shao"], "publication_date": "2016/5/2", "journal": "IEEE transactions on information forensics and security", "volume": "11", "issue": "8", "pages": "1847-1861", "publisher": "IEEE", "description": "Association rule mining and frequent itemset mining are two popular and widely studied data analysis techniques for a range of applications. In this paper, we focus on privacy-preserving mining on vertically partitioned databases. In such a scenario, data owners wish to learn the association rules or frequent itemsets from a collective data set and disclose as little information about their (sensitive) raw data as possible to other data owners and third parties. To ensure data privacy, we design an efficient homomorphic encryption scheme and a secure comparison scheme. We then propose a cloud-aided frequent itemset mining solution, which is used to build an association rule mining solution. Our solutions are designed for outsourced databases that allow multiple data owners to efficiently share their data securely without compromising on data privacy. Our solutions leak less information about the raw data than most\u00a0\u2026", "total_citations": {"2016": 6, "2017": 26, "2018": 33, "2019": 31, "2020": 33, "2021": 33, "2022": 25, "2023": 19}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:Tyk-4Ss8FVUC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4801862/", "authors": ["Sonja Buchegger", "Anwitaman Datta"], "publication_date": "2009/2/2", "source": "2009 Sixth International Conference on Wireless On-Demand Network Systems and Services", "pages": "161-168", "publisher": "IEEE", "description": "Online Social Networks like Facebook, MySpace, Xing, etc. have become extremely popular. Yet they have some limitations that we want to overcome for a next generation of social networks: privacy concerns and requirements of Internet connectivity, both of which are due to web-based applications on a central site whose owner has access to all data. To overcome these limitations, we envision a paradigm shift from client-server to a peer-to-peer infrastructure coupled with encryption so that users keep control of their data and can use the social network also locally, without Internet access. This shift gives rise to many research questions intersecting networking, security, distributed systems and social network analysis, leading to a better understanding of how technology can support social interactions. This paper is an attempt to identify the core functionalities necessary to build social networking applications and\u00a0\u2026", "total_citations": {"2008": 1, "2009": 10, "2010": 18, "2011": 16, "2012": 29, "2013": 24, "2014": 19, "2015": 18, "2016": 20, "2017": 6, "2018": 7, "2019": 7, "2020": 7, "2021": 11, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:hFOr9nPyWt4C": {"external_link": "https://link.springer.com/chapter/10.1007/978-1-4419-7142-5_17", "authors": ["Anwitaman Datta", "Sonja Buchegger", "Le-Hung Vu", "Thorsten Strufe", "Krzysztof Rzadca"], "publication_date": "2010", "journal": "Handbook of social network technologies and applications", "pages": "349-378", "publisher": "Springer US", "description": "Current Online social networks (OSN) are web services run on logically centralized infrastructure. Large OSN sites use content distribution networks and thus distribute some of the load by caching for performance reasons, nevertheless there is a central repository for user and application data. This centralized nature of OSNs has several drawbacks including scalability, privacy, dependence on a provider, need for being online for every transaction, and a lack of locality. There have thus been several efforts toward decentralizing OSNs while retaining the functionalities offered by centralized OSNs. A decentralized online social network (DOSN) is a distributed system for social networking with no or limited dependency on any dedicated central infrastructure. In this chapter we explore the various motivations of a decentralized approach to online social networking, discuss several concrete proposals and types of\u00a0\u2026", "total_citations": {"2010": 1, "2011": 3, "2012": 12, "2013": 11, "2014": 17, "2015": 15, "2016": 21, "2017": 18, "2018": 21, "2019": 15, "2020": 13, "2021": 15, "2022": 16, "2023": 13}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:2osOgNQ5qMEC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1551021/", "authors": ["Anwitaman Datta", "Manfred Hauswirth", "Renault John", "Roman Schmidt", "Karl Aberer"], "publication_date": "2005/8/31", "conference": "Fifth IEEE International Conference on Peer-to-Peer Computing (P2P'05)", "pages": "57-66", "publisher": "IEEE", "description": "Among the open problems in P2P systems, support for nontrivial search predicates, standardized query languages, distributed query processing, query load balancing, and quality of query results have been identified as some of the most relevant issues. This paper describes how range queries as an important nontrivial search predicate can be supported in a structured overlay network that provides O(log n) search complexity on top of a trie abstraction. We provide analytical results that show that the proposed approach is efficient, supports arbitrary granularity of ranges, and demonstrate that its algorithmic complexity in terms of messages is independent of the size of the queried ranges and only depends on the size of the result set. In contrast to other systems which provide evaluation results only through simulations, we validate the theoretical analysis of the algorithms with large-scale experiments on the\u00a0\u2026", "total_citations": {"2004": 1, "2005": 4, "2006": 16, "2007": 20, "2008": 24, "2009": 16, "2010": 22, "2011": 9, "2012": 12, "2013": 5, "2014": 4, "2015": 2, "2016": 5, "2017": 3, "2018": 2, "2019": 1, "2020": 0, "2021": 0, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:isC4tDSrTZIC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6151349/", "authors": ["Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2012/1/3", "conference": "2012 fourth international conference on communication systems and networks (COMSNETS 2012)", "pages": "1-10", "publisher": "IEEE", "description": "Recent years have seen several earnest initiatives from both academic researchers as well as open source communities to implement and deploy decentralized online social networks (DOSNs). The primary motivations for DOSNs are privacy and autonomy from big brotherly service providers. However decentralization introduces many challenges. One of the principal problems is to guarantee availability of data even when the data owner is not online, so that others can access the said data even when a node is offline or down. Intuitively this can be solved by replicating the data on other users' machines. Existing DOSN proposals try to solve this problem using heuristics which are agnostic to the various kinds of heterogeneity both in terms of end user resources as well as end user behaviors in such a system. In this paper, we argue that a pragmatic design needs to explicitly allow for and leverage on system\u00a0\u2026", "total_citations": {"2011": 1, "2012": 8, "2013": 14, "2014": 15, "2015": 23, "2016": 16, "2017": 18, "2018": 14, "2019": 4, "2020": 5, "2021": 6, "2022": 3, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:qjMakFHDy7sC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1210265/", "authors": ["Anwitaman Datta", "Manfred Hauswirth", "Karl Aberer"], "publication_date": "2003/6/24", "conference": "EEE International Conference on E-Commerce, 2003. CEC 2003.", "pages": "303-312", "publisher": "IEEE", "description": "The huge success of eBay has proven the demand for customer-to-customer (C2C) electronic commerce. eBay is a centralized infrastructure with all its scalability problems (network bandwidth, server load, availability, etc.). We argue that C2C e-commerce is an application domain that maps naturally onto the emergent field of P2P systems simply by its underlying interaction model of customers, i.e., peers. This offers the opportunity to take P2P systems beyond mere file sharing systems into interesting new application domains. The long-term goal would be to design a fully functional decentralized system which resembles eBay without eBay's dedicated, centralized infrastructure. Since security (authenticity, non-repudiation, trust, etc.) is key to any e-commerce infrastructure, our envisioned P2P e-commerce platform has to address this adequately. As the first step in this direction we present an approach for a\u00a0\u2026", "total_citations": {"2003": 4, "2004": 4, "2005": 8, "2006": 13, "2007": 21, "2008": 12, "2009": 11, "2010": 9, "2011": 6, "2012": 8, "2013": 4, "2014": 3, "2015": 2, "2016": 4, "2017": 3, "2018": 2, "2019": 5, "2020": 3, "2021": 2, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:UeHWp8X0CEIC": {"external_link": "https://infoscience.epfl.ch/record/54358", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth", "Roman Schmidt"], "publication_date": "2005", "source": "31st International Conference on Very Large Databases (VLDB)", "issue": "CONF", "description": "We address the problem of how a data-oriented, structured overlay networks can be constructed efficiently from scratch in a self-organized way, a problem that has so far not been addressed in the literature. This problem occurs when using overlay networks to implement index structures for data-oriented applications such as peer-to-peer databases or peer-to-peer information retrieval. There changing application requirements frequently lead to re-indexing of the data and hence (re-) construction of overlay networks. Standard maintenance algorithms for overlay networks cannot efficiently deal with this task as they are inherently sequential. We propose a randomized algorithm which is completely decentralized and parallel that can construct a new overlay network with short latency. At the same time our approach ensures good load-balancing for skewed data key distributions which result from preserving key order relationships as necessitated by data-oriented applications. We provide both a theoretical analysis of the basic algorithms and a complete system implementation that has been tested on PlanetLab. We are using this system to support peer-to-peer information retrieval and database applications.", "total_citations": {"2005": 5, "2006": 18, "2007": 19, "2008": 11, "2009": 12, "2010": 6, "2011": 5, "2012": 7, "2013": 6, "2014": 1, "2015": 4, "2016": 1, "2017": 2, "2018": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:YOwf2qJgpHMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5541690/", "authors": ["Krzysztof Rzadca", "Anwitaman Datta", "Sonja Buchegger"], "publication_date": "2010/6/21", "conference": "2010 IEEE 30th International Conference on Distributed Computing Systems", "pages": "599-609", "publisher": "IEEE", "description": "In peer-to-peer storage systems, peers replicate each others' data in order to increase availability. If the matching is done centrally, the algorithm can optimize data availability in an equitable manner for all participants. However, if matching is decentralized, the peers' selfishness can greatly alter the results, leading to performance inequities that can render the system unreliable and thus ultimately unusable. We analyze the problem using both theoretical approaches (complexity analysis for the centralized system, game theory for the decentralized one) and simulation. We prove that the problem of optimizing availability in a centralized system is NP-hard. In decentralized settings, we show that the rational behavior of selfish peers will be to replicate only with similarly-available peers. Compared to the socially-optimal solution, highly available peers have their data availability increased at the expense of decreased\u00a0\u2026", "total_citations": {"2010": 3, "2011": 8, "2012": 14, "2013": 17, "2014": 18, "2015": 8, "2016": 6, "2017": 8, "2018": 1, "2019": 3, "2020": 2, "2021": 3, "2022": 0, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:3fE2CSJIrl8C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1645953.1645958", "authors": ["Xin Liu", "Anwitaman Datta", "Krzysztof Rzadca", "Ee-Peng Lim"], "publication_date": "2009/11/2", "book": "Proceedings of the 18th ACM conference on Information and knowledge management", "pages": "7-16", "description": "Trust plays important roles in diverse decentralized environments, including our society at large. Computational trust models help to, for instance, guide users' judgements in online auction sites about other users; or determine quality of contributions in web 2.0 sites. Most of the existing trust models, however, require historical information about past behavior of a specific agent being evaluated - information that is not always available. In contrast, in real life interactions among users, in order to make the first guess about the trustworthiness of a stranger, we commonly use our \"instinct\" - essentially stereotypes developed from our past interactions with \"similar\" people. We propose StereoTrust, a computational trust model inspired by real life stereotypes. A user forms stereotypes using her previous transactions with other agents. A stereotype contains certain features of agents and an expected outcome of the transaction\u00a0\u2026", "total_citations": {"2010": 4, "2011": 5, "2012": 15, "2013": 14, "2014": 13, "2015": 9, "2016": 4, "2017": 10, "2018": 4, "2019": 6, "2020": 4, "2021": 2, "2022": 3, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:zYLM7Y9cAGgC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1698603/", "authors": ["Anwitaman Datta", "Karl Aberer"], "publication_date": "2006/9/6", "conference": "Sixth IEEE International Conference on Peer-to-Peer Computing (P2P'06)", "pages": "133-144", "publisher": "IEEE", "description": "Content storage in a distributed collaborative environment uses redundancy for better resilience and thus provides good availability and durability. In a peer-to-peer environment, where peers continuously leave and rejoin the network, various lazy strategies can be employed to maintain a minimal redundancy of stored content in the system. Existing static resilience analyses fail to capture in detail the system's behavior over time, particularly the probability mass function of the actual available redundancy, since it ignores the crucial interplay between churn and maintenance operations, and looks only at the average system property. We perform a Markovian time-evolution analysis of the system specified by probability mass function of each possible system state, and establish that given a fixed rate of churn and a specific maintenance strategy, the system operates in a corresponding steady-state (dynamic\u00a0\u2026", "total_citations": {"2006": 1, "2007": 6, "2008": 5, "2009": 11, "2010": 13, "2011": 15, "2012": 10, "2013": 4, "2014": 2, "2015": 1, "2016": 2, "2017": 2, "2018": 1, "2019": 1, "2020": 0, "2021": 1, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:IjCSPb-OGe4C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1318567/", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2004/7", "journal": "IEEE Transactions on Knowledge and Data Engineering", "volume": "16", "issue": "7", "pages": "858-869", "publisher": "IEEE", "description": "Identification is an essential building block for many services in distributed information systems. The quality and purpose of identification may differ, but the basic underlying problem is always to bind a set of attributes to an identifier in a unique and deterministic way. Name/directory services, such as DNS, X.500, or UDDI, are a well-established concept to address this problem in distributed information systems. However, none of these services addresses the specific requirements of peer-to-peer systems with respect to dynamism, decentralization, and maintenance. We propose the implementation of directories using a structured peer-to-peer overlay network and apply this approach to support self-contained maintenance of routing tables with dynamic IP addresses in structured P2P systems. Thus, we keep routing tables intact without affecting the organization of the overlay networks, making it logically independent\u00a0\u2026", "total_citations": {"2004": 7, "2005": 7, "2006": 7, "2007": 10, "2008": 7, "2009": 12, "2010": 6, "2011": 4, "2012": 5, "2013": 4, "2014": 1, "2015": 3, "2016": 3, "2017": 0, "2018": 0, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&citation_for_view=VWi3_OIAAAAJ:70eg2SAEIzsC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S156742231200049X", "authors": ["Xin Liu", "Anwitaman Datta", "Krzysztof Rzadca"], "publication_date": "2013/1/1", "journal": "Electronic Commerce Research and Applications", "volume": "12", "issue": "1", "pages": "24-39", "publisher": "Elsevier", "description": "Models of computational trust support users in taking decisions. They are commonly used to guide users\u2019 judgements in online auction sites; or to determine quality of contributions in Web 2.0 sites. However, most existing systems require historical information about the past behavior of the specific agent being judged. In contrast, in real life, to anticipate and to predict a stranger\u2019s actions in absence of the knowledge of such behavioral history, we often use our \u201cinstinct\u201d\u2014essentially stereotypes developed from our past interactions with other \u201csimilar\u201d persons. In this paper, we propose StereoTrust, a computational trust model inspired by stereotypes as used in real-life. A stereotype contains certain features of agents and an expected outcome of the transaction. When facing a stranger, an agent derives its trust by aggregating stereotypes matching the stranger\u2019s profile. Since stereotypes are formed locally\u00a0\u2026", "total_citations": {"2012": 1, "2013": 2, "2014": 8, "2015": 8, "2016": 4, "2017": 9, "2018": 6, "2019": 5, "2020": 10, "2021": 2, "2022": 12, "2023": 7}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:8AbLer7MMksC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/8395", "authors": ["Xin Liu", "Anwitaman Datta"], "publication_date": "2012", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "26", "issue": "1", "pages": "1938-1944", "description": "Modeling trust in complex dynamic environments is an important yet challenging issue since an intelligent agent may strategically change its behavior to maximize its profits. In thispaper, we propose a context aware trust model to predict dynamic trust by using a Hidden Markov Model (HMM) to model an agent's interactions. Although HMMs have already been applied in the past to model an agent's dynamic behavior to greatly improve the traditional static probabilistic trust approaches, most HMM based trust models only focus on outcomes of the past interactions without considering interaction context, which we believe, reflects immensely on the dynamic behavior or intent of an agent. Interaction contextual information is comprehensively studied and integrated into the model to more precisely approximate an agent's dynamic behavior. Evaluation using real auction data and synthetic data demonstrates the efficacy of our approach in comparison with previous state-of-the-art trust mechanisms.", "total_citations": {"2013": 7, "2014": 3, "2015": 8, "2016": 9, "2017": 2, "2018": 2, "2019": 8, "2020": 8, "2021": 8, "2022": 6, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:WF5omc3nYNoC": {"external_link": "https://www.inderscienceonline.com/doi/abs/10.1504/IJBPIM.2005.006962", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2005/1/1", "journal": "International Journal of Business Process Integration and Management", "volume": "1", "issue": "1", "pages": "26-33", "publisher": "Inderscience Publishers", "description": "The success story of eBay has shown the demand for customer-to-customer (C2C) electronic commerce. eBay is a centralised infrastructure with all its scalability problems (network bandwidth, server load, availability, etc.). In this paper, we argue that C2C e-commerce is an application domain that maps naturally onto the emerging field of peer-to-peer (P2P) systems simply by its underlying interaction model of customers, i.e., peers. This offers the opportunity to take P2P systems beyond mere file sharing systems into interesting new application domains. The long-term goal would be to design a fully functional decentralised system which resembles eBay without eBay's dedicated, centralised infrastructure. Since security (authenticity, non-repudiation, trust, etc.) is key to any e-commerce infrastructure, our envisioned P2P e-commerce platform has to address these security issues adequately. As the first step in this\u00a0\u2026", "total_citations": {"2004": 3, "2005": 3, "2006": 9, "2007": 10, "2008": 2, "2009": 3, "2010": 6, "2011": 7, "2012": 2, "2013": 2, "2014": 0, "2015": 3, "2016": 2, "2017": 0, "2018": 0, "2019": 2, "2020": 3, "2021": 1, "2022": 3, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:u_35RYKgDlwC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6038754/", "authors": ["Rajesh Sharma", "Anwitaman Datta", "Matteo Dell'Amico", "Pietro Michiardi"], "publication_date": "2011/8/31", "conference": "2011 IEEE International Conference on Peer-to-Peer Computing", "pages": "348-351", "publisher": "IEEE", "description": "Friend-to-friend networks, i.e. peer-to-peer networks where data are exchanged and stored solely through nodes owned by trusted users, can guarantee dependability, privacy and uncensorability by exploiting social trust. However, the limitation of storing data only on friends can come to the detriment of data availability: if no friends are online, then data stored in the system will not be accessible. In this work, we explore the tradeoffs between redundancy (i.e., how many copies of data are stored on friends), data placement (the choice of which friend nodes to store data on) and data availability (the probability of finding data online). We show that the problem of obtaining maximal availability while minimizing redundancy is NP-complete; in addition, we perform an exploratory study on data placement strategies, and we investigate their performance in terms of redundancy needed and availability obtained. By\u00a0\u2026", "total_citations": {"2012": 9, "2013": 5, "2014": 14, "2015": 6, "2016": 10, "2017": 5, "2018": 5, "2019": 1, "2020": 3, "2021": 1, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:kNdYIx-mwKoC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5380695/", "authors": ["Le-Hung Vu", "Karl Aberer", "Sonja Buchegger", "Anwitaman Datta"], "publication_date": "2009/12/7", "conference": "2009 annual computer security applications conference", "pages": "419-428", "publisher": "IEEE", "description": "We study a new application of threshold-based secret sharing in a distributed online social network (DOSN), where users need a means to back up and recover their private keys in a network of untrusted servers. Using a simple threshold-based secret sharing in such an environment is insufficiently secured since delegates keeping the secret shares may collude to steal the user's private keys. To mitigate this problem, we propose using different techniques to improve the system security: by selecting only the most reliable delegates for keeping these shares and further by encrypting the shares with passwords. We develop a mechanism to select the most reliable delegates based on an effective trust measure. Specifically, relationships among the secret owner, delegate candidates and their related friends are used to estimate the trustworthiness of a delegate. This trust measure minimizes the likelihood of the secret\u00a0\u2026", "total_citations": {"2010": 4, "2011": 7, "2012": 5, "2013": 9, "2014": 7, "2015": 5, "2016": 6, "2017": 2, "2018": 9, "2019": 1, "2020": 1, "2021": 0, "2022": 1, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:kRWSkSYxWN8C": {"external_link": "https://www.nowpublishers.com/article/Details/CIT-068", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2013/6/5", "journal": "Foundations and Trends\u00ae in Communications and Information Theory", "volume": "9", "issue": "4", "pages": "383-466", "publisher": "Now Publishers, Inc.", "description": "This survey comprises a tutorial on traditional erasure codes and their applications to networked distributed storage systems (NDSS), followed by a survey of novel code families tailor made for better repairability in NDSS.", "total_citations": {"2013": 5, "2014": 11, "2015": 11, "2016": 12, "2017": 5, "2018": 3, "2019": 1, "2020": 1, "2021": 4, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:6ZxmRoH8BuwC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3201064.3201105", "authors": ["Indira Sen", "Anupama Aggarwal", "Shiven Mian", "Siddharth Singh", "Ponnurangam Kumaraguru", "Anwitaman Datta"], "publication_date": "2018/5/15", "book": "Proceedings of the 10th ACM conference on web science", "pages": "205-209", "description": "Instagram is a significant platform for users to share media; reflecting their interests. It is used by marketers and brands to reach their potential audience for advertisement. The number of likes on posts serves as a proxy for social reputation of the users, and in some cases, social media influencers with an extensive reach are compensated by marketers to promote products. This emerging market has led to users artificially bolstering the likes they get to project an inflated social worth. In this study, we enumerate the potential factors which contribute towards a genuine like on Instagram. Based on our analysis of liking behaviour, we build an automated mechanism to detect fake likes on Instagram which achieves a high precision of 83.5%. Our work serves an important first step in reducing the effect of fake likes on Instagram influencer market.", "total_citations": {"2018": 4, "2019": 13, "2020": 7, "2021": 11, "2022": 13, "2023": 8}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:Y0pCki6q_DkC": {"external_link": "https://www.degruyter.com/document/doi/10.1515/PIKO.2003.86/html", "authors": ["Karl Aberer", "Ph Cudr\u00e9-Mauroux", "Anwitaman Datta", "Zoran Despotovic", "Manfred Hauswirth", "Magdalena Punceva", "Roman Schmidt", "Jie Wu"], "publication_date": "2003/6", "volume": "26", "issue": "2", "pages": "86-89", "publisher": "Walter de Gruyter GmbH & Co. KG", "description": "The limitations of client/server systems become evident in an Internet-scale distributed environment. Peer-to-peer (P2P) systems offer an interesting alternative to traditional client/server systems: Every node acts both as a client and a server and \u201epays\u201c its participation by providing access to its computing resources. Systems such as Napster and Gnutella have proven their practical applicability. In this article we give an overview of our P-Grid system which provides an advanced P2P infrastructure targeted at application domains beyond mere file-sharing. We present the conceptual foundations and outline some of the applications we are developing at the moment.", "total_citations": {"2003": 4, "2004": 4, "2005": 6, "2006": 7, "2007": 4, "2008": 3, "2009": 4, "2010": 9, "2011": 7, "2012": 4, "2013": 0, "2014": 2, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:L8Ckcad2t8MC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6089443/", "authors": ["Frederique Oggier", "Anwitaman Datta"], "publication_date": "2011/10/16", "conference": "2011 IEEE Information Theory Workshop", "pages": "30-34", "publisher": "IEEE", "description": "Self-Repairing Codes (SRC) are codes designed to suit the need of coding for distributed networked storage: they not only allow stored data to be recovered even in the presence of node failures, they also provide a repair mechanism where as little as two live nodes can be contacted to regenerate the data of a failed node. In this paper, we propose a new instance of self-repairing codes, based on constructions of spreads coming from projective geometry. We study some of their properties to demonstrate the suitability of these codes for distributed networked storage.", "total_citations": {"2010": 2, "2011": 6, "2012": 4, "2013": 16, "2014": 7, "2015": 8, "2016": 6, "2017": 0, "2018": 0, "2019": 1, "2020": 1, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:YsMSGLbcyi4C": {"external_link": "https://link.springer.com/chapter/10.1007/11428589_24", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2004/6/2", "book": "Self-star Workshop", "pages": "373-391", "publisher": "Springer Berlin Heidelberg", "description": "This paper presents and evaluates uncoordinated on-line algorithms for simultaneous storage and replication load-balancing in DHT-based peer-to-peer systems. We compare our approach with the classical balls into bins model, and point out both the similarities as well as the differences which call for new load-balancing mechanisms specifically targeted at P2P systems. Some of the peculiarities of P2P systems, which make our problem challenging are that both the network membership and the data indexed in the network are dynamic, there is neither global coordination nor global information to rely on, and the load-balancing mechanism ideally should not compromise the structural properties and thus the search efficiency of the DHT, while preserving the semantic information of the data (e.g.,lexicographic ordering to enable range searches).", "total_citations": {"2004": 3, "2005": 6, "2006": 10, "2007": 3, "2008": 7, "2009": 4, "2010": 2, "2011": 6, "2012": 6, "2013": 3, "2014": 0, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:AvfA0Oy_GE0C": {"external_link": "https://books.google.com/books?hl=en&lr=&id=bxQeBQAAQBAJ&oi=fnd&pg=PP1&dq=info:7KKKKnEhSLcJ:scholar.google.com&ots=vdwiy5X-pz&sig=OegsxMcYaSN2vVOlo2ygGHcBT6E", "authors": ["Xin Liu", "Anwitaman Datta", "Ee-Peng Lim"], "publication_date": "2014/10/29", "publisher": "CRC Press", "description": "Computational Trust Models and Machine Learning provides a detailed introduction to the concept of trust and its application in various computer science areas, including multi-agent systems, online social networks, and communication systems. Identifying trust modeling challenges that cannot be addressed by traditional approaches, this book: Explains how reputation-based systems are used to determine trust in diverse online communities Describes how machine learning techniques are employed to build robust reputation systems Explores two distinctive approaches to determining credibility of resources\u2014one where the human role is implicit, and one that leverages human input explicitly Shows how decision support can be facilitated by computational trust models Discusses collaborative filtering-based trust aware recommendation systems Defines a framework for translating a trust modeling problem into a learning problem Investigates the objectivity of human feedback, emphasizing the need to filter out outlying opinions Computational Trust Models and Machine Learning effectively demonstrates how novel machine learning techniques can improve the accuracy of trust assessment.", "total_citations": {"2015": 2, "2016": 6, "2017": 6, "2018": 10, "2019": 6, "2020": 3, "2021": 5, "2022": 8, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:QIV2ME_5wuYC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-17679-1_20", "authors": ["Anwitaman Datta", "Rajesh Sharma"], "publication_date": "2011", "conference": "Distributed Computing and Networking: 12th International Conference, ICDCN 2011, Bangalore, India, January 2-5, 2011. Proceedings 12", "pages": "227-238", "publisher": "Springer Berlin Heidelberg", "description": "We propose and investigate a gossip based, social principles and behavior inspired decentralized mechanism (GoDisco) to disseminate information in online social community networks, using exclusively social links and exploiting semantic context to keep the dissemination process selective to relevant nodes. Such a designed dissemination scheme using gossiping over a egocentric social network is unique and is arguably a concept whose time has arrived, emulating word of mouth behavior and can have interesting applications like probabilistic publish/subscribe, decentralized recommendation and contextual advertisement systems, to name a few. Simulation based experiments show that despite using only local knowledge and contacts, the system has good global coverage and behavior.", "total_citations": {"2010": 3, "2011": 3, "2012": 8, "2013": 14, "2014": 4, "2015": 7, "2016": 2, "2017": 1, "2018": 3, "2019": 0, "2020": 0, "2021": 1, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:RHpTSmoSYBkC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6038668/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2011/8/31", "conference": "2011 IEEE International Conference on Peer-to-Peer Computing", "pages": "112-121", "publisher": "IEEE", "description": "Recent years have witnessed a slew of coding techniques custom designed for networked storage systems. Network coding inspired regenerating codes are the most prolifically studied among these new age storage centric codes. A lot of effort has been invested in understanding the fundamental achievable trade-offs of storage and bandwidth usage to maintain redundancy in presence of different models of failures, showcasing the efficacy of regenerating codes with respect to traditional erasure coding techniques. For practical usability in open and adversarial environments, as is typical in peer-to-peer systems, we need however not only resilience against erasures, but also from (adversarial) errors. In this paper, we study the resilience of generalized regenerating codes (supporting multi-repairs, using collaboration among newcomers) in the presence of two classes of Byzantine nodes, relatively benign selfish\u00a0\u2026", "total_citations": {"2012": 3, "2013": 7, "2014": 6, "2015": 10, "2016": 3, "2017": 4, "2018": 5, "2019": 1, "2020": 2, "2021": 1, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:Se3iqnhoufwC": {"external_link": "https://link.springer.com/chapter/10.1007/11822035_3", "authors": ["Anwitaman Datta", "Karl Aberer"], "publication_date": "2006/9/18", "book": "International Workshop of the EuroNGI Network of Excellence", "pages": "7-22", "publisher": "Springer Berlin Heidelberg", "description": "Structured overlay networks is an important and interesting primitive that can be used by diverse peer-to-peer applications. Multiple overlays can result either because of network partitioning or (more likely) because different groups of peers build such overlays separately before coming in contact with each other and wishing to coalesce the overlays together. This paper is a first look into how multiple such overlays (all using the same protocols) can be merged \u2013 which is critical for usability and adoption of such an internet-scale distributed system. We elaborate how two networks using the same protocols can be merged, looking specifically into two different overlay design principles: (i) maintaining the ring invariant and (ii) structural replications, either of which are used in various overlay networks to guarantee functional correctness in a highly dynamic (membership changes) environment\u00a0\u2026", "total_citations": {"2006": 1, "2007": 6, "2008": 1, "2009": 5, "2010": 5, "2011": 3, "2012": 4, "2013": 6, "2014": 4, "2015": 3, "2016": 1, "2017": 3, "2018": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:O3NaXMp0MMsC": {"external_link": "https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12022", "authors": ["Xin Liu", "Gilles Tredan", "Anwitaman Datta"], "publication_date": "2014/11", "journal": "Computational Intelligence", "volume": "30", "issue": "4", "pages": "700-721", "description": "In many large\u2010scale distributed systems and on the Web, agents need to interact with other unknown agents to carry out some tasks or transactions. The ability to reason about and assess the potential risks in carrying out such transactions is essential for providing a safe and reliable interaction environment. A traditional approach to reason about the risk of a transaction is to determine if the involved agent is trustworthy on the basis of its behavior history. As a departure from such traditional trust models, we propose a generic, trust framework based on machine learning where an agent uses its own previous transactions (with other agents) to build a personal knowledge base. This is used to assess the trustworthiness of a transaction on the basis of the associated features, particularly using the features that help discern successful transactions from unsuccessful ones. These features are handled by applying\u00a0\u2026", "total_citations": {"2013": 4, "2014": 5, "2015": 2, "2016": 2, "2017": 2, "2018": 6, "2019": 5, "2020": 8, "2021": 3, "2022": 4, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:hqOjcs7Dif8C": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=1f9ac8478d6fc4e78c7273d1482ef04e1b2ff313", "authors": ["Anwitaman Datta"], "publication_date": "2003/6", "journal": "Proc. of the CAiSE 2003 Doctoral Symposium", "description": "Both peer-to-peer overlays (P2P) and mobile ad-hoc networks (MANET) have recently attracted a lot of attention in the research community as well as the industry. Both the domains share certain similarities, primarily the fact that both are instances of self-organizing decentralized systems. However the two domains, apart from sharing many similarities have several differences particularly from the routing/searching perspective [35]. Consequently, it is imperative that any P2P overlay network that is built for MANET should account for, apart from the traditional challenges of P2P like decentralization, self-organization and unreliable peer availability leading to topology dynamics, the peculiarities of the underlying mobile ad-hoc network, particularly resource constrains like memory of portable devices, bandwidth, power, low computation capability, unpredictable (dis) connectivity and dynamics of topology because of peer mobility pattern [8]. We discuss some of the important issues concerning structured P2P systems in general, followed by a discussion on the interplay between these two (P2P and MANET) self-organizing networks from a data management perspective, aiming to achieve efficient and robust information search and access schemes, and a novel information dissemination paradigm, suitable for peer-to-peer applications in a mobile ad-hoc environment.", "total_citations": {"2004": 6, "2005": 8, "2006": 1, "2007": 2, "2008": 4, "2009": 4, "2010": 2, "2011": 3, "2012": 4, "2013": 4, "2014": 1, "2015": 1, "2016": 1, "2017": 0, "2018": 0, "2019": 0, "2020": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:dBIO0h50nwkC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8637544/", "authors": ["Silivanxay Phetsouvanh", "Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2018/11/17", "conference": "2018 IEEE International conference on data mining workshops (ICDMW)", "pages": "244-251", "publisher": "IEEE", "description": "The Bitcoin network is a complex network that records anonymous financial transactions while encapsulating the relationships among its pseudonymous users. This paper proposes graph mining techniques to explore the relationships among wallet addresses (pseudonyms for Bitcoin users) suspected to be involved in a given extortion racket, exploiting the anonymity of the Bitcoin network to collect and launder money. Starting around Bitcoin addresses of potential interest, neighborhood subgraphs are analyzed in terms of path length and confluence to detect suspicious Bitcoin flow and other wallet addresses controlled by the suspected perpetrators. We show with a dataset of the Ashley Madison blackmail campaign from August 2015 how the mechanisms can be used both to estimate the amount of money that was extorted by the suspected perpetrators under the specific blackmail campaign, and also estimate\u00a0\u2026", "total_citations": {"2018": 1, "2019": 5, "2020": 6, "2021": 11, "2022": 9, "2023": 10}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:ufrVoPGSRksC": {"external_link": "https://link.springer.com/chapter/10.1007/11530657_10", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2005", "journal": "Peer-to-peer systems and applications", "pages": "137-153", "publisher": "Springer Berlin Heidelberg", "description": "Peer-to-peer systems are often characterized as self-organizing systems. Such characterization is frequently used to informally express properties of Peer-to-Peer systems such as the distribution of control, locality of processing, and the emergence of global structures from local interactions. Self-organizing systems are considered as being particularly scalable and failure resilient.", "total_citations": {"2005": 1, "2006": 3, "2007": 4, "2008": 4, "2009": 1, "2010": 7, "2011": 4, "2012": 3, "2013": 2, "2014": 3, "2015": 1, "2016": 2, "2017": 2, "2018": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:W7OEmFMy1HYC": {"external_link": "https://infoscience.epfl.ch/record/52538", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2003", "issue": "REP_WORK", "description": "Structured peer-to-peer (P2P) systems are considered as the next generation application backbone on the Internet. An important problem of these systems is load balancing in the presence of non-uniform data distributions. In this paper we propose a completely decentralized mechanism that in parallel addresses a local and a global load balancing problem:(1) balancing the storage load uniformly among peers participating in the network and (2) uniformly replicating different data items in the network while optimally exploiting existing storage capacity. Our approach is based on the P-Grid P2P system which is our variant of a structured P2P network. Problem (1) is solved by directly adapting the search structure to the data distribution. This may result in an unbalanced search structure, but we will show that the expected search cost in P-Grid in number of messages remains logarithmic under all circumstances. Problem (2) is solved by a dynamic, reactive balancing method based on sampling the P-Grid structure. Through simulations we show that our solution provides a scalable approach to these load balancing problems. Finally we discuss issues that had to be addressed beyond the theoretical aspects when implementing our approach as part of a practical P2P system.", "total_citations": {"2003": 2, "2004": 13, "2005": 3, "2006": 7, "2007": 5, "2008": 2, "2009": 0, "2010": 0, "2011": 1, "2012": 4, "2013": 0, "2014": 0, "2015": 0, "2016": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:5Ul4iDaHHb8C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6566922/", "authors": ["Lluis Pamies-Juarez", "Anwitaman Datta", "Frederique Oggier"], "publication_date": "2013/4/14", "conference": "2013 Proceedings IEEE INFOCOM", "pages": "1294-1302", "publisher": "IEEE", "description": "To achieve reliability in distributed storage systems, data has usually been replicated across different nodes. However the increasing volume of data to be stored has motivated the introduction of erasure codes, a storage efficient alternative to replication, particularly suited for archival in data centers, where old datasets (rarely accessed) can be erasure encoded, while replicas are maintained only for the latest data. Many recent works consider the design of new storage-centric erasure codes for improved repairability. In contrast, this paper addresses the migration from replication to encoding: traditionally erasure coding is an atomic operation in that a single node with the whole object encodes and uploads all the encoded pieces. Although large datasets can be concurrently archived by distributing individual object encodings among different nodes, the network and computing capacity of individual nodes constrain\u00a0\u2026", "total_citations": {"2012": 1, "2013": 6, "2014": 2, "2015": 0, "2016": 5, "2017": 10, "2018": 5, "2019": 4, "2020": 2, "2021": 1, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:M3NEmzRMIkIC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-20161-5_65", "authors": ["Chenliang Li", "Aixin Sun", "Anwitaman Datta"], "publication_date": "2011", "conference": "Advances in Information Retrieval: 33rd European Conference on IR Research, ECIR 2011, Dublin, Ireland, April 18-21, 2011. Proceedings 33", "pages": "653-664", "publisher": "Springer Berlin Heidelberg", "description": "In this paper we propose a general framework for word sense disambiguation using knowledge latent in Wikipedia. Specifically, we exploit the rich and growing Wikipedia corpus in order to achieve a large and robust knowledge repository consisting of keyphrases and their associated candidate topics. Keyphrases are mainly derived from Wikipedia article titles and anchor texts associated with wikilinks. The disambiguation of a given keyphrase is based on both the commonness of a candidate topic and the context-dependent relatedness where unnecessary (and potentially noisy) context information is pruned. With extensive experimental evaluations using different relatedness measures, we show that the proposed technique achieved comparable disambiguation accuracies with respect to state-of-the-art techniques, while incurring orders of magnitude less computation cost.", "total_citations": {"2011": 1, "2012": 7, "2013": 5, "2014": 6, "2015": 6, "2016": 2, "2017": 1, "2018": 3, "2019": 1, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:KlAtU1dfN6UC": {"external_link": "https://infoscience.epfl.ch/record/54391/files/TR-IC-2003-67.pdf", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2004", "source": "The 6th Workshop on Distributed Data and Structures (WDAS 2004)", "issue": "CONF", "description": "Efficient route maintenance in DHTs is still an area of very active research due to its complexity and multitude of aspects to be considered. In this paper we propose novel correctionon-failure (CoF) and correction-on-use (CoU) approaches that support route maintenance more efficiently than existing methods even under highly dynamical network conditions. In contrast to previous work which addresses static resilience, we apply the more realistic model of viewing changes in the network as a continuous Markovian process and demonstrate that the system can reach a dynamic equilibrium in the presence of continuous changes while remaining operational, efficient, and scalable. We devise a generally applicable method for analyzing the dynamic behavior of route maintenance and use it to proof the efficiency of our approach. The equilibrium equations derived from the analytical model allow us to predict a system\u2019s behavior over a wide range of parameters and demonstrate its scalability. Simulation results additionally verify our analytical results. Our approach also introduces the principle of data independence into route maintenance which we demonstrate to be achievable at low cost. This separation of concern disentangles the overlay from the underlying network dynamics and is an important step towards semantic overlay networks as a basic constituent in distributed information management. It specifically facilitates the application of the P2P paradigm in mobile ad-hoc networks, identity management, tracking of past interactions (eg, for reputation management), etc. which are of basic importance for overlay supported P2P commerce\u00a0\u2026", "total_citations": {"2004": 1, "2005": 3, "2006": 2, "2007": 3, "2008": 1, "2009": 1, "2010": 2, "2011": 1, "2012": 1, "2013": 0, "2014": 1, "2015": 10, "2016": 6, "2017": 1, "2018": 0, "2019": 2, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:rO6llkc54NcC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6008893/", "authors": ["Xin Liu", "Anwitaman Datta"], "publication_date": "2011/5/16", "conference": "2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum", "pages": "1052-1061", "publisher": "IEEE", "description": "Recently emerged cloud computing offers a promising platform for executing scientific workflow applications due to its similar performance compared to the grid, lower cost, elasticity and so on. Collaborative cloud environments, which share resources of multiple geographically distributed data centers owned by different organizations enable researchers from all over the world to conduct their large scale data intensive research together through Internet. However, since scientific workflows consume and generate huge amount of data, it is thus essential to manage the data effectively for the purpose of high performance and cost effectiveness. In this paper, we propose intelligent data placement strategy to improve performance of workflows while minimizing data transfer among data centers. Specifically, at the startup stage, the whole dataset is divided into small data items which are then distributed among multiple\u00a0\u2026", "total_citations": {"2012": 4, "2013": 2, "2014": 3, "2015": 6, "2016": 2, "2017": 2, "2018": 3, "2019": 4, "2020": 4, "2021": 1, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:_Qo2XoVZTnwC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1963192.1963289", "authors": ["Anwitaman Datta", "Jackson Tan Teck Yong", "Anthony Ventresque"], "publication_date": "2011/3/28", "book": "Proceedings of the 20th international conference companion on World wide web", "pages": "201-204", "description": "Searching for people by exploration of social networks structure is an interesting problem which has recently gathered a lot of attention. Expert recommendation is an important but also extensively researched problem. In contrast, the generalized problem of team recommendation has not been studied a lot. The purpose of this demo is to show a multidisciplinary team search and recommendation prototype. While the current demo uses specific (NTU academic) data-set, the framework is generic, and can be extended for other domains subject to availability of suitable information.", "total_citations": {"2011": 2, "2012": 2, "2013": 3, "2014": 8, "2015": 7, "2016": 0, "2017": 0, "2018": 4, "2019": 3, "2020": 1, "2021": 0, "2022": 1, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:dQ2og3OwTAUC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6691581/", "authors": ["Kyumars Sheykh Esmaili", "Lluis Pamies-Juarez", "Anwitaman Datta"], "publication_date": "2013/10/6", "conference": "2013 IEEE International Conference on Big Data", "pages": "246-254", "publisher": "IEEE", "description": "Erasure codes are an integral part of many distributed storage systems aimed at Big Data, since they provide high fault-tolerance for low overheads. However, traditional erasure codes are inefficient on replenishing lost data (vital for long term resilience) and on reading stored data in degraded environments (when nodes might be unavailable). Consequently, novel codes optimized to cope with distributed storage system nuances are vigorously being researched. In this paper, we take an engineering alternative, exploring the use of simple and mature techniques - juxtaposing a standard erasure code with RAID-4 like parity to realize cross object redundancy (CORE), and integrate it with HDFS. We benchmark the implementation in a proprietary cluster and in EC2. Our experiments show that for an extra 20% storage overhead (compared to traditional erasure codes) CORE yields up to 58% saving in bandwidth and\u00a0\u2026", "total_citations": {"2012": 1, "2013": 1, "2014": 6, "2015": 5, "2016": 6, "2017": 2, "2018": 4, "2019": 0, "2020": 3, "2021": 2, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:XiVPGOgt02cC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-35668-1_4", "authors": ["Lluis Pamies-Juarez", "Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2013", "conference": "Distributed Computing and Networking: 14th International Conference, ICDCN 2013, Mumbai, India, January 3-6, 2013. Proceedings 14", "pages": "42-56", "publisher": "Springer Berlin Heidelberg", "description": "Distributed storage systems usually achieve fault tolerance by replicating data across different nodes. However, redundancy schemes based on erasure codes can provide a storage-efficient alternative to replication. This is particularly suited for data archival since archived data is rarely accessed. Typically, the migration to erasure-encoded storage does not leverage on the existing replication based redundancy, and simply discards (garbage collects) the excessive replicas. In this paper we propose a new decentralized erasure coding process that achieves the migration in a network-efficient manner in contrast to the traditional coding processes. The proposed approach exploits the presence of data that is already replicated across the system and distributes the redundancy generation among those nodes that store part of this replicated data, which in turn reduces the overall amount of data transferred\u00a0\u2026", "total_citations": {"2013": 4, "2014": 4, "2015": 4, "2016": 4, "2017": 7, "2018": 6, "2019": 2, "2020": 1, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:0EnyYjriUFMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4215411/", "authors": ["Anwitaman Datta", "Roman Schmidt", "Karl Aberer"], "publication_date": "2007/5/14", "conference": "Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGrid'07)", "pages": "453-460", "publisher": "IEEE", "description": "Query-load (forwarding and answering) balancing in structured overlays is one of the most critical and least studied problems. It has been assumed that caching heuristics can take care of it. We expose that caching, while necessary, is not in itself sufficient. We then provide simple and effective load-aware variants of the standard greedy routing used in overlays, exploiting routing redundancy originally needed for fault-tolerance, to achieve very good query load-balancing.", "total_citations": {"2007": 1, "2008": 5, "2009": 7, "2010": 3, "2011": 5, "2012": 4, "2013": 3, "2014": 3, "2015": 0, "2016": 0, "2017": 0, "2018": 1, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:J_g5lzvAfSwC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2447712.2447735", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2013/3/6", "source": "Acm Sigact News", "volume": "44", "issue": "1", "pages": "89-105", "publisher": "ACM", "description": "The increasing amount of digital data generated by today's society asks for better storage solutions. This survey looks at a new generation of coding techniques designed specifically for the maintenance needs of networked distributed storage systems (NDSS), trying to reach the best compromise among storage space efficiency, fault-tolerance, and maintenance overheads. Four families of codes, namely, pyramid, hierarchical, regenerating and locally repairable codes such as self-repairing codes, along with a heuristic of cross-object coding to improve repairability in NDSS are presented at a high level. The code descriptions are accompanied with simple nexamples emphasizing the main ideas behind each of these code families. We discuss their pros and cons before concluding with a brief and preliminary comparison. This survey deliberately excludes technical details and does not contain an exhaustive list of\u00a0\u2026", "total_citations": {"2013": 4, "2014": 1, "2015": 5, "2016": 2, "2017": 4, "2018": 5, "2019": 2, "2020": 3, "2021": 2, "2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:R3hNpaxXUhUC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5590910/", "authors": ["Piotr Turek", "Adam Wierzbicki", "Radosaw Nielek", "Albert Hupa", "Anwitaman Datta"], "publication_date": "2010/8/20", "conference": "2010 IEEE Second International Conference on Social Computing", "pages": "17-24", "publisher": "IEEE", "description": "This paper describes an approach to evaluating teams of contributors in Wikipedia based on social network analysis. We present the idea of creating an implicit social network based on characteristics of pages' edit history and collaboration between contributors. This network consists of four dimensions: trust, distrust, acquaintance and knowledge. Trust and distrust are based on content modifications (copying and deleting respectively), acquaintance is based on the amount of discussion on articles' talk pages between a given pair of authors and knowledge is based on the categories in which an author typically contributes. Our social network is based on the entire Wikipedia edit history, and therefore is a summary of all recorded author interactions. This social network can be used to assess the quality of a team of authors and consequently, to recommend good teams. The social network can also be used by\u00a0\u2026", "total_citations": {"2010": 1, "2011": 2, "2012": 3, "2013": 1, "2014": 3, "2015": 4, "2016": 4, "2017": 1, "2018": 4, "2019": 1, "2020": 0, "2021": 3, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:8k81kl-MbHgC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0140366407002873", "authors": ["Di Wu", "Ye Tian", "Kam-Wing Ng", "Anwitaman Datta"], "publication_date": "2008/2/5", "journal": "Computer communications", "volume": "31", "issue": "2", "pages": "220-239", "publisher": "Elsevier", "description": "Due to the prevalence of peer dynamics (i.e., churn), object maintenance becomes a fundamental issue in peer-to-peer storage systems. Although quite a few prototypes have been designed and implemented, they lack theoretical analysis to shed light on how the system evolves under churn and how to configure the system properly. The performance of peer-to-peer storage systems under churn (e.g., storage capacity, bandwidth usage, bandwidth spike, etc.) also become unclear. In this paper, we develop a simple model based on stochastic differential equations, with which we can analytically study the time-evolution of peer-to-peer storage systems under churn, and the interplay between object maintenance and churn. Different from previous Markovian analysis, we provide closed-form terms to capture the time-evolution of the storage system, and formally derive its related performance metrics under different\u00a0\u2026", "total_citations": {"2009": 6, "2010": 6, "2011": 5, "2012": 3, "2013": 3, "2014": 0, "2015": 1, "2016": 2, "2017": 0, "2018": 0, "2019": 3, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:eQOLeE2rZwMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1232142/", "authors": ["Manfred Hauswirth", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2003/9/1", "conference": "14th International Workshop on Database and Expert Systems Applications, 2003. Proceedings.", "pages": "942-946", "publisher": "IEEE", "description": "Due to the limited number of available IP addresses most computers on the Internet use dynamic IP addresses which cause problems for applications that have to maintain routing tables, for example, peer-to-peer systems. To overcome this we propose unique peer identifiers in the routing tables and apply the peer-to-peer system itself to maintain consistent ID-to-IP mappings to be used in the routing process. While this may sound like a recursive hen-egg problem we show that it is in fact possible to devise such a mapping service for realistic scenarios. Our approach is completely decentralized, self-maintaining, and light-weight. It takes into account security to provide sufficient security guarantees for the mappings. We also assume that the service operates in an environment with low online probability of the peers constituting the service.", "total_citations": {"2002": 1, "2003": 9, "2004": 3, "2005": 5, "2006": 1, "2007": 3, "2008": 0, "2009": 2, "2010": 1, "2011": 0, "2012": 3, "2013": 0, "2014": 0, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:UebtZRa9Y70C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4268170/", "authors": ["Anwitaman Datta", "Ion Stoica", "Mike Franklin"], "publication_date": "2007/6/25", "conference": "27th International Conference on Distributed Computing Systems (ICDCS'07)", "pages": "13-13", "publisher": "IEEE", "description": "We propose a new genre of overlay network for disseminating information from popular but resource constrained sources. We call this communication primitive as latency gradated overlay, where information consumers self- organize themselves according to their individual resource constraints and the latency they are willing to tolerate in receiving the information from the source. Such a communication primitive finds immediate use in applications like RSS feeds aggregation. We propose heuristic algorithms to construct LagOver based on preferably some partial knowledge of the network at users (no knowledge slows the construction process) but no global coordination. The algorithms are evaluated based on simulations and show good characteristics including convergence, satisfying peers' latency and bandwidth constraints even in presence of moderately high membership dynamics. There are two points worth\u00a0\u2026", "total_citations": {"2007": 2, "2008": 3, "2009": 4, "2010": 7, "2011": 5, "2012": 4, "2013": 1, "2014": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:_FxGoFyzp5QC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1647799/", "authors": ["Sarunas Girdzijauskas", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2005/4/3", "conference": "21st International Conference on Data Engineering Workshops (ICDEW'05)", "pages": "1187-1187", "publisher": "IEEE", "description": "In this paper we show that the topologies of most logarithmic-style P2P systems like Pastry, Tapestry or P-Grid resemble small-world graphs. Inspired by Kleinberg\u2019s small-world model [7] we extend the model of building \"routing-efficient\" small-world graphs and propose two new models. We show that the graph, constructed according to our model for uniform key distribution and logarithmic outdegree, will have similar properties as the topologies of structured P2P systems with logarithmic outdegree. Moreover, we propose a novel model of building graphs which support uneven node distributions and preserves all desired properties of Kleinberg\u2019s small-world model. With such a model we are setting a reference base for nowadays emerging P2P systems that need to support uneven key distributions.", "total_citations": {"2005": 4, "2006": 5, "2007": 4, "2008": 4, "2009": 3, "2010": 2, "2011": 4, "2012": 1, "2013": 0, "2014": 0, "2015": 1, "2016": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:_Ybze24A_UAC": {"external_link": "https://link.springer.com/article/10.1007/S10207-016-0329-X", "authors": ["Lichun Li", "Anwitaman Datta"], "publication_date": "2017/2", "journal": "International Journal of Information Security", "volume": "16", "pages": "23-42", "publisher": "Springer Berlin Heidelberg", "description": "Data outsourcing is plagued with several security and privacy concerns. Oblivious RAM (ORAM) can be used to address one of the many concerns, specifically to protect the privacy of data access pattern from outsourced cloud storage. This is achieved by simulating each original read or write operation with some read and write operations on both real and dummy data items. This paper proposes two single-server write-only ORAM schemes and one multi-server scheme, which simulate only the write operations and protect only the write pattern. The reduction in functionality however allows to build much simpler and efficient (in terms of communication/storage cost) ORAMs. Our schemes can achieve constant communication cost with acceptable storage usage. Write-only ORAM can be used in two situations: (i) only the write pattern is considered to contain sensitive information and needs protection. (ii) In\u00a0\u2026", "total_citations": {"2016": 3, "2017": 8, "2018": 4, "2019": 3, "2020": 2, "2021": 2, "2022": 4, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:SdhP9T11ey4C": {"external_link": "https://infoscience.epfl.ch/record/134967", "authors": ["Sonja Buchegger", "Doris Schioberg", "Le-Hung Vu", "Anwitaman Datta"], "publication_date": "2009", "source": "SNS'09: Proceedings of the Second ACM EuroSys Workshop on Social Network Systems", "issue": "CONF", "pages": "46\u201352", "description": "To address privacy concerns in Online Social Networks (OSNs), we propose to use a distributed, peer-to-peer approach coupled with encryption. To verify the feasibility of such an approach, we designed a two-tiered architecture and protocols that recreate the core features provided by OSNs in a decentralized way. This paper focuses on the description of the prototype built for the P2P infrastructure (as a first step without the encryption part) for social networks and shares early experiences from the prototype and insights gained since first outlining the challenges and possibilities of decentralized alternatives to OSNs.", "total_citations": {"2010": 1, "2011": 2, "2012": 1, "2013": 3, "2014": 1, "2015": 1, "2016": 1, "2017": 2, "2018": 3, "2019": 3, "2020": 6, "2021": 1, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:roLk4NBRz8UC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1334943/", "authors": ["Anwitaman Datta", "Sarunas Girdzijauskas", "Karl Aberer"], "publication_date": "2004/8/27", "conference": "Proceedings. Fourth International Conference on Peer-to-Peer Computing, 2004. Proceedings.", "pages": "159-166", "publisher": "IEEE", "description": "We show in this paper that de Bruijn networks, despite providing efficient search while using constant routing table size, as well as simplicity of the understanding and implementation of such networks, are unsuitable where key distribution will be uneven, a realistic scenario for most practical applications. In presence of arbitrarily skewed data distribution, it has only recently been shown that some traditional P2P overlay networks with non-constant (typically logarithmic) instead of constant routing table size can meet conflicting objectives of storage load balancing as well as search efficiency. So this paper, while showing that de Bruijn networks fail to meet these dual objectives, opens up a more general problem for the research community as to whether P2P systems with constant routing table can at all achieve the conflicting objectives of retaining search efficiency as well as storage load balancing, while preserving\u00a0\u2026", "total_citations": {"2004": 1, "2005": 2, "2006": 2, "2007": 7, "2008": 1, "2009": 1, "2010": 4, "2011": 3, "2012": 2, "2013": 4, "2014": 0, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:GnPB-g6toBAC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6009113/", "authors": ["Piotr Turek", "Adam Wierzbicki", "Rados\u0142aw Nielek", "Anwitaman Datta"], "publication_date": "2011/9/1", "journal": "IEEE Potentials", "volume": "30", "issue": "5", "pages": "15-20", "publisher": "IEEE", "description": "Web 2.0 technology and so-called social media are among the most popular (among users and researchers alike) Internet technologies today. Among them, Wiki technology\u2014created to simplify HTML editing and enable open, collaborative editing of pages by ordinary Web users\u2014occupies an important place. Wiki is increasingly adopted by businesses as a useful form of knowledge management and sharing, creating \u201ccorporate Wikis.\u201d However, the most widely known application of Wiki technology\u2014Wikipedia\u2014is, according to many analysts, more than just an open encyclopedia that uses Wiki.", "total_citations": {"2011": 1, "2012": 2, "2013": 2, "2014": 4, "2015": 1, "2016": 3, "2017": 3, "2018": 3, "2019": 1, "2020": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:maZDTaKrznsC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5767057/", "authors": ["Liu Xin", "Anwitaman Datta"], "publication_date": "2010/10/9", "conference": "6th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2010)", "pages": "1-8", "publisher": "IEEE", "description": "Cloud computing has emerged as a popular paradigm that offers computing resources (e.g. CPU, storage, bandwidth, software) as scalable and on-demand services over the Internet. As more players enter this emerging market, a heterogeneous cloud computing market is expected to evolve, where individual players will have different volumes of resources, and will provide specialized services, and with different levels of quality of services. It is expected that service providers will thus, besides competing, also collaborate to complement their resources in order to improve resource utilization and combine individual services to offer more complex value chains and end-to-end solutions required by the customers. It is challenging to select suitable partners in a decentralized setting due to various factors such as lack of global coordination or information, as well as diversity and scale. Trust is known to play an important\u00a0\u2026", "total_citations": {"2011": 2, "2012": 3, "2013": 1, "2014": 4, "2015": 4, "2016": 5, "2017": 1, "2018": 2, "2019": 1, "2020": 2, "2021": 0, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:tkaPQYYpVKoC": {"external_link": "https://arxiv.org/abs/1302.5192", "authors": ["Kyumars Sheykh Esmaili", "Lluis Pamies-Juarez", "Anwitaman Datta"], "publication_date": "2013/2/21", "journal": "arXiv preprint arXiv:1302.5192", "description": "Erasure codes are an integral part of many distributed storage systems aimed at Big Data, since they provide high fault-tolerance for low overheads. However, traditional erasure codes are inefficient on reading stored data in degraded environments (when nodes might be unavailable), and on replenishing lost data (vital for long term resilience). Consequently, novel codes optimized to cope with distributed storage system nuances are vigorously being researched. In this paper, we take an engineering alternative, exploring the use of simple and mature techniques -juxtaposing a standard erasure code with RAID-4 like parity. We carry out an analytical study to determine the efficacy of this approach over traditional as well as some novel codes. We build upon this study to design CORE, a general storage primitive that we integrate into HDFS. We benchmark this implementation in a proprietary cluster and in EC2. Our experiments show that compared to traditional erasure codes, CORE uses 50% less bandwidth and is up to 75% faster while recovering a single failed node, while the gains are respectively 15% and 60% for double node failures.", "total_citations": {"2012": 1, "2013": 6, "2014": 1, "2015": 3, "2016": 2, "2017": 6, "2018": 3, "2019": 3, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:EkHepimYqZsC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6051411/", "authors": ["Christian Von der Weth", "Anwitaman Datta"], "publication_date": "2011/10/18", "journal": "IEEE Internet Computing", "volume": "16", "issue": "1", "pages": "34-42", "publisher": "IEEE", "description": "Distributed NoSQL systems aim to provide high availability for large volumes of data but lack the inherent support of complex queries often required by overlying applications. Common solutions based on inverted lists for single terms perform poorly in large-scale distributed settings. The authors thus propose a multiterm indexing technique that can store the inverted lists of combinations of terms. A query-driven mechanism adaptively stores popular term combinations derived from the recent query history. Experiments show that this approach reduces the overall bandwidth consumption by half, significantly improving the NoSQL system's capacity and response time with only marginal overhead in terms of additional, but cheaper, required (storage) resources.", "total_citations": {"2012": 1, "2013": 4, "2014": 4, "2015": 5, "2016": 2, "2017": 4, "2018": 4, "2019": 1, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:MXK_kJrjxJIC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-540-71661-7_25", "authors": ["Sarunas Girdzijauskas", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2005/8/28", "book": "International Workshop on Databases, Information Systems, and Peer-to-Peer Computing", "pages": "247-258", "publisher": "Springer Berlin Heidelberg", "description": "The research on P2P systems which support skewed key distributions has rapidly advanced in the recent years. Yet, the assumptions on the skews we are dealing with remained pretty simple: most of the existing literature assumes simple monotonous key distribution skews. However, this is not always the case. For example, Gnutella filename traces show that complex key-distributions rather than monotonous skews occur in practice. We show that one of the seminal P2P systems which support skewed keys - Mercury\u00a0[7], performs poorly given such complex distributions generated from the trace of Gnutella filenames. We discuss the shortcomings of such state-of-the-art techniques. We present an overlay network Oscar, based on a novel overlay construction mechanism, which does not depend on the key-distribution complexity. We demonstrate through simulations that our technique performs well and\u00a0\u2026", "total_citations": {"2006": 2, "2007": 0, "2008": 2, "2009": 3, "2010": 4, "2011": 6, "2012": 2, "2013": 1, "2014": 2, "2015": 0, "2016": 1, "2017": 0, "2018": 0, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:DJbcl8HfkQkC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8885359/", "authors": ["Pedro Garcia Lopez", "Alberto Montresor", "Anwitaman Datta"], "publication_date": "2019/7/7", "conference": "2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)", "pages": "1901-1911", "publisher": "IEEE", "description": "The old mantra of decentralizing the Internet is coming again with fanfare, this time around the blockchain technology hype. We have already seen a technology supposed to change the nature of the Internet: peer-to-peer. The reality is that peer-to-peer naming systems failed, peer-to-peer social networks failed, and yes, peer-to-peer storage failed as well. In this paper, we will review the research on distributed systems in the last few years to identify the limits of open peer-to-peer networks. We will address issues like system complexity, security and frailty, instability and performance. We will show how many of the aforementioned problems also apply to the recent breed of permissionless blockchain networks. The applicability of such systems to mature industrial applications is undermined by the same properties that make them so interesting for a libertarian audience: namely, their openness, their pseudo-anonymity\u00a0\u2026", "total_citations": {"2019": 1, "2020": 5, "2021": 12, "2022": 2, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:QYdC8u9Cj1oC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8637400/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Silivanxay Phetsouvanh", "Anwitaman Datta"], "publication_date": "2018/11/17", "conference": "2018 IEEE international conference on Data Mining Workshops (ICDMW)", "pages": "1469-1474", "publisher": "IEEE", "description": "We showcase a graph mining tool, BiVA, for visualization and analysis of the Bitcoin network. It enables data exploration, visualization of subgraphs around nodes of interest, and integrates both standard and new algorithms, including a general algorithm for flow based clustering for directed graphs, and other Bitcoin network specific wallet address aggregation mechanisms. The BiVA user interface makes it easy to get started with a basic visualization that gives insights into nodes of interests, and the tool is modular, allowing easy integration of new algorithms. Its functionalities are demonstrated with a case study of extortion of Ashley Madison data breach victims.", "total_citations": {"2018": 1, "2019": 2, "2020": 1, "2021": 7, "2022": 5, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:5awf1xo2G04C": {"external_link": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.22829", "authors": ["Chenliang Li", "Aixin Sun", "Anwitaman Datta"], "publication_date": "2013/6", "journal": "Journal of the American Society for Information Science and Technology", "volume": "64", "issue": "6", "pages": "1203-1223", "description": "The semantic knowledge of Wikipedia has proved to be useful for many tasks, for example, named entity disambiguation. Among these applications, the task of identifying the word sense based on Wikipedia is a crucial component because the output of this component is often used in subsequent tasks. In this article, we present a two\u2010stage framework (called TSDW) for word sense disambiguation using knowledge latent in Wikipedia. The disambiguation of a given phrase is applied through a two\u2010stage disambiguation process: (a) The first\u2010stage disambiguation explores the contextual semantic information, where the noisy information is pruned for better effectiveness and efficiency; and (b) the second\u2010stage disambiguation explores the disambiguated phrases of high confidence from the first stage to achieve better redisambiguation decisions for the phrases that are difficult to disambiguate in the first stage\u00a0\u2026", "total_citations": {"2014": 5, "2015": 3, "2016": 4, "2017": 5, "2018": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:Zph67rFs4hoC": {"external_link": "https://link.springer.com/article/10.1023/A:1021529411332", "authors": ["Karl Aberer", "Anwitaman Datta", "Zoran Despotovic", "Andreas Wombacher"], "publication_date": "2003/1", "journal": "Electronic Commerce Research", "volume": "3", "pages": "83-111", "publisher": "Kluwer Academic Publishers", "description": "In Web-based information commerce it is diffcult to disentangle presentation from process logic, and sometimes even data is not separate from the presentation. Consequently, it becomes crucial to define an abstract model for business processes and their mapping into an active user interface presentation, using the principle of separation of concern. We endeavor to extend XSLT to accommodate the separation of process information from the data structure and presentation. We support declarative design further by a language designed to concisely specify information commerce processes. The isolation of the aspects of data, process and presentation makes it easier for developers to work independently and to focus on their primary responsibility.", "total_citations": {"2004": 6, "2005": 6, "2006": 1, "2007": 2, "2008": 1, "2009": 0, "2010": 0, "2011": 1, "2012": 0, "2013": 0, "2014": 2, "2015": 0, "2016": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:ye4kPcJQO24C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2557547.2557556", "authors": ["Dinh Tien Tuan Anh", "Anwitaman Datta"], "publication_date": "2014/3/3", "book": "Proceedings of the 4th ACM conference on Data and application security and privacy", "pages": "13-24", "description": "In this paper, we focus on the problem of data privacy on the cloud, particularly on access controls over stream data. The nature of stream data and the complexity of sharing data make access control a more challenging issue than in traditional archival databases. We present Streamforce -- a system allowing data owners to securely outsource their data to an untrusted (curious-but-honest) cloud. The owner specifies fine-grained policies which are enforced by the cloud. The latter performs most of the heavy computations, while learning nothing about the data content. To this end, we employ a number of encryption schemes, including deterministic encryption, proxy-based attribute based encryption and sliding-window encryption. In Streamforce, access control policies are modeled as secure continuous queries, which entails minimal changes to existing stream processing engines, and allows for easy expression of a\u00a0\u2026", "total_citations": {"2015": 3, "2016": 1, "2017": 4, "2018": 1, "2019": 6, "2020": 3, "2021": 1, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:cFHS6HbyZ2cC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5763460/", "authors": ["Christian von der Weth", "Anwitaman Datta"], "publication_date": "2011/3/22", "conference": "2011 IEEE International Conference on Advanced Information Networking and Applications", "pages": "617-624", "publisher": "IEEE", "description": "Finding relevant and reliable information on the web is a non-trivial task. While internet search engines do find correct web pages with respect to a set of keywords, they often cannot ensure the relevance or reliability of their content. An emerging trend is to harness internet users in the spirit of Web 2.0, to discern and personalize relevant and reliable information. Users collaboratively search or browse for information, either directly by communicating or indirectly by adding meta information (e.g., tags) to web pages. While gaining much popularity, such approaches are bound to specific service providers, or the Web 2.0 sites providing the necessary features, and the knowledge so generated is also confined to, and subject to the whims and censorship of such providers. To overcome these limitations we introduce COBS, a browser-centric knowledge repository which enjoys the inherent openness (similar to Wikipedia\u00a0\u2026", "total_citations": {"2010": 1, "2011": 1, "2012": 2, "2013": 3, "2014": 3, "2015": 4, "2016": 3, "2017": 1, "2018": 1, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:IWHjjKOFINEC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1816123.1816141", "authors": ["Yi Zhang", "Aixin Sun", "Anwitaman Datta", "Kuiyu Chang", "Ee-Peng Lim"], "publication_date": "2010/6/21", "book": "Proceedings of the 10th annual joint conference on Digital libraries", "pages": "119-128", "description": "Wikipedia is one of the most successful online knowledge bases, attracting millions of visits daily. Not surprisingly, its huge success has in turn led to immense research interest for a better understanding of the collaborative knowledge building process. In this paper, we performed a (terrorism) domain-specific case study, comparing and contrasting the knowledge evolution in Wikipedia with a knowledge base created by domain experts. Specifically, we used the Terrorism Knowledge Base (TKB) developed by experts at MIPT. We identified 409 Wikipedia articles matching TKB records, and went ahead to study them from three aspects: creation, revision, and link evolution. We found that the knowledge building in Wikipedia had largely been independent, and did not follow TKB - despite the open and online availability of the latter, as well as awareness of at least some of the Wikipedia contributors about the TKB\u00a0\u2026", "total_citations": {"2011": 2, "2012": 5, "2013": 2, "2014": 2, "2015": 1, "2016": 1, "2017": 1, "2018": 3, "2019": 1, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:HtS1dXgVpQUC": {"external_link": "https://arxiv.org/abs/1905.08517", "authors": ["Anwitaman Datta"], "publication_date": "2019/5/21", "journal": "arXiv preprint arXiv:1905.08517", "description": "Fuelled by the success (and hype) around cryptocurrencies, distributed ledger technologies (DLT), particularly blockchains, have gained a lot of attention from a wide spectrum of audience who perceive blockchains as a key to carry out business processes that have hitherto been cumbersome in a cost and time effective manner. Governments across the globe have responded to this promising but nascent technology differently - from being apathetic or adopting a wait-and-watch approach: letting the systems shape themselves, to creating regulatory sandboxes and sponsoring capacity building, or in some instances (arguably) over-regulating and attempting to put the blockchain genie back in the bottle. Possible government role spans across a spectrum: regulating crypto-currencies and initial coin offerings (ICO), formulating regulatory frameworks for managing the adoption of blockchains, particularly in critical infrastructure industries, facilitating capacity building, and finally, embracing blockchain technology in conducting the activities of the government itself - be it internally, or in using them to deliver public services. In this paper we survey the last, namely, the use of blockchain and associated distributed ledger technologies in the government technology (GovTech) stack, and discuss the merits and concerns associated with the existing initiatives and approaches.", "total_citations": {"2019": 4, "2020": 6, "2021": 2, "2022": 3, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:ZfRJV9d4-WMC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-45249-9_30", "authors": ["Chih Wei Ling", "Anwitaman Datta"], "publication_date": "2014", "conference": "Distributed Computing and Networking: 15th International Conference, ICDCN 2014, Coimbatore, India, January 4-7, 2014. Proceedings 15", "pages": "453-468", "publisher": "Springer Berlin Heidelberg", "description": "In this paper, we introduce InterCloud RAIDer, which realizes a multi-cloud private data backup system by composing (i) a data deduplication technique to reduce the overall storage overhead, (ii) erasure coding to achieve redundancy at low overhead, which is dispersed across multiple cloud services to realize fault-tolerance against individual service providers, specifically we use non-systematic instances of erasure codes to provide a basic level of privacy from individual cloud stores, and finally, (iii) a proof of data possession mechanism to detect misbehaving services - where we optimize the implementation by exploiting hash digests that are created in the prior deduplication phase. Apart from the uniqueness and non-triviality of putting these modules together, the system design also had to deal with artefacts and heterogeneity across different cloud storage services we used, namely Dropbox, Google\u00a0\u2026", "total_citations": {"2015": 3, "2016": 6, "2017": 3, "2018": 0, "2019": 2, "2020": 4, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:738O_yMBCRsC": {"external_link": "https://link.springer.com/article/10.1007/s10723-012-9212-9", "authors": ["Tien Tuan Anh Dinh", "Wang Wenqiang", "Anwitaman Datta"], "publication_date": "2012/3", "journal": "Journal of Grid Computing", "volume": "10", "pages": "151-172", "publisher": "Springer Netherlands", "description": "Sharing data from various sources and of diverse kinds, and fusing them together for sophisticated analytics and mash-up applications are emerging trends, and are prerequisites for realizing grand visions such as that of cyber-physical systems enabled smart cities. Cloud infrastructure can enable such data sharing both because it can scale easily to an arbitrary volume of data and computation needs on demand, as well as because of natural collocation of diverse such data sets within the infrastructure. However, in order to convince data owners that their data are well protected while being shared among cloud users, the cloud platform needs to provide flexible mechanisms for the users to express the constraints (access rules) subject to which the data should be shared, and likewise, enforce them effectively. We study a comprehensive set of practical scenarios where data sharing needs to be enforced by\u00a0\u2026", "total_citations": {"2012": 5, "2013": 0, "2014": 5, "2015": 3, "2016": 1, "2017": 0, "2018": 1, "2019": 0, "2020": 1, "2021": 1, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:UHK10RUVsp4C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6691658/", "authors": ["Kyumars Sheykh Esmaili", "Aatish Chiniah", "Anwitaman Datta"], "publication_date": "2013/10/6", "conference": "2013 IEEE International Conference on Big Data", "pages": "28-32", "publisher": "IEEE", "description": "In the past few years erasure codes have been increasingly embraced by distributed storage systems as an alternative for replication, since they provide high fault-tolerance for low overheads. Erasure codes, however, have few shortcomings that need to be addressed to make them a complete solution for networked storage systems. Lack of support for efficient data repair and data update are the two most notable shortcomings. We recently proposed to use a 2-dimensional product code-Reed-Solomon coding per object and simple XORing across objects- and showed that at a reasonable storage overhead, it can greatly reduce the repair cost. In this paper we propose an efficient approach to handle data updates in cross-object erasure-coded storage systems. Our proposed solution has been implemented and experimentally evaluated. Our results show that compared to the naive approach (re-encoding the data\u00a0\u2026", "total_citations": {"2015": 4, "2016": 4, "2017": 2, "2018": 0, "2019": 1, "2020": 1, "2021": 3, "2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:u9iWguZQMMsC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167739X13000460", "authors": ["Lluis Pamies-Juarez", "Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2013/8/1", "journal": "Future Generation Computer Systems", "volume": "29", "issue": "6", "pages": "1353-1362", "publisher": "North-Holland", "description": "Erasure coding is a storage-efficient alternative to replication for achieving reliable data backup in distributed storage systems. During the storage process, traditional erasure codes require a unique source node to create and upload all the redundant data to the different storage nodes. However, such a source node may have limited communication and computation capabilities, which constrain the storage process throughput. Moreover, the source node and the different storage nodes might not be able to send and receive data simultaneously\u2013e.g., nodes might be busy in a data center setting, or simply be offline in a peer-to-peer setting\u2013which can further threaten the efficacy of the overall storage process. In this paper, we propose an \u201cin-network\u201d redundancy generation process which distributes the data insertion load among the source and storage nodes by allowing the storage nodes to generate new redundant\u00a0\u2026", "total_citations": {"2013": 2, "2014": 1, "2015": 1, "2016": 3, "2017": 3, "2018": 2, "2019": 2, "2020": 1, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:OU6Ihb5iCvQC": {"external_link": "https://www.ijcai.org/Proceedings/11/Papers/358.pdf", "authors": ["Xin Liu", "Anwitaman Datta"], "publication_date": "2011/6/28", "conference": "Twenty-Second International Joint Conference on Artificial Intelligence", "description": "Predicting trust among the agents is of great importance to various open distributed settings (eg, emarket, peer-to-peer networks, etc.) in that dishonest agents can easily join the system and achieve their goals by circumventing agreed rules, or gaining unfair advantages, etc. Most existing trust mechanisms derive trust by statistically investigating the target agent\u2019s historical information. However, even if rich historical information is available, it is challenging to model an agent\u2019s behavior since an intelligent agent may strategically change its behavior to maximize its profits. We therefore propose a trust prediction approach to capture dynamic behavior of the target agent. Specifically, we first identify features which are capable of describing/representing context of a transaction. Then we use these features to measure similarity between context of the potential transaction and that of previous transactions to estimate trustworthiness of the potential transaction based on previous similar transactions\u2019 outcomes. Evaluation using real auction data and synthetic data demonstrates efficacy of our approach in comparison with an existing representative trust mechanism.", "total_citations": {"2011": 1, "2012": 2, "2013": 2, "2014": 1, "2015": 2, "2016": 2, "2017": 1, "2018": 1, "2019": 0, "2020": 3, "2021": 2, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:aqlVkmm33-oC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1671948.1671950", "authors": ["\u0160ar\u016bnas Girdzijauskas", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2010/2/25", "journal": "ACM Transactions on Autonomous and Adaptive Systems (TAAS)", "volume": "5", "issue": "1", "pages": "1-25", "publisher": "ACM", "description": "Recent years have seen advances in building large Internet-scale index structures, generally known as structured overlays. Early structured overlays realized distributed hash tables (DHTs) which are ill suited for anything but exact queries. The need to support range queries necessitates systems that can handle uneven load distributions. However such systems suffer from practical problems\u2014including poor latency, disproportionate bandwidth usage at participating peers, or unrealistic assumptions on peers' homogeneity, in terms of available storage or bandwidth resources. In this article we consider a system that is not only able to support uneven load distributions but also to operate in heterogeneous environments, where each peer can autonomously decide how much of its resources to contribute to the system. We provide the theoretical foundations of realizing such a network and present a newly proposed\u00a0\u2026", "total_citations": {"2009": 2, "2010": 2, "2011": 4, "2012": 2, "2013": 1, "2014": 1, "2015": 2, "2016": 1, "2017": 0, "2018": 0, "2019": 0, "2020": 1, "2021": 1, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:4MWp96NkSFoC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2723771", "authors": ["Krzysztof Rzadca", "Anwitaman Datta", "Gunnar Kreitz", "Sonja Buchegger"], "publication_date": "2015/9/1", "journal": "ACM Transactions on Autonomous and Adaptive Systems (TAAS)", "volume": "10", "issue": "3", "pages": "1-32", "publisher": "ACM", "description": "In a decentralized storage system, agents replicate each other\u2019s data to increase availability. Compared to organizationally centralized solutions, such as cloud storage, a decentralized storage system requires less trust in the provider and may result in smaller monetary costs. Our system is based on reciprocal storage contracts that allow the agents to adopt to changes in their replication partners\u2019 availability (by dropping inefficient contracts and forming new contracts with other partners). The data availability provided by the system is a function of the participating agents\u2019 availability. However, a straightforward system in which agents\u2019 matching is decentralized uses the given agent availability inefficiently. As agents are autonomous, the highly available agents form cliques replicating data between each other, which makes the system too hostile for the weakly available newcomers. In contrast, a centralized, equitable\u00a0\u2026", "total_citations": {"2016": 1, "2017": 3, "2018": 1, "2019": 3, "2020": 3, "2021": 2, "2022": 1, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:NMxIlDl6LWMC": {"external_link": "https://link.springer.com/article/10.1007/s13278-011-0037-5", "authors": ["Chenliang Li", "Anwitaman Datta", "Aixin Sun"], "publication_date": "2012/9", "journal": "Social Network Analysis and Mining", "volume": "2", "pages": "265-278", "publisher": "Springer Vienna", "description": "As people participate actively in social networking and peer-production sites, there are additional, implicit relations that emerge from various user activities. Mining such latent relations, or wisdom of crowds, is in itself an important area of ongoing research, with both general as well as domain-specific custom-made techniques. In this paper, we propose a new similarity measure, which we call expert-based similarity to discover semantic relations among Wikipedia articles from the co-editorship perspective. Also, different kinds of relations among entities may reveal diverse information. Both to explore and expose such a premise, we carry out a case study leveraging on multiple relations among Wikipedia articles. Specifically, we use expert-based similarity as well as other standard similarity measures, to discern the influence and impact of several factors which are hypothysed to generate controversies in\u00a0\u2026", "total_citations": {"2011": 1, "2012": 1, "2013": 5, "2014": 2, "2015": 3, "2016": 3, "2017": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:Tiz5es2fbqcC": {"external_link": "https://patents.google.com/patent/US8928503B2/en", "inventors": "Frederique Oggier, Anwitaman Datta", "publication_date": "2015/1/6", "patent_office": "US", "patent_number": "8928503", "application_number": "13809823", "description": "In an embodiment, a data encoding method may be provided. The data encoding method may include: inputting data to be encoded; determining a polynomial so that an evaluation of the polynomial at a sum of a first supporting point of the polynomial and a second supporting point of the polynomial corresponds to the sum of an evaluation of the polynomial at the first supporting point and an evaluation of the polynomial at the second supporting point, wherein coefficients of the polynomial are determined based on the data to be encoded; and generating a plurality of encoded data items by evaluating the polynomial at a plurality of supporting points.", "total_citations": {"2016": 3, "2017": 3, "2018": 2, "2019": 4, "2020": 1, "2021": 0, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:mVmsd5A6BfQC": {"external_link": "https://link.springer.com/chapter/10.1007/978-1-84882-229-0_12", "authors": ["Albert Hupa", "Krzysztof Rzadca", "Adam Wierzbicki", "Anwitaman Datta"], "publication_date": "2010", "journal": "Computational Social Network Analysis: Trends, Tools and Research Advances", "pages": "319-347", "publisher": "Springer London", "description": "Social networks are commonly used to enhance recommender systems. Most of such systems recommend a single resource or a person. However, complex problems or projects usually require a team of experts that must work together on a solution. Team recommendation is much more challenging, mostly because of the complex interpersonal relations between members. This chapter presents fundamental concepts on how to score a team based on members\u2019 social context and their suitability for a particular project. We represent the social context of an individual as a three-dimensional social network (3DSN) composed of a knowledge dimension expressing skills, a trust dimension and an acquaintance dimension. Dimensions of a 3DSN are used to mathematically formalize the criteria for prediction of the team\u2019s performance. We use these criteria to formulate the team recommendation problem as a\u00a0\u2026", "total_citations": {"2010": 2, "2011": 4, "2012": 0, "2013": 0, "2014": 4, "2015": 1, "2016": 0, "2017": 0, "2018": 1, "2019": 2, "2020": 1, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:_Re3VWB3Y0AC": {"external_link": "https://link.springer.com/article/10.1007/s10207-016-0347-8", "authors": ["Lichun Li", "Michael Militzer", "Anwitaman Datta"], "publication_date": "2017/11", "journal": "International Journal of Information Security", "volume": "16", "pages": "603-625", "publisher": "Springer Berlin Heidelberg", "description": "Even as data and analytics-driven applications are becoming increasingly popular, retrieving data from shared databases poses a threat to the privacy of their users. For example, investors/patients retrieve records about stocks/diseases they are interested in from a stock/medical database. Knowledge of such interest is sensitive information that the database server would have access to, unless some mitigating measures are deployed. Private information retrieval (PIR) is a promising security primitive to protect the privacy of users\u2019 interests. PIR allows the retrieval of a data record from a database without letting the database server know which record is being retrieved. The privacy guarantees could either be information theoretic or computational. Alternatively, anonymizers, which hide the identities of data users, may be used to protect the privacy of users\u2019 interests for some situations. In this paper, we study\u00a0\u2026", "total_citations": {"2016": 3, "2017": 1, "2018": 1, "2019": 1, "2020": 4, "2021": 1, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:PELIpwtuRlgC": {"external_link": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23139", "authors": ["Anwitaman Datta", "Jackson Tan Teck Yong", "Stefano Braghin"], "publication_date": "2014/12", "journal": "Journal of the Association for Information Science and Technology", "volume": "65", "issue": "12", "pages": "2518-2533", "description": "It is often necessary to compose a team consisting of experts with diverse competencies to accomplish complex tasks. However, for its proper functioning, it is also preferable that a team be socially cohesive. A team recommendation system, which facilitates the search for potential team members, can be of great help both for (a) individuals who need to seek out collaborators and for (b) managers who need to build a team for some specific tasks. Such a decision support system that readily helps summarize multiple metrics indicating a team (and its members) quality, and possibly rank the teams in a personalized manner according to the end users' preferences, thus serves as a tool to cope with what would otherwise be an information avalanche. In this work, we present Social Web Application for Team Recommendation, a general\u2010purpose framework to compose various information retrieval and social graph mining\u00a0\u2026", "total_citations": {"2014": 1, "2015": 2, "2016": 1, "2017": 1, "2018": 2, "2019": 3, "2020": 2, "2021": 2, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:J-pR_7NvFogC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167923612002515", "authors": ["Adam Wierzbicki", "Tomasz Kaszuba", "Radoslaw Nielek", "Paulina Adamska", "Anwitaman Datta"], "publication_date": "2013/1/1", "journal": "Decision Support Systems", "volume": "54", "issue": "2", "pages": "929-940", "publisher": "North-Holland", "description": "Computational trust representations are used by Trust Management (TM) systems to elicit information from users about the behavior of others. In most practically used TM systems, simple computational trust representations dominate, such as the three-valued discrete scale of \u201cnegative\u201d, \u201cneutral\u201d and \u201cpositive\u201d used in reputation systems of Internet auctions. This paper asks the question: what is the appropriate system for computational representation of human trust? In order to find an answer, we study a large trace of feedbacks and textual comments from a reputation system of an Internet auction. We discover that users systematically try to add information in the textual comments. Text-mining and NLP approaches reveal a taxonomy of non-positive feedbacks and an importance order on the categories of non-positive behavior. This importance order is further supported by survey data. Based on these observations\u00a0\u2026", "total_citations": {"2014": 1, "2015": 3, "2016": 1, "2017": 3, "2018": 2, "2019": 0, "2020": 0, "2021": 1, "2022": 2, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:LPZeul_q3PIC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2349896.2349898", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2012/7/23", "book": "Proceedings of the Asia-Pacific Workshop on Systems", "pages": "1-6", "description": "The problem of replenishing redundancy in erasure code based fault-tolerant storage has received a great deal of attention recently, leading to the design of several new coding techniques [3], aiming at a better repairability. In this paper, we adopt a different point of view, by proposing to code across different already encoded objects to alleviate the repair problem. We show that the addition of parity pieces - the simplest form of coding - significantly boosts repairability without sacrificing fault-tolerance for equivalent storage overhead. The simplicity of our approach as well as its reliance on time-tested techniques makes it readily deployable.", "total_citations": {"2011": 1, "2012": 1, "2013": 7, "2014": 1, "2015": 0, "2016": 1, "2017": 0, "2018": 1, "2019": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:P7Ujq4OLJYoC": {"external_link": "https://link.springer.com/article/10.1007/s13278-020-00650-x", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta", "Silivanxay Phetsouvanh"], "publication_date": "2020/12", "journal": "Social Network Analysis and Mining", "volume": "10", "pages": "1-14", "publisher": "Springer Vienna", "description": "We consider a particular instance of user interactions in the Bitcoin network, that of interactions among wallet addresses belonging to scammers. Aggregation of multiple inputs and change addresses are common heuristics used to establish relationships among addresses and analyze transaction amounts in the Bitcoin network. We propose a flow centric approach that complements such heuristics, by studying the branching, merger and propagation of Bitcoin flows. We study a recent sextortion campaign by exploring the ego network of known offending wallet addresses. We compare and combine different existing and new heuristics, which allows us to identify (1) Bitcoin addresses of interest (including possible recurrent go-to addresses for the scammers) and (2) relevant Bitcoin flows, from scam Bitcoin addresses to a Binance exchange and to other other scam addresses, that suggest connections among\u00a0\u2026", "total_citations": {"2021": 4, "2022": 7, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:3htObqc8RwsC": {"external_link": "https://arxiv.org/abs/1910.00985", "authors": ["Tien Tuan Anh Dinh", "Anwitaman Datta", "Beng Chin Ooi"], "publication_date": "2019/10/2", "journal": "arXiv preprint arXiv:1910.00985", "description": "Research in blockchain systems has mainly focused on improving security and bridging the performance gaps between blockchains and databases. Despite many promising results, we observe a worrying trend that the blockchain landscape is fragmented in which many systems exist in silos. Apart from a handful of general-purpose blockchains, such as Ethereum or Hyperledger Fabric, there are hundreds of others designed for specific applications and typically do not talk to each other. In this paper, we describe our vision of interoperable blockchains. We argue that supporting interaction among different blockchains requires overcoming challenges that go beyond data standardization. The underlying problem is to allow smart contracts running in different blockchains to communicate. We discuss three open problems: access control, general cross-chain transactions, and cross-chain communication. We describe partial solutions to some of these problems in the literature. Finally, we propose a novel design to overcome these challenges.", "total_citations": {"2020": 1, "2021": 3, "2022": 5, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:vDijr-p_gm4C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2556948", "authors": ["Kyumars Sheykh Esmaili", "Shahin Salavati", "Anwitaman Datta"], "publication_date": "2014/6/1", "journal": "ACM Transactions on Asian Language Information Processing (TALIP)", "volume": "13", "issue": "2", "pages": "1-18", "publisher": "ACM", "description": "The Kurdish language is an Indo-European language spoken in Kurdistan, a large geographical region in the Middle East. Despite having a large number of speakers, Kurdish is among the less-resourced languages and has not seen much attention from the IR and NLP research communities. This article reports on the outcomes of a project aimed at providing essential resources for processing Kurdish texts. A principal output of this project is Pewan, the first standard Test Collection to evaluate Kurdish Information Retrieval systems. The other language resources that we have built include a lightweight stemmer and a list of stopwords. Our second principal contribution is using these newly-built resources to conduct a thorough experimental study on Kurdish documents. Our experimental results show that normalization, and to a lesser extent, stemming, can greatly improve the performance of Kurdish IR systems.", "total_citations": {"2013": 1, "2014": 1, "2015": 0, "2016": 1, "2017": 2, "2018": 2, "2019": 1, "2020": 1, "2021": 4, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:6yz0xqPARnAC": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=78e84a2ab71bb1eaf246fdaa9c2beeb7b40c1f82", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2011/9/13", "source": "CoRR, vol. abs/1109.2317", "description": "The continuously increasing amount of digital data generated by today\u2019s society asks for better storage solutions. This survey looks at a new generation of coding techniques designed specifically for the needs of distributed networked storage systems, trying to reach the best compromise among storage space efficiency, fault tolerance, and maintenance overheads. Four families of codes tailor-made for distributed settings, namely-pyramid, hierarchical, regenerating and self-repairing codesare presented at a high level, emphasizing the main ideas behind each of these codes, and discussing their pros and cons, before concluding with a quantitative comparison among them. This survey deliberately excluded technical details for the codes, nor does it provide an exhaustive summary of the numerous works. Instead, it provides an overview of the major code families in a manner easily accessible to a broad audience, by presenting the big picture of advances in coding techniques for distributed storage solutions.", "total_citations": {"2012": 2, "2013": 5, "2014": 2, "2015": 2, "2016": 2, "2017": 0, "2018": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:-f6ydRqryjwC": {"external_link": "https://link.springer.com/article/10.1007/s12083-010-0081-3", "authors": ["Sarunas Girdzijauskas", "Wojciech Galuba", "Vasilios Darlagiannis", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2011/9", "journal": "Peer-to-Peer Networking and Applications", "volume": "4", "pages": "259-273", "publisher": "Springer US", "description": "Many structured overlay networks rely on a ring invariant as a core network connectivity element. The responsibility ranges of the participating peers and navigability principles (greedy routing) heavily depend on the ring structure. For correctness guarantees, each node needs to eagerly maintain its immediate neighboring links - the ring invariant. However, the ring maintenance is an expensive task and it may not even be possible to maintain the ring invariant continuously under high churn, particularly as the network size grows. Furthermore, routing anomalies in the network, peers behind firewalls and Network Address Translators (NATs) create non-transitivity effects, which inevitably lead to the violation of the ring invariant. We argue that reliance on the ring structure is a serious impediment for real life deployment and scalability of structured overlays. In this paper we propose an overlay called Fuzzynet\u00a0\u2026", "total_citations": {"2010": 1, "2011": 1, "2012": 4, "2013": 1, "2014": 0, "2015": 3, "2016": 1, "2017": 1, "2018": 0, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:4DMP91E08xMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4565029/", "authors": ["Minh-Tam Le", "Hoang-Vu Dang", "Ee-Peng Lim", "Anwitaman Datta"], "publication_date": "2008/6/17", "conference": "2008 IEEE International Conference on Intelligence and Security Informatics", "pages": "52-57", "publisher": "IEEE", "description": "When multiple users with diverse backgrounds and beliefs edit Wikipedia together, disputes often arise due to disagreements among the users. In this paper, we introduce a novel visualization tool known as WikiNetViz to visualize and analyze disputes among users in a dispute-induced social network. WikiNetViz is designed to quantify the degree of dispute between a pair of users using the article history. Each user (and article) is also assigned a controversy score by our proposed Controversy Rank model so as to measure the degree of controversy of a user (and an article) by the amount of disputes between the user (article) and other users in articles of varying degrees of controversy. On the constructed social network, WikiNetViz can perform clustering so as to visualize the dynamics of disputes at the user group level. It also provides an article viewer for examining an article revision so as to determine the article\u00a0\u2026", "total_citations": {"2010": 2, "2011": 3, "2012": 1, "2013": 1, "2014": 3, "2015": 1, "2016": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:lvd772isFD0C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-030-55746-1_8", "authors": ["Anwitaman Datta"], "publication_date": "2021", "journal": "Blockchain and the Public Sector: Theories, Reforms, and Case Studies", "pages": "175-195", "publisher": "Springer International Publishing", "description": "In this paper we carry out a survey of vision & white papers and reports from industry as well as private industry actors, along with academic literature, to understand how blockchain is being used for digital government and public services. The purpose of this survey is to explore which fundamental properties of blockchain technology are being harnessed, and how; putting it in perspective by reviewing technological alternatives when pertinent, and by also discussing the cautions one needs to take to use blockchains in a prudent and correct manner. The case studies discussed in this paper are thus not exhaustive, nor is any individual case discussed in great depth. Instead, we focus on capturing a wide spectrum of representative use cases to expose the efficacy as well as limitations of integrating blockchains in the government technology stack.", "total_citations": {"2021": 3, "2022": 1, "2023": 8}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:ULOm3_A8WrAC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-540-30192-9_50", "authors": ["Fabius Klemm", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2005", "conference": "Current Trends in Database Technology-EDBT 2004 Workshops: EDBT 2004 Workshops PhD, DataX, PIM, P2P&DB, and ClustWeb, Heraklion, Crete, Greece, March 14-18, 2004. Revised Selected Papers 9", "pages": "506-515", "publisher": "Springer Berlin Heidelberg", "description": "The two main approaches to find data in peer-to-peer (P2P) systems are unstructured networks using flooding and structured networks using a distributed index. A distributed index is usually built over all keys that are stored in the network whether they are queried or not. Indexing all keys is no longer feasible when indexing metadata, as the key space becomes very large. Here we need a query-adaptive approach that indexes only keys worth indexing, i.e. keys that are queried at least with a certain frequency. In this paper we study the cost of indexing and propose a query-adaptive partial distributed hash table (PDHT) that does not keep all keys in the index. We model and analyze a scenario to show that query-adaptive partial indexing outperforms pure flooding and \u201cindex-everything\u201d strategies. Furthermore, our scheme is able to automatically adjust the index to changing query frequencies and\u00a0\u2026", "total_citations": {"2004": 1, "2005": 2, "2006": 1, "2007": 2, "2008": 1, "2009": 3, "2010": 0, "2011": 0, "2012": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:Wp0gIr-vW9MC": {"external_link": "https://www.researchgate.net/profile/Aixin-Sun/publication/221520150_On_Stability_Clarity_and_Co-occurrence_of_Self-Tagging/links/09e41505bbfafab75b000000/On-Stability-Clarity-and-Co-occurrence-of-Self-Tagging.pdf", "authors": ["Aixin Sun", "Anwitaman Datta"], "publication_date": "2009", "conference": "WSDM (Late Breaking-Results)", "description": "Most studies on tags focus on collaborative tagging systems where each resource (eg, article, photo) can be tagged by multiple users with multiple tags. The tag usage patterns in self-tagging systems where a resource (eg, a blog post) can only be tagged by its owner, however, have not been well studied. From the tags assigned by bloggers to their own blog posts, we obtain interesting insights on tag distribution stability and tag clarity. We further discuss the meaning of tag co-occurrences in the context of blogs and argue that tag networks based on co-occurrence from self-tagging system needs to be interpreted differently than that in collaborative tagging systems.", "total_citations": {"2009": 1, "2010": 4, "2011": 1, "2012": 4, "2013": 0, "2014": 0, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:9ZlFYXVOiuMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4274895/", "authors": ["Anwitaman Datta"], "publication_date": "2007/7/9", "conference": "First International Conference on Self-Adaptive and Self-Organizing Systems (SASO 2007)", "pages": "109-118", "publisher": "IEEE", "description": "Peer-to-peer index structures distributed and managed over the planet, commonly known as structured overlays (e.g., distributed hash tables), are posed to play the role of a fundamental building block for internet-scale distributed applications and information systems. One of the biggest impediment in realizing index distributed at intra-planetary scales is to be able to merge distinct indices that might have been constructed independently and separately, or have resulted from network partitions. By facilitating merger of such isolated index-structures, decentralized bootstrapping of structured overlays is made possible. We argue that such a self-organizational attribute of decentralized bootstrapping is of paramount importance for large scale systems. In this paper we provide algorithms and simulation based evaluation of merger of two tree-structured overlay networks. The experiments validate some intuitions\u00a0\u2026", "total_citations": {"2009": 3, "2010": 2, "2011": 2, "2012": 2, "2013": 1, "2014": 0, "2015": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:olpn-zPbct0C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-36071-8_4", "authors": ["Lluis Pamies-Juarez", "Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2013", "conference": "Distributed Computing and Internet Technology: 9th International Conference, ICDCIT 2013, Bhubaneswar, India, February 5-8, 2013. Proceedings 9", "pages": "47-68", "publisher": "Springer Berlin Heidelberg", "description": "Given the vast volume of data that needs to be stored reliably, many data-centers and large-scale file systems have started using erasure codes to achieve reliable storage while keeping the storage overhead low. This has invigorated the research on erasure codes tailor made to achieve different desirable storage system properties such as efficient redundancy replenishment mechanisms, resilience against data corruption, degraded reads, to name a few prominent ones. A problem that has mainly been overlooked until recently is that of how the storage system can be efficiently populated with erasure coded data to start with. In this paper, we will look at two distinct but related scenarios: (i) migration to archival - leveraging on existing replicated data to create an erasure encoded archive, and (ii) data insertion - new data being inserted in the system directly in erasure coded format. We will elaborate on\u00a0\u2026", "total_citations": {"2013": 4, "2014": 1, "2015": 1, "2016": 2, "2017": 1, "2018": 0, "2019": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:1sJd4Hv_s6UC": {"external_link": "https://link.springer.com/article/10.1007/s10922-011-9198-9", "authors": ["Xin Liu", "Anwitaman Datta"], "publication_date": "2012/6", "journal": "Journal of Network and Systems Management", "volume": "20", "pages": "200-225", "publisher": "Springer US", "description": "Peer-to-peer storage services are a cost-effective alternative for data backup. A basic question that arises in the design of such systems is: In which peers do we store redundant data? Choosing appropmailriate peers for data backup is important at a microscopic level, from an end-user\u2019s perspective to guarantee good performance, e.g., quick access, high availability, etc., as well as at a macroscopic level, e.g., for system optimization, fairness, etc. Existing systems apply different techniques, including random selection, based on a distributed hash table (DHT) or based on the peers\u2019 past availability pattern. In this paper, we propose as an alternative, a contextual trust based data placement scheme to select suitable data holders. It is originally designed for and applicable to scenarios where there is inadequate historical information about peers, a common scenario in large-scale systems. Specifically, our\u00a0\u2026", "total_citations": {"2011": 1, "2012": 0, "2013": 1, "2014": 2, "2015": 1, "2016": 0, "2017": 2, "2018": 1, "2019": 0, "2020": 0, "2021": 0, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:_kc_bZDykSQC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4221802/", "authors": ["Sarunas Girdzijauskas", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2006/4/15", "conference": "2007 IEEE 23rd International Conference on Data Engineering", "pages": "1365-1367", "publisher": "IEEE", "description": "Quite a few data-oriented overlay networks have been designed in recent years. These designs often (implicitly) assume various homogeneity which seriously limit their usability in real world. In this paper we present some performance results of the Oscar overlay, which simultaneously deals with heterogeneity as observed in the Internet (capacity of computers, bandwidth) as well as non-uniformity observed in data-oriented applications.", "total_citations": {"2007": 3, "2008": 2, "2009": 1, "2010": 1, "2011": 3, "2012": 0, "2013": 0, "2014": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:Ug5p-4gJ2f0C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7950839/", "authors": ["Chih Wei Ling", "Anwitaman Datta", "Jun Xu"], "publication_date": "2017/6/16", "journal": "IEEE Internet Computing", "volume": "22", "issue": "1", "pages": "42-51", "publisher": "IEEE", "description": "Traffic surveillance devices such as cameras and sensors that are integrated into intelligent transportation systems (ITSs) generate large volumes of data. To deal with the extreme volume and the massively geographically distributed sources of data, we advocate a tiered storage and processing architecture, using edge nodes to augment a centralized backbone, facilitated by network coding (NetCod) and control techniques and emerging fog-computing solutions. To that end, we first survey several technologies and concepts, and then elaborate on the core components needed in a distributed multilevel storage infrastructure (DMSI) for secure and reliable acquisition, storage, and analysis of increasing volumes of intelligent surveillance system data.", "total_citations": {"2018": 2, "2019": 5, "2020": 2, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:tOudhMTPpwUC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6295982/", "authors": ["Xin Liu", "Anwitaman Datta", "Hui Fang", "Jie Zhang"], "publication_date": "2012/6/25", "conference": "2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications", "pages": "246-253", "publisher": "IEEE", "description": "Reputation systems deployed in popular online auction sites simply aggregate feedback about a seller's past transactions. By studying a real auction site dataset, we infer that a non-negligible fraction of unsatisfactory transactions involve sellers with high reputation. Such a phenomenon can be interpreted by motivation theory from behaviorial science: A seller with high reputation has more business opportunities. Bad feedback for latest transactions do not immediately affect his reputation adequately to hurt business, hence he may not be as prudent as before. In this work, we propose the concept of imprudence to study and detect the inappropriate behavior of a 'reliable' seller (i.e., the one with high reputation computed using conventional approaches). Specifically, we first identify and verify the features that influence a seller's imprudence behavior. We then design a novel intelligent buying agent to combine these\u00a0\u2026", "total_citations": {"2013": 1, "2014": 4, "2015": 2, "2016": 0, "2017": 0, "2018": 1, "2019": 0, "2020": 1, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:zA6iFVUQeVQC": {"external_link": "https://arxiv.org/abs/1107.3129", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2011/7/15", "journal": "arXiv preprint arXiv:1107.3129", "description": "Distributed data storage systems are essential to deal with the need to store massive volumes of data. In order to make such a system fault-tolerant, some form of redundancy becomes crucial, incurring various overheads - most prominently in terms of storage space and maintenance bandwidth requirements. Erasure codes, originally designed for communication over lossy channels, provide a storage efficient alternative to replication based redundancy, however entailing high communication overhead for maintenance, when some of the encoded fragments need to be replenished in news ones after failure of some storage devices. We propose as an alternative a new family of erasure codes called self-repairing codes (SRC) taking into account the peculiarities of distributed storage systems, specifically the maintenance process. SRC has the following salient features: (a) encoded fragments can be repaired directly from other subsets of encoded fragments by downloading less data than the size of the complete object, ensuring that (b) a fragment is repaired from a fixed number of encoded fragments, the number depending only on how many encoded blocks are missing and independent of which specific blocks are missing. This paper lays the foundations by defining the novel self-repairing codes, elaborating why the defined characteristics are desirable for distributed storage systems. Then homomorphic self-repairing codes (HSRC) are proposed as a concrete instance, whose various aspects and properties are studied and compared - quantitatively or qualitatively with respect to other codes including traditional erasure codes as well as other\u00a0\u2026", "total_citations": {"2010": 1, "2011": 1, "2012": 2, "2013": 5, "2014": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:dhFuZR0502QC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5583200/", "authors": ["Sally Ang", "Krzysztof Rzadca", "Anwitaman Datta"], "publication_date": "2010/7/19", "conference": "2010 IEEE International Conference on Multimedia and Expo", "pages": "1154-1155", "publisher": "IEEE", "description": "Current collaborative software usually have no or limited support for ad-hoc collaboration. SharedMind supports synchronous collaboration, i.e. real-time collaboration, and asynchronous collaboration, i.e. the merging of local instances of a document modified by different users after dis- and reconnects to a group of collaborators. SharedMind is completely decentralized and supports ad-hoc collaboration for interconnected (sub)groups. It demonstrates the confluence of social media and tools for computer supported collaborative works.", "total_citations": {"2010": 1, "2011": 2, "2012": 2, "2013": 0, "2014": 0, "2015": 1, "2016": 0, "2017": 0, "2018": 0, "2019": 2, "2020": 0, "2021": 0, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=20&pagesize=80&citation_for_view=VWi3_OIAAAAJ:HeT0ZceujKMC": {"external_link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5629", "authors": ["Silivanxay Phetsouvanh", "Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2021/1/10", "journal": "Concurrency and Computation: Practice and Experience", "volume": "33", "issue": "1", "pages": "e5629", "description": "Distinct transactions among different and unrelated users are combined together to create a single Bitcoin transaction (mixing transaction) to obfuscate the relationships among the actual participants (more specifically, the wallet addresses used for the transactions). We consider multi\u2010input multi\u2010output transactions with at least two inputs and three outputs as proxy, to analyze four characteristic periods of \u223c50 days each, representing periods before the introduction of mixing, in its early days, during its growth, and after the volume of such multi\u2010input multi\u2010output transactions became more or less stabile. Structural properties and characteristics of the transaction and wallet address networks are computed and compared, through standard tools, but also via the introduction of two novel techniques that provide indicators of mixing\u2010like behaviors: (1) an entropy characterization to detect abnormally uniform inputs and\u00a0\u2026", "total_citations": {"2021": 3, "2022": 2, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:HIFyuExEbWQC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8664236/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Silivanxay Phetsouvanh", "Anwitaman Datta"], "publication_date": "2018/10/28", "conference": "2018 International Symposium on Information Theory and Its Applications (ISITA)", "pages": "50-54", "publisher": "IEEE", "description": "Given a graph, the notion of entropic centrality was introduced by Tutzauer to characterize vertices which are important in the sense that there is a high uncertainty about the destination of an atomic flow starting at them, assuming that at each hop, the flow is equally likely to continue to any unvisited vertex, or to be terminated there. We generalize this notion of entropic centrality to non-atomic flows, and furthermore show that the case of a non-atomic flow splitting with equal probability across different subsets of edges results in the same entropic centrality as that of the atomic flow. This gives a new and more generalized interpretation to the original entropic centrality notion. Finally, we demonstrate using network graphs derived from Bitcoin transactions that depending on the graph characteristics, the presented entropy based centrality metric can provide a unique perspective not captured by other existing centrality\u00a0\u2026", "total_citations": {"2019": 4, "2020": 1, "2021": 2, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:LI9QrySNdTsC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167739X15002538", "authors": ["Ertem Esiner", "Anwitaman Datta"], "publication_date": "2016/2/1", "journal": "Future Generation Computer Systems", "volume": "55", "pages": "17-28", "publisher": "North-Holland", "description": "Auditability is crucial for data outsourcing, facilitating accountability and identifying data loss or corruption incidents in a timely manner, reducing in turn the risks from such losses. In recent years, in synch with the growing trend of outsourcing, a lot of progress has been made in designing probabilistic (for efficiency) provable data possession (PDP) schemes. However, even the recent and advanced PDP solutions that do deal with dynamic data, do so in a limited manner, and for only the latest version of the data. A naive solution treating different versions in isolation would work, but leads to tremendous overheads, and is undesirable. In this paper, we present algorithms to achieve full persistence (all intermediate configurations are preserved and are modifiable) for an optimized skip list (known as FlexList) so that versioned data can be audited. The proposed scheme provides deduplication at the level of logical\u00a0\u2026", "total_citations": {"2016": 1, "2017": 1, "2018": 1, "2019": 2, "2020": 0, "2021": 0, "2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:BUYA1_V_uYcC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7164993/", "authors": ["J Harshan", "Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2015/6/29", "conference": "2015 IEEE 35th International Conference on Distributed Computing Systems", "pages": "798-799", "publisher": "IEEE", "description": "In this work, we study the problem of storing reliably an archive of versioned data. Specifically, we focus on systems where the differences (deltas) between subsequent versions rather than the whole objects are stored - a typical model for storing versioned data. For reliability, we propose erasure encoding techniques that exploit the sparsity of information in the deltas while storing them reliably in a distributed back-end storage system, resulting in improved I/O read performance to retrieve the whole versioned archive. Along with the basic techniques, we propose a few optimization heuristics, and evaluate the techniques' efficacy analytically and with numerical simulations.", "total_citations": {"2015": 1, "2016": 3, "2017": 0, "2018": 1, "2019": 1, "2020": 0, "2021": 1, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:bnK-pcrLprsC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S1574119212001162", "authors": ["Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2013/4/1", "journal": "Pervasive and Mobile Computing", "volume": "9", "issue": "2", "pages": "324-335", "publisher": "Elsevier", "description": "In this paper we propose GoDisco++, a gossip based approach for information dissemination in online social community networks. GoDiscoo++ uses local information available to nodes\u2014that is information associated with a node and its neighbors. The algorithm exploits multiple relations which may exist between nodes, and applies social principles and behavior inspired decentralized mechanisms for targeted dissemination. The dissemination process works with the dual aims of (i) maximizing the spread among relevant nodes (high recall) and (ii) minimizing spamming among non-relevant nodes (high precision). Such a designed dissemination scheme can have interesting applications like probabilistic publish/subscribe, decentralized recommendation and contextual advertisement systems, to name a few. We validate the proposed approach with simulation experiments performed using real and synthetic\u00a0\u2026", "total_citations": {"2013": 2, "2014": 0, "2015": 1, "2016": 0, "2017": 1, "2018": 3, "2019": 1, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:B3FOqHPlNUQC": {"external_link": "https://arxiv.org/abs/1206.2187", "authors": ["Lluis Pamies-Juarez", "Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2012/6/11", "journal": "arXiv preprint arXiv:1206.2187", "description": "Erasure coding techniques are getting integrated in networked distributed storage systems as a way to provide fault-tolerance at the cost of less storage overhead than traditional replication. Redundancy is maintained over time through repair mechanisms, which may entail large network resource overheads. In recent years, several novel codes tailor-made for distributed storage have been proposed to optimize storage overhead and repair, such as Regenerating Codes that minimize the per repair traffic, or Self-Repairing Codes which minimize the number of nodes contacted per repair. Existing studies of these coding techniques are however predominantly theoretical, under the simplifying assumption that only one object is stored. They ignore many practical issues that real systems must address, such as data placement, de/correlation of multiple stored objects, or the competition for limited network resources when multiple objects are repaired simultaneously. This paper empirically studies the repair performance of these novel storage centric codes with respect to classical erasure codes by simulating realistic scenarios and exploring the interplay of code parameters, failure characteristics and data placement with respect to the trade-offs of bandwidth usage and speed of repairs.", "total_citations": {"2011": 1, "2012": 0, "2013": 5, "2014": 1, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:RGFaLdJalmkC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5767002/", "authors": ["Anwitaman Datta"], "publication_date": "2010/10/9", "conference": "6th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2010)", "pages": "1-9", "publisher": "IEEE", "description": "In this (invited) paper, we present a work in progress social library and reference management system called SoJa (Social Jabref), which is realized on top of a decentralized (peer-to-peer) social information system. The contribution of the work is multi-fold. It provides a platform to collaborate and socialize to carry out a specific task (managing and sharing bibliographic meta-information). From systems design perspective, it is an effort to realize social software on a peer-to-peer infrastructure, as well as make such a peer-to-peer system robust and reliable by leveraging on the social network. Particularly, we discuss how (we think) social networks can be leveraged to build reliable indexing, routing and storage services. We elaborate on the SocialCircle DHT which exclusively uses social links, and hence is expected to be naturally robust against various kinds of attacks. We also discuss several open challenges\u00a0\u2026", "total_citations": {"2011": 1, "2012": 1, "2013": 2, "2014": 0, "2015": 1, "2016": 0, "2017": 1, "2018": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:D03iK_w7-QYC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5591325/", "authors": ["Xin Liu", "Tomasz Kaszuba", "Radoslaw Nielek", "Anwitaman Datta", "Adam Wierzbicki"], "publication_date": "2010/8/20", "conference": "2010 IEEE Second International Conference on Social Computing", "pages": "513-520", "publisher": "IEEE", "description": "Encountering unknown sellers is very common in online auction sites. In such a scenario, a buyer can not estimate trustworthiness of the unknown seller based on the seller's past behavior. The buyer is thus exposed to the risks of being cheated. In this paper we describe a stereotypes based mechanism to determine the risk of a potential transaction even if the seller is personally unknown to not only the buyer but also to the rest of the system. Specifically, our approach first identifies discriminating attributes which are capable of distinguishing successful transactions from unsuccessful ones. A buyer can use its own past transactions (with other sellers) to form such stereotypes. Alternatively, the community's collective knowledge can also be used to build such stereotypes. When posed to a potential transaction with an unknown seller, buyers can estimate trustworthiness (and thus the risk) by combining the\u00a0\u2026", "total_citations": {"2011": 1, "2012": 2, "2013": 2, "2014": 1, "2015": 0, "2016": 2, "2017": 0, "2018": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:7PzlFSSx8tAC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-05118-0_36", "authors": ["Xin Liu", "Anwitaman Datta"], "publication_date": "2009", "conference": "Stabilization, Safety, and Security of Distributed Systems: 11th International Symposium, SSS 2009, Lyon, France, November 3-6, 2009. Proceedings 11", "pages": "515-530", "publisher": "Springer Berlin Heidelberg", "description": "Maintaining redundancy in P2P storage systems is essential for reliability guarantees. Numerous P2P storage system maintenance algorithms have been proposed in the last years, each supposedly improving upon the previous approaches. We perform a systematic comparative study of the various strategies taking also into account the influence of different garbage collection mechanisms, an issue not studied so far. Our experiments show that while some strategies generally perform better than some others, there is no universally best strategy, and their relative superiority depends on various other design choices as well as the specific evaluation criterion. Our results can be used by P2P storage systems designers to make prudent design decisions, and our exploration of the various evaluation metrics also provides a more comprehensive framework to compare algorithms for P2P storage systems. While\u00a0\u2026", "total_citations": {"2011": 3, "2012": 3, "2013": 1, "2014": 1, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:5icHVeHT4IsC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9340178/", "authors": ["Bhawani Shanker Bhati", "Jordan Ivanchev", "Iva Bojic", "Anwitaman Datta", "David Eckhoff"], "publication_date": "2021/1/29", "journal": "IEEE Access", "volume": "9", "pages": "23608-23623", "publisher": "IEEE", "description": "In this article, we propose a    -anonymity approach that prioritizes the generalization of attributes based on their utility. We focus on transport data, which we consider a special case in which many or all attributes are quasi-identifiers (e.g., origin, destination, ride start time), as they allow correlation with easily observable auxiliary data. The novelty in our approach lies in introducing normalization techniques as well as distance and utility metrics that allow the consideration of not only numerical attributes but also categorical attributes by representing them in tree or graph form. The prioritization of the attributes in the generalization process is based on the attributes\u2019 utility and can further be influenced by either automatically or manually assigned attribute weights. We evaluate and compare different options for all components of our mechanism as well as present an extensive performance evaluation of our approach\u00a0\u2026", "total_citations": {"2022": 6, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:tYavs44e6CUC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2833312.2833452", "authors": ["Ertem Esiner", "Anwitaman Datta"], "publication_date": "2016/1/4", "book": "Proceedings of the 17th International Conference on Distributed Computing and Networking", "pages": "1-10", "description": "In this paper we propose a protocol that allows end-users in a decentralized setup (without requiring any trusted third party) to protect data shipped to remote servers using two factors - knowledge (passwords) and possession (a time based one time password generation for authentication) that is portable. The protocol also supports revocation and recreation of a new possession factor if the older possession factor is compromised, provided the legitimate owner still has a copy of the possession factor. Furthermore, akin to some other recent works, our approach naturally protects the outsourced data from the storage servers themselves, by application of encryption and dispersal of information across multiple servers. We also extend the basic protocol to demonstrate how collaboration can be supported even while the stored content is encrypted, and where each collaborator is still restrained from accessing the data\u00a0\u2026", "total_citations": {"2016": 1, "2017": 0, "2018": 1, "2019": 2, "2020": 1, "2021": 0, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:LjlpjdlvIbIC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6570839/", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2013/6/7", "conference": "2013 International Symposium on Network Coding (NetCod)", "pages": "1-6", "publisher": "IEEE", "description": "Erasure coding provides a mechanism to store data redundantly for fault-tolerance in a cost-effective manner. Recently, there has been a renewed interest in designing new erasure coding techniques with different desirable properties, including good repairability and degraded read performance, or efficient redundancy generation processes. Very often, these novel techniques exploit the computational resources available `in the network', i.e., leverage on storage units which are not passive entities supporting only read/write of data, but also can carry out some computations. This article accompanies an identically titled tutorial at the IEEE International Symposium on Network Coding (NetCod 2013), and portrays a big picture of some of the important processes within distributed storage systems, where erasure codes designed by explicitly taking into account the nuances of distributed storage systems can provide\u00a0\u2026", "total_citations": {"2015": 3, "2016": 1, "2017": 1, "2018": 2, "2019": 0, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:WA5NYHcadZ8C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6413594/", "authors": ["Stefano Braghin", "Jackson Tan Teck Yong", "Anthony Ventresque", "Anwitaman Datta"], "publication_date": "2012/12/17", "conference": "2012 IEEE 18th International Conference on Parallel and Distributed Systems", "pages": "845-850", "publisher": "IEEE", "description": "Team recommendation aids decision support, by not only identifying individuals who are experts for various aspects of a complex task, but also determining various properties of the team as a group. Several aspects such as cohesion and repetition of teams have been identified as important indicators, besides individuals' expertise, in determining how well a team performs. While such information often do not exist explicitly, digital footprint of users' activities can be harnessed to retrieve the same from diverse sources. In this work, we lay out a proof-of-concept on how to do so in the case of scientific knowledge workers, as well as demonstrate some necessary visualization, manipulation and communication tools to determine and manage multi-disciplinary teams. While the focus of our presentation is the specific application 'SWAT' for team recommendation, it also serves as a vehicle demonstrating how, in general\u00a0\u2026", "total_citations": {"2013": 1, "2014": 5, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 1, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:35N4QoGY0k4C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-24704-0_33", "authors": ["Anthony Ventresque", "Jackson Tan Teck Yong", "Anwitaman Datta"], "publication_date": "2011", "conference": "Social Informatics: Third International Conference, SocInfo 2011, Singapore, October 6-8, 2011. Proceedings 3", "pages": "296-299", "publisher": "Springer Berlin Heidelberg", "description": "Forming multidisciplinary teams is a key to carry out complex tasks, which is increasingly the case higher up in the knowledge value chain. In this paper, we study academic teams, by proposing a representation of the information available from various data sources, through (i) competence, (ii) social and (iii) team networks. Each of these projections of the interactions between individuals and concepts have specific characteristics. We then empirically evaluate the impact of these notions on team formation process. The objective is to guide team recommendation systems design.", "total_citations": {"2012": 1, "2013": 0, "2014": 3, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 1, "2020": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:JV2RwH3_ST0C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5583207/", "authors": ["Christian von der Weth", "Anwitaman Datta", "Sally Ang"], "publication_date": "2010/7/19", "conference": "2010 IEEE International Conference on Multimedia and Expo", "pages": "272-273", "publisher": "IEEE", "description": "User-generated content in the spirit of Web 2.0 is a promising means to improve the search for relevant information on the web, particularly multimedia content. The idea is that user col-laboratively search or browse for information, either directly by communicating or indirectly by adding meta information (e.g., tags) to web pages. However, current solutions are bound to specific web sites providing such features. To overcome this limitation we introduce COBS, making Web 2.0 features available also for the 'old' web. In this demo we present the front-end, a browser add-on that enables users to tag, rate or comment arbitrary web pages and to communicate with others in both a synchronous and asynchronous manner.", "total_citations": {"2010": 1, "2011": 2, "2012": 1, "2013": 2, "2014": 1, "2015": 0, "2016": 0, "2017": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:M3ejUd6NZC8C": {"external_link": "https://infoscience.epfl.ch/record/118259", "authors": ["Sarunas Girdzijauskas", "Wojciech Galuba", "Vasilios Darlagiannis", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2008", "issue": "REP_WORK", "description": "Many structured overlay networks rely on a ring invariant as a core network connectivity element. The responsibility ranges of the participating peers and navigability principles (greedy routing) heavily depend on the ring structure. For correctness guarantees, each node needs to eagerly maintain its immediate neighboring links-the ring invariant. However, the ring maintenance is an expensive task and it may not even be possible to maintain the ring invariant continuously under high churn, particularly as the network size grows. Furthermore, routing anomalies in the network, peers behind firewalls and Network Address Translators (NATs) create non-transitivity effects, which inevitably lead to the violation of the ring invariant. We argue that reliance on the ring structure is a serious impediment for real life deployment and scalability of structured overlays. In this paper we propose an overlay called Fuzzynet, which does not rely on the ring invariant, yet have all the functionalities of structured overlays. Fuzzynet takes the idea of lazy overlay maintenance further by dropping any explicit connectivity and data maintenance requirement, relying merely on the actions performed when new Fuzzynet peers join the network. We show that with sufficient amount of neighbors (O (logN), comparable to traditional structured overlays), even under high churn, data can be retrieved in Fuzzynet whp We validate our novel design principles by simulations as well as PlanetLab experiments and compare it with ring based overlays.", "total_citations": {"2009": 3, "2010": 3, "2011": 0, "2012": 0, "2013": 1, "2014": 0, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:4TOpqqG69KYC": {"external_link": "https://infoscience.epfl.ch/record/54442/files/Aberer05PGrid.pdf", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth", "Roman Schmidt"], "publication_date": "2005", "source": "Datenbank Spektrum", "issue": "ARTICLE", "pages": "5-13", "description": "2 DesignIn diesem Abschnitt geben wir einen \u00dcberblick \u00fcber den Entwurf der Struktur von P-Grid sowie den wichtigsten Algorithmen zur Wartung eines P-Grid-Netzwerkes in einer dynamischen Netzwerkumgebung.", "total_citations": {"2006": 3, "2007": 3, "2008": 1, "2009": 0, "2010": 0, "2011": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:4X0JR2_MtJMC": {"external_link": "https://ojs.aaai.org/index.php/ICWSM/article/view/19383", "authors": ["Shakshi Sharma", "Ekanshi Agrawal", "Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2022/5/31", "journal": "Proceedings of the International AAAI Conference on Web and Social Media", "volume": "16", "pages": "1312-1321", "description": "COVID-19, which was first detected in late 2019 in Wuhan, China, has spread to the rest of the world and is currently deemed a global pandemic. A flux of events triggered by a wide ranging set of factors such as virus mutations and waves of infections, imperfect medical and policy interventions, and vested interest driven political posturing all have created a continuous state of uncertainty and strife. In this verbile environment, misinformation and fake news thrive and propagate easily through the modern efficient all-pervading media and social media tools, resulting in an infodemic running its course in conjunction with the pandemic. In this work, we present a COVID-19 related dataset\u2013FaCov\u2013a compilation of fact-checking articles that examine and evaluate some of the most widely circulated rumors and claims concerning the coronavirus. We have collected articles from 13 very popular fact-checking sources, along with information about the articles and the vetted verity assigned to the claims being evaluated. We also share insights into the dataset to highlight and understand the major conversations and conflicts in narratives encompassing the pandemic.", "total_citations": {"2022": 4, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:0N-VGjzr574C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8038443/", "authors": ["Thomas Paul", "Niklas Lochschmidt", "Hani Salah", "Anwitaman Datta", "Thorsten Strufe"], "publication_date": "2017/7/31", "conference": "2017 26th International Conference on Computer Communication and Networks (ICCCN)", "pages": "1-10", "publisher": "IEEE", "description": "P2P-based social networking services are severely challenged by churn and the lack of reliable service providers, especially considering the high frequency of posts and profile updates of their users. Improved consistency and data availability shall facilitate better acceptance, which in turn will enhance privacy, an inherent benefit of this class of systems. We present Lilliput, a P2P storage primitive designed with the characteristics of Online Social Network workloads in mind. Lilliput separates the storage of static bulk data (videos and photo albums) from the essential social glue (e.g. basic profile information, frequent updates, notifications, and personal messages): it provides the latter through agile, lightweight replica groups. Extensive simulations show that Lilliput ensures high data availability (99.07% to 99.64%) and consistency, with a small bandwidth usage under realistic usage and load models.", "total_citations": {"2017": 1, "2018": 2, "2019": 0, "2020": 0, "2021": 1, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:S16KYo8Pm5AC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7851142/", "authors": ["Piotr Skowron", "Krzysztof Rzadca", "Anwitaman Datta"], "publication_date": "2017/2/13", "journal": "IEEE Intelligent Systems", "volume": "32", "issue": "1", "pages": "17-23", "publisher": "IEEE", "description": "To successfully complete a complex project, agents (companies or individuals) must form a team with the required competencies and resources. A team can be formed either by the project issuer based on individual agents' offers (centralized formation) or by the agents themselves (decentralized formation) bidding for a project as a consortium. The authors investigate rational strategies for agents, propose concepts to characterize the stability of winning teams and study computational complexity of finding these concepts of stability.", "total_citations": {"2016": 1, "2017": 1, "2018": 0, "2019": 1, "2020": 0, "2021": 1, "2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:kzcrU_BdoSEC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0164121213002835", "authors": ["Dinh Tien Tuan Anh", "Milind Ganjoo", "Stefano Braghin", "Anwitaman Datta"], "publication_date": "2014/6/1", "journal": "Journal of Systems and Software", "volume": "92", "pages": "20-31", "publisher": "Elsevier", "description": "The proliferation of mobile devices coupled with Internet access is generating a tremendous amount of highly personal and sensitive data. Applications such as location-based services and quantified self harness such data to bring meaningful context to users\u2019 behavior. As social applications are becoming prevalent, there is a trend for users to share their mobile data. The nature of online social networking poses new challenges for controlling access to private data, as compared to traditional enterprise systems. First, the user may have a large number of friends, each associated with a unique access policy. Second, the access control policies must be dynamic and fine-grained, i.e. they are content-based, as opposed to all-or-nothing. In this paper, we investigate the challenges in sharing of mobile data in social applications. We design and evaluate a middleware running on Google App Engine, named Mosco, that\u00a0\u2026", "total_citations": {"2014": 2, "2015": 0, "2016": 3, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:geHnlv5EZngC": {"external_link": "https://link.springer.com/article/10.1007/s00607-012-0201-4", "authors": ["Anwitaman Datta"], "publication_date": "2012/9", "journal": "Computing", "volume": "94", "pages": "783-809", "publisher": "Springer Vienna", "description": "Peer-to-peer index structures distributed and managed over the planet, commonly known as structured overlays (e.g., distributed hash tables) have been touted to play the role of a fundamental building block for internet-scale distributed systems. Traditional designs consider incremental or possibly even parallelized construction of a single overlay, which implicitly assumes global control and coordination to enforce the construction of an unique overlay. However, if merger of originally isolated overlays is made possible, then one can realize decentralized bootstrapping of overlays. So to say, smaller overlays can be constructed using any of the traditional mechanisms, which can then organically coalesce to form a larger overlay. Such self-organizational attributes of decentralized bootstrapping and organic growth are of paramount importance for large scale systems. In our previous works, we explained the\u00a0\u2026", "total_citations": {"2013": 1, "2014": 0, "2015": 2, "2016": 1, "2017": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:TQgYirikUcIC": {"external_link": "https://ink.library.smu.edu.sg/sis_research/2406/", "authors": ["Hock Hee Ang", "Vikvekanand GOPALKRISHNAN", "Steven CH Hoi", "Wee Keong Ng", "Anwitaman Datta"], "publication_date": "2008", "pages": "13", "publisher": "VLDB Endowment", "description": "Data mining tasks in P2P are bound by issues like scalability, peer dynamism, asynchronism, and data privacy preservation. These challenges pose difficulties for deploying conventional machine learning techniques in P2P networks, which may be hard to achieve classification accuracies comparable to regular centralized solutions. We recently investigated the classification problem in P2P networks and proposed a novel P2P classification approach by cascading Reduced Support Vector Machines (RSVM). Although promising results were obtained, the existing solution has some drawback of redundancy in both communication and computation. In this paper, we present a new approach to over the limitation of the previous approach. The new method can effectively reduce the redundancy and thus significantly improve the efficiency of communication and computation, meanwhile it still maintains good classification accuracies comparable to both the centralized solution and the previously proposed P2P solution. Experimental results demonstrate the feasibility and effectiveness of the new P2P classification solution.", "total_citations": {"2009": 1, "2010": 1, "2011": 1, "2012": 0, "2013": 2, "2014": 1, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:qxL8FJ1GzNcC": {"external_link": "https://infoscience.epfl.ch/record/54383", "authors": ["Karl Aberer", "Philippe Cudr\u00e9-Mauroux", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2003", "source": "Ubiquitous Mobile Information and Collaboration Systems (UMICS 2003)", "issue": "CONF", "description": "The proliferation of digital camera devices (stand-alone or combined with cell phones), new protocols such as MMS and the desire of people to com-municate and share their experience call for new systems to support these needs in new Internet-scale infrastructures. In this paper we outline our plans for an Internet-scale P2P system that enables users to share (globally or only within a group) and efficiently locate photographs based on semi-automatically provided meta-information (by the devices and the user).", "total_citations": {"2005": 1, "2006": 0, "2007": 3, "2008": 1, "2009": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:OR75R8vi5nAC": {"external_link": "https://peerj.com/articles/cs-220/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Silivanxay Phetsouvanh", "Anwitaman Datta"], "publication_date": "2019/9/16", "journal": "PeerJ Computer Science", "volume": "5", "pages": "e220", "publisher": "PeerJ Inc.", "description": "The notion of entropic centrality measures how central a node is in terms of how uncertain the destination of a flow starting at this node is: the more uncertain the destination, the more well connected and thus central the node is deemed. This implicitly assumes that the flow is indivisible, and at every node, the flow is transferred from one edge to another. The contribution of this paper is to propose a split-and-transfer flow model for entropic centrality, where at every node, the flow can actually be arbitrarily split across choices of neighbours. We show how to map this to an equivalent transfer entropic centrality set-up for the ease of computation, and carry out three case studies (an airport network, a cross-shareholding network and a Bitcoin transactions subnetwork) to illustrate the interpretation and insights linked to this new notion of centrality.", "total_citations": {"2020": 1, "2021": 2, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:WJVC3Jt7v1AC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167739X17322859", "authors": ["Ertem Esiner", "Anwitaman Datta"], "publication_date": "2019/1/1", "journal": "Future Generation Computer Systems", "volume": "90", "pages": "291-306", "publisher": "North-Holland", "description": "We propose a trusted third party free protocol for secure (in terms of content access, manipulation, and confidentiality) data storage and multi-user collaboration over an infrastructure of untrusted storage servers. It is achieved by the application of data dispersal, encryption as well as two-factor (knowledge and possession) based authentication and access control techniques so that unauthorized parties (attackers) or a small set of colluding servers cannot gain access to the stored data. The protocol design takes into account usability issues as opposed to the closest prior work Esiner and Datta (2016). We explore the security implications of the proposed model with event tree analysis and report on experiment results to demonstrate the practicality of the approach concerning computational overheads. Given that the protocol does not rely on any trusted third party, and most operations including actual collaboration do\u00a0\u2026", "total_citations": {"2020": 3, "2021": 1, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:vbGhcppDl1QC": {"external_link": "https://arxiv.org/abs/1503.05434", "authors": ["J Harshan", "Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2015/3/17", "journal": "arXiv preprint arXiv:1503.05434", "description": "In this paper, we study the problem of storing an archive of versioned data in a reliable and efficient manner in distributed storage systems. We propose a new storage technique called differential erasure coding (DEC) where the differences (deltas) between subsequent versions are stored rather than the whole objects, akin to a typical delta encoding technique. However, unlike delta encoding techniques, DEC opportunistically exploits the sparsity (i.e., when the differences between two successive versions have few non-zero entries) in the updates to store the deltas using compressed sensing techniques applied with erasure coding. We first show that DEC provides significant savings in the storage size for versioned data whenever the update patterns are characterized by in-place alterations. Subsequently, we propose a practical DEC framework so as to reap storage size benefits against not just in-place alterations but also real-world update patterns such as insertions and deletions that alter the overall data sizes. We conduct experiments with several synthetic workloads to demonstrate that the practical variant of DEC provides significant reductions in storage overhead (up to 60\\% depending on the workload) compared to baseline storage system which incorporates concepts from Rsync, a delta encoding technique to store and synchronize data across a network.", "total_citations": {"2014": 1, "2015": 0, "2016": 2, "2017": 2, "2018": 0, "2019": 0, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:wbdj-CoPYUoC": {"external_link": "https://arxiv.org/abs/1210.0660", "authors": ["Tien Tuan Anh Dinh", "Anwitaman Datta"], "publication_date": "2012/10/2", "journal": "arXiv preprint arXiv:1210.0660", "description": "There is an increasing trend for businesses to migrate their systems towards the cloud. Security concerns that arise when outsourcing data and computation to the cloud include data confidentiality and privacy. Given that a tremendous amount of data is being generated everyday from plethora of devices equipped with sensing capabilities, we focus on the problem of access controls over live streams of data based on triggers or sliding windows, which is a distinct and more challenging problem than access control over archival data. Specifically, we investigate secure mechanisms for outsourcing access control enforcement for stream data to the cloud. We devise a system that allows data owners to specify fine-grained policies associated with their data streams, then to encrypt the streams and relay them to the cloud for live processing and storage for future use. The access control policies are enforced by the cloud, without the latter learning about the data, while ensuring that unauthorized access is not feasible. To realize these ends, we employ a novel cryptographic primitive, namely proxy-based attribute-based encryption, which not only provides security but also allows the cloud to perform expensive computations on behalf of the users. Our approach is holistic, in that these controls are integrated with an XML based framework (XACML) for high-level management of policies. Experiments with our prototype demonstrate the feasibility of such mechanisms, and early evaluations suggest graceful scalability with increasing numbers of policies, data streams and users.", "total_citations": {"2012": 1, "2013": 0, "2014": 0, "2015": 4, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:XiSMed-E-HIC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-25959-3_35", "authors": ["Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2012", "conference": "Distributed Computing and Networking: 13th International Conference, ICDCN 2012, Hong Kong, China, January 3-6, 2012. Proceedings 13", "pages": "473-487", "publisher": "Springer Berlin Heidelberg", "description": "Information dissemination in a decentralized network is a challenging issue as no single node can have knowledge of the whole network for reasons like security, access control, memory. Most importantly - a centralized service provider is missing which can cater to user requests. In this paper we propose and investigate an algorithm for information dissemination in decentralized networks which only uses local information - that is information associated with a node and its neighbors for disseminating a piece of information with a goal of maximum coverage and minimum spamming. The approach emulates multiagent system using particle swarms, and explores multiple relations that exist among nodes while selecting potential forwarders in case members having same interests are not well connected. The approach is generic enough to be used in various kinds of scenarios: for example in job market or\u00a0\u2026", "total_citations": {"2013": 2, "2014": 0, "2015": 2, "2016": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:qUcmZB5y_30C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5230728/", "authors": ["Lukasz Zaczek", "Anwitaman Datta"], "publication_date": "2009/6/22", "conference": "2009 International Workshop on Social Informatics", "pages": "10-15", "publisher": "IEEE", "description": "This paper presents our approach to use social network information in P2P networks in order to efficiently retrieve relevant information by exploiting existing trust relations of the social network links. The novelty of our work is to demonstrate that only a subset of the whole social network is adequate to build an efficient and reliable service. We use our P2P network, which is an adaptation of virtual ring routing mechanisms originally proposed for ad-hoc networks, to deploy a directory service facilitating search for friends - a common functionality required in online social networks as well. We expect our mechanism can be used in facilitating the deployment of peer-to-peer online social networks. Small scale experiment results, using both artificial as well as real social network graphs, show that with even only small subset of nodes from the whole social network, the approach achieves a high level of query success.", "total_citations": {"2010": 2, "2011": 1, "2012": 0, "2013": 0, "2014": 1, "2015": 0, "2016": 0, "2017": 1, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:gKiMpY-AVTkC": {"external_link": "https://arxiv.org/abs/2102.05568", "authors": ["Qikun Xiang", "Ariel Neufeld", "Gareth W Peters", "Ido Nevat", "Anwitaman Datta"], "publication_date": "2021/2/10", "journal": "arXiv preprint arXiv:2102.05568", "description": "The cyber risk insurance market is at a nascent stage of its development, even as the magnitude of cyber losses is significant and the rate of cyber risk events is increasing. Existing cyber risk insurance products as well as academic studies have been focusing on classifying cyber risk events and developing models of these events, but little attention has been paid to proposing insurance risk transfer strategies that incentivize mitigation of cyber loss through adjusting the premium of the risk transfer product. To address this important gap, we develop a Bonus-Malus model for cyber risk insurance. Specifically, we propose a mathematical model of cyber risk insurance and cybersecurity provisioning supported with an efficient numerical algorithm based on dynamic programming. Through a numerical experiment, we demonstrate how a properly designed cyber risk insurance contract with a Bonus-Malus system can resolve the issue of moral hazard and benefit the insurer.", "total_citations": {"2022": 3, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:DUooU5lO8OsC": {"external_link": "https://patents.google.com/patent/US20180024746A1/en", "inventors": "Harshan Jagadeesh, Anwitaman Datta, Frederique Oggier", "publication_date": "2018/1/25", "patent_office": "US", "application_number": "15550317", "description": "There is provided a method of encoding multiple versions of data. The method includes computing a difference between a version of a data object and a subsequent version of the data object to produce a difference object, determining a sparsity level of the difference 10 object; determining whether the sparsity level satisfies a predetermined condition; and compressing the difference object to produce a compressed difference object and erasure encoding the compressed difference object to produce a codeword if the sparsity level is determined to satisfy the predetermined condition. There is also provided a corresponding method of decoding encoded multiple versions of data, a method of storing multiple 15 versions of data in a distributed storage system, and a distributed storage system.", "total_citations": {"2019": 1, "2020": 2, "2021": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:lmc2jWPfTJgC": {"external_link": "https://link.springer.com/article/10.1007/s00607-015-0468-3", "authors": ["Anwitaman Datta", "Lluis Pamies-Juarez", "Frederique Oggier"], "publication_date": "2016/3", "journal": "Computing", "volume": "98", "pages": "319-341", "publisher": "Springer Vienna", "description": "Erasure coding has become an integral part of the storage infrastructure in data-centers and cloud backends\u2014since it provides significantly higher fault tolerance for substantially lower storage overhead compared to a naive approach like n-way replication. Fault tolerance refers to the ability to achieve very high availability despite (temporary) failures, but for long term data durability, the redundancy provided by erasure coding needs to be replenished as storage nodes fail or are retired. Traditional erasure codes are not easily amenable to repairs, and their repair process is usually both expensive and slow. Consequently, in recent years, numerous novel codes tailor-made for distributed storage have been proposed to optimize the repair process. Broadly, most of these codes belong to either of the two following families: network coding inspired regenerating codes that aim at minimizing the per repair traffic\u00a0\u2026", "total_citations": {"2016": 2, "2017": 0, "2018": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:uWiczbcajpAC": {"external_link": "https://link.springer.com/article/10.1007/s00607-014-0426-5", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2015/2", "journal": "Computing", "volume": "97", "pages": "171-201", "publisher": "Springer Vienna", "description": "Networked distributed data storage systems are essential to deal with the needs of storing massive volumes of data. Dependability of such a system relies on its fault tolerance (data should be available in case of node failures) as well as its maintainability (its ability to repair lost data to ensure redundancy replenishment over time). Erasure codes provide a storage efficient alternative to replication based redundancy in storage systems, ensuring the same fault tolerance at a lower storage overhead cost. Traditional erasure codes however have the drawback of entailing high communication overhead for maintenance, when encoded fragments are lost due to storage device failures, and need to be replenished in new nodes. We propose a new family of erasure codes called self-repairing codes (SRC) taking into account the peculiarities of distributed storage systems, specifically to improve its maintainability\u00a0\u2026", "total_citations": {"2016": 3, "2017": 1, "2018": 0, "2019": 0, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:UxriW0iASnsC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2009916.2010155", "authors": ["Aixin Sun", "Anwitaman Datta", "Ee-Peng Lim", "Kuiyu Chang"], "publication_date": "2011/7/24", "book": "Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval", "pages": "1271-1272", "description": "We demonstrate SSNetViz that is developed for integrating, visualizing and querying heterogeneous semantic social networks obtained from multiple information sources. A semantic social network refers to a social network graph with multi-typed nodes and links. We demonstrate various innovative features of SSNetViz with social networks from three information sources covering a similar set of entities and relationships in terrorism domain.", "total_citations": {"2012": 1, "2013": 1, "2014": 1, "2015": 0, "2016": 0, "2017": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:HoB7MX3m0LUC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2009916.2010098", "authors": ["Chenliang Li", "Anwitaman Datta", "Aixin Sun"], "publication_date": "2011/7/24", "book": "Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval", "pages": "1159-1160", "description": "The common tags given by multiple users to a particular document are often semantically relevant to the document and each tag represents a specific topic. In this paper, we attempt to emulate human tagging behavior to recommend tags by considering the concepts contained in documents. Specifically, we represent each document using a few most relevant concepts contained in the document, where the concept space is derived from Wikipedia. Tags are then recommended based on the tag concept model derived from the annotated documents of each tag. Evaluated on a Delicious dataset of more than 53K documents, the proposed technique achieved comparable tag recommendation accuracy as the state-of-the-art, while yielding an order of magnitude speed-up.", "total_citations": {"2012": 1, "2013": 1, "2014": 0, "2015": 0, "2016": 0, "2017": 0, "2018": 1, "2019": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:TFP_iSt0sucC": {"external_link": "https://aamas.csc.liv.ac.uk/Proceedings/aamas2011/papers/R3.pdf", "authors": ["Liu Xin", "Gilles Tredan", "Anwitaman Datta"], "publication_date": "2011/5/2", "book": "The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 3", "pages": "1071-1072", "description": "A traditional approach to reasoning about the trustworthiness of a transaction is to determine the trustworthiness of the specific agent involved, based on its past behavior. As a departure from such traditional trust models, we propose a transaction centered trust model (MetaTrust) where an agent uses its previous transactions to assess the trustworthiness of a potential transaction based on associated metainformation, which is capable of distinguishing successful transactions from unsuccessful ones. This meta information is harnessed using a machine learning algorithm (namely, discriminant analysis) to extract relationships between the potential transaction and previous transactions.", "total_citations": {"2011": 1, "2012": 0, "2013": 1, "2014": 0, "2015": 2, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:e5wmG9Sq2KIC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1593254.1593288", "authors": ["Ee-Peng Lim", "Maureen", "Nelman Lubis Ibrahim", "Aixin Sun", "Anwitaman Datta", "Kuiyu Chang"], "publication_date": "2009/8/12", "book": "Proceedings of the 11th International Conference on Electronic Commerce", "pages": "213-221", "description": "SSnetViz is an ongoing research to design and implement a visualization engine for heterogeneous semantic social networks. A semantic social network is a multi-modal network that contains nodes representing different types of people or object entities, and edges representing relationships among them. When multiple heterogeneous semantic social networks are to be visualized together, SSnetViz provides a suite of functions to store heterogeneous semantic social networks, to integrate them for searching and analysis. We will illustrate these functions using social networks related to terrorism research, one crafted by domain experts and another from Wikipedia.", "total_citations": {"2010": 2, "2011": 1, "2012": 0, "2013": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:ns9cj8rnVeAC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0743731509000100", "authors": ["Zhijun Wang", "Anwitaman Datta", "Sajal K Das", "Mohan Kumar"], "publication_date": "2009/4/1", "journal": "Journal of parallel and distributed computing", "volume": "69", "issue": "4", "pages": "360-372", "publisher": "Academic Press", "description": "Peer-to-peer (P2P) has become a mainstream architecture in numerous diverse distributed applications. However current P2P systems do not provide consistency guarantees under multiple reader multiple writer scenarios. Such a feature is desirable as well as necessary for supporting more diverse applications than merely file-sharing systems. In this paper, we develop a highly scalable and efficient algorithm, called Consistency Maintenance through Virtual servers (CMV), in P2P systems. In this algorithm, consistency of each dynamic file is maintained by a Virtual Server (VS). A file update can only be accepted through the VS to ensure one-copy serializability consistency. The VS of a file is a logical network composed of multiple Replica Peers (RPs) that have replicas of the file. Mathematical analysis is performed for optimal parameter selections that achieve minimum overhead messages for maintaining file\u00a0\u2026", "total_citations": {"2016": 2, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 1, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:4vMrXwiscB8C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8664249/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Silivanxay Phetsouvanh", "Anwitaman Datta"], "publication_date": "2018/10/28", "conference": "2018 International Symposium on Information Theory and Its Applications (ISITA)", "pages": "242-246", "publisher": "IEEE", "description": "We revisit a Renyi entropy based measure introduced originally for image clustering [1], and study its application to graph clustering. To effectuate Renyi entropy based graph clustering, we propose a simulated annealing algorithm. We explore our algorithm's efficacy and limitations with the Karate club graph [2], as well as some other real world network.", "total_citations": {"2019": 3, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Z5m8FVwuT1cC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6970792/", "authors": ["Anwitaman Datta"], "publication_date": "2014/11/2", "conference": "2014 IEEE Information Theory Workshop (ITW 2014)", "pages": "60-64", "publisher": "IEEE", "description": "The need to store humongous volumes of data has regurgitated the study of erasure codes, so that reliable fault-tolerant distributed (for scaling out) data stores can be built while keeping the overheads low. In the context of storage codes, one of the most vigorously researched aspect in the last half a decade or so is their repairability - which looks into mechanisms to rebuild the data at a new storage node, to substitute the loss of information when an existing node fails. Desirable (sometimes mutually conflicting or reinforcing) repairability properties include reduction in the volume of I/O operations, minimize bandwidth usage, fast repairs, reduction in the number of live nodes to be contacted to carry out a repair (repair locality), repairing multiple failures simultaneously, etc.", "total_citations": {"2016": 1, "2017": 0, "2018": 0, "2019": 0, "2020": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:IUKN3-7HHlwC": {"external_link": "https://cogcomp.seas.upenn.edu/papers/fact_finder_chapter_clean.pdf", "authors": ["Jeff Pasternack", "Dan Roth", "X Liu", "A Datta", "EP Lim"], "publication_date": "2014", "journal": "Computational Trust Models and Machine Learning", "pages": "39-72", "publisher": "Chapman and Hall/CRC", "description": "The Information Age has made publishing, distributing and collecting information easier, resulting in the exponential growth of information available to us. Databases were once ledgers written by hand by a single person; today they can be vast stores of data agglomerated from a myriad of disparate sources. The mass media, formerly limited to newspapers and television programs held to strict journalistic standards, has expanded to include collaborative content such as blogs, wikis, and message boards. Documents covering nearly every topic abound on the Internet, but the authors are often anonymous and the accuracy uncertain.To cope with this new abundance, we employ information retrieval to suggest documents, and information extraction to tell us what they say, but how can we determine what we should actually believe? Not all information sources are equally trustworthy, and simply accepting the majority view often leads to errors: a Google search for \u201cwater runs downhill\u201d returns 17.5 K documents, while \u201cwater runs uphill\u201d yields 116K.", "total_citations": {"2016": 1, "2017": 1, "2018": 0, "2019": 1, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:VL0QpB8kHFEC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-38844-6_4", "authors": ["Lorenzo Bossi", "Stefano Braghin", "Anwitaman Datta", "Alberto Trombetta"], "publication_date": "2013", "conference": "User Modeling, Adaptation, and Personalization: 21th International Conference, UMAP 2013, Rome, Italy, June 10-14, 2013 Proceedings 21", "pages": "38-50", "publisher": "Springer Berlin Heidelberg", "description": "Often one needs to form teams in order to perform a complex collaborative task. Therefore, it is interesting and useful to assess how well constituents of a team have performed, and leverage this knowledge to guide future team formation. In this work we propose a model for assessing the reputation of participants in collaborative teams. The model takes into account several features such as the different skills that a participant has and the feedback of team participants on her/his previous works. We validate our model based on synthetic datasets extrapolated from real-life scenarios.", "total_citations": {"2014": 2, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:dshw04ExmUIC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S138912861000174X", "authors": ["Krzysztof Rzadca", "Jackson Tan Teck Yong", "Anwitaman Datta"], "publication_date": "2010/8/26", "journal": "Computer Networks", "volume": "54", "issue": "12", "pages": "1986-2006", "publisher": "Elsevier", "description": "Current real-time collaborative application implementations use dedicated infrastructure to carry out all communication and synchronization activities. Specifically, they require all end nodes to communicate directly with and through the central server. In this paper, we investigate scenarios in which the most resource intensive functionality of continuous communication among collaborators to disseminate changes is decentralized, utilizing the end users themselves as relays. We observe that communication characteristics of real-time collaboration makes use of existing multicast mechanisms unsuitable. As collaborative editing sessions are typically long and repeated, it is possible to gather and leverage node behavior (their instabilities and frequency of sending updates) and communication links (latencies and average costs). Several criteria to determine the quality of a multicast tree can be identified: cost, latency\u00a0\u2026", "total_citations": {"2012": 2, "2013": 0, "2014": 0, "2015": 1, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:ZHo1McVdvXMC": {"external_link": "https://link.springer.com/chapter/10.1007/978-1-4419-6515-8_10", "authors": ["Ee-Peng Lim", "Aixin Sun", "Anwitaman Datta", "Kuiyu Chang"], "publication_date": "2010", "journal": "Link Mining: Models, Algorithms, and Applications", "pages": "265-281", "publisher": "Springer New York", "description": "With increasing interest in querying and analyzing graph data from multiple sources, algorithms and tools to integrate different graphs become very important. Integration of graphs can take place at the schema and instance levels. While links among graph nodes pose additional challenges to graph information integration, they can also serve as useful features for matching nodes representing real-world entities. This chapter introduces a general framework to perform graph information integration. It then gives an overview of the state-of-the-art research and tools in graph information integration.", "total_citations": {"2014": 1, "2015": 0, "2016": 1, "2017": 1, "2018": 0, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:HDshCWvjkbEC": {"external_link": "https://www.igi-global.com/chapter/trust-fairness-management-p2p-grid/40826", "authors": ["Adam Wierzbicki", "Tomasz Kaszuba", "Radoslaw Nielek"], "publication_date": "2010", "book": "Handbook of Research on P2p and Grid Systems for Service-oriented Computing: Models, Methodologies and Applications", "pages": "748-773", "publisher": "IGI Global", "description": "Peer-to-Peer (P2P) and Grid systems serve whole communities of users, and are thus good examples of information systems that should realize social goals. One of the most important social goals is fairness. For that reason, P2P and Grid systems incorporate many mechanisms, algorithms and methods for providing fairness that are referred to as Fairness Management in this chapter. Information systems that serve communities of users can also apply social concepts to support users. Trust is one such concept that is often applied in P2P and Grid systems that apply Trust Management to support users in making decisions under uncertainty that is due to other users\u2019 behavior. This chapter describes Trust Management and Fairness Management in P2P and Grid systems, showing that the two subjects are connected. Trust Management can be used to improve fairness without centralized control. The chapter includes\u00a0\u2026", "total_citations": {"2010": 1, "2011": 1, "2012": 1, "2013": 0, "2014": 0, "2015": 0, "2016": 0, "2017": 0, "2018": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:hMod-77fHWUC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-540-71661-7_32", "authors": ["Anwitaman Datta", "Wolfgang Nejdl", "Karl Aberer"], "publication_date": "2005/8/28", "book": "International Workshop on Databases, Information Systems, and Peer-to-Peer Computing", "pages": "331-342", "publisher": "Springer Berlin Heidelberg", "description": "Balancing query-load in structured overlays is an important and mostly unattended problem, apart from heuristics to deal with hot-spots. We determine the optimal caching strategy - how many caches (dependent on relative frequency of queries) to reduce search latency and where to place these caches? Our query-adaptive replication scheme provides first-order balancing of query-load. We also elaborate the limitations of first-order balancing (ignored by all existing heuristics) though it should have been obvious given the experiences of the P2P community with storage-load balancing.This work lays the ground for our ongoing work on load-aware routing in structured overlays as a mechanism complementing caching to achieve query-load balancing.", "total_citations": {"2006": 1, "2007": 1, "2008": 0, "2009": 0, "2010": 0, "2011": 1, "2012": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:U4n9YNQMCAIC": {"external_link": "https://arxiv.org/abs/2306.09735", "authors": ["Dani\u00ebl Reijsbergen", "Aung Maw", "Jingchi Zhang", "Tien Tuan Anh Dinh", "Anwitaman Datta"], "publication_date": "2023/6/16", "journal": "arXiv preprint arXiv:2306.09735 (ICDCS 2023 demo paper)", "description": "A plethora of different blockchain platforms have emerged in recent years, but many of them operate in silos. As such, there is a need for reliable cross-chain communication to enable blockchain interoperability. Blockchain interoperability is challenging because transactions can typically not be reverted - as such, if one transaction is committed then the protocol must ensure that all related transactions are committed as well. Existing interoperability approaches, e.g., Cosmos and Polkadot, are limited in the sense that they only support interoperability between their own subchains, or require intrusive changes to existing blockchains. To overcome this limitation, we propose PIEChain, a general, Kafka-based cross-chain communication framework. We utilize PIEChain for a practical case study: a cross-chain auction in which users who hold tokens on multiple chains bid for a ticket sold on another chain. PIEChain is the first publicly available, practical implementation of a general framework for cross-chain communication.", "total_citations": {"2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Ak0FvsSvgGUC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9976471/", "authors": ["Shakshi Sharma", "Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2022/12/8", "journal": "IEEE Transactions on Computational Social Systems", "publisher": "IEEE", "description": "In this work, we collect a moderate-sized representative corpus of tweets (over 200 000) pertaining to COVID-19 vaccination spanning for a period of seven months (September 2020\u2013March 2021). Following a transfer learning approach, we utilize a pretrained transformer-based XLNet model to classify tweets as misleading or nonmisleading and manually validate the results with random subsets of samples. We leverage this to study and contrast the characteristics of tweets in the corpus that are misleading in nature against non-misleading ones. This exploratory analysis enables us to design features such as sentiments, hashtags, nouns, and pronouns which can, in turn, be exploited for classifying tweets as (non-)misleading using various machine learning (ML) models in an explainable manner. Specifically, several ML models are employed for prediction, with up to 90% accuracy, with the importance of each\u00a0\u2026", "total_citations": {"2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:lgwcVrK6X84C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9940268/", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2022/11/4", "journal": "IEEE Access", "volume": "10", "pages": "118617-118638", "publisher": "IEEE", "description": "For over a decade, erasure codes have become an integral part of large-scale data storage solutions and data-centers. However, in commercial systems, they are, so far, used predominantly for static data. In the meanwhile, there has also been almost a decade and a half of research on mutable erasure coded data, looking at various associated issues, including update computation, concurrency control and consistency, which has led to a variety of reasonably mature techniques. In this work we aim at curating and systematizing this knowledge on managing mutable erasure coded data. We believe the time is right, both because of the richness and maturity of the literature itself, and also, given the pervasiveness of erasure codes in data-centers, because it is natural to expect a transition to accommodate mutable content using erasure coded redundancy in order to support more diverse and versatile overlying\u00a0\u2026", "total_citations": {"2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:nVrZBo8bIpAC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167739X21000406", "authors": ["Silivanxay Phetsouvanh", "Anwitaman Datta", "Alwen Tiu"], "publication_date": "2021/5/1", "journal": "Future Generation Computer Systems", "volume": "118", "pages": "438-452", "publisher": "North-Holland", "description": "This work explores how to enhance pseudonymous whistleblower submission systems, specifically by supporting protocol level unlinkability, while also making the system resilient against (distributed) denial of service attacks. To that end, we propose a blind signature based protocol which facilitates assignment of trust to anonymous posters in a manner which depends on the quality of prior posts, yet unlinkable to said posts or corresponding poster. This (multi-level) trust is leveraged to prioritize the posts, thus mitigating the effect that spam posts may have on the party reviewing the posts. We design and carry out simulations to explore the resilience of the whistleblower submission system against denial of service attacks while applying the proposed approach. Our experiments affirm that for a range of realistic scenarios the proposed approach provides reasonable mitigation.", "total_citations": {"2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:tH6gc1N1XXoC": {"external_link": "https://peerj.com/articles/cs-366/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2021/2/25", "journal": "PeerJ Computer Science", "volume": "7", "pages": "e366", "publisher": "PeerJ Inc.", "description": "This article explores a graph clustering method that is derived from an information theoretic method that clusters points in R n relying on Renyi entropy, which involves computing the usual Euclidean distance between these points. Two view points are adopted:(1) the graph to be clustered is first embedded into R d for some dimension d so as to minimize the distortion of the embedding, then the resulting points are clustered, and (2) the graph is clustered directly, using as distance the shortest path distance for undirected graphs, and a variation of the Jaccard distance for directed graphs. In both cases, a hierarchical approach is adopted, where both the initial clustering and the agglomeration steps are computed using Renyi entropy derived evaluation functions. Numerical examples are provided to support the study, showing the consistency of both approaches (evaluated in terms of F-scores).", "total_citations": {"2021": 1, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:KUbvn5osdkgC": {"external_link": "https://link.springer.com/article/10.1007/s00607-016-0485-x", "authors": ["J Harshan", "Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2016/12", "journal": "Computing", "volume": "98", "pages": "1305-1329", "publisher": "Springer Vienna", "description": "In this paper we study the problem of storing reliably an archive of versioned data. Specifically, we focus on systems where the differences (deltas) between subsequent versions rather than the whole objects are stored\u2014a typical model for storing versioned data. For reliability, we propose erasure encoding techniques that exploit the sparsity of information in the deltas while storing them reliably in a distributed back-end storage system, resulting in improved I/O read performance to retrieve the whole versioned archive. Along with the basic techniques, we propose a few optimization heuristics, and evaluate the techniques\u2019 efficacy analytically and with numerical simulations.", "total_citations": {"2016": 1, "2017": 1, "2018": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:xtoqd-5pKcoC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7794352/", "authors": ["Anwitaman Datta", "Wan Hee Cho"], "publication_date": "2016/9/26", "conference": "2016 IEEE 35th Symposium on Reliable Distributed Systems (SRDS)", "pages": "229-238", "publisher": "IEEE", "description": "Over the life-cycle of a data object, it may be difficult to determine a priori how much redundancy to store it with. The desired degree of fault-tolerance may change over time, for instance, because the importance of the data changes, or the storage system environment changes. If the redundancy is achieved using replication, then changing the degree of fault-tolerance would mean adding (or removing) replicas - a reasonably straightforward operation. However, if erasure code is used instead (which is preferable, given the significantly lower storage overhead of erasure codes with respect to fully replicated systems), then, while shrinking redundancy can still be achieved similarly, expanding redundancy becomes non-trivial. A naive approach will require re-coding, which is both network resource and computation heavy. In this paper, we explore the possibility of using network coding techniques, to both distribute\u00a0\u2026", "total_citations": {"2018": 1, "2019": 1, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:hMsQuOkrut0C": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167739X16000078", "authors": ["J Harshan", "Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2016/6/1", "journal": "Future Generation Computer Systems", "volume": "59", "pages": "47-62", "publisher": "North-Holland", "description": "We propose a differential versioning based data storage (DiVers) architecture for distributed storage systems, which relies on a novel erasure coding technique that exploits sparsity across versions. The emphasis of this work is to demonstrate how sparsity exploiting codes (SEC), originally designed for I/O optimization, can be extended to significantly reduce storage overhead in a repository of versioned data. In addition to facilitating reduced storage, we address some key reliability aspects for DiVers such as (i)\u00a0mechanisms to deploy the coding technique with arbitrarily varying size of data across versions, and (ii)\u00a0investigating the right allocation strategy for the encoded blocks over a network of distributed nodes across different versions so as to achieve the best fault tolerance. We also discuss system issues related to the management of data structures for accessing and manipulating the files over the differential\u00a0\u2026", "total_citations": {"2016": 1, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Dip1O2bNi0gC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-662-54054-1_2", "authors": ["J Harshan", "Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2016", "journal": "Transactions on Large-Scale Data-and Knowledge-Centered Systems XXX: Special Issue on Cloud Computing", "pages": "23-65", "publisher": "Springer Berlin Heidelberg", "description": "In this paper, we study the problem of storing an archive of versioned data in a reliable and efficient manner. The proposed technique is relevant in cloud settings, where, because of the huge volume of data to be stored, distributed (scale-out) storage systems deploying erasure codes for fault tolerance is typical. However existing erasure coding techniques do not leverage redundancy of information across multiple versions of a file. We propose a new technique called differential erasure coding (DEC) where the differences (deltas) between subsequent versions are stored rather than the whole objects, akin\u00a0to a typical delta encoding technique. However, unlike delta encoding techniques, DEC opportunistically exploits the sparsity (i.e., when the differences between two successive versions have few non-zero entries) in the updates to store the deltas using sparse sampling techniques applied with erasure\u00a0\u2026", "total_citations": {"2019": 1, "2020": 1, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:tKAzc9rXhukC": {"external_link": "https://arxiv.org/abs/1312.5155", "authors": ["Kyumars Sheykh Esmaili", "Anwitaman Datta"], "publication_date": "2013/12/16", "journal": "arXiv preprint arXiv:1312.5155", "description": "There are different ways to realize Reed Solomon (RS) codes. While in the storage community, using the generator matrices to implement RS codes is more popular, in the coding theory community the generator polynomials are typically used to realize RS codes. Prominent exceptions include HDFS-RAID, which uses generator polynomial based erasure codes, and extends the Apache Hadoop's file system. In this paper we evaluate the performance of an implementation of polynomial realization of Reed-Solomon codes, along with our optimized version of it, against that of a widely-used library (Jerasure) that implements the main matrix realization alternatives. Our experimental study shows that despite significant performance gains yielded by our optimizations, the polynomial implementations' performance is constantly inferior to those of matrix realization alternatives in general, and that of Cauchy bit matrices in particular.", "total_citations": {"2015": 1, "2016": 0, "2017": 0, "2018": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:f2IySw72cVMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6038707/", "authors": ["Christian von der Weth", "Anwitaman Datta"], "publication_date": "2011/8/22", "conference": "2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology", "volume": "1", "pages": "356-363", "publisher": "IEEE", "description": "Improving web search solely based on algorithmic refinements has reached a plateau. The emerging generation of searching techniques tries to harness the ``wisdom of crowds'', using inputs from users in the spirit of Web 2.0. In this paper, we introduce a framework facilitating friends augmented search techniques (FAST). To that end, we present a browser add-on as front end for collaborative browsing and searching, supporting synchronous and asynchronous collaboration between users. We then describe the back end, a distributed key-value store for efficient information retrieval in the presence of an evolving knowledge base. The mechanisms we explore in supporting efficient query processing for FAST are applicable for many other recent Web 2.0 applications that rely on similar key-value stores. The specific collaborative search tool we present is expected to be an useful utility in its own right and spur further\u00a0\u2026", "total_citations": {"2010": 1, "2011": 0, "2012": 0, "2013": 0, "2014": 1, "2015": 0, "2016": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:p2g8aNsByqUC": {"external_link": "https://arxiv.org/abs/1108.3915", "authors": ["Dinh Tien Tuan Anh", "Wang Wenqiang", "Anwitaman Datta"], "publication_date": "2011/8/19", "journal": "arXiv preprint arXiv:1108.3915", "description": "Sharing data from various sources and of diverse kinds, and fusing them together for sophisticated analytics and mash-up applications are emerging trends, and are prerequisites for grand visions such as that of cyber-physical systems enabled smart cities. Cloud infrastructure can enable such data sharing both because it can scale easily to an arbitrary volume of data and computation needs on demand, as well as because of natural collocation of diverse such data sets within the infrastructure. However, in order to convince data owners that their data are well protected while being shared among cloud users, the cloud platform needs to provide flexible mechanisms for the users to express the constraints (access rules) subject to which the data should be shared, and likewise, enforce them effectively. We study a comprehensive set of practical scenarios where data sharing needs to be enforced by methods such as aggregation, windowed frame, value constrains, etc., and observe that existing basic access control mechanisms do not provide adequate flexibility to enable effective data sharing in a secure and controlled manner. In this paper, we thus propose a framework for cloud that extends popular XACML model significantly by integrating flexible access control decisions and data access in a seamless fashion. We have prototyped the framework and deployed it on commercial cloud environment for experimental runs to test the efficacy of our approach and evaluate the performance of the implemented prototype.", "total_citations": {"2014": 2, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:hC7cP41nSMkC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5071855/", "authors": ["Krzysztof Rzadca", "Jackson Tan Teck Yong", "Anwitaman Datta"], "publication_date": "2009/5/18", "conference": "2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid", "pages": "60-67", "publisher": "IEEE", "description": "Current implementations of real-time collaborative applications rely on a dedicated infrastructure to carry out all synchronizing and communication functions, and require all end nodes to communicate directly with and through the central server. In this paper, we investigate an architecture, in which the most resource intensive functionality of continuous communication among collaborators to disseminate changes is decentralized, utilizing the end users as relays. We observe that communication characteristics of real-time collaboration makes use of existing multicast mechanisms unsuitable. As collaborative editing sessions are typically long, we are able to gather and then use additional parameters of nodes (their instabilities and frequency of sending updates) and communication links (latencies and average costs). We identify several criteria to determine the quality of a multicast tree: cost, latency and instability. We\u00a0\u2026", "total_citations": {"2009": 2, "2010": 0, "2011": 0, "2012": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:PR6Y55bgFSsC": {"external_link": "https://scholar.google.com/scholar?cluster=14339794054595527796&hl=en&oi=scholarr", "authors": ["Anwitaman Datta"], "publication_date": "2009", "book": "Encyclopedia of Database Systems", "pages": "2075-2081", "total_citations": {"2014": 1, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:WqliGbK-hY8C": {"external_link": "https://scholar.google.com/scholar?cluster=17197296540987934115&hl=en&oi=scholarr", "authors": ["Anwitaman Datta"], "publication_date": "2009", "book": "Encyclopedia of Database Systems", "pages": "1627-1632", "total_citations": {"2011": 1, "2012": 0, "2013": 0, "2014": 0, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 0, "2021": 1, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:OTTXONDVkokC": {"external_link": "https://infoscience.epfl.ch/record/58584", "authors": ["Anwitaman Datta", "Karl Aberer"], "publication_date": "2005", "issue": "REP_WORK", "description": "Content storage in a distributed collaborative environment uses redundancy for better resilience. This redundancy is either achieved by pure replication or using erasure codes for more efficient utilization of available storage. Increasingly such schemes are employed in peer-to-peer environments, though more realistically in local or wide area network settings, which is still characterized by moderate attrition (churn) of network membership. An mportant aspect of guaranteeing persistence and availability in such a system is to maintain the redundancy. A proactive mechanism of replenishing lost redundancy can however be prohibitive, and hence lazier maintenance schemes are desirable. Such systems' performance has typically been studied based on simulations, and more recently some prototype based experimental results have also been reported. While such a methodology is essential in designing and deploying a reliable system, the missing link in the existing literature is a sufficiently accurate analytical model to capture the dynamics of the system. The existing analytical models essentially capture the static resilience of the system. What's more realistic is to evaluate whether-given a rate of churn, and some chosen maintenance strategy, the system operates at a steady state and if so, what is the operational cost of such a system. Since simulations are restricted to chosen workloads (be it synthetic or trace driven), they are limited to only those chosen workloads, even while providing a good initial (hopefully empirical) insight to systems designers. A precise analytical model capturing the system's dynamicity however is expected to provide a\u00a0\u2026", "total_citations": {"2007": 1, "2008": 0, "2009": 0, "2010": 0, "2011": 1, "2012": 0, "2013": 0, "2014": 0, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Bg7qf7VwUHIC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9467280/", "authors": ["Anwitaman Datta", "Adamas Aqsa Fahreza", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2021/6/29", "journal": "IEEE Access", "volume": "9", "pages": "93298-93314", "publisher": "IEEE", "description": "In this paper we study the problem of consistency in distributed storage systems relying on erasure coding for storage efficient fault-tolerance. We propose QLOC - a flexible framework for supporting the storage of warm data, i.e., data which, while not being very frequently in use, nevertheless continues to be accessed for reads or writes regularly. QLOC builds upon (1) a generic family of local reconstruction codes with guarantees in terms of fault-tolerance, efficient recovery from failures and degraded mode operations, and can be instantiated with parameters customized to requirements such as storage overhead and reliability dictated by user needs and operational environments, and (2) quorum-based consistency mechanisms with support for read-modify-write operations without any underlying atomic primitives, providing deployment choices trading-off fault-tolerance, consistency and concurrency requirements\u00a0\u2026", "total_citations": {"2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:gVv57TyPmFsC": {"external_link": "https://www.mdpi.com/1099-4300/23/2/177", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2021/1/30", "journal": "Entropy", "volume": "23", "issue": "2", "pages": "177", "publisher": "MDPI", "description": "We consider the problem of designing grid quorum systems for maximum distance separable (MDS) erasure code based distributed storage systems. Quorums are used as a mechanism to maintain consistency in replication based storage systems, for which grid quorums have been shown to produce optimal load characteristics. This motivates the study of grid quorums in the context of erasure code based distributed storage systems. We show how grid quorums can be built for erasure coded data, investigate the load characteristics of these quorum systems, and demonstrate how sequential consistency is achieved even in the presence of storage node failures.", "total_citations": {"2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:bKqednn6t2AC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0167739X18328450", "authors": ["Chih Wei Ling", "Anwitaman Datta", "Jun Xu"], "publication_date": "2019/11/1", "journal": "Future Generation Computer Systems", "volume": "100", "pages": "440-455", "publisher": "North-Holland", "description": "A large volume of data is generated by traffic surveillance devices such as cameras and sensors integrated into an intelligent transportation system (ITS), a subfield of the Internet of Things (IoT). We argue that network coding can be applied to leverage on an emerging fog architecture that relies on edge resources, to achieve higher throughput, saving up network bandwidth, and provide resilience to link failures, while also achieving simple obfuscation against wire-tapping attacks by linearly combining the source packets. There are two broad linear network coding paradigms in the literature \u2014 deterministic and random network coding, each with their own strengths and limitations. With the aid of software-defined network (SDN), we rethink about the possibility of applying a hybrid approach to deal with networks at different scales. Under network conditions that reflect expected network properties of an ITS, our\u00a0\u2026", "total_citations": {"2021": 1, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:SpbeaW3--B0C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7756227/", "authors": ["Wan Hee Cho", "Anwitaman Datta"], "publication_date": "2016/6/27", "conference": "2016 IEEE 36th International Conference on Distributed Computing Systems Workshops (ICDCSW)", "pages": "176-183", "publisher": "IEEE", "description": "Redundancy is an essential mechanism for fault-tolerance, and yet, it inherently leads to overheads. This prompts an obvious question: how much resource ought to be provisioned in order to account for such overheads? As obvious as the question itself is, a good response is illusive. Provisioning in excess would cause wastage or under-utilization of capacity, while under-provisioning will lead to service disruptions to outright catastrophes. In the context of data storage, such adverse situations would be temporary unavailability to permanent loss of data. Thus, it is imperative to adapt the redundancy (elastic redundancy) in the system as per the environment and end user needs. In the context of data storage, if the redundancy is realized using full replication of data, then elasticity can be achieved by just creating (or garbage collecting) further copies of the said data. However, if erasure code is used instead (which is\u00a0\u2026", "total_citations": {"2016": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:e_rmSamDkqQC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7536588/", "authors": ["Ertem Esiner", "Shun Hanli Hanley", "Anwitaman Datta"], "publication_date": "2016/6/27", "conference": "2016 IEEE 36th International Conference on Distributed Computing Systems (ICDCS)", "pages": "757-758", "publisher": "IEEE", "description": "While many commercial systems as well as academic techniques for data outsourcing to and content confidentiality from untrusted data stores have been developed over the last decade, when it comes to multi-factor authentication based layered security, existing approaches typically rely on a logically centralized service. In this demo, we present DMZtore edge storage system that incorporates a decentralized multi-factor access control scheme [1] achieving layered security.", "total_citations": {"2019": 1, "2020": 0, "2021": 0, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:ipzZ9siozwsC": {"external_link": "https://www.researchgate.net/profile/Krzysztof-Rzadca-2/publication/260167425_People_are_Processors_Coalitional_Auctions_for_Complex_Projects/links/00b7d533a825eef098000000/People-are-Processors-Coalitional-Auctions-for-Complex-Projects.pdf", "authors": ["Piotr Skowron", "Krzysztof Rzadca", "Anwitaman Datta"], "publication_date": "2014/5", "journal": "CoRR, abs/1402.2970", "description": "To successfully complete a complex project, be it a construction of an airport or of a backbone IT system or crowd-sourced projects, agents (companies or individuals) must form a team (a coalition) having required competences and resources. A team can be formed either by the project issuer based on individual agents\u2019 offers (centralized formation); or by the agents themselves (decentralized formation) bidding for a project as a consortium\u2014in that case many feasible teams compete for the employment contract. In these models, we investigate rational strategies of the agents (what salary should they ask? with whom should they team up?) under different organizations of the market. We propose various concepts allowing to characterize the stability of the winning teams. We show that there may be no (rigorously) strongly winning coalition, but the weakly winning and the auction-winning coalitions are guaranteed to exist. In a general setting, with an oracle that decides whether a coalition is feasible, we show how to find winning coalitions with a polynomial number of calls to the oracle. We also determine the complexity of the problem in a special case in which a project is a set of independent tasks. Each task must be processed by a single agent, but processing speeds differ between agents and tasks.", "total_citations": {"2014": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:vRqMK49ujn8C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-32873-2_5", "authors": ["Wen Qiang Wang", "Dinh Tien Tuan Anh", "Hock Beng Lim", "Anwitaman Datta"], "publication_date": "2012/8/27", "book": "Workshop on Secure Data Management", "pages": "58-74", "publisher": "Springer Berlin Heidelberg", "description": "The proliferation of sensing devices create plethora of data-streams, which in turn can be harnessed to carry out sophisticated analytics to support various real-time applications and services as well as long-term planning, e.g., in the context of intelligent cities or smart homes. A mature cloud infrastructure brings such a vision closer to reality than ever before, as more and more data owners are moving their data to the cloud. Hence, the ability to flexibly and easily control the granularity at which they share their data with other entities become more important. It makes data owners feel comfortable to share to start with, and also provide them a platform to realize different business models or logics. In this paper, we explore some basic operations to flexibly control the access on a data-stream and propose a framework eXACML+ that extends the standard XACML model to achieve the same. We develop a\u00a0\u2026", "total_citations": {"2012": 1, "2013": 0, "2014": 0, "2015": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:t6usbXjVLHcC": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=95167cd34eedb6a8565f87fb4389aaff6b38fbfd#page=33", "authors": ["Dinh Tien Tuan Anh", "Anwitaman Datta"], "publication_date": "2012", "journal": "Data Engineering", "pages": "31", "description": "Migration of one\u2019s computing infrastructure to the cloud is gathering momentum with the emergence of relatively mature cloud computing technologies. As data and computation are being outsourced, concerns over data security (such as confidentiality, privacy and integrity) remain one of the greatest hurdles to overcome. In the meanwhile, the increasing need for sharing data between or within cloud-based systems (for instance, sharing between enterprise systems or users of a social network application) demands even more care in ensuring data security. In this paper, we investigate the challenges in outsourcing access control of user data to the cloud. We identify what constitute a finegrained cloud-based access control system and present the design-space along with a discussion on the current state-of-the-art. We then describe a system which extends an Attribute-Based Encryption scheme to achieve more fine-grainedness as compared to existing approaches. Our system not only protects data from both the cloud service provider and unauthorized access from other users, it also moves the heavy computations towards the cloud, taking advantage of the latter\u2019s relatively unbounded resources. Additionally, we integrate an XML-based framework (XACML) for flexible, high-level policy management. Finally, we discuss some open problems, solving which would lead to a further robust and flexible cloud-based access control system.", "total_citations": {"2014": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:NaGl4SEjCO4C": {"external_link": "https://link.springer.com/article/10.1007/s12083-010-0085-z", "authors": ["Xin Liu", "Anwitaman Datta"], "publication_date": "2011/9", "journal": "Peer-to-Peer Networking and Applications", "volume": "4", "pages": "309-324", "publisher": "Springer US", "description": "RSS (really simple syndication) based feeds have become the defacto mechanism of web based publish subscribe. Peer-to-Peer delivery of such feeds can not only alleviate the load at the content server, but also reduce the dissemination latency. However, due to openness of P2P system, malicious peers can join the network as easily as normal peers do. Such malicious peers may pretend to relay but actually not, and thus deny service, or even disseminate counterfeit updates, rendering a Peer-to-Peer mechanism not only useless, but even harmful (e.g. by false updates). We propose overlay independent randomized strategies to mitigate these ill-effects of malicious peers at a marginal overhead, thus enjoying the benefits of Peer-to-Peer dissemination, along with the assurance of content integrity in RSS like web-based publish-subscribe applications without altering currently deployed server\u00a0\u2026", "total_citations": {"2011": 1, "2012": 0, "2013": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:BqipwSGYUEgC": {"external_link": "https://arxiv.org/abs/1105.4452", "authors": ["Christian von der Weth", "Anwitaman Datta"], "publication_date": "2011/5/23", "journal": "arXiv preprint arXiv:1105.4452", "description": "NoSQL systems are more and more deployed as back-end infrastructure for large-scale distributed online platforms like Google, Amazon or Facebook. Their applicability results from the fact that most services of online platforms access the stored data objects via their primary key. However, NoSQL systems do not efficiently support services referring more than one data object, e.g. the term-based search for data objects. To address this issue we propose our architecture based on an inverted index on top of a NoSQL system. For queries comprising more than one term, distributed indices yield a limited performance in large distributed systems. We propose two extensions to cope with this challenge. Firstly, we store index entries not only for single term but also for a selected set of term combinations depending on their popularity derived from a query history. Secondly, we additionally cache popular keys on gateway nodes, which are a common concept in real-world systems, acting as interface for services when accessing data objects in the back end. Our results show that we can significantly reduces the bandwidth consumption for processing queries, with an acceptable, marginal increase in the load of the gateway nodes.", "total_citations": {"2011": 1, "2012": 0, "2013": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:OP4eGU-M3BUC": {"external_link": "https://www.cucse.org/ICDCNpictures/AnwitamanDatta.pdf", "authors": ["Anwitaman Datta"], "publication_date": "2010", "journal": "ICDCN tutorial", "description": "This decade has witnessed vigorous research on peer-to-peer research\u2013encompassing numerous areas including structured overlays, file sharing and content distribution networks and storage systems to name a few. Numerous books, tutorials and surveys on peer-to-peer systems exist, but none exclusively focus on storage systems, nor do they exhaustively explore the design space. This tutorial will summarize the fundamental design issues related to peer-to-peer storage systems, pertaining to the reliability aspect of system vis-a-vis availability and durability. Efficient data indexing and searching as well as security issues are also important aspects of storage systems, but will be out of the scope of this tutorial, but brief references will be provided.Peer-to-peer (P2P) storage is a paradigm to leverage the combined storage capacity of a network of storage devices (peers) contributed typically by autonomous end\u00a0\u2026", "total_citations": {"2011": 1, "2012": 0, "2013": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:blknAaTinKkC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-540-89533-6_27", "authors": ["Maureen", "Aixin Sun", "Ee-Peng Lim", "Anwitaman Datta", "Kuiyu Chang"], "publication_date": "2008", "conference": "Digital Libraries: Universal and Ubiquitous Access to Information: 11th International Conference on Asian Digital Libraries, ICADL 2008, Bali, Indonesia, December 2-5, 2008. Proceedings 11", "pages": "266-275", "publisher": "Springer Berlin Heidelberg", "description": "In this paper, we focus on the visualization of heterogeneous semantic networks obtained from multiple data sources. A semantic network comprising a set of entities and relationships is often used for representing knowledge derived from textual data or database records. Although the semantic networks created for the same domain at different data sources may cover a similar set of entities, these networks could also be very different because of naming conventions, coverage, view points, and other reasons. Since digital libraries often contain data from multiple sources, we propose a visualization tool to integrate and analyze the differences among multiple social networks. Through a case study on two terrorism-related semantic networks derived from Wikipedia and Terrorism Knowledge Base (TKB) respectively, the effectiveness of our proposed visualization tool is demonstrated.", "total_citations": {"2010": 1, "2011": 0, "2012": 0, "2013": 0, "2014": 0, "2015": 0, "2016": 0, "2017": 0, "2018": 0, "2019": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:4JMBOYKVnBMC": {"external_link": "https://infoscience.epfl.ch/record/52701", "authors": ["Anwitaman Datta", "Karl Aberer", "Wolfgang Nejdl"], "publication_date": "2004", "issue": "REP_WORK", "description": "This paper focuses on replication in DHT based structured overlay networks, and presents a theoretical framework for optimal replication in such networks with respect to query frequency. In particular, we determine the optimal replication factor for query-adaptive load balancing, and a topology specific placement strategy for an important class of DHT networks. We also provide a taxonomy of replication strategies in existing systems, discussing them with respect to this optimal scheme, and sketch further issues relevant for implementing this scheme in DHT networks. a.. keywords: Query-adaptivity, Optimal replication, Load-balancing, Distributed Hash Tables", "total_citations": {"2004": 1, "2005": 0, "2006": 0, "2007": 0, "2008": 0, "2009": 0, "2010": 0, "2011": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:mB3voiENLucC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1021243/", "authors": ["Karl Aberer", "Anwitaman Datta", "Zoran Despotovic"], "publication_date": "2002/6/26", "conference": "Proceedings Fourth IEEE International Workshop on Advanced Issues of E-Commerce and Web-Based Information Systems (WECWIS 2002)", "pages": "69-78", "publisher": "IEEE", "description": "In the web context, it is difficult to disentangle presentation from process logic, and sometimes even data is not separate from the presentation. Consequently, it becomes crucial to define an abstract model for business processes, and their mapping into an active user interface presentation, using the principle of separation of concern between the process logic, data and its presentation aspects. We endeavour to extend declarative (rule based) XSLT to accommodate the separation of process information from the data structure and presentation, and thus propose to design process aware stylesheets, in a minimally invasive manner. The isolation of the three otherwise entangled aspects of web-processes makes it easy to develop and maintain web-applications in a more independent manner where each individual developer can focus on his/her primary responsibility, like describing the process, maintaining a\u00a0\u2026", "total_citations": {"2007": 1, "2008": 0, "2009": 0, "2010": 0, "2011": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:7Hz3ACDFbsoC": {"external_link": "https://arxiv.org/abs/2309.00639", "authors": ["Shakshi Sharma", "Anwitaman Datta", "Vigneshwaran Shankaran", "Rajesh Sharma"], "publication_date": "2023/8/25", "journal": "arXiv preprint arXiv:2309.00639", "description": "We demonstrate the Misinformation Concierge, a proof-of-concept that provides actionable intelligence on misinformation prevalent in social media. Specifically, it uses language processing and machine learning tools to identify subtopics of discourse and discern non/misleading posts; presents statistical reports for policy-makers to understand the big picture of prevalent misinformation in a timely manner; and recommends rebuttal messages for specific pieces of misinformation, identified from within the corpus of data - providing means to intervene and counter misinformation promptly. The Misinformation Concierge proof-of-concept using a curated dataset is accessible at: https://demo-frontend-uy34.onrender.com/", "total_citations": {"2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:kVjdVfd2voEC": {"external_link": "https://arxiv.org/abs/2306.09754", "authors": ["Dani\u00ebl Reijsbergen", "Bretislav Hajek", "Tien Tuan Anh Dinh", "Jussi Keppo", "Hank Korth", "Anwitaman Datta"], "publication_date": "2023/6/16", "journal": "arXiv preprint arXiv:2306.09754", "description": "Decentralized Finance (DeFi), in which digital assets are exchanged without trusted intermediaries, has grown rapidly in value in recent years. The global DeFi ecosystem is fragmented into multiple blockchains, fueling the demand for cross-chain commerce. Existing approaches for cross-chain transactions, e.g., bridges and cross-chain deals, achieve atomicity by locking assets in escrow. However, locking up assets increases the financial risks for the participants, especially due to price fluctuations and the long latency of cross-chain transactions. Stablecoins, which are pegged to a non-volatile asset such as the US dollar, help mitigate the risk associated with price fluctuations. However, existing stablecoin designs are tied to individual blockchain platforms, and trusted parties or complex protocols are needed to exchange stablecoin tokens between blockchains. Our goal is to design a practical stablecoin for cross-chain commerce. Realizing this goal requires addressing two challenges. The first challenge is to support a large and growing number of blockchains efficiently. The second challenge is to be resilient to price fluctuations and blockchain platform failures. We present CroCoDai to address these challenges. We also present three prototype implementations of our stablecoin system, and show that it incurs small execution overhead.", "total_citations": {"2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:48xauSegjOkC": {"external_link": "https://arxiv.org/abs/2208.07665", "authors": ["Simone Bottoni", "Anwitaman Datta", "Federico Franzoni", "Emanuele Ragnoli", "Roberto Ripamonti", "Christian Rondanini", "Gokhan Sagirlar", "Alberto Trombetta"], "publication_date": "2022/8/16", "journal": "arXiv preprint arXiv:2208.07665", "description": "Limited scalability and transaction costs are, among others, some of the critical issues that hamper a wider adoption of distributed ledger technologies (DLT). That is particularly true for the Ethereum blockchain, which, so far, has been the ecosystem with the highest adoption rate. Quite a few solutions, especially on the Ethereum side of things, have been attempted in the last few years. Most of them adopt the approach to offload transactions from the blockchain mainnet, a.k.a. Level 1 (L1), to a separate network. Such systems are collectively known as Level 2 (L2) systems. While mitigating the scalability issue, the adoption of L2 introduces additional drawbacks: users have to trust that the L2 system has correctly performed transactions or, conversely, high computational power is required to prove transactions correctness. In addition, significant technical knowledge is needed to set up and manage such an L2 system. To tackle such limitations, we propose 1DLT: a novel system that enables rapid and trustless deployment of an Ethereum Virtual Machine based blockchain that overcomes those drawbacks.", "total_citations": {"2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:LgRImbQfgY4C": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0743731521002094", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2022/3/1", "journal": "Journal of Parallel and Distributed Computing", "volume": "161", "pages": "1-19", "publisher": "Academic Press", "description": "We consider the design and analysis of quorum systems over erasure coded warm data (with low frequency of writes and accesses in general) to guarantee sequential consistency under a fail-stop model while supporting atomic read-modify-write operations by multiple clients. We propose a definition of asymmetric quorum systems that suit the framework of coded data by explicitly exploiting the structural properties of code and instantiate it over distinct families of coding strategies: maximum distance separable (MDS) codes and codes with locality, and we indicate a mechanism for synchronizing stale nodes using differential updates, which again exploits the code structures. The proposed quorum system's behavior is analyzed theoretically, exploring several aspects: viability of quorums under node unavailability; contention of resources between read and write operations; and quorum load. We complement these\u00a0\u2026", "total_citations": {"2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:edDO8Oi4QzsC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7980104/", "authors": ["Ertem Esiner", "Anwitaman Datta"], "publication_date": "2017/6/5", "conference": "2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)", "pages": "1672-1682", "publisher": "IEEE", "description": "In this work we focus on integrity and consistency of data accessed and manipulated by multiple collaborating users, and stored in an (untrusted) hosted service. This is a problem, aspects of which have been studied in isolation in hitherto distinct communities. Consistency is one of the cardinal problems of distributed computing. Integrity of hosted data has been studied over the last decade, and numerous techniques for proof of data possession and/or retrievability have been explored. The latter line of work however have often assumed static data, and techniques to handle dynamic or versioned data have only very recently been proposed. Yet, even the existing solutions that handle mutable content do so under the assumption that only a single data owner (using a single client) manipulate and verify said data. This is a serious limitation in terms of the variety of applications that can benefit from such mechanisms\u00a0\u2026", "total_citations": {"2017": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:q3CdL3IzO_QC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0020019017300327", "authors": ["Ertem Esiner", "Anwitaman Datta"], "publication_date": "2017/6/1", "journal": "Information Processing Letters", "volume": "122", "pages": "34-39", "publisher": "Elsevier", "description": "We leverage on authenticated data structures to guarantee correctness and completeness of query results over encrypted data. Our contribution is in bridging two independent lines of work (searchable encryption, and provable data possession) resulting in a general purpose technique, which does so without increasing the client storage overhead, while only a small token and a data structure is added to the server side (in comparison to a base searchable encryption without mechanisms for determining result integrity), where the data structure can simultaneously also be used for integrity checks on the stored data.", "total_citations": {"2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:7T2F9Uy0os0C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2541603.2541606", "authors": ["Tien Tuan Anh Dinh", "Anwitaman Datta"], "publication_date": "2013/12/9", "book": "Proceedings of the First International Workshop on Middleware for Cloud-Enabled Sensing", "pages": "1-6", "description": "The advent of cloud computing is driving a paradigm shift in the computing landscape. An increasing number of businesses and individuals are moving their data and computation to the cloud. While the benefits of cloud computing are numerous, security remains one of the biggest concerns as data and computation are outsourced to untrusted third parties. In this invited paper, we summarize our efforts to securely outsource collaborative sensing and analytic applications to untrusted clouds. Particularly, we consider stream data sharing and collaborative data mining. First, we present Streamforce, a system for secure enforcement of fine-grained access control for stream data. It ensures both data privacy against the curious clouds and access control against dishonest users, while offloading most of the expensive computations to the cloud. Using a number of encryption schemes for the underlying security\u00a0\u2026", "total_citations": {"2017": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:WbkHhVStYXYC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6151352/", "authors": ["Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2012/1/3", "conference": "2012 Fourth International Conference on Communication Systems and Networks (COMSNETS 2012)", "pages": "1-7", "publisher": "IEEE", "description": "We propose a decentralized ranking algorithm for finding top-k users in a semantic social overlay based network. In large semantic networks the problem of finding top k users (or nodes) with respect to a particular topic is important. Be it a co-authorship graph where a author is looking for other top k authors with respect to a topic, or the problem to find top k influential nodes with respect to an interest (or topic) in a social network. In large networks, global knowledge is difficult to keep at individual nodes because the networks are (i) dynamic in nature and (ii) usually scale to very large numbers. Hence there is a necessity to design algorithms based on local neighborhood. Our proposed algorithm exploits social links and uses local information only. The algorithm scales upto any size of the network. The experimental results on both synthetic and real-world datasets show the effectiveness of our approach.", "total_citations": {"2013": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:tS2w5q8j5-wC": {"external_link": "https://scholar.google.com/scholar?cluster=13780786320690841416&hl=en&oi=scholarr", "authors": ["Tien Tuan Anh Dinh", "Quach Vinh Thanh", "Anwitaman Datta"], "publication_date": "2012", "journal": "CoRR", "total_citations": {"2013": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:2P1L_qKh6hAC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-13654-2_7", "authors": ["Ee-Peng Lim", "Agus Trisnajaya Kwee", "Nelman Lubis Ibrahim", "Aixin Sun", "Anwitaman Datta", "Kuiyu Chang", "Maureen"], "publication_date": "2010", "conference": "The Role of Digital Libraries in a Time of Global Change: 12th International Conference on Asia-Pacific Digital Libraries, ICADL 2010, Gold Coast, Australia, June 21-25, 2010. Proceedings 12", "pages": "50-60", "publisher": "Springer Berlin Heidelberg", "description": "Information networks in Wikipedia evolve as users collaboratively edit articles that embed the networks. These information networks represent both the structure and content of community\u2019s knowledge and the networks evolve as the knowledge gets updated. By observing the networks evolve and finding their evolving patterns, one can gain higher order knowledge about the networks and conduct longitudinal network analysis to detect events and summarize trends. In this paper, we present SSNetViz+, a visual analytic tool to support visualization and exploration of Wikipedia\u2019s information networks. SSNetViz+ supports time-based network browsing, content browsing and search. Using a terrorism information network as an example, we show that different timestamped versions of the network can be interactively explored. As information networks in Wikipedia are created and maintained by collaborative\u00a0\u2026", "total_citations": {"2012": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:a0OBvERweLwC": {"external_link": "https://link.springer.com/chapter/10.1007/978-0-387-09751-0_50", "authors": ["Adam Wierzbicki", "Anwitaman Datta", "\u0141ukasz \u017baczek", "Krzysztof Rzadca"], "publication_date": "2009/10/15", "book": "Handbook of Peer-to-Peer Networking", "pages": "1367-1400", "publisher": "Springer US", "description": "Among many potential applications of mobile P2P systems, collaboration applications are among the most prominent. Examples of applications such as Groove (although not intended for mobile networks), collaboration tools for disaster recovery (the WORKPAD project), and Skype\u2019s collaboration extensions, all demonstrate the potential of P2P collaborative applications. Yet, the development of such applications for mobile P2P systems is still difficult because of the lack of middleware.", "total_citations": {"2017": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:YFjsv_pBGBYC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5071867/", "authors": ["Anwitaman Datta", "Liu Xin"], "publication_date": "2009/5/18", "conference": "2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid", "pages": "156-163", "publisher": "IEEE", "description": "Using peer-to-peer overlays to notify users whenever a new update occurs is a promising approach to support Web based publish subscribe systems like really simple syndication (RSS). Such a peer-to-peer approach can scale well by reducing load at the source and also guarantee timeliness of notifications. Several such overlay based approaches have been proposed in recent years. However, malicious peers may pretend to relay but actually not, and thus deny service, or even propagate counterfeit updates - thus rendering a peer-to-peer mechanism not only useless, but even harmful (e.g., by false updates). We propose overlay independent randomized strategies to mitigate these ill-effects of malicious peers at a marginal overhead, thus enjoying the benefits of peer-to-peer dissemination, along with the assurance of content integrity in RSS like Web-based publish-subscribe applications without altering\u00a0\u2026", "total_citations": {"2011": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:MLfJN-KU85MC": {"external_link": "https://scholar.google.com/scholar?cluster=4208745713820562107&hl=en&oi=scholarr", "authors": ["Anwitaman Datta"], "publication_date": "2009", "publisher": "CIKM", "total_citations": {"2013": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:9c2xU6iGI7YC": {"external_link": "https://scholar.google.com/scholar?cluster=13659672615645303734&hl=en&oi=scholarr", "authors": ["Wu Di", "YE TIAN", "Kam-Wing NG", "Anwitaman DATTA"], "publication_date": "2008", "journal": "Computer communications", "volume": "31", "issue": "2", "pages": "220-239", "publisher": "Elsevier", "description": "Due to the prevalence of peer dynamics (ie, churn), object maintenance becomes a fundamental issue in peer-to-peer storage systems. Although quite a few prototypes have been designed and implemented, they lack theoretical analysis to shed light on how the system evolves under churn and how to configure the system properly. The performance of peer-to-peer storage systems under churn (eg, storage capacity, bandwidth usage, bandwidth spike, etc.) also become unclear. In this paper, we develop a simple model based on stochastic differential equations, with which we can analytically study the time-evolution of peer-to-peer storage systems under churn, and the interplay between object maintenance and churn. Different from previous Markovian analysis, we provide closed-form terms to capture the time-evolution of the storage system, and formally derive its related performance metrics under different maintenance strategies. Our analytical results provide valuable directions on the optimization of peer-to-peer storage systems, eg, reducing bandwidth usage, provisioning for bandwidth spike, improving system capacity. Besides analytical studies, our theoretical results are also validated by extensive simulations.", "total_citations": {"2012": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:_xSYboBqXhAC": {"external_link": "https://infoscience.epfl.ch/record/87517", "authors": ["Anwitaman Datta"], "publication_date": "2006", "issue": "3615", "publisher": "EPFL", "description": "Large-scale networked systems often, both by design or chance exhibit self-organizing properties. Understanding self-organization using tools from cybernetics, particularly modeling them as Markov processes is a first step towards a formal framework which can be used in (decentralized) systems research and design. Interesting aspects to look for include the time evolution of a system and to investigate if and when a system converges to some absorbing states or stabilizes into a dynamic (and stable) equilibrium and how it performs under such an equilibrium state. Such a formal framework brings in objectivity in systems research, helping discern facts from artefacts as well as providing tools for quantitative evaluation of such systems. This thesis introduces such formalism in analyzing and evaluating peer-to-peer (P2P) systems in order to better understand the dynamics of such systems which in turn helps in better designs. In particular this thesis develops and studies the fundamental building blocks for a P2P storage system. In the process the design and evaluation methodology we pursue illustrate the typical methodological approaches in studying and designing self-organizing systems, and how the analysis methodology influences the design of the algorithms themselves to meet system design goals (preferably with quantifiable guarantees). These goals include efficiency, availability and durability, load-balance, high fault-tolerance and self-maintenance even in adversarial conditions like arbitrarily skewed and dynamic load and high membership dynamics (churn), apart of-course the specific functionalities that the system is supposed to\u00a0\u2026", "total_citations": {"2007": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:j3f4tGmQtD8C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1231390/", "authors": ["Prasenjit Dey", "Anwitaman Datta"], "publication_date": "2003/6/11", "conference": "WET ICE 2003. Proceedings. Twelfth IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises, 2003.", "pages": "101-106", "publisher": "IEEE", "description": "We try to analyze a generic model for 2-tier distributed systems, exploring the possibility of optimal cluster sizes from an information management perspective, such that the overall cost for updating and searching information may be minimized by adopting a judiciously lazy updating policy. We do not assume either centralized coordination or decentralization, and since it is an initial work, we only advocate the existence of such optimal policies rather than how such policies may be discovered by the system participants. We put our work in perspective using two examples from diverse domains of distributed systems, namely the wireless cellular networks, which are based on centralized coordination and self-organizing peer-to-peer systems using clusters (for example, Kazaa).", "total_citations": {"2006": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:bEWYMUwI8FkC": {"external_link": "https://www.academia.edu/download/30838269/10.1.1.12.7681.pdf", "authors": ["Karl Aberer", "Anwitaman Datta", "Manfred Hauswirth"], "publication_date": "2003", "publisher": "Technical Report IC-2003-25, EPFL", "description": "PGP\u2019s \u201cweb of trust\u201d approach provides basic identification facilities. One benefit of this approach is that it tries to lower the infrastructure requirements such that, for example, no certification authorities are required. In this paper we also pursue this objective but take it even further. We present a self-contained P2P-based directory that provides similar guarantees for identification as PGP, and like PGP requires no dedicated, third-party infrastructure. The participating peers provide the infrastructure along with their normal operation. But unlike PGP it does not require out-of-system mechanisms to disseminate the public key. Instead we exploit properties of the underlying P2P system to ensure correct key publication and retrieval by probabilistic quorums. We argue that this is an efficient and more reliable mechanism compared to web-of-trust approaches.", "total_citations": {"2003": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:artPoR2Yc-kC": {"external_link": "https://www.academia.edu/download/39927062/Autonomous_Gossiping_A_Self-Organizing_E20151112-31360-by4u8f.pdf", "authors": ["Anwitaman Datta", "Silvia Quarteroni", "Karl Aberer"], "description": "We introduce autonomous gossiping (A/G), a new genre epidemic algorithm for selective dissemination of information in contrast to previous usage of epidemic algorithms which flood the whole network. A/G is a paradigm which suits well in a mobile ad-hoc networking (MANET) environment because it does not require any infrastructure or middleware like multicast tree and (un) subscription maintenance for publish/subscribe, but uses ecological and economic principles in a self-organizing manner in order to achieve any arbitrary selectivity (flexible casting). The trade-off of using a stateless self-organizing mechanism like A/G is that it does not guarantee completeness deterministically as is one of the original objectives of alternate selective dissemination schemes like publish/subscribe. We argue that such incompleteness is not a problem in many non-critical real-life civilian application scenarios and realistic node mobility patterns, where the overhead of infrastructure maintenance may outweigh the benefits of completeness, more over, at present there exists no mechanism to realize publish/subscribe or other paradigms for selective dissemination in MANET environments.", "total_citations": {"2008": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:MpfHP-DdYjUC": {"external_link": "https://arxiv.org/abs/2309.04125", "authors": ["Jingchi Zhang", "Anwitaman Datta"], "publication_date": "2023/9/8", "journal": "arXiv preprint arXiv:2309.04125", "description": "In a traditional cloud storage system, users benefit from the convenience it provides but also take the risk of certain security and privacy issues. To ensure confidentiality while maintaining data sharing capabilities, the Ciphertext-Policy Attribute-based Encryption (CP-ABE) scheme can be used to achieve fine-grained access control in cloud services. However, existing approaches are impaired by three critical concerns: illegal authorization, key disclosure, and privacy leakage. To address these, we propose a blockchain-based data governance system that employs blockchain technology and attribute-based encryption to prevent privacy leakage and credential misuse. First, our ABE encryption system can handle multi-authority use cases while protecting identity privacy and hiding access policy, which also protects data sharing against corrupt authorities. Second, applying the Advanced Encryption Standard (AES) for data encryption makes the whole system efficient and responsive to real-world conditions. Furthermore, the encrypted data is stored in a decentralized storage system such as IPFS, which does not rely on any centralized service provider and is, therefore, resilient against single-point failures. Third, illegal authorization activity can be readily identified through the logged on-chain data. Besides the system design, we also provide security proofs to demonstrate the robustness of the proposed system."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:LdasjJ6CEcoC": {"external_link": "https://arxiv.org/abs/2308.02163", "authors": ["Anwitaman Datta", "Dani\u00ebl Reijsbergen", "Jingchi Zhang", "Suman Majumder"], "publication_date": "2023/8/4", "journal": "arXiv preprint arXiv:2308.02163", "description": "By enabling users to safely transfer digital tokens without trusted intermediaries, blockchains have fueled the rise of Decentralized Finance (DeFi). However, the current DeFi ecosystem consists of multiple independent blockchains, and cross-chain token trading is a challenge because the desirable properties of individual blockchains do not always generalize to a multi-chain setting. Recently, advances have been made in the generalization of these properties, but there is still a lack of an overarching framework that provides the full set of properties required for practical cross-chain commerce: transaction atomicity, stablecoin support, privacy-preserving digital identities, and general applicability. In this paper, we present BlockChain I/O to provide such a framework. BlockChain I/O uses entities called cross-chain services to relay information between different chains. Cross-chain services cannot violate transaction atomicity, and are disincentivized from other types of misbehavior -- i.e., causing delays or misrepresenting information -- through an audit system. BlockChain I/O uses stablecoins to mitigate price fluctuations, and a Digital ID system to allow users to prove aspects of their identity without violating privacy. After presenting the core architecture of BlockChain I/O, we demonstrate how to use it to implement a cross-chain marketplace. Finally, we use an experimental evaluation to demonstrate BlockChain I/O's practical performance."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:BzfGm06jWhQC": {"external_link": "https://peerj.com/articles/cs-1339/", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2023/4/20", "journal": "PeerJ Computer Science", "volume": "9", "pages": "e1339", "publisher": "PeerJ Inc.", "description": "This work is motivated by applications of parsimonious cladograms for the purpose of analyzing non-biological data. Parsimonious cladograms were introduced as a means to help understanding the tree of life, and are now used in fields related to biological sciences at large, eg., to analyze viruses or to predict the structure of proteins. We revisit parsimonious cladograms through the lens of clustering and compare cladograms optimized for parsimony with dendograms obtained from single linkage hierarchical clustering. We show that despite similarities in both approaches, there exist datasets whose clustering dendogram is incompatible with parsimony optimization. Furthermore, we provide numerical examples to compare via F-scores the clustering obtained through both parsimonious cladograms and single linkage hierarchical dendograms."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:43bX7VzcjpAC": {"external_link": "https://link.springer.com/article/10.1007/s12553-023-00734-6", "authors": ["Zachary Tan", "Anwitaman Datta"], "publication_date": "2023/3", "journal": "Health and Technology", "volume": "13", "issue": "2", "pages": "301-326", "publisher": "Springer Berlin Heidelberg", "description": "DataThis study looks at the content on Reddit\u2019s COVID-19 community, r/Coronavirus, to capture and understand the main themes and discussions around the global pandemic, and their evolution over the first year of the pandemic.\u00a0It studies 356,690 submissions (posts) and 9,413,331 comments associated with the submissions, corresponding to the period of 20th January 2020 and 31st January 2021.MethodologyOn each of these datasets we carried out analysis based on lexical sentiment and topics generated from unsupervised topic modelling. The study found that negative sentiments show higher ratio in submissions while negative sentiments were of the same ratio as positive ones in the comments. Terms associated more positively or negatively were identified. Upon assessment of the upvotes and downvotes, this study also uncovered contentious topics, particularly \u201cfake\u201d or misleading news.ResultsThrough\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:cK4Rrx0J3m0C": {"external_link": "https://drops.dagstuhl.de/opus/volltexte/2023/18420/", "authors": ["Simone Bottoni", "Anwitaman Datta", "Federico Franzoni", "Emanuele Ragnoli", "Roberto Ripamonti", "Christian Rondanini", "Gokhan Sagirlar", "Alberto Trombetta"], "publication_date": "2023", "conference": "4th International Conference on Blockchain Economics, Security and Protocols (Tokenomics 2022)", "publisher": "Schloss Dagstuhl-Leibniz-Zentrum f\u00fcr Informatik", "description": "Limited scalability and transaction costs are some of the critical issues that hamper a wider adoption of distributed ledger technologies (DLTs). That is particularly true for the Ethereum [Wood, 2014] blockchain, which, so far, has been the ecosystem with the highest adoption rate. Several solutions have been attempted in the last few years, most of which adopt the approach to offload transactions from the blockchain mainnet, aka Level 1 (L1), to a separate network. Such solutions are collectively known as Level 2 (L2) systems. While improving scalability, the adoption of L2 introduces additional drawbacks: users have to trust that the L2 system has correctly performed transactions or, conversely, high computational power is required to prove transactions\u2019 correctness. In addition, significant technical knowledge is needed to set up and manage such an L2 system. To tackle such limitations, we propose 1DLT: a novel system that enables rapid deployment of an Ethereum Virtual Machine based (EVM-based) blockchain that overcomes those drawbacks."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=100&pagesize=100&citation_for_view=VWi3_OIAAAAJ:F1b5ZUV5XREC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9756449/", "authors": ["Frederique Oggier", "Silivanxay Phetsouvanh", "Anwitaman Datta"], "publication_date": "2022/4/13", "journal": "IEEE Access", "volume": "10", "pages": "40001-40026", "publisher": "IEEE", "description": "The structure of many complex networks includes edge directionality and weights on top of their topology. Network analysis that can seamlessly consider combination of these properties are desirable. In this paper, we study two important such network analysis techniques, namely, centrality and clustering. An information-flow based model is adopted for clustering, which itself builds upon an information theoretic measure for computing centrality. Our principal contributions include (1) a generalized model of Markov entropic centrality with the flexibility to tune the importance of node degrees, edge weights and directions, with a closed-form asymptotic analysis, which (2) leads to a novel two-stage graph clustering algorithm. The centrality analysis helps reason about the suitability of our approach to cluster a given graph, and determine \u2018query\u2019 nodes, around which to explore local community structures, leading to an\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:GFxP56DSvIMC": {"external_link": "https://link.springer.com/article/10.1007/s13278-021-00720-8", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2021/12", "journal": "Social Network Analysis and Mining", "volume": "11", "pages": "1-14", "publisher": "Springer Vienna", "description": "We propose a two-step methodology for exploring the temporal characteristics of a network. First, we construct a graph time series, where each snapshot is the result of a temporal whole-graph embedding. The embedding is carried out using the degree, Katz and betweenness centralities to characterize first and higher order proximities among vertices. Then a principal component analysis is performed over the collected temporal graph samples, which exhibits eigengraphs, graphs whose temporal weight variations model the sampled graph series. Analysis of the temporal timeline of each of the main eigengraphs reveals moments of importance in terms of structural graph changes. Parameters such as the dimension of the embeddings and the number of temporal samples are explored. Two case studies are presented: a Bitcoin subgraph, where findings are cross-checked by looking at the subgraph\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:zCSUwVk65WsC": {"external_link": "https://dr.ntu.edu.sg/handle/10220/25483", "authors": ["Anwitaman Datta", "Fr\u00e9d\u00e9rique Oggier"], "publication_date": "2015", "description": "Networked distributed storage systems (NDSS) use erasure codes in lieu of replication for realising data redundancy. An interesting research challenge is to derive the largest advantage from the trade\u2013offs between storage overhead and reliability that erasure codes provide, while optimising them to satisfy specific storage needs like repairability and better degraded read performance. Many coding strategies for NDSS exploit the storage nodes' computational ability to improve on repairability by applying network coding techniques. However, not every storage node in a NDSS is necessarily endowed with computing capability. This paper studies the effects of passive nodes, i.e., nodes without computational ability, on the repairability of erasure coded data, and how they may impair the promised performance of novel coding techniques. Specifically, we determine a lower bound on the minimum storage overhead in an active\u2013passive mixed storage network, indicative of the price to pay in storage to achieve bandwidth efficient repairability."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:WZBGuue-350C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-662-48567-5_1", "authors": ["Quach Vinh Thanh", "Anwitaman Datta"], "publication_date": "2015", "journal": "Transactions on Large-Scale Data-and Knowledge-Centered Systems XXII", "pages": "1-32", "publisher": "Springer Berlin Heidelberg", "description": "An abundance of data generated from a multitude of sources, and intelligence derived by analyzing the same, has become an important asset across many walks of life. Simultaneously, it raises serious concerns about privacy. Differential privacy has become a popular way to reason about the amount of information about individual entries of a dataset that is divulged upon giving out a perturbed result for a query on a given data-set. However, current differentially-private algorithms are computationally inefficient, and do not explicitly exploit the abundance of data, thus wearing out the privacy budget irrespective of the volume of data. In this paper, we propose BPMiner, a solution that is both private and accurate, while simultaneously addressing the computation and budget challenges of very big datasets. The main idea is a non-trivial combination between differential privacy, sample-and-aggregation, and a\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:kz9GbA2Ns4gC": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d976bbff6bfa716f07652030f12b1394b2a1bb22", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2015", "journal": "by International Journal on Information and", "description": "A major change has been recently witnessed in networked distributed storage systems (NDSS), with increased use of erasure codes in lieu of replication for realizing data redundancy. Yet, both the industry and academic research communities are still trying to derive most advantage from the trade-offs between storage overhead and reliability that erasure codes provide, while optimizing them to satisfy specific storage needs like repairability and better degraded read performance."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:EYYDruWGBe4C": {"external_link": "https://www.inderscienceonline.com/doi/abs/10.1504/IJICOT.2015.068697", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2015/1/1", "journal": "International Journal of Information and Coding Theory", "volume": "3", "issue": "1", "pages": "58-77", "publisher": "Inderscience Publishers", "description": "Networked distributed storage systems (NDSS) use erasure codes in lieu of replication for realising data redundancy. An interesting research challenge is to derive the largest advantage from the trade\u2013offs between storage overhead and reliability that erasure codes provide, while optimising them to satisfy specific storage needs like repairability and better degraded read performance. Many coding strategies for NDSS exploit the storage nodes' computational ability to improve on repairability by applying network coding techniques. However, not every storage node in a NDSS is necessarily endowed with computing capability. This paper studies the effects of passive nodes, i.e., nodes without computational ability, on the repairability of erasure coded data, and how they may impair the promised performance of novel coding techniques. Specifically, we determine a lower bound on the minimum storage overhead in\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:0CzhzZyukY4C": {"external_link": "https://scholar.google.com/scholar?cluster=7378022577627343756&hl=en&oi=scholarr", "authors": ["Fr\u00e9d\u00e9rique Oggier", "Anwitaman Datta"], "publication_date": "2014", "description": "Networked distributed data storage systems are essential to deal with the needs of storing massive volumes of data. Dependability of such a system relies on its fault tolerance (data should be available in case of node failures) as well as its maintainability (its ability to repair lost data to ensure redundancy replenishment over time). Erasure codes provide a storage efficient alternative to replication based redundancy in storage systems, ensuring the same fault tolerance at a lower storage overhead cost. Traditional erasure codes however have the drawback of entailing high communication overhead for maintenance, when encoded fragments are lost due to storage device failures, and need to be replenished in new nodes. We propose a new family of erasure codes called self-repairing codes (SRC) taking into account the peculiarities of distributed storage systems, specifically to improve its maintainability by\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:4hFrxpcac9AC": {"external_link": "https://scholar.google.com/scholar?cluster=6284757380775724879&hl=en&oi=scholarr", "authors": ["Xin Liu", "Anwitaman Datta", "Karl Aberer"], "publication_date": "2014", "book": "Encyclopedia of Social Network Analysis and Mining", "pages": "250-260"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:yqoGN6RLRZoC": {"external_link": "https://ui.adsabs.harvard.edu/abs/2013arXiv1312.5155S/abstract", "authors": ["Kyumars Sheykh Esmaili", "Anwitaman Datta"], "publication_date": "2013/12", "journal": "arXiv e-prints", "pages": "arXiv: 1312.5155", "description": "There are different ways to realize Reed Solomon (RS) codes. While in the storage community, using the generator matrices to implement RS codes is more popular, in the coding theory community the generator polynomials are typically used to realize RS codes. Prominent exceptions include HDFS-RAID, which uses generator polynomial based erasure codes, and extends the Apache Hadoop's file system. In this paper we evaluate the performance of an implementation of polynomial realization of Reed-Solomon codes, along with our optimized version of it, against that of a widely-used library (Jerasure) that implements the main matrix realization alternatives. Our experimental study shows that despite significant performance gains yielded by our optimizations, the polynomial implementations' performance is constantly inferior to those of matrix realization alternatives in general, and that of Cauchy bit matrices in\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:5MTHONV0fEkC": {"external_link": "https://ui.adsabs.harvard.edu/abs/2013arXiv1302.5192S/abstract", "authors": ["Kyumars Sheykh Esmaili", "Lluis Pamies-Juarez", "Anwitaman Datta"], "publication_date": "2013/2", "journal": "arXiv e-prints", "pages": "arXiv: 1302.5192", "description": "Erasure codes are an integral part of many distributed storage systems aimed at Big Data, since they provide high fault-tolerance for low overheads. However, traditional erasure codes are inefficient on reading stored data in degraded environments (when nodes might be unavailable), and on replenishing lost data (vital for long term resilience). Consequently, novel codes optimized to cope with distributed storage system nuances are vigorously being researched. In this paper, we take an engineering alternative, exploring the use of simple and mature techniques-juxtaposing a standard erasure code with RAID-4 like parity. We carry out an analytical study to determine the efficacy of this approach over traditional as well as some novel codes. We build upon this study to design CORE, a general storage primitive that we integrate into HDFS. We benchmark this implementation in a proprietary cluster and in EC2. Our\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Mojj43d5GZwC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6425748/", "authors": ["Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2012/8/26", "conference": "2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining", "pages": "294-301", "publisher": "IEEE", "description": "Modeling and understanding social network structure has interested researchers from many backgrounds including social science, computer science, theoretical physics and graph theory. Notable models include [1] and [2] achieving graphs with power-law degree distribution using preferential attachment and small-world characteristics using randomized rewiring of a regular ring lattice respectively. In contrast to a body of follow-up research which refine upon these seminal works to better capture the graph structure and characteristics (such as improving clustering coefficient by considering social triads along with preferential attachment [3]), this work aims additionally to model the geographic spread in social networks. With increased mobility in our society as well as enhanced communication opportunities social networks are increasingly spread all over the globe. Synthetic graphs imitating real-world social\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:BwyfMAYsbu0C": {"external_link": "https://arxiv.org/abs/1206.2038", "authors": ["Dinh Tien Tuan Anh", "Quach Vinh Thanh", "Anwitaman Datta"], "publication_date": "2012/6/10", "journal": "arXiv preprint arXiv:1206.2038", "description": "An increasing number of businesses are replacing their data storage and computation infrastructure with cloud services. Likewise, there is an increased emphasis on performing analytics based on multiple datasets obtained from different data sources. While ensuring security of data and computation outsourced to a third party cloud is in itself challenging, supporting analytics using data distributed across multiple, independent clouds is even further from trivial. In this paper we present CloudMine, a cloud-based service which allows multiple data owners to perform privacy-preserved computation over the joint data using their clouds as delegates. CloudMine protects data privacy with respect to semi-honest data owners and semi-honest clouds. It furthermore ensures the privacy of the computation outputs from the curious clouds. It allows data owners to reliably detect if their cloud delegates have been lazy when carrying out the delegated computation. CloudMine can run as a centralized service on a single cloud, or as a distributed service over multiple, independent clouds. CloudMine supports a set of basic computations that can be used to construct a variety of highly complex, distributed privacy-preserving data analytics. We demonstrate how a simple instance of CloudMine (secure sum service) is used to implement three classical data mining tasks (classification, association rule mining and clustering) in a cloud environment. We experiment with a prototype of the service, the results of which suggest its practicality for supporting privacy-preserving data analytics as a (multi) cloud-based service."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:4fKUyHm3Qg0C": {"external_link": "https://arxiv.org/abs/1206.1653", "authors": ["Stefano Braghin", "Jackson Tan", "Rajesh Sharma", "Anwitaman Datta"], "publication_date": "2012/6/8", "journal": "arXiv preprint arXiv:1206.1653", "description": "In this work we describe the PriSM framework for decentralized deployment of a federation of autonomous social networks (ASN). The individual ASNs are centrally managed by organizations according to their institutional needs, while cross-ASN interactions are facilitated subject to security and confidentiality requirements specified by administrators and users of the ASNs. Such decentralized deployment, possibly either on private or public clouds, provides control and ownership of information/flow to individual organizations. Lack of such complete control (if third party online social networking services were to be used) has so far been a great barrier in taking full advantage of the novel communication mechanisms at workplace that have however become commonplace for personal usage with the advent of Web 2.0 platforms and online social networks. PriSM provides a practical solution for organizations to harness the advantages of online social networking both in intra/inter-organizational settings without sacrificing autonomy, security and confidentiality needs."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:ubry08Y2EpUC": {"external_link": "https://scholar.google.com/scholar?cluster=12697847226399862636&hl=en&oi=scholarr", "authors": ["Anwitaman Datta", "Frederique Oggier"], "publication_date": "2012", "description": "The problem of replenishing redundancy in erasure code based fault-tolerant storage has received a great deal of attention recently, leading to the design of several new coding techniques [3], aiming at a better repairability. In this paper, we adopt a different point of view, by proposing to code across different already encoded objects to alleviate the repair problem. We show that the addition of parity pieces-the simplest form of coding-significantly boosts repairability without sacrificing fault-tolerance for equivalent storage overhead. The simplicity of our approach as well as its reliance on timetested techniques makes it readily deployable."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:a9-T7VOCCH8C": {"external_link": "https://scholar.google.com/scholar?cluster=2251646340850250968&hl=en&oi=scholarr", "authors": ["Frederique Oggier", "Anwitaman Datta"], "publication_date": "2011", "description": "Self-Repairing Codes (SRC) are codes designed to suit the need of coding for distributed networked storage: they not only allow stored data to be recovered even in the presence of node failures, they also provide a repair mechanism where as little as two live nodes can be contacted to regenerate the data of a failed node. In this paper, we propose a new instance of self-repairing codes, based on constructions of spreads coming from projective geometry. We study some of their properties to demonstrate the suitability of these codes for distributed networked storage."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:CHSYGLWDkRkC": {"external_link": "https://arxiv.org/abs/1006.2433", "authors": ["Anwitaman Datta"], "publication_date": "2010/6/12", "journal": "arXiv preprint arXiv:1006.2433", "description": "In this paper we introduce a novel gossiping primitive to support privacy preserving data analytics (PPDA). In contrast to existing computational PPDA primitives such as secure multiparty computation and data randomization based approaches, the proposed primitive `anonymous gossiping' is a communication primitive for privacy preserving personalized information aggregation complementing such traditional computational analytics. We realize this novel primitive by composing existing gossiping mechanisms for peer sampling & information aggregation and onion routing technique for establishing anonymous communication. This is more an `ideas' paper, rather than providing concrete and quantified results."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:u-coK7KVo8oC": {"external_link": "https://scholar.google.com/scholar?cluster=8376395212358723874&hl=en&oi=scholarr", "authors": ["Krzysztof Rzadca", "Anwitaman Datta", "Sonja Buchegger"], "publication_date": "2010", "description": "In peer-to-peer storage systems, peers replicate each others\u2019 data in order to increase availability. If the matching is done centrally, the algorithm can optimize data availability in an equitable manner for all participants. However, if matching is decentralized, the peers\u2019 selfishness can greatly alter the results, leading to performance inequities that can render the system unreliable and thus ultimately unusable. We analyze the problem using both theoretical approaches (complexity analysis for the centralized system, game theory for the decentralized one) and simulation. We prove that the problem of optimizing availability in a centralized system is NP-hard. In decentralized settings, we show that the rational behavior of selfish peers will be to replicate only with similarly-available peers. Compared to the socially-optimal solution, highly available peers have their data availability increased at the expense of decreased\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:ZzlSgRqYykMC": {"external_link": "https://ink.library.smu.edu.sg/context/sis_research/article/1511/viewcontent/icadl10.pdf", "authors": ["Ee Peng LIM", "Agus Trisnajaya KWEE", "Nelman Lubis IBRAHIM", "Aixin SUN", "Anwitaman DATTA", "Kuiyu CHANG", "Maureen MAUREEN"], "publication_date": "2010", "journal": "The Role of Digital Libraries in a Time of Global Change: 12th International Conference on Asia-Pacific Digital Libraries, ICADL", "pages": "21-25", "description": "Information networks in Wikipedia evolve as users collaboratively edit articles that embed the networks. These information networks represent both the structure and content of community\u2019s knowledge and the networks evolve as the knowledge gets updated. By observing the networks evolve and finding their evolving patterns, one can gain higher order knowledge about the networks and conduct longitudinal network analysis to detect events and summarize trends. In this paper, we present SSNetViz+, a visual analytic tool to support visualization and exploration of Wikipedia\u2019s information networks. SSNetViz+ supports timebased network browsing, content browsing and search. Using a terrorism information network as an example, we show that different timestamped versions of the network can be interactively explored. As information networks in Wikipedia are created and maintained by collaborative editing efforts\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:AXPGKjj_ei8C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-12257-6_6", "authors": ["Anwitaman Datta", "Krzysztof Rzadca", "Sally Ang", "Goh Chee Hong"], "publication_date": "2010", "journal": "e-Research Collaboration: Theory, Techniques and Challenges", "pages": "85-104", "publisher": "Springer Berlin Heidelberg", "description": "Recent portable devices, from sophisticated mobile phones, to netbooks, thanks to wireless networking and powerful batteries, give hardware support for collaborative work on the go, even when the Internet connection is not available. Yet, current collaboration software requires a dedicated server to synchronize clients, and thus a stable network connection. In this chapter, we present two tools that use peer-to-peer paradigm to build serverless collaboration networks. PBDMS enables users to share, search and review bibliographic databases. SharedMind provides collaborative document editing to FreeMind, popular, open source mind-mapping software. Both tools handle disconnections and network divisions, enabling users to continue their work and to synchronize with their reachable peers. Both tools have been implemented and tested in small scale. PBDMS is available for download at                  http\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:NhqRSupF_l8C": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-642-13672-6_7", "authors": ["Hock Hee Ang", "Vivekanand Gopalkrishnan", "Anwitaman Datta", "Wee Keong Ng", "Steven CH Hoi"], "publication_date": "2010", "conference": "Advances in Knowledge Discovery and Data Mining: 14th Pacific-Asia Conference, PAKDD 2010, Hyderabad, India, June 21-24, 2010. Proceedings. Part II 14", "pages": "63-70", "publisher": "Springer Berlin Heidelberg", "description": "Distributed classification aims to build an accurate classifier by learning from distributed data while reducing computation and communication cost. A P2P network where numerous users come together to share resources like data content, bandwidth, storage space and CPU resources is an excellent platform for distributed classification. However, two important aspects of the learning environment have often been overlooked by other works, viz., 1) location of the peers which results in variable communication cost and 2) heterogeneity of the peers\u2019 data which can help reduce redundant communication. In this paper, we examine the properties of network and data heterogeneity and propose a simple yet efficient P2P classification approach that minimizes expensive inter-region communication while achieving good generalization performance. Experimental results demonstrate the feasibility and effectiveness\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:3s1wT3WcHBgC": {"external_link": "https://www.igi-global.com/chapter/handbook-research-p2p-grid-systems/40820", "authors": ["Anwitaman Datta", "Di Wu", "Liu Xin", "Adam Wierzbicki"], "publication_date": "2010", "book": "Handbook of Research on P2P and Grid Systems for Service-Oriented Computing: Models, Methodologies and Applications", "pages": "616-634", "publisher": "IGI Global", "description": "Peer-to-Peer (P2P) storage systems leverage the combined storage capacity of a network of storage devices (peers) contributed typically by autonomous end-users as a common pool of storage space to store and share content. A major challenge in such a system comprising of autonomous participants is to guarantee quality of service in terms of persistence and availability of the stored content. This chapter focuses on the different possible design choices for maintaining redundancy in P2P storage systems, including algorithm details of maintenance mechanisms, analytical models to understand system\u2019s dynamics, empirical results from simulation experiments as well as experiences from prototype deployments."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:r0BpntZqJG4C": {"external_link": "https://link.springer.com/chapter/10.1007/978-0-387-09751-0_11", "authors": ["Anwitaman Datta"], "publication_date": "2009/10/15", "book": "Handbook of Peer-to-Peer Networking", "pages": "281-308", "publisher": "Springer US", "description": "Structured overlays are an important primitive in building various peer-to-peer (P2P) systems, and is used for various functions including address independent end-to-end routing, managing multicast groups, indexing of content in a decentralized environment and P2P storage, among others. While they operate in a decentralized manner, and the self-stabilizing mechanisms to maintain the overlays are also decentralized, bootstrapping structured overlays have traditionally assumed implicit centralization and/or coordination. In this chapter, we provide a survey of different flavors of structured overlay construction mechanisms \u2013 including quasi-sequential mechanisms which are predominantly in use, followed by parallelized approaches, and finally looking into how two isolated overlay can be merged, which is key to decentralized bootstrapping."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:PaBasH6fAo0C": {"external_link": "https://ink.library.smu.edu.sg/context/sis_research/article/1470/viewcontent/p213_lim.pdf", "authors": ["Ee Peng LIM", "Maureen MAUREEN", "Nelman Lubis IBRAHIM", "Aixin SUN", "Anwitaman DATTA", "Kuiyu CHANG"], "publication_date": "2009", "journal": "Proceedings of the Eleventh International Conference on Electronic Commerce (ICEC 2009), August", "pages": "12-15", "description": "SSnetViz is an ongoing research to design and implement a visualization engine for heterogeneous semantic social networks. A semantic social network is a multi-modal network that contains nodes representing different types of people or object entities, and edges representing relationships among them. When multiple heterogeneous semantic social networks are to be visualized together, SSnetViz provides a suite of functions to store heterogeneous semantic social networks, to integrate them for searching and analysis. We will illustrate these functions using social networks related to terrorism research, one crafted by domain experts and another from Wikipedia."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:fFSKOagxvKUC": {"external_link": "https://dr.ntu.edu.sg/handle/10356/42460", "authors": ["Anwitaman Datta"], "publication_date": "2009", "description": "The original objective of the project was to explore the fundamental and conceptual challenges, as well as carry out implementation in realizing a peer-topeer overlay based application layer internet, which will facilitate Web 2.0 applications and services in a network and device independent manner. The work carried out within the context of the SuG itself comprised on mainly exploring conceptual problems \u2013 particularly algorithms for overlay design \u2013 for efficient content discovery and dissemination in peer-to-peer settings."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:SeFeTyx0c_EC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-540-88875-8_8", "authors": ["Anwitaman Datta", "Liu Xin"], "publication_date": "2008/11/9", "book": "OTM Confederated International Conferences\" On the Move to Meaningful Internet Systems\"", "pages": "16-17", "publisher": "Springer Berlin Heidelberg", "description": "Using peer-to-peer overlays to notify users whenever a new update occurs is a promising approach to support web based publish subscribe systems like RSS. Such a peer-to-peer approach can scale well by reducing load at the source and also guarantee timeliness of notifications. However, malicious peers may stop propagating the updates or modify them, thus making the P2P mechanism useless or even harmful. We propose overlay independent randomized strategies to mitigate these ill-effects of malicious peers at a marginal overhead. In the P2P approaches, generally a small subset of the end-users (Rootpeers) pull directly from the source and push any update downstream (to Downstream peers). Several such P2P approaches have been proposed [1], [2], [3]. Unlike other approaches, our approach puts the focus on the security issue, that is to protect the system against various\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:8xutWZnSdmoC": {"external_link": "https://ink.library.smu.edu.sg/context/sis_research/article/2259/viewcontent/isi2008.pdf", "authors": ["Minh-Tam LE", "Hoang-Vu DANG", "Ee Peng LIM", "Anwitaman DATTA"], "publication_date": "2008", "journal": "IS 2008: IEEE Conference on Intelligence and Security Informatics, 17-20 June 2008", "pages": "52-57", "description": "When multiple users with diverse backgrounds and beliefs edit Wikipedia together, disputes often arise due to disagreements among the users. In this paper, we introduce a novel visualization tool known as WikiNetViz to visualize and analyze disputes among users in a dispute-induced social network. WikiNetViz is designed to quantify the degree of dispute between a pair of users using the article history. Each user (and article) is also assigned a controversy score by our proposed ControversyRank model so as to measure the degree of controversy of a user (and an article) by the amount of disputes between the user (article) and other users in articles of varying degrees of controversy. On the constructed social network, WikiNetViz can perform clustering so as to visualize the dynamics of disputes at the user group level. It also provides an article viewer for examining an article revision so as to determine the article\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:xtRiw3GOFMkC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/1651267/", "authors": ["Anwitaman Datta", "Martin Hasler", "Karl Aberer"], "publication_date": "2005/12/19", "conference": "2005 International Conference on Collaborative Computing: Networking, Applications and Worksharing", "pages": "4 pp.", "publisher": "IEEE", "description": "We do a case study of two different analysis techniques for studying the stochastic behavior of a randomized system/algorithms: (i) The first approach can be broadly termed as a mean value analysis (MVA), where the evolution of the mean state is studied assuming that the system always actually resides in the mean state; (ii) The second approach looks at the probability distribution function of the system states at any time instance, thus studying the evolution of the (probability mass) distribution function (EoDF)."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:ruyezt5ZtCIC": {"external_link": "https://pdfs.semanticscholar.org/0a1f/8819d8cffd8b10fddc7114352ed1d31dd15c.pdf", "authors": ["Karl Aberer", "GI Arbeitsgespr\u00e4ch", "Anwitaman Datta", "Manfred Hauswirth", "Roman Schmidt"], "publication_date": "2003/10/31", "description": "Self-organizing Distributed Data Access Page 1 \u00a92003, Karl Aberer, School of Computer and \nCommunication Sciences TU Berlin 31. October, 2003 Self-organizing Distributed Data \nAccess Karl Aberer School of Computer and Communication Sciences, EPFL karl.aberer@epfl.ch \nlsirwww.epfl.ch TU Berlin, October 31, 2003 joint work with: Anwitaman Datta, Manfred \nHauswirth, Roman Schmidt, Philippe Cudre-Mauroux, Zoran Despotovic Page 2 \u00a92003, Karl \nAberer, School of Computer and Communication Sciences TU Berlin 31. October, 2003 \nOutline 1.Self-organizing Information systems 2. Introduction of P-Grid 3. Identity management \n4. Semantic interoperability 5. Conclusion Page 3 \u00a92003, Karl Aberer, School of Computer \nand Communication Sciences TU Berlin 31. October, 2003 1. What is Self-organization ? \u2022 \nInformal characterization (physics, biology, cybernetics,\u2026 and CS) \u2013 distribution of control (= \u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Aul-kAQHnToC": {"external_link": "https://core.ac.uk/download/pdf/35456033.pdf", "authors": ["Hock Kee ANG", "Vivekanand Gopalkrishnan", "Anwitaman DATTA", "Wee Keong NG", "Steven CH HOI"], "journal": "Advances in Knowledge Discovery and Data Mining: 14th Pacific-Asia Conference, PAKDD 2010, Hyderabad, India, June 21-24, 2010. Proceedings. Part II", "pages": "63-70", "description": "Distributed classification aims to build an accurate classifier by learning from distributed data while reducing computation and communication cost. A P2P network where numerous users come together to share resources like data content, bandwidth, storage space and CPU resources is an excellent platform for distributed classification. However, two important aspects of the learning environment have often been overlooked by other works, viz., 1) location of the peers which results in variable communication cost and 2) heterogeneity of the peers\u2019 data which can help reduce redundant communication. In this paper, we examine the properties of network and data heterogeneity and propose a simple yet efficient P2P classification approach that minimizes expensive interregion communication while achieving good generalization performance. Experimental results demonstrate the feasibility and effectiveness of the proposed solution."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:_OXeSy2IsFwC": {"external_link": "https://scholar.google.com/scholar?cluster=2086355062406797176&hl=en&oi=scholarr", "authors": ["Ee Peng LIM", "Aixin SUN", "Anwitaman DATTA", "CHANG KUIYU"], "journal": "Link Mining: Models, Algorithms, and Applications", "pages": "265-281", "description": "With increasing interest in querying and analyzing graph data from multiple sources, algorithms and tools to integrate different graphs become very important. Integration of graphs can take place at the schema and instance levels. While links among graph nodes pose additional challenges to graph information integration, they can also serve as useful features for matching nodes representing realworld entities. This chapter introduces a general framework to perform graph information integration. It then gives an overview of the state-of-the-art research and tools in graph information integration."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:Ehil0879vHcC": {"external_link": "https://core.ac.uk/download/pdf/35453393.pdf", "authors": ["Hock Hee ANG", "Vikvekanand GOPALKRISHNAN", "Steven CH HOI", "Wee Keong NG", "Anwitaman DATTA"], "journal": "VLDB Workshop on Peer-to-Peer Computing 2008, August 23, Auckland, 23 August: Proceedings", "pages": "13-25", "description": "Data mining tasks in P2P are bound by issues like scalability, peer dynamism, asynchronism, and data privacy preservation. These challenges pose difficulties for deploying conventional machine learning techniques in P2P networks, which may be hard to achieve classification accuracies comparable to regular centralized solutions. We recently investigated the classification problem in P2P networks and proposed a novel P2P classification approach by cascading Reduced Support Vector Machines (RSVM). Although promising results were obtained, the existing solution has some drawback of redundancy in both communication and computation. In this paper, we present a new approach to over the limitation of the previous approach. The new method can effectively reduce the redundancy and thus significantly improve the efficiency of communication and computation, meanwhile it still maintains good classification accuracies comparable to both the centralized solution and the previously proposed P2P solution. Experimental results demonstrate the feasibility and effectiveness of the new P2P classification solution."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:XvxMoLDsR5gC": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=63c611b40064a4c9a9548d1ae5d30d166e3fd782", "authors": ["Anwitaman Datta"], "description": "Peer-to-Peer index structures distributed and managed over the planet, commonly known as structured overlays (eg, Distributed Hash Tables) have been touted to play the role of a fundamental building block for internet-scale distributed systems. Traditional designs consider incremental or possibly even parallelized construction of a single overlay, which implicitly assumes global control and coordination to enforce the construction of an unique overlay. However, if merger of originally isolated overlays is made possible, then one can realize decentralized bootstrapping of overlays. So to say, smaller overlays can be constructed using any of the traditional mechanisms, which can then organically coalesce to form a larger overlay. Such a self-organizational attribute of decentralized bootstrapping is of paramount importance for large scale systems. In our previous works, we explained the challenges of merging important families of (tree and ring) structured overlays [6], and identified that tree structured overlays are relatively easier to merge in a transparent manner [5]. In this paper we investigate how two ring structured overlays can be merged, both in terms of the necessary algorithms, as well as how it performs during the merger process. We also introduce interesting new metrics to evaluate the merger process and carry out asymptotic analysis for estimating the same, besides conducting simulation experiments to validate the theory as well as measure other aspects of the overlays\u2019 performance."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VWi3_OIAAAAJ&cstart=200&pagesize=100&citation_for_view=VWi3_OIAAAAJ:L7CI7m0gUJcC": {"external_link": "https://scholar.google.com/scholar?cluster=1478975833241530907&hl=en&oi=scholarr", "authors": ["Piotr Skowron", "Krzysztof Rzadca", "Anwitaman Datta"], "description": "To successfully complete a complex project, be it a construction of an airport or of a backbone IT system, agents (companies or individuals) must form a team (a coalition) having required competences and resources. A team can be formed either by the project issuer based on individual agents\u2019 offers (centralized formation, corresponding to the setsystem auctions in the literature); or by the agents themselves (decentralized formation) bidding for a project as a consortium\u2014in that case many feasible teams compete for the contract. In these models, we investigate rational strategies of the agents (what salary should they ask? with whom should they team up?) under different organizations of the market. We propose various concepts allowing to characterize the stability of the winning teams. We show that there may be no (rigorously) strongly winning coalition, but the weakly winning and the auction-winning coalitions\u00a0\u2026"}}