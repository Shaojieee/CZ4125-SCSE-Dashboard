{"full_name": "Liu Weichen", "email": "liu@ntu.edu.sg", "google_scholar": "https://scholar.google.com/citations?user=UozjxW8AAAAJ&hl=en", "dr_ntu": "https://dr.ntu.edu.sg/cris/rp/rp00280", "designation": "Associate Professor, School of Computer Science and Engineering", "image_path": "./profile_img/liu_weichen.jpg", "biography": "Dr. Weichen Liu is an Associate Professor at the School of Computer Science and Engineering, Nanyang Technological University, Singapore. He was a Nanyang Assistant Professor (NAP) during 2018-2023. He received his PhD degree from the Hong Kong University of Science and Technology, and the MEng and BEng degrees from Harbin Institute of Technology, China. Dr. Liu serves as an Associate Editor of IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), and a Subject Area Editor of Elsevier Journal of Systems Architecture (JSA). He served as a General Chair of the 25th IEEE International Symposium on Real-Time Computing (ISORC 2020), a Program Chair of ISORC 2019, a Track Chair of ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED 2021, 2022), The 16th IEEE International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC 2023), and a chair, technical program committee member, organizing committee member and guest editor of over 20 premier international conferences, journals, workshops and student forums, including DAC, ICCAD, ASP-DAC, CODES+ISSS, RTSS, RTAS, ISLPED, GLSVLSI, MSC@ESWEEK, SRF@ASP-DAC, EAI@ICDCS, etc. Dr. Liu authored and co-authored more than 170 research papers in peer-reviewed journals, conferences and books, and received the best paper candidate awards from DATE 2023, GLSVLSI 2022, ASP-DAC 2020, 2019 and 2016, CASES 2015, CODES+ISSS 2009, and the best poster paper awards from SRF@ASP-DAC 2020 and 2017, RTCSA 2017, AMD-TFE 2010. His research was supported by leading industrial partners including Intel, AMD, Xilinx, MediaTek, Huawei and HP.", "orcid": "https://orcid.org/0000-0001-9348-4662", "other_websites": ["https://personal.ntu.edu.sg/liu/"], "bachelor_degree": null, "masters": null, "phd": null, "name": "Liu Weichen", "id": "rp00280", "publications": {"Publication Year": ["2018", "2010", "2011", "2013", "2012", "2010", "2019", "2012", "2021", "2014", "2010", "2012", "2008", "2014", "2010", "2020", "2019", "2017", "2014", "2020", "2017", "2016", "2018", "2017", "2018", "2020", "2007", "2009", "2019", "2014", "2019", "2014", "2020", "2010", "2018", "2011", "2019", "2018", "2019", "2016", "2012", "2020", "2019", "2017", "2019", "2018", "2015", "2020", "2016", "2014", "2020", "2019", "2009", "2021", "2021", "2021", "2020", "2019", "2019", "2017", "2022", "2021", "2019", "2018", "2017", "2020", "2016", "2014", "2011", "2021", "2019", "2019", "2015", "2015", "2009", "2007", "2020", "2019", "2018", "2017", "2015", "2014", "2013", "2022", "2021", "2021", "2020", "2020", "2018", "2017", "2016", "2012", "2009", "2006", "2020", "2020", "2018", "2017", "2014", "2022", "2021", "2020", "2019", "2018", "2015", "2014", "2009", "2022", "2022", "2021", "2021", "2019", "2019", "2018", "2015", "2011", "2023", "2022", "2022", "2021", "2021", "2020", "2019", "2018", "2013", "2023", "2023", "2023", "2022", "2022", "2021", "2021", "2021", "2020", "2019", "2018", "2018", "2017", "2016", "2015", "2012", "2023", "2023", "2023", "2023", "2023", "2023", "2023", "2023", "2023", "2023", "2023", "2023", "2022", "2022", "2022", "2021", "2020", "2020", "2018", "2018", "2017", "2015", "Unknown"], "Title": ["TripImputor: real-time imputing taxi trip purpose leveraging multi-sourced urban data", "Crosstalk noise and bit error rate analysis for optical network-on-chip", "A NoC Traffic Suite Based on Real Applications", "3-D mesh-based optical network-on-chip for multiprocessor system-on-chip", "Formal worst-case analysis of crosstalk noise in mesh-based optical networks-on-chip", "A hierarchical hybrid optical-electronic network-on-chip", "HolyLight: A Nanophotonic Accelerator for Deep Learning in Data Centers", "A torus-based hierarchical optical-electronic network-on-chip for multiprocessor system-on-chip", "Bringing AI to edge: From deep learning\u2019s perspective", "UNION: A Unified Inter/Intrachip Optical Network for Chip Multiprocessors", "Union: A unified inter/intra-chip optical network for chip multiprocessors", "System-level modeling and analysis of thermal effects in optical networks-on-chip", "Efficient SAT-based mapping and scheduling of homogeneous synchronous dataflow graphs for throughput optimization", "Building high-performance smartphones via non-volatile memory: The swap approach", "Satisfiability modulo graph theory for task mapping and scheduling on multiprocessor systems", "Solving dynamic multiobjective problem via autoencoding evolutionary search", "Fault-tolerant routing mechanism in 3D optical network-on-chip based on node reuse", "Task mapping on smart noc: Contention matters, not the distance", "A case study on the communication and computation behaviors of real applications in NoC-based MPSoCs", "Co-exploring neural architecture and network-on-chip design for real-time artificial intelligence", "Efficient drone hijacking detection using onboard motion sensors", "Application mapping and scheduling for network-on-chip-based multiprocessor system-on-chip with fine-grain communication optimization", "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit", "Fotonoc: A folded torus-like network-on-chip based many-core systems-on-chip in the dark silicon era", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "LightBulb: A Photonic-Nonvolatile-Memory-based Accelerator for Binarized Convolutional Neural Networks", "An efficient algorithm for online soft real-time task placement on reconfigurable hardware devices", "An efficient technique for analysis of minimal buffer requirements of synchronous dataflow graphs with model checking", "Timing-Anomaly Free Dynamic Scheduling of Conditional DAG Tasks on Multi-Core Systems", "DR. Swap: Energy-efficient paging for smartphones", "Response time bounds for typed dag parallel tasks on heterogeneous multi-cores", "Enhancing lifetime of NVM-based main memory with bit shifting and flipping", "Occlusion-Aware GAN for Face De-Occlusion in the Wild", "Power Gating Aware Task Scheduling in MPSoC", "Chip temperature optimization for dark silicon many-core systems", "Modeling and analysis of thermal effects in optical networks-on-chip", "Scheduling and Analysis of Parallel Real-Time Tasks with Semaphores", "Energy-efficient application mapping and scheduling for lifetime guaranteed MPSoCs", "Leaking your engine speed by spectrum analysis of real-Time scheduling sequences", "FoToNoC: A hierarchical management strategy based on folded lorus-like Network-on-Chip for dark silicon many-core systems", "Thermal analysis for 3D optical network-on-chip based on a novel low-cost 6\u00d7 6 optical router", "XOR-Net: An Efficient Computation Pipeline for Binary Neural Network Inference on Edge Devices", "WDM-MDM Silicon-Based Optical Switching for Data Center Networks", "Dark silicon-aware hardware-software collaborated design for heterogeneous many-core systems", "Thermal-aware design and simulation approach for optical NoCs", "Optimal application mapping and scheduling for network-on-chips with computation in STT-RAM based router", "Distributed sensor network-on-chip for performance optimization of soft-error-tolerant multiprocessor system-on-chip", "Contention-Aware Routing for Thermal-Reliable Optical Networks-on-Chip", "Thermal-Aware Task Scheduling for 3D-Network-on-Chip: A Bottom to Top Scheme", "Thermal-aware task scheduling for 3D-network-on-chip: A Bottom-to-Top scheme", "On the Analysis of Parallel Real-Time Tasks with Spin Locks", "Real-Time Scheduling of DAG Tasks with Arbitrary Deadlines", "On-line mpsoc scheduling considering power gating induced power/ground noise", "O-Star: An Optical Switching Architecture Featuring Mode and Wavelength-Division Multiplexing for On-Chip Many-Core Systems", "EDLAB: A benchmark for edge deep learning accelerators", "ArSMART: An Improved SMART NoC Design Supporting Arbitrary-Turn Transmission", "Reduced Worst-Case Communication Latency Using Single-Cycle Multihop Traversal Network-on-Chip", "Analyzing GEDF Scheduling for Parallel Real-Time Tasks with Arbitrary Deadlines", "Routing in optical network-on-chip: minimizing contention with guaranteed thermal reliability", "Hardware-software collaboration for dark silicon heterogeneous many-core systems", "LightNAS: On Lightweight and Scalable Neural Architecture Search for Embedded Platforms", "ZeroBN: Learning Compact Neural Networks For Latency-Critical Edge Systems", "Suspension-Based Locking Protocols for Parallel Real-Time Tasks", "Taijinet: Towards partial binarized convolutional neural network for embedded systems", "Quantitative Modeling of Thermo-Optic Effects in Optical Networks-on-Chip", "Edgenas: Discovering efficient neural architectures for edge systems", "ApproxMap: On task allocation and scheduling for resilient applications", "An improved thermal model for static optimization of application mapping and scheduling in multiprocessor system-on-chip", "A Hardware-Software Collaborated Method for Soft-Error Tolerant MPSoC", "HSCoNAS: Hardware-software co-design of efficient dnns via neural architecture search", "Hardware-Software Collaborative Thermal Sensing in Optical Network-on-Chip--based Manycore Systems", "Thermal Sensing Using Micro-ring Resonators in Optical Network-on-Chip", "Efficient SAT-based application mapping and scheduling on multiprocessor systems for throughput maximization", "Traffic-aware application mapping for network-on-chip based multiprocessor system-on-chip", "Efficient algorithms for 2D area management and online task placement on runtime reconfigurable FPGAs", "Improved schedulability analysis of edf scheduling on reconfigurable hardware devices", "Priority assignment on partitioned multiprocessor systems with shared resources", "CASS: Criticality-Aware Standby-Sparing for real-time systems", "NV-eCryptfs: Accelerating Enterprise-Level Cryptographic File System with Non-Volatile Memory", "A Systematic and Realistic Network-on-Chip Traffic Modeling and Generation Technique for Emerging Many-Core Systems", "An efficient technique for chip temperature optimization of multiprocessor systems in the dark silicon era", "Contention-aware task and communication co-scheduling for network-on-chip based multiprocessor system-on-chip", "On-Chip Sensor Network for Efficient Management of Power Gating-Induced Power/Ground Noise in Multiprocessor System on Chip", "TAB: Unified and Optimized Ternary, Binary, and Mixed-precision Neural Network Inference on the Edge", "Optimized Data Reuse via Reordering for Sparse Matrix-Vector Multiplication on FPGAs", "Designing Efficient DNNs via Hardware-Aware Neural Architecture Search and Beyond", "Mitigation of Tampering Attacks for MR-Based Thermal Sensing in Optical NoCs", "MindReading: An Ultra-Low-Power Photonic Accelerator for EEG-based Human Intention Recognition", "Analyzing Data Cache Related Preemption Delay With Multiple Preemptions", "Revisiting gpc and and connector in real-time calculus", "An efficient technique of application mapping and scheduling on real-time multiprocessor systems for throughput optimization", "A novel low-waveguide-crossing floorplan for fat tree based optical networks-on-chip", "A case study of on-chip sensor network in multiprocessor system-on-chip", "An Algorithm for Detecting Firewall Filters Conflicts", "Person re-identification via pose-aware multi-semantic learning", "Contention Minimized Bypassing in SMART NoC", "ACA-SDS: Adaptive Crypto Acceleration for Secure Data Storage in Big Data", "Work-in-progress: fixed priority scheduling of real-time flows with arbitrary deadlines on SMART NoCs", "A systematic network-on-chip traffic modeling and generation methodology", "SurgeNAS: a comprehensive surgery on hardware-aware differentiable neural architecture search", "Attack Mitigation of Hardware Trojans for Thermal Sensing via Micro-ring Resonator in Optical NoCs", "Lightweight Thermal Monitoring in Optical Networks-on-Chip via Router Reuse", "Scope-Aware Useful Cache Block Calculation for Cache-Related Pre-Emption Delay Analysis With Set-Associative Data Caches", "Fine-Grained Task-Level Parallel and Low Power H. 264 Decoding in Multi-Core Systems", "nCode: Limiting harmful writes to emerging mobile NVRAM through code swapping", "On-chip sensor networks for soft-error tolerant real-time multiprocessor systems-on-chip", "Efficient Software Synthesis for Dynamic Single Appearance Scheduling of Synchronous Dataflow", "Smart Scissor: Coupling Spatial Redundancy Reduction and CNN Compression for Embedded Hardware", "You only search once: on lightweight differentiable architecture search for resource-constrained embedded platforms", "Locking protocols for parallel real-time tasks with semaphores under federated scheduling", "CARTAD: Compiler-Assisted Reinforcement Learning for Thermal-Aware Task Scheduling and DVFS on Multicores", "Energy-efficient crypto acceleration with HW/SW co-design for HTTPS", "Wear-aware Memory Management Scheme for Balancing Lifetime and Performance of Multiple NVM Slots", "Hardware/Software Adaptive Cryptographic Acceleration for Big Data Processing", "User experience enhanced task scheduling and processor frequency scaling for energy-sensitive mobile devices", "Coroutine-Based Synthesis of Efficient Embedded Software From SystemC Models", "Latency-constrained DNN architecture learning for edge systems using zerorized batch normalization", "iMAD: An In-Memory Accelerator for AdderNet with Efficient 8-bit Addition and Subtraction Operations", "HACScale: Hardware-Aware Compound Scaling for Resource-Efficient DNNs", "Parallel Multipath Transmission for Burst Traffic Optimization in Point-to-Point NoCs", "Efficient AUTOSAR-Compliant CAN-FD Frame Packing with Observed Optimality", "Autonomous temperature sensing for optical network-on-chip", "Dynamic No-Fly Zone for Drones", "Towards Fast and Lightweight Checkpointing for Mobile Virtualization Using NVRAM", "FONoC: A Fat Tree Based Optical Network-on-Chip for Multiprocessor System-on-Chip", "FIONA: Fine-grained Incoherent Optical DNN Accelerator Search for Superior Efficiency and Robustness", "Accelerating Gustavson-based SpMM on Embedded FPGAs with Element-wise Parallelism and Access Pattern-aware Caches", "Crossbar-Aligned & Integer-Only Neural Network Compression for Efficient in-Memory Acceleration", "Collate: Collaborative Neural Network Learning for Latency-Critical Edge Systems", "Toward Minimum WCRT Bound for DAG Tasks Under Prioritized List Scheduling Algorithms", "MARCO: A High-performance Task Mapping and Routing Co-optimization Framework for Point-to-Point NoC-based Heterogeneous Computing Systems", "Contention minimization in emerging smart NoC via direct and indirect routes", "Partial order based non-preemptive communication scheduling towards real-time networks-on-chip", "Load-aware Adaptive Cache Management Scheme for Enterprise-level Stackable Cryptographic File System*", "Design of a Hierarchical Clos-Benes Optical Network-on-Chip Architecture", "User Experience-Enhanced and Energy-Efficient Task Scheduling on Heterogeneous Multi-Core Mobile Systems", "Work-in-Progress: Communication Optimization for Thermal Reliable Optical Network-on-Chip", "Fixed priority scheduling of real-time flows with arbitrary deadlines on smart NoCs: work-in-progress", "Through Global Sharing to Improve Network Efficiency for Radio-Frequency Interconnect Based Network-on-Chip", "Realistic Task Parallelization of the H. 264 Decoding Algorithm for Multiprocessors", "An efficient soft error protection scheme for MPSoC and FPGA-based verification", "High-speed and energy-efficient asynchronous carry look-ahead adder", "EvoLP: Self-Evolving Latency Predictor for Model Compression in Real-Time Edge Systems", "CRIMP: Compact & Reliable DNN Inference on In-Memory Processing via Crossbar-Aligned Compression and Non-ideality Adaptation", "Automated Optical Accelerator Search: Expediting Green and Ubiquitous DNN-Powered Intelligence", "On Hardware-Aware Design and Optimization of Edge Intelligence", "iMAT: Energy-Efficient In-Memory Acceleration for Ternary Neural Networks With Sparse Dot Product", "Automated Optical Accelerator Search Toward Superior Acceleration Efficiency, Inference Robustness and Development Speed", "Towards Efficient Convolutional Neural Network for Embedded Hardware via Multi-Dimensional Pruning", "An Efficient Gustavson-based Sparse Matrix-matrix Multiplication Accelerator on Embedded FPGAs", "EdgeCompress: Coupling Multi-Dimensional Model Compression and Dynamic Inference for EdgeAI", "EMNAPE: Efficient Multi-Dimensional Neural Architecture Pruning for EdgeAI", "MUGNoC: A Software-Configured Multicast-Unicast-Gather NoC for Accelerating CNN Dataflows", "Fast and Low Overhead Metadata Operations for NVM-Based File System Using Slotted Paging", "Work-in-Progress: What to Expect of Early Training Statistics? An Investigation on Hardware-Aware Neural Architecture Search", "LAMP: Load-Balanced Multipath Parallel Transmission in Point-to-Point NoCs", "Thermal Reliability and Communication Performance Co-optimization for WDM-Based Optical Networks-on-Chip", "COSMA: An Efficient Concurrency-Oriented Space Management Scheme for In-memory File Systems", "Mobi-PMFS: An Efficient and Durable In-Memory File System for Mobile Devices", "Work-in-Progress: Response Time Bounds for Typed DAG Parallel Tasks on Heterogeneous Multi-cores", "Communication optimization for thermal reliable optical network-on-chip: work-in-progress", "Communication optimization for thermal reliable many-core systems: work-in-progress", "Isolation of Physical and Logical Views of Dark-Silicon Many-Core Systems for Reliability and Performance Co-Optimization", "Editor-at-Large board"], "Link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:KvGcghnThk8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Jxy3h8XkNu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:S_0nULq340kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:5n9gSBKMxCsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:tVg3zZbtnc0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:4w9WtRFcIoYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:RiW20FJDrgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:SsmmYIE5d0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:eIWZJKaDF6kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:cFcI8uaobsAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:PBekU-LVBrQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:GKX6TSFDq9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:rGOK5rmJZT0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:2yHMXrjStuAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:utCHnwRdBgEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:I6TX2FUo6loC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:n3sXDxCj2GoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:NYu48kWxaQAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cdM53WF7QocC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:h-OLoDDdPfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ic8hN12bw4QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:rhSvDnGaX0QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zeZllD8TmcoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:62L9AWR-SnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:U5I91ptAnUUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:hN_26_r6h7cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UWSlATeI89AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:unKmnnpx3RcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:B4wWq2ztVNgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:spwacExez6wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:uwohsRgU7yoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:MdMr--dQ_pMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:QhmGFXoqNHAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TmI2AlsRohcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:12oLulcdP1kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cUWptXWc3MAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TdcqFaaFpGIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:62yiFa7nMbkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TKVID9p7UpsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0wD49__q8KEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ZjmTu7HDCaEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:X8aq8RHJ9bUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4ZjPyBmb-CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:teyi7TG2FwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:7E1sdDGsGRMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ULSBFf147LAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:T64LSalLz9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zI9YInTrFVIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:1UYbAEPjJNAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:OkCShBBh3G8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:aUNTuf31cPIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:bGIpCNGh66kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:U8aB7V8aZVQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ib87rSy7x5MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ItgTnG0mAXQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:sduUCncrepAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:QuPaituDtm8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:m7gEShFDljgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Fv7Qhv_DOnIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:EvHYAMKeY9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wlh7PBhwZ8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:kVZqXsXrJl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wsYPZf_qF0UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ZXswLDrTefgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4G0aqHQeUQIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TLwS_1sUIYkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:-e1qr6N6M9MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:w9EjUEod0xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yG6gRY0c4kQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4I90hQsHr_gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yRL2jD08WzAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:RjbMpExGKWAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:fkjBimb5U_kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:DjjA23gMNckC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:CgSwehex2-EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:IjbvboqL_eAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:x3zuONe3eqIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:tVbZQR0Ku0MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0nST21YUXoUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ent5SSDJ8eoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:SpbQ_efOBbkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7-gQGTwtAzQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7DTIKO_nxaIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:END1nS_e-6cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w1G5vK4DiEkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:-EqDysdaREAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w2v21TepJGQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:yHoQYHXJRqAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oKUQpTv76aEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:qfTKKVVEecAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oFWWKr2Zb18C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:FP-YCU5gdjEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:vQKLzKM0twkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:ClN-LZ0IzgkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:g4gGp8M7V98C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:zLla2nKXDtwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:HklM7qHXWrUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:STWYWLtSq6gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NAkivslCrNUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:prKdS1S5QkMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uENYxwZKF5gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:BtfE7wd9KvMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:ZD92IwzDgOkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:TCy96lt6RIkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uPwIINvFgpoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:nFloTcPoiwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:RaRNlNDkcy8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Dq1jD5C1HUoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:FjmlLC3huY4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:jKffii5DqX8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:btULBOGQ_gcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:V0QqM0Py3VsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Yeq4f8IuGg4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:3eo-xq64HD0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:pGq6TLPqxssC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WWyA8FEaYkEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:B_SudGh4-BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:RDd164uRGEsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WeWrUA-9SBMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:pQthLKZIaNQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:LNbnizmRdgkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:8s_vhd3wPlUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oy0z8GdgWhYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VyewGSb6xwwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:6biGW3np0psC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:TKTY8N1AUUAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:EpUiTTZsFn8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Nw5Pwe77XXAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:CRQ797xmLJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VBbLNo9YSJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VJOaslTFpLQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:QDEWnZBrHwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Uwzdpet-joYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uwWlEQcBbEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:XfMaBeGYgSgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WgBxaE7EUScC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7rVtnTjEZJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:IxBLoz_EsGYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:6gD0efnhv6MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:jh7fJAhS9AIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:327GGIiaIgIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:eNpUmiHIC2gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:UlSRQUDYeUMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NXjrwPNzFTMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:tYdqGa2HnWcC"], "Topic": ["Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Artificial Intelligenc", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Hardware Design and Neural Network Optimization", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Artificial Intelligenc", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Federated Learning", "Operating System", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Database Managemen", "Operating System", "Hardware Design and Neural Network Optimization", "Others", "Others", "Others", "Others", "Others", "Others", "Operating System", "Cryptography", "Hardware Design and Neural Network Optimization", "Computing", "Operating System", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Operating System", "Database Managemen", "Hardware Design and Neural Network Optimization", "Cryptography", "Artificial Intelligenc", "Operating System", "Cryptography", "Operating System", "Hardware Design and Neural Network Optimization", "Hardware Design and Neural Network Optimization", "Artificial Intelligenc", "Hardware Design and Neural Network Optimization", "Operating System", "Artificial Intelligenc", "Hardware Design and Neural Network Optimization", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others"], "# of Citations": [153, 145, 147, 121, 93, 90, 83, 82, 71, 58, 58, 60, 60, 59, 55, 48, 45, 43, 43, 39, 38, 38, 36, 36, 35, 34, 34, 33, 31, 32, 28, 26, 26, 24, 24, 22, 20, 16, 16, 16, 15, 15, 15, 15, 14, 14, 14, 13, 13, 13, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10, 10, 10, 9, 9, 9, 9, 8, 8, 8, 8, 8, 7, 8, 7, 6, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "Description": ["Travel behavior understanding is a long-standing and critically important topic in the area of smart cities. Big volumes of various GPS-based travel data can be easily collected, among which the taxi GPS trajectory data is a typical example. However, in GPS trajectory data, there is usually little information on travelers' activities, thereby they can only support limited applications. Quite a few studies have been focused on enriching the semantic meaning for raw data, such as travel mode/purpose inferring. Unfortunately, trip purpose imputation receives relatively less attention and requires no real-time response. To narrow the gap, we propose a probabilistic two-phase framework named TripImputor, for making the real-time taxi trip purpose imputation and recommending services to passengers at their dropoff points. Specifically, in the first phase, we propose a two-stage clustering algorithm to identify candidate activity\u00a0\u2026", "Crosstalk noise is an intrinsic characteristic of photonic devices used by optical networks-on-chip (ONoCs) as well as a potential issue. For the first time, this paper analyzed and modeled the crosstalk noise, signal-to-noise ratio (SNR), and bit error rate (BER) of optical routers and ONoCs. The analytical models for crosstalk noise, minimum SNR, and maximum BER in meshbased ONoCs are presented. An automated crosstalk analyzer for optical routers is developed. We find that crosstalk noise significantly limits the scalability of ONoCs. For example, due to crosstalk noise, the maximum BER is 10-3 on the 8x8 mesh-based ONoC using an optimized crossbar-based optical router. To achieve the BER of 10-9 for reliable transmissions, the maximum ONoC size is 6x6. A novel compact high-SNR optical router is proposed to improve the maximum ONoC size to 8x8.", "As benchmark programs for microprocessor architectures, network-on-chip (NoC) traffic patterns are essential tools for NoC performance assessments and architecture explorations. The fidelity of NoC traffic patterns has profound influence on NoC studies. For the first time, this paper presents a realistic traffic benchmark suite, called MCSL, and the methodology used to generate it. The publicly released MCSL benchmark suite includes a set of realistic traffic patterns for 8 real applications and covers popular NoC architectures. It captures not only the communication behaviors in NoCs but also the temporal dependencies among them. MCSL benchmark suite can be easily incorporated into existing NoC simulators and significantly improve NoC simulation accuracy. We developed a systematic traffic generation methodology to create MCSL based on real applications. The methodology uses formal computational\u00a0\u2026", "Optical networks-on-chip (ONoCs) are emerging communication architectures that can potentially offer ultrahigh communication bandwidth and low latency to multiprocessor systems-on-chip (MPSoCs). In addition to ONoC architectures, 3-D integrated technologies offer an opportunity to continue performance improvements with higher integration densities. In this paper, we present a 3-D mesh-based ONoC for MPSoCs, and new low-cost nonblocking 4  4, 5  5, 6  6, and 7  7 optical routers for dimension-order routing in the 3-D mesh-based ONoC. Besides, we propose an optimized floorplan for the 3-D mesh-based ONoC. The floorplan follows the regular 3-D mesh topology but implements all optical routers in a single optical layer. The floorplan is optimized to minimize the number of extra waveguide crossings caused when merging the 3-D ONoC to one optical layer. Based on a set of real applications and uniform\u00a0\u2026", "Crosstalk noise is an intrinsic characteristic as well as a potential issue of photonic devices. In large scale optical networks-on-chips (ONoCs), crosstalk noise could cause severe performance degradation and prevent ONoC from communicating properly. The novel contribution of this paper is the systematical modeling and analysis of the crosstalk noise and the signal-to-noise ratio (SNR) of optical routers and mesh-based ONoCs using a formal method. Formal analytical models for the worst-case crosstalk noise and minimum SNR in mesh-based ONoCs are presented. The crosstalk analysis is performed at device, router, and network levels. A general 5  5 optical router model is proposed for router level analysis. The minimum SNR optical link candidates, which constrain the scalability of mesh-based ONoCs, are identified. It is also shown that symmetric mesh-based ONoCs have the best SNR performance. The presented formal\u00a0\u2026", "Network-on-chip (NoC) can improve the performance, power efficiency, and scalability of multiprocessor system-on-chip (MPSoC). However, traditional NoCs using metallic interconnects consume significant amount of power to deliver even higher communication bandwidth required in the near future. Optical NoCs are based on CMOS-compatible optical waveguides and micro resonators, and promise significant bandwidth and power advantages. In this paper, we propose a hybrid optical mesh NoC, HOME, which utilizes optical waveguides as well as metallic interconnects in a hierarchical manner. HOME employs a new set of protocols to improve the network throughput and latency. We compared HOME with a matched optical mesh NoC for a 64-core MPSoC in 45nm, using SPICE simulations and our cycle-accurate multi-objective NoC simulation platform, MoLab. Comparing with the optical mesh NoC, HOME\u00a0\u2026", "Convolutional Neural Networks (CNNs) are widely adopted in object recognition, speech processing and machine translation, due to their extremely high inference accuracy. However, it is challenging to compute massive computationally expensive convolutions of deep CNNs on traditional CPUs and GPUs. Emerging Nanophotonic technology has been employed for on-chip data communication, because of its CMOS compatibility, high bandwidth and low power consumption. In this paper, we propose a nanophotonic accelerator, HolyLight, to boost the CNN inference throughput in datacenters. Instead of an all-photonic design, HolyLight performs convolutions by photonic integrated circuits, and process the other operations in CNNs by CMOS circuits for high inference accuracy. We first build HolyLight-M by microdisk-based matrix-vector multipliers. We find analog-to-digital converters (ADCs) seriously limit its\u00a0\u2026", "Networks-on-chip (NoCs) are emerging as a key on-chip communication architecture for multiprocessor systems-on-chip (MPSoCs). Optical communication technologies are introduced to NoCs in order to empower ultra-high bandwidth with low power consumption. However, in existing optical NoCs, communication locality is poorly supported, and the importance of floorplanning is overlooked. These significantly limit the power efficiency and performance of optical NoCs. In this work, we address these issues and propose a torus-based hierarchical hybrid optical-electronic NoC, called THOE. THOE takes advantage of both electrical and optical routers and interconnects in a hierarchical manner. It employs several new techniques including floorplan optimization, an adaptive power control mechanism, low-latency control protocols, and hybrid optical-electrical routers with a low-power optical switching fabric. Both of\u00a0\u2026", "Edge computing and artificial intelligence (AI), especially deep learning algorithms, are gradually intersecting to build the novel system, namely edge intelligence. However, the development of edge intelligence systems encounters several challenges, and one of these challenges is the computational gap between computation-intensive deep learning algorithms and less-capable edge systems. Due to the computational gap, many edge intelligence systems cannot meet the expected performance requirements. To bridge the gap, a plethora of new techniques and optimization methods were proposed in the past years: lightweight deep learning models, network compression, and efficient neural architecture search. Although some reviews or surveys have partially covered this large body of literature, we lack a systematic and comprehensive review to discuss all aspects of these deep learning techniques which are\u00a0\u2026", "As modern computing systems become increasingly complex, communication efficiency among and inside chips has become as important as the computation speeds of individual processing cores. Traditionally, to maximize design flexibility, interchip and intrachip communication architectures are separately designed under different constraints. Jointly designing communication architectures for both interchip and intrachip communication could, however, potentially yield better solutions. In this paper, we present a unified inter/intrachip optical network, called UNION, for chip multiprocessors (CMPs). UNION is based on recent progresses in nanophotonic technologies. It connects not only cores on a single CMP, but also multiple CMPs in a system. UNION employs a hierarchical optical network to separate interchip communication traffic from intrachip communication traffic. It fully utilizes a single optical network to\u00a0\u2026", "As modern computing systems become increasingly complex, communication efficiency among and inside chips has become as important as the computation speeds of individual processing cores. Traditionally, to maximize design flexibility, interchip and intrachip communication architectures are separately designed under different constraints. Jointly designing communication architectures for both interchip and intrachip communication could, however, potentially yield better solutions. In this paper, we present a unified inter/intrachip optical network, called UNION, for chip multiprocessors (CMPs). UNION is based on recent progresses in nanophotonic technologies. It connects not only cores on a single CMP, but also multiple CMPs in a system. UNION employs a hierarchical optical network to separate interchip communication traffic from intrachip communication traffic. It fully utilizes a single optical network to\u00a0\u2026", "The performance of multiprocessor systems, such as chip multiprocessors (CMPs), is determined not only by individual processor performance, but also by how efficiently the processors collaborate with one another. It is the communication architecture that determines the collaboration efficiency on the hardware side. Optical networks-on-chip (ONoCs) are emerging communication architectures that can potentially offer ultra-high communication bandwidth and low latency to multiprocessor systems. Thermal sensitivity is an intrinsic characteristic of photonic devices used by ONoCs as well as a potential issue. This paper systematically modeled and quantitatively analyzed the thermal effects in ONoCs. We used an 8    8 mesh-based ONoC as a case study and evaluated the impacts of thermal effects in the average power efficiency for real MPSoC applications. We revealed three important factors regarding ONoC\u00a0\u2026", "As Moore's law comes to an end, multiprocessor systems are becoming ubiquitous in today's embedded systems design. In this paper, we address the problem of mapping a homogeneous synchronous dataflow (HSDF) graph onto a multiprocessor platform with the objective of maximizing system throughput. We present two optimization approaches based on branch-and-bound and SAT-solving to explore the design space of all possible actor-to-processor mappings and static order schedules on each processor. In the logic-based benders decomposition (LBBD) approach, we decompose the problem into a master problem of finding a feasible actor mapping and scheduling, and a sub-problem of deadlock-checking and throughput computation. In the integrated approach, we integrate branch-and-bound search into the SAT engine to achieve more effective search tree pruning and better scalability. Performance\u00a0\u2026", "Smartphones are getting increasingly high-performance with advances in mobile processors and larger main memories to support feature-rich applications. However, the storage subsystem has always been a prohibitive factor that slows down the pace of reaching even higher performance while maintaining good user experience. Despite today's smartphones are equipped with larger-than-ever main memories, they consume more energy and still run out of memory. But the slow NAND flash based storage vetoes the possibility of swapping---an important technique to extend main memory---and leaves a system that constantly terminates user applications under memory pressure. In this paper, we revisit swapping for smartphones with fast, byte-addressable, non-volatile memory (NVM) technologies. Instead of using flash, we build the swap area with NVM, to allow high performance without sacrificing user\u00a0\u2026", "Task graph scheduling on multiprocessor systems is a representative multiprocessor scheduling problem. A solution to this problem consists of the mapping of tasks to processors and the scheduling of tasks on each processor. Optimal solution can be obtained by exploring the entire design space of all possible mapping and scheduling choices. Since the problem is NP-hard, scalability becomes the main concern in solving the problem optimally. In this paper, a SAT-based optimization framework is proposed to address this problem, in which SAT solver is enhanced by integrating with a scheduling analysis tool in a branch and bound manner to prune the solution space efficiently. Performance evaluation results show that our technique has average performance improvement in more than an order of magnitude compared to state-of-the-art techniques. We further build a cycle-accurate network-on-chip simulator\u00a0\u2026", "Dynamic multiobjective optimization problem (DMOP) denotes the multiobjective optimization problem, which contains objectives that may vary over time. Due to the widespread applications of DMOP existed in reality, DMOP has attracted much research attention in the last decade. In this article, we propose to solve DMOPs via an autoencoding evolutionary search. In particular, for tracking the dynamic changes of a given DMOP, an autoencoder is derived to predict the moving of the Pareto-optimal solutions based on the nondominated solutions obtained before the dynamic occurs. This autoencoder can be easily integrated into the existing multiobjective evolutionary algorithms (EAs), for example, NSGA-II, MOEA/D, etc., for solving DMOP. In contrast to the existing approaches, the proposed prediction method holds a closed-form solution, which thus will not bring much computational burden in the iterative\u00a0\u2026", "The three-dimensional Network-on-Chips (3D NoCs) has become a mature multi-core interconnection architecture in recent years. However, the traditional electrical lines have very limited bandwidth and high energy consumption, making the photonic interconnection promising for future 3D Optical NoCs (ONoCs). Since existing solutions cannot well guarantee the fault-tolerant ability of 3D ONoCs, in this paper, we propose a reliable optical router (OR) structure which sacrifices less redundancy to obtain more restore paths. Moreover, by using our fault-tolerant routing algorithm, the restore path can be found inside the disabled OR under the deadlock-free condition, i.e., fault-node reuse. Experimental results show that the proposed approach outperforms the previous related works by maximum 81.1 percent and 33.0 percent on average for throughput performance under different synthetic and real traffic patterns. It\u00a0\u2026", "On-chip communication is the bottleneck of system performance for NoC-based MPSoCs. SMART, a recently proposed NoC architecture, enables single-cycle multi-hop communications. In SMART NoCs, unconflicted messages can go through an express bypass and the communication efficiency is significantly improved, while conflicted messages have to be buffered for guaranteed delivery with extra delays. Therefore, that performance of SMART NoC may be seriously degraded when communication contention increases. In this paper, we present task mapping techniques to address this problem for SMART NoCs, with the consideration of communication contention, rather than inter-processor distance, by minimizing conflicts and thus maximizing bypass utilization. We first model the entire problem by ILP formulations to find the theoretically optimal solution, and further propose polynomial-time algorithms for\u00a0\u2026", "Network-on-chip (NoC) based multiprocessor system-on-chips (MPSoCs) have been proposed as promising architectures to meet modern applications' ever-increasing demands for computing capability under limited power budget. Understanding the behaviors of MPSoC applications is the key to design MPSoCs under tight power and performance constraints. In this case study, we systematically examine the computation and communication behaviors of four real applications on MPSoCs based on three popular NoC topologies. We formally model real multiprocessor applications as task communication graphs (TCG) to accurately capture their computation and communication requirements. We publicly release a multiprocessor benchmark suite called COSMIC online, which includes the TCG models. In this work, we analyze the spatial distributions of workloads and traffics for each application, and evaluate their\u00a0\u2026", "Hardware-aware Neural Architecture Search (NAS), which automatically finds an architecture that works best on a given hardware design, has prevailed in response to the ever-growing demand for real-time Artificial Intelligence (AI). However, in many situations, the underlying hardware is not pre-determined. We argue that simply assuming an arbitrary yet fixed hardware design will lead to inferior solutions, and it is best to co-explore neural architecture space and hardware design space for the best pair of neural architecture and hardware design. To demonstrate this, we employ Network-on-Chip (NoC) as the infrastructure and propose a novel framework, namely NANDS, to co-explore NAS space and NoC Design Search (NDS) space with the objective to maximize accuracy and throughput. Since two metrics are tightly coupled, we develop a multi-phase manager to guide NANDS to gradually converge to\u00a0\u2026", "The fast growth of civil drones raises significant security challenges. A legitimate drone may be hijacked by GPS spoofing for illegal activities, such as terrorist attacks. The target of this paper is to develop techniques to let drones detect whether they have been hijacked using onboard motion sensors (accelerometers and gyroscopes). Ideally, the linear acceleration and angular velocity measured by motion sensors can be used to estimate the position of a drone, which can be compared with the position reported by GPS to detect whether the drone has been hijacked. However, the position estimation by motion sensors is very inaccurate due to the significant error accumulation over time. In this paper, we propose a novel method to detect hijacking based on motion sensors measurements and GPS, which overcomes the accumulative error problem. The computational complexity of our method is very low, and thus is\u00a0\u2026", "Network-on-chip (NoC) is promising for the communication paradigm of the next-generation multiprocessor system-on-chip (MPSoC). As communication has become an integral part of on-chip computing, and even the performance bottleneck, researchers are paying much attention to its implementation and optimization. Traditional techniques that model communication inaccurately will lead to unexpected runtime performance, which is on average 90.8% worse than the predicted results based on observation, and are not suitable for the deep optimization of communication-intensive scenarios. In this paper, techniques are presented for the NoC-based MPSoCs that integrate optimization on interprocessor communications with the objective of minimizing the schedule length. A fine-grained integer-linear programming (ILP) model is proposed to properly address the communication latency with a network contention\u00a0\u2026", "With the fast growth of civil drones, their security problems meet significant challenges. A commercial drone may be hijacked by a GPS-spoofing attack for illegal activities, such as terrorist attacks. The target of this article is to develop a technique that only uses onboard gyroscopes to determine whether a drone has been hijacked. Ideally, GPS data and the angular velocities measured by gyroscopes can be used to estimate the acceleration of a drone, which can be further compared with the measurement of the accelerometer to detect whether a drone has been hijacked. However, the detection results may not always be accurate due to some calculation and measurement errors, especially when no hijacking occurs in curve trajectory situations. To overcome this, in this article, we propose a novel and simple method to detect hijacking only based on gyroscopes\u2019 measurements and GPS data, without using any\u00a0\u2026", "Dark silicon refers to the phenomenon that a fraction of a many-core chip has to become \u201cdark\u201d or \u201cdim\u201d in order to guarantee the system to be kept in a safe temperature range and allowable power budget. Techniques have been developed to selectively activate non-adjacent cores on many-core chip to avoid temperature hotspot, while resulting unexpected increase of communication overhead due to the longer average distance between active cores, and in turn affecting application performance and energy efficiency, when Network-on-Chip (NoC) is used as a scalable communication subsystem. To address the brand-new challenges brought by dark silicon, in this paper, we present FoToNoC, a Folded Torus-like NoC, coupled with a hierarchical management strategy for heterogeneous many-core systems. On top of it, objectives of maximizing application performance, energy efficiency and chip reliability are\u00a0\u2026", "Dark silicon is the phenomenon that a fraction of many-core chip has to be turned off or run in a low-power state in order to maintain the safe chip temperature. System-level thermal management techniques normally map application on non-adjacent cores, while communication efficiency among these cores will be oppositely affected over conventional network-on-chip (NoC). Recently, SMART NoC architecture is proposed, enabling single-cycle multi-hop bypass channels to be built between distant cores at runtime, to reduce communication latency. However, communication efficiency of SMART NoC will be diminished by communication contention, which will in turn decrease system performance. In this paper, we first propose an Integer-Linear Programming (ILP) model to properly address communication problem, which generates the optimal solutions with the consideration of inter-processor communication. We\u00a0\u2026", "Although Convolutional Neural Networks (CNNs) have demonstrated the state-of-the-art inference accuracy in various intelligent applications, each CNN inference involves millions of expensive floating point multiply-accumulate (MAC) operations. To energy-efficiently process CNN inferences, prior work proposes an electro-optical accelerator to process power-of-2 quantized CNNs by electro-optical ripple-carry adders and optical binary shifters. The electro-optical accelerator also uses SRAM registers to store intermediate data. However, electro-optical ripple-carry adders and SRAMs seriously limit the operating frequency and inference throughput of the electro-optical accelerator, due to the long critical path of the adder and the long access latency of SRAMs. In this paper, we propose a photonic nonvolatile memory (NVM)-based accelerator, Light-Bulb, to process binarized CNNs by high frequency photonic\u00a0\u2026", "Reconfigurable devices such as field programmable gate arrays (FPGAs) are very popular in today's embedded systems (design due to their low-cost, high-performance and flexibility. Partially runtime-reconfigurable (PRTR) FPGAs allow hardware tasks to be placed and removed dynamically at runtime. Hardware task scheduling on PRTR FPGAs brings many challenging issues to traditional real-time scheduling theory, which have not been adequately addressed by the real-time research community compared to software task scheduling on CPUs. In this paper, we present an efficient online task placement algorithm for minimizing fragmentation on PRTR FPGAs. First, we present a novel 2D area fragmentation metric that takes into account probability distribution of sizes of future task arrivals; second, we take into the time axis to obtain a 3D fragmentation metric. Simulation experiments indicate that our techniques\u00a0\u2026", "Synchronous Dataflow (SDF) is a widely-used model of computation for digital signal processing and multimedia applications, which are typically implemented on memory constrained hardware platforms. SDF can be statically analyzed and scheduled, and the memory requirement for correct execution can be predicted at compile time. In this paper, we present an efficient technique based on model-checking for exact analysis of minimal buffer requirement of an SDF graph to guarantee deadlock-free execution. Performance evaluation shows that our approach can achieve significant performance improvements compared to related work.", "In this paper, we propose a novel approach to schedule conditional DAG parallel tasks, with which we can derive safe response time upper bounds significantly better than the state-of-the-art counterparts. The main idea is to eliminate the notorious timing anomaly in scheduling parallel tasks by enforcing certain order constraints among the vertices, and thus the response time bound can be accurately predicted off-line by somehow \u201csimulating\u201d the runtime scheduling. A key challenge to apply the timing-anomaly free scheduling approach to conditional DAG parallel tasks is that at runtime it may generate exponentially many instances from a conditional DAG structure. To deal with this problem, we develop effective abstractions, based on which a safe response time upper bound is computed in polynomial time. We also develop algorithms to explore the vertex orders to shorten the response time bound. The\u00a0\u2026", "Smartphones are becoming increasingly energy-hungry to support feature-rich applications, posing a lot of pressure on battery lifetime and making energy consumption a non-negligible issue. In particular, DRAM is among the most demanding components in energy consumption. In this paper, we propose DR. Swap, an energy-efficient paging design to reduce energy consumption in smartphones. We adopt emerging energy-efficient non-volatile memory (NVM) and use it as the swap area. Utilizing NVM's byte-addressability, we propose direct read which guarantees zero-copy for read-only pages in the swap area. Experimental results based on the Google Nexus 5 smartphone show that our technique can effectively reduce energy consumption.", "Heterogenerous multi-cores utilize the strength of different architectures for executing particular types of workload, and usually offer higher performance and energy efficiency. In this paper, we study the worst-case response time (WCRT) analysis of typed scheduling of parallel DAG tasks on heterogeneous multi-cores, where the workload of each vertex in the DAG is only allowed to execute on a particular type of cores. The only known WCRT bound for this problem is grossly pessimistic and suffers the non-self-sustainability problem. In this paper, we propose two new WCRT bounds. The first new bound has the same time complexity as the existing bound, but is more precise and solves its non-self-sustainability problem. The second new bound explores more detailed task graph structure information to greatly improve the precision, but is computationally more expensive. We prove that the problem of computing the\u00a0\u2026", "Non-volatile memory (NVM) is considered as the most promising candidate of main memory due to many attractive properties, such as shock-resistivity, non-volatility, high density and near zero leakage power. However, the write endurance and high write energy consumption greatly limit its adoption in modern memory systems. In this paper, we propose a write reduction technique, called Min-Shift, to reduce the total number of writes to NVM. The basic idea is to re-encode the data to be written via bit shifting and flipping. This is motivated by the fact that NVM write operation takes more latency than read, and the energy cost of the value to be written varies a lot. The effectiveness of Min-Shift is verified by mathematical analysis and experiment. Experimental results show that the proposed technique can reduce the number of writes by 57.3% on average. The lifetime of NVM is 2.3\u00d7 longer than before.", "Occluded faces-as a common scene in real life-have a significant negative impact on most face recognition systems. Existing methods try to remove the occlusions by a single-stage generative adversarial network (GAN), which is unaware of the occlusion and thus has difficulties in generalizing to a large variety of occlusion types, e.g., different objects at various positions. To this end, we propose the two-stage Occlusion-Aware GAN (OA-GAN), where the first GAN is for disentangling the occlusions, which will be served as the additional input of the second GAN for synthesizing the final de-occluded faces. In this way, our two-stage model can handle diverse occlusions in the wild and is naturally more explainable because of its awareness of the occluded objects. Extensive experiments on both synthetic and real-world datasets validate the superiority of the two-stage OAGAN design. Furthermore, by applying the\u00a0\u2026", "Shrinking the feature size allows more and better functions on a single chip. However, it makes multiprocessor system-on-chip (MPSoC) more susceptible to various reliability threats. Power supply noise is a major reliability problem faced by low power MPSoCs using power gating techniques. Powering on and off a processing unit in MPSoCs will induce large power/ground (P/G) noise and can cause timing divergence and even functional errors in surrounding processing units. Previous work on resilient architectures mainly focused on power/thermal management and neglected the important side-effect: P/G noise induced by power gating. In this paper, for the first time, we formulate a task scheduling problem with the consideration of P/G noise based on our detailed P/G noise analysis platform for MPSoC. Two efficient algorithms are proposed to reduce noise protection penalty and improve MPSoC performance\u00a0\u2026", "In the dark silicon era, a fundamental problem is given a real-time computation demand, how to determine if an on-chip multiprocessor system is able to accept this demand and to maintain its reliability by keeping every core within a safe temperature range. In this paper, a practical thermal model is described for quick chip temperature prediction. Integrated with the thermal model, we present a mixed integer linear programming (MILP) model to find the optimal task-to-core assignment with the minimum chip peak temperature. For the worst case where even the minimum chip peak temperature exceeds the safe temperature, a heuristic algorithm, called temperature-constrained task selection (TCTS), is proposed to optimize the system performance within chip safe temperature. The optimality of the TCTS algorithm is formally proven. Extensive performance evaluations show that our thermal model achieves an average\u00a0\u2026", "The performance of multiprocessor systems, such as chip multiprocessors (CMPs), is determined not only by the performance of their processors, but also by how efficiently they collaborate with one another. It is the communication architectures which determine the collaboration efficiency on the hardware side. Optical networks-on-chip (ONoCs) are emerging communication architectures that can potentially offer ultra-high communication bandwidth and low latency to multiprocessor systems. Thermal sensitivity is an intrinsic characteristic of photonic devices used by ONoCs as well as a potential issue. For the first time, this paper systematically modeled and quantitatively analyzed the thermal effects in ONoCs and their impacts. We presented an analytical ONoC thermal model, and show that on-chip temperature fluctuations can dramatically reduce the worst-case ONoC power efficiency. For instance, the power\u00a0\u2026", "This paper for the first time studies the scheduling and analysis of parallel real-time tasks with semaphores. In parallel task systems, each task may issue multiple requests to a semaphore, which raises new challenges to the design and analysis problems. We propose a new locking protocol LPP that limits the maximal number of requests to a semaphore by a task that can block other tasks at any time. We develop analysis techniques to safely bound the task response times, with which we prove that the best real-time performance is achieved if only one request to a semaphore by a task is allowed to block other tasks at a time. Experiments under different parameter settings are conducted to compare our proposed protocol and analysis techniques with the state-of-the-art spinlock protocol and analysis techniques for parallel real-time tasks.", "Energy optimization is one of the most critical objectives for the synthesis of multiprocessor system-on-chip (MPSoC). Besides, to ensure a long processor lifetime and to maintain a safe chip temperature are also important for multiprocessor manufactures under deep submicrometer process technologies. This paper presents a mixed integer linear programming (MILP) model to determine the mapping and scheduling of real-time applications onto embedded MPSoC platforms, such that the total energy consumption is minimized with the lifetime reliability constraint and the temperature threshold constraint satisfied. We develop a lightweight temperature model that can be integrated in the MILP model to predict the chip temperature accurately and efficiently. By exploiting the dynamic voltage and frequency scaling capability of modern processors, processor voltage/frequency assignment is also considered in our MILP\u00a0\u2026", "This paper identifies and studies a new security/privacy issue for automobile vehicles. Specifically, attackers can infer the engine speed of a vehicle by observing and analyzing the real-time scheduling sequences on the Engine Control Unit (ECU). First, we present the problem model of engine-triggered task executed on ECU. And then, we introduce two Engine-triggered Task Period Tracing methods (DFT-based ETPT and FRSP-based ETPT) to infer the period variation of engine-triggered task. Finally, simulation experiments are conducted to demonstrate the effect of this new timing side-channel information leakage with our proposed methods.", "In this dark silicon era, techniques have been developed to selectively activate nonadjacent cores in physical locations to maintain the safe temperature and allowable power budget on a many-core chip. This will result in unexpected increase in the communication overhead due to longer average distance between active cores in a typical mesh-based Network-on-Chip (NoC), and in turn reduce the system performance and energy efficiency. In this paper, we present FoToNoC, a Folded Torus-like NoC, and a hierarchical management strategy on top of it, to address this tradeoff problem for heterogeneous many-core systems. Optimizations of chip temperature, inter-core communication, application performance, and system energy consumption are well isolated in FoToNoC, and addressed in different design phases and aspects. A cluster-based hierarchical strategy is proposed to manage the system adaptively in\u00a0\u2026", "We propose 3D mesh-based optical network-on-chip (ONoC) based on a novel low-cost 6\u00d76 optical router, and quantitatively analyze thermal effects on the 3D ONoC. Evaluation results show that with the traditional thermal tuning technique using microheater, the average power efficiency of the 3D ONoC is about 2.7pJ/bit, while chip temperature varies spatially between 55\u00b0C and 85\u00b0C. In comparison, a new technique using the optimal device setting can improve the average power efficiency to 2.1pJ/bit. It is shown that in this particular case, the effectiveness of the two techniques is comparable. If we apply both techniques at the same time, the average power efficiency can be further improved to 1.3pJ/bit.", "Accelerating the inference of Convolution Neural Networks (CNNs) on edge devices is essential due to the small memory size and poor computation capability of these devices. Network quantization methods such as XNOR-Net, Bi-Real-Net, and XNOR-Net++ reduce the memory usage of CNNs by binarizing the CNNs. They also simplify the multiplication operations to bit-wise operations and obtain good speedup on edge devices. However, there are hidden redundancies in the computation pipeline of these methods, constraining the speedup of those binarized CNNs. In this paper, we propose XOR-Net as an optimized computation pipeline for binary networks both without and with scaling factors. As XNOR is realized by two instructions XOR and NOT on CPU/GPU platforms, XOR-Net avoids NOT operations by using XOR instead of XNOR, thus reduces bit-wise operations in both aforementioned kinds of binary\u00a0\u2026", "Optical switching has been investigated for a long time, as a possible effective solution to overcome the limitations of power consumption, footprint and scalability in data center networks (DCNs). However, with the increasing DC traffic and narrow channel spacing between wavelengths for optical interconnects, traditional single-mode and multi-waveguide optical switching solutions have encountered bandwidth bottlenecks. To this end, we propose a 2\u00d72 silicon-based on-chip optical switching architecture compatible with hybrid wavelength-andmode division multiplexing (WDM-MDM), and it is found experimentally that the proposed design increases the bandwidth 8\u00d7 times with low crosstalk.", "ARM's big. LITTLE architecture coupled with Heterogeneous Multi-Processing (HMP) has enabled energy-efficient solutions in the dark silicon era. System-level techniques activate nonadjacent cores to eliminate chip thermal hotspot. However, it unexpectedly increases communication delay due to longer distance in network architectures, and in turn degrades application performance and system energy efficiency. In this paper, we present a novel hierarchical hardware-software collaborated approach to address the performance/temperature conflict in dark silicon many-core systems. Optimizations on interprocessor communication, application performance, chip temperature and energy consumption are well isolated and addressed in different phases. Evaluation results show that on average 22.57% reduction of communication latency, 23.04% improvement on energy efficiency and 6.11\u00b0C reduction of chip peak\u00a0\u2026", "For chip multiprocessors, one major challenge is to bridge the increasing speed gap between processor and the global on-chip interconnect delay. By integrating optical interconnects in network-on-chip (NoC) architectures, optical NoCs can overcome the power and bandwidth bottleneck of traditional electrical on-chip networks. However, while considering the thermal sensitivity of silicon photonic devices used in optical NoCs, optical interconnects may not have advantages in power efficiency as compared with their electrical counterparts. To tackle this problem, in this article, we propose a thermal-aware design and simulation approach for optical NoCs. Key techniques include thermal-sensitive optical power loss models from device level to network level, a thermal-aware adaptive routing mechanism, and a thermal-aware simulation platform. The thermal-aware simulation platform enables optical NoC simulation\u00a0\u2026", "Spin-Torque Transfer Magnetic RAM (STT-RAM), one of the emerging nonvolatile memory (NVM) technologies explored as the replacement for SRAM memory architectures, is particularly promising due to the fast access speed, high integration density, and zero standby power consumption. Recently, hybrid deigns with SRAM and STT-RAM buffers for routers in Network-on-Chip (NoC) systems have been widely implemented to maximize the mutually complementary characteristics of different memory technologies, and leverage the efficiency of intra-router latency and system power consumption. With the realization of Processing-in-Memory enabled by STT-RAM, in this paper, we novelly offload the execution from processors to the STT-RAM based on-chip routers to improve the application performance. On top of the hybrid buffer design in routers, we further present system-level approaches, including an ILP\u00a0\u2026", "As transistor density continues to increase with the advent of nanotechnology, reliability issues raised by more frequently appeared soft errors are becoming even more critical to the next-generation multiprocessor systems. In this paper, we present a systematic approach to address the soft-error problem in multiprocessor system-on-chip with the consideration of system performance optimization. To guarantee the system correctness, a hardware-software collaborated approach is proposed to protect the processors from soft errors. Tiny hardware sensors are embedded in the processor cores to detect the soft errors, and the software-based rollback scheduling mechanisms are applied for error recovery. The protection costs on hardware duplication and software redundancy are effectively reduced. To optimize the system performance, a distributed control system is built on top of the on-chip communication network\u00a0\u2026", "Optical network-on-chip (ONoC) architecture offers ultrahigh bandwidth, low latency, and low power dissipation for new-generation manycore systems. However, the benefits in communication performance and energy efficiency will be diminished by communication contention. The intrinsic thermal susceptibility is another challenge for ONoC designs. Under on-chip temperature variations, core functional devices suffer from significant thermal-induced optical power loss, which seriously threatens ONoCs' reliability. In this article, we develop novel routing techniques to resolve both issues for ONoCs. By analyzing the thermal effect in ONoCs, we first present a routing criterion at the network level. Combined with device-level thermal tuning, it can implement thermal-reliable ONoCs. Two routing approaches, including a mixed-integer linear programming (MILP) model and a heuristic algorithm (called CAR), are further\u00a0\u2026", "Three-dimensional network-on-chip (3D-NoC) emerges as a potential multi-core architecture delivering high performance, high energy efficiency and great scalability. However, 3D-NoC suffers from severe thermal problems due to its high power density. To solve this problem, thermal-aware scheduling is an effective solution. However, the high complexity of the thermal model of 3D-NoC becomes a major hurdle for developing efficient thermal-aware scheduling algorithms for 3D-NoC. In this paper, we propose a novel thermal-aware task scheduling scheme named as the Bottom-to-Top (B2T) approach to address this challenge. This heuristic-based method performs task allocation on processing units to efficiently minimize the peak temperature and improve the execution time of the tasks with low complexity. The algorithm is first designed for two-layer 3D-NoC and then extended to 3D-NoC with an arbitrary number of\u00a0\u2026", "Three-dimensional network-on-chip (3D-NoC) emerges as a potential multi-core architecture delivering high performance, high energy efficiency and great scalability. However, 3D-NoC suffers from severe thermal problems due to its high power density. To solve this problem, thermal-aware scheduling is an effective solution. However, the high complexity of the thermal model of 3D-NoC becomes a major hurdle for developing efficient thermal-aware scheduling algorithms for 3D-NoC. In this paper, we propose a novel thermal-aware task scheduling scheme named as the Bottom-to-Top (B2T) approach to address this challenge. This heuristic-based method performs task allocation on processing units to efficiently minimize the peak temperature and improve the execution time of the tasks with low complexity. The algorithm is first designed for two-layer 3D-NoC and then extended to 3D-NoC with an arbitrary number of\u00a0\u2026", "Locking protocol is an essential component in resource management of real-time systems, which coordinates mutually exclusive accesses to shared resources from different tasks. Although the design and analysis of locking protocols have been intensively studied for sequential real-time tasks, there has been a little work on this topic for parallel real-time tasks. In this article, we study the analysis of parallel real-time tasks using spin locks to protect accesses to shared resources in three commonly used request serving orders (unordered, FIFO-order, and priority-order). A remarkable feature making our analysis method more accurate is to systematically analyze the blocking time which may delay a task's finishing time, where the impact to the total workload and the longest path length is jointly considered, rather than analyzing them separately and counting all blocking time as the workload that delays a task's finishing\u00a0\u2026", "Real-time and embedded systems are shifting from single-core to multi-core processors, on which the software must be parallelized to fully utilize the computation capacity of the hardware. Recently, much work has been done on real-time scheduling of parallel tasks modeled as directed acyclic graphs (DAG). However, most of these studies assume tasks to have implicit or constrained deadlines. Much less work considered the general case of arbitrary deadlines (i.e., the relative deadline is allowed to be larger than the period), which is more difficult to analyze due to intra-task interference among jobs. In this article, we study the analysis of Global Earliest Deadline First (GEDF) scheduling for DAG parallel tasks with arbitrary deadlines. We develop new analysis techniques for GEDF scheduling of a single DAG task and this new analysis techniques can guarantee a better capacity augmentation bound 2.41 (the best\u00a0\u2026", "Power gating induced power/ground(P/G) noise is a major reliability problem facing by low power MPSoCs using power gating techniques. Powering on and off a process unit in MPSoCs will induce large P/G noise and can cause timing divergence and even functional errors in surrounding processing units. P/G noise is different from thermal or energy which is an accumulative effect. The noise level should be predicted and victim circuits should be protected before the noise is induced. hence, the power gating-aware scheduling problem with the consideration of P/G noise should be solved using an on-line method considering the run-time variation of tasks' execution time. In this paper, we formulate an on-line task scheduling problem with the consideration of P/G noise based on our detailed P/G noise analysis platform for MPSoC. An efficient on-line Greedy Heuristic (GH) algorithm that adapts well to real-time\u00a0\u2026", "In this paper, we propose O-Star, a scalable optical switching architecture for on-chip many-core systems, employing hybrid mode and wavelength division multiplexing technology. The O-Star uses the Benes topology as the core switching module to realize non-blocking switching. Besides, we design a wavelength and mode allocation module to enable each processor to transmit data in parallel. To quantitatively analyze the minimum hardware cost required, we establish a mathematical model for the different number of processors. As a proof of concept, a 64-core optical switching architecture featuring 8-port Benes topology, 2-mode, and 4-wavelength channels is simulated with single channel 25 Gbps data rate. The O-Star is flexible to scale, both for the number of supported processors and the switching capacity. O-Star holds promise for realizing large-scale optical switching networks to address the incoming\u00a0\u2026", "A new trend tends to deploy deep learning algorithms to edge environments to mitigate privacy and latency issues from cloud computing.  Diverse edge deep learning accelerators are devised to speed up the inference of deep learning algorithms on edge devices.  Various edge deep learning accelerators feature different characteristics in terms of power and performance, which make it a very challenging task to efficiently and uniformly compare different accelerators.  In this paper, we introduce EDLAB, an end-to-end benchmark, to evaluate the overall performance of edge deep learning accelerators. EDLAB consists of state-of-the-art deep learning models, a unified workload preprocessing and deployment framework, as well as a collection of comprehensive metrics. In addition, we propose parameterized models to model the hardware performance bound so that EDLAB can identify the hardware potentials and the hardware utilization of different deep learning applications. Finally, we employ EDLAB to benchmark three edge deep learning accelerators and analyze the benchmarking results. From the analysis we obtain some insightful observations that can guide the design of efficient deep learning applications.", "SMART NoC, which transmits unconflicted flits to distant processing elements (PEs) in one cycle through the express bypass, is a high-performance NoC design proposed recently. However, if contention occurs, flits with low priority would not only be buffered but also could not fully utilize bypass. Although there exist several routing algorithms that decrease contentions by rounding busy routers and links, they cannot be directly applicable to SMART since it lacks the support for arbitrary-turn (i.e., the number and direction of turns are free of constraints) routing. Thus, in this article, to minimize contentions and further utilize bypass, we propose an improved SMART NoC, called ArSMART, in which the arbitrary-turn transmission is enabled. Specifically, ArSMART divides the whole NoC into multiple clusters where the route computation is conducted by the cluster controller and the data forwarding is performed by the\u00a0\u2026", "The communication latency in traditional network-on-chip (NoC) with hop-by-hop traversal is inherently restricted by the distance between source-destination communicating pairs. SMART, as one of the dynamically reconfigurable NoC architectures, enables the new feature of single-cycle long-distance communication by building a direct bypass path between distant cores dynamically at runtime. With the increasing of the number of integrated cores in multi/many-core systems, SMART has been deemed a promising communication backbone in such systems. However, SMART is generally optimized for average-case performance for best-effort traffics, not offering real-time guaranteed services for real-time traffics, and thus SMART often shows extremely poor real-time performance (e.g., schedulability). To make SMART latency-predictable for real-time traffics, by combining with the single-cycle bypass forwarding\u00a0\u2026", "Real-time and embedded systems are shifting from single-core to multi-core processors, on which software must be parallelized to fully utilize the computation capacity of hardware. Recently much work has been done on real-time scheduling of parallel tasks modeled as directed acyclic graphs (DAG). However, most of these studies assume tasks to have implicit or constrained deadlines. Much less work considered the general case of arbitrary deadlines (i.e., the relative deadline is allowed to be larger than the period), which is more difficult to analyze due to intra-task interference among jobs. In this paper, we study the analysis of Global Earliest Deadline First (GEDF) scheduling for DAG parallel tasks with arbitrary deadlines. We develop new analysis techniques for GEDF scheduling of a single DAG task, which not only outperform the state-of-the-art in general evidenced by empirical evaluation, but also\u00a0\u2026", "Communication contention and thermal susceptibility are two potential issues in optical network-on-chip (ONoC) architecture, which are both critical for ONoC designs. However, minimizing conflict and guaranteeing thermal reliability are incompatible in most cases. In this paper, we present a routing criterion in the network level. Combined with device-level thermal tuning, it can implement thermal-reliable ONoC. We further propose two routing approaches (including a mixed-integer linear programming (MILP) model and a heuristic algorithm (CAR)) to minimize communication conflict based on the guaranteed thermal reliability, and meanwhile, mitigate the energy overheads of thermal regulation in the presence of chip thermal variations. By applying the criterion, our approaches achieve excellent performance with largely reduced complexity of design space exploration. Evaluation results on synthetic\u00a0\u2026", "In dark silicon many-core systems, system-level techniques have been developed to selectively activate nonadjacent cores in physical locations to maintain the allowable power budget and eliminate thermal hotspot. However, this will unexpectedly increase communication overhead due to the longer average distance between active cores in a typical mesh-based Network-on-Chip (NoC), and in turn reduce application performance. Inspired by ARM\u2019s big. LITTLE architecture coupled with Heterogeneous Multi-Processing (HMP) which enables energy-efficient solutions, in this paper, we propose two alternative hardware\u2013software collaborated techniques to address the temperature/communication conflict in the dark silicon era. A Folded Torus-like NoC, FoToNoC, is presented to address the Cluster-switching based heterogeneous system, and a Quad-core-group based NoC, QcNoC, is presented to address the In\u00a0\u2026", "Neural architecture search (NAS) is an emerging paradigm to automate the design of competitive deep neural networks (DNNs). In practice, DNNs are subject to strict latency constraints and any violation may lead to catastrophic consequences (e.g., autonomous vehicles). However, to obtain the architecture that strictly satisfies the required latency constraint, previous hardware-aware differentiable NAS methods have to repeat a plethora of search runs to tune relevant hyperparameters by trial and error, and as a result, the total design cost increases proportionally (empirically by ten times). To tackle this, we, in this article, introduce a lightweight and scalable hardware-aware NAS framework named LightNAS, which consists of two separate stages. In the first stage, we strive to search for the architecture that strictly satisfies the required latency constraint at the macro level in a differentiable manner, and more\u00a0\u2026", "Edge devices have been widely adopted to bring deep learning applications onto low power embedded systems, mitigating the privacy and latency issues of accessing cloud servers. The increasingly computational demand of complex neural network models leads to large latency on edge devices with limited resources. Many application scenarios are real-time and have a strict latency constraint, while conventional neural network compression methods are not latency-oriented. In this work, we propose a novel compact neural networks training method to reduce the model latency on latency-critical edge systems. A latency predictor is also introduced to guide and optimize this procedure. Coupled with the latency predictor, our method can guarantee the latency for a compact model by only one training process. The experiment results show that, compared to state-of-the-art model compression methods, our approach\u00a0\u2026", "Suspension-based locks are widely used in realtime systems to coordinate simultaneous accesses to exclusive shared resources. Although suspension-based locks have been well studied for sequential real-time tasks, little work has been done on this topic for parallel real-time tasks. This paper for the first time studies the problem of how to extend existing sequential-task locking protocols and their analysis techniques to the parallel task model. More specifically, we extend two locking protocols OMLP and OMIP, which were designed for clustered scheduling of sequential real-time tasks, to federated scheduling of parallel real-time tasks, and develop path-oriented techniques to analyze and count blocking time. Experiments are conducted to evaluate the performance of our proposed approaches and compare them against the state-of-the-art.", "We have witnessed the tremendous success of deep neural networks. However, this success comes with the considerable computation and storage costs which make it difficult to deploy these networks directly on resource-constrained embedded systems. To address this problem, we propose TaiJiNet, a binary-network-based framework that combines binary convolutions and pointwise convolutions, to reduce the computation and storage overhead while maintaining a comparable accuracy. Furthermore, in order to provide TaiJiNet with more flexibility, we introduce a strategy called partial binarized convolution to efficiently balance network performance and accuracy. We evaluate TaiJiNet with the CIFAR-10 and ImageNet datasets. The experimental results show that with the proposed TaiJiNet framework, the binary version of AlexNet can achieve 26x compression rate with a negligible 0.8% accuracy drop when\u00a0\u2026", "Optical networks-on-chip (ONoCs) is a new promising communication paradigm that upgrades the traditional on-chip networks (NoCs) with the ultra-high communication bandwidth and low latency. Silicon microring resonators (MRRs), as a critical component of ONoCs used to implement the selection and redirection of optical signals, are inherently sensitive to the environmental temperature. The applicability of the ONoCs is essentially restricted by the performance of these optical devices that relies on the thermal conditions of the chip. In this paper, we study the thermo-optic effects of the MRRs quantitatively, build and verify the models of the MRRs based on the finite-difference time-domain (FDTD) method. We present formal relationship models between the temperature of a MRR and its optical losses and resonance wavelength. For the first time, the variation between the two types of MRRs, the parallel microring\u00a0\u2026", "Edge systems integrated with deep neural networks (DNNs) are deemed to pave the way for future artificial intelligence (AI). However, designing accurate and efficient DNNs for resource-limited edge systems is challenging as well as requires a huge amount of engineering efforts from human experts since the design space is highly complex and diverse. Also, previous works mostly focus on designing DNNs with less floating-point operations (FLOPs), but indirect FLOPs count does not necessarily reflect the complexity of DNNs. To tackle these, we, in this paper, propose a novel neural architecture search (NAS) approach, namely EdgeNAS, to automatically discover efficient DNNs for less capable edge systems. To this end, we propose an end-to-end learning-based latency estimator, which is able to directly approximate the architecture latency on edge systems while incurring negligible computational overheads\u00a0\u2026", "Many emerging applications are inherently error-resilient and hence do not require exact computation. In this paper, we consider the task allocation and scheduling problem for mapping such applications to voltage-scalable multiprocessor systems. The proposed solution, namely ApproxMap, judiciously determines the mapping and execution sequence of resilient tasks to minimize the energy consumption of the application while meeting their target quality requirements and timing constraints. To be specific, ApproxMap generates energy-efficient yet flexible task schedule at design-time, and conducts lightweight online adjustment according to runtime dynamics for further energy-efficiency improvement. Experimental results on various task graphs demonstrate the efficacy of ApproxMap.", "With the increasing power density and number of cores integrated into a single chip, thermal management is widely recognized as one of the essential issues in Multi-Processor Systems-on-Chip (MPSoCs). An uncontrolled temperature could significantly decrease system performance, lead to high cooling and packaging costs, and even cause serious damage. These issues have made temperature one of the major factors that must be addressed in MPSoC designs. Static scheduling of applications should take the thermal effects of task executions into consideration to keep the chip temperature under a safety threshold. However, inaccurate temperature estimation would cause processor overheating or system performance degradation. In this paper, we propose an improved thermal modeling technique that can be used to predict the chip temperature more accurately and efficiently at design time. We further\u00a0\u2026", "Multiprocessor systems-on-chip (MPSoCs) are attractive platforms for embedded applications with growing complexity, because integrating a system or a complex subsystem on a single chip provides better performance and energy efficiency and lower cost per function. As feature sizes and power supply voltages continually decrease, MPSoCs are becoming more susceptible to soft errors. However, traditional soft-error tolerant methods introduce large area, power and performance overheads to MPSoCs. This paper presents a low-overhead hardware-software collaborated method, called SENoC, to dynamically mitigate soft errors on MPSoCs using an on-chip sensor network. We developed a low-cost on-chip sensor network to collaboratively monitor and detect soft errors, and implemented software-based mechanisms to guarantee correct task executions. To maximize the performance of soft-error tolerant\u00a0\u2026", "In this paper, we present a novel multi-objective hardware-aware neural architecture search (NAS) framework, namely HSCoNAS, to automate the design of deep neural networks (DNNs) with high accuracy but low latency upon target hardware. To accomplish this goal, we first propose an effective hardware performance modeling method to approximate the runtime latency of DNNs on target hardware, which will be integrated into HSCoNAS to avoid the tedious on-device measurements. Besides, we propose two novel techniques, i.e., dynamic channel scaling to maximize the accuracy under the specified latency and progressive space shrinking to refine the search space towards target hardware as well as alleviate the search overheads. These two techniques jointly work to allow HSCoNAS to perform fine-grained and efficient explorations. Finally, an evolutionary algorithm (EA) is incorporated to conduct the\u00a0\u2026", "Continuous technology scaling in manycore systems leads to severe overheating issues. To guarantee system reliability, it is critical to accurately yet efficiently monitor runtime temperature distribution for effective chip thermal management. As an emerging communication architecture for new-generation manycore systems, optical network-on-chip (ONoC) satisfies the communication bandwidth and latency requirements with low power dissipation. Moreover, observation shows that it can be leveraged for runtime thermal sensing. In this article, we propose a brand-new on-chip thermal sensing approach for ONoC-based manycore systems by utilizing the intrinsic thermal sensitivity of optical devices and the inter-processor communications in ONoCs. It requires no extra hardware but utilizes existing optical devices in ONoCs and combines them with lightweight software computation in a hardware-software\u00a0\u2026", "In this paper, we for the first time utilize the micro-ring resonators (MRs) in optical networks-on-chip (ONoCs) to implement thermal sensing without requiring additional hardware or chip area. The challenges in accuracy and reliability that arise from fabrication-induced process variations (PVs) and device-level wavelength tuning mechanism are resolved. We quantitatively model the intrinsic thermal sensitivity of MRs with finegrained consideration of wavelength tuning mechanism. Based on it, a novel PV-tolerant thermal sensor design is proposed. By exploiting the hidden \u2018redundancy\u2019 in wavelength division multiplexing (WDM) technique, our sensor achieves accurate and efficient temperature measurement with the capability of PV tolerance. Evaluation results based on professional photonic component and circuit simulations show an average of 86.49% improvement in measurement accuracy compared to the\u00a0\u2026", "Multiprocessor systems are becoming ubiquitous in today's embedded systems design. In this paper, we address the problem of mapping an application represented by a Homogeneous Synchronous Dataflow (HSDF) graph onto a real-time multiprocessor platform with the objective of maximizing total throughput. We propose that the optimal solution to the problem is composed of three components: actor-to-processor mapping, retiming, and actor ordering on each processor. The entire problem is systematically modeled into a SAT problem and solved by a modern SAT solver formally such that the optimal solution can be guaranteed. In order to explore the vast solution space more efficiently, we develop a specific HSDF theory solver based on the special characteristics of the timed HSDF, and integrate it into the general search framework of the SAT solver. The enhanced optimization framework implemented in\u00a0\u2026", "Network on Chip (NoC) has become a promising solution for the communication paradigm of the next-generation multiprocessor system-on-chip (MPSoC). As communication has become an integral part of on-chip computing, researchers are paying more attention to its implementation and optimization. Traditional techniques that model inter-processor communication inaccurately will lead to unexpected runtime performance, which is on average 90.8% worse than the predicted results based on an observation. In this paper, we present an application mapping and scheduling technique for NoC-based MPSoCs that integrates fine-grain optimization on inter-processor communications with the objective of minimizing the schedule length. A communication model is proposed to address properly the latency of inter-processor communication with network contention. Performance evaluation results show that solutions\u00a0\u2026", "Partial runtime reconfigurable (PRTR) FPGAs allow HW tasks to be placed and removed dynamically at runtime. We make two contributions in this paper. First, we present an efficient algorithm for finding the complete set of Maximal Empty Rectangles on a 2D PRTR FPGA. We also present a HW implementation of the algorithm with negligible runtime overhead. Second, we present an efficient online deadline-constrained task placement algorithm for minimizing area fragmentation on the FPGA by using an area fragmentation metric that takes into account probability distribution of sizes of future task arrivals as well as the time axis. The techniques presented in this paper are useful in an operating system for runtime reconfigurable FPGAs to manage the HW resources on the FPGA when HW tasks that arrive and finish dynamically at runtime.", "Reconfigurable devices, such as field programmable gate arrays (FPGAs), are very popular in today's embedded systems design due to their low-cost, high-performance and flexibility. Partially runtime-reconfigurable (PRTR) FPGAs allow hardware tasks to be placed and removed dynamically at runtime. Hardware task scheduling on PRTR FPGAs brings many challenging issues to traditional real-time scheduling theory, which have not been adequately addressed by the research community compared to software task scheduling on CPUs. In this paper, we consider the schedulability analysis problem of HW task scheduling on PRPR FPGAs. We derive utilization bound tests for two variants of global EDF scheduling, and use synthetic tasksets to compare performance of the tests to existing work and simulation results.", "Driven by industry demand, there is an increasing need to develop real-time multiprocessor systems which contain shared resources. The Multiprocessor Stack Resource Policy (MSRP) and Multiprocessor resource sharing Protocol (MrsP) are two major protocols that manage access to shared resources. Both of them can be applied to Fixed-Priority Preemptive Scheduling (FPPS), which is enforced by most commercial real-time systems regulations, and which requires task priorities to be assigned before deployment. Along with MSRP and MrsP, there exist two forms of schedulability tests that bound the worst-case blocking time due to resource accesses: the traditional ones being more widely adopted and the more recently developed holistic ones which deliver tighter analysis. On uniprocessor systems, there are several well-established optimal priority assignment algorithms. Unfortunately, on multiprocessor\u00a0\u2026", "The standby-sparing (SS) is a promising technique which deploys the dual-processor platform, i.e., one primary processor and one spare processor, to achieve fault tolerance for real-time systems. In the existing SS framework, all applications have their backup copies on the spare processor, but, in practice, not all applications on a system are equally important to the system. Some low critical tasks may be traded off for other system objectives. Motivated by this, in this paper, we integrate the concept of criticality into the SS framework. Such integration enables the SS framework to further reduce energy consumption. We propose an offline approach to determine an energy-efficient frequency for the primary processor. Additionally, as the cluster systems are emerging as the mainstream computing platform, we consider the SS technique on the cluster/island systems and propose an algorithm to determine the energy\u00a0\u2026", "The development of cloud computing and big data results in a large amount of data transmitting and storing. In order to protect sensitive data from leakage and unauthorized access, many cryptographic file systems are proposed to transparently encrypt file contents before storing them on storage devices, such as eCryptfs. However, the time-consuming encryption operations cause serious performance degradation. We found that compared with non-crypto file system EXT4, the performance slowdown could be up to 58.53 and 86.89 percent respectively for read and write with eCryptfs. Although prior work has proposed techniques to improve the efficiency of cryptographic file system through computation acceleration, no solution focused on the inefficiency working flow, which is demonstrated to be a major factor affecting system performance. To address this open problem, we present NV-eCryptfs, an asynchronous\u00a0\u2026", "As programs for microprocessor architectures, network-on-chip (NoC) traffic patterns are essential tools for NoC performance assessment and design exploration. The fidelity of NoC traffic patterns has profound influence on NoC studies. In this paper, we present a systematic traffic modeling and generation methodology and a traffic suite for efficient evaluation of NoC-based many-core systems. The publicly released MCSL (multi-constraint system-level) traffic suite includes a set of realistic traffic patterns for real-world applications and covers popular NoC architectures. It captures both the communication behaviors in NoCs and the temporal dependencies among them. The MCSL traffic suite can be easily incorporated into existing NoC simulators and significantly improve NoC simulation accuracy. The proposed methodology uses formal computational models to capture both communication and computation\u00a0\u2026", "In the dark silicon era, a fundamental problem is: given a real-time computation demand represented by a set of independent applications with their own power consumption, how to determine if an on-chip multiprocessor system is able to respond to this demand and maintain its reliability by keeping every core within the safe temperature range. In this paper, we first present a novel thermal model for the prediction of chip peak temperature assuming the application-to-core mapping is determined. The mathematical model combines linearized steady-state thermal model with empirical scaling factors to achieve significantly improved accuracy and running efficiency. Based on it, a MILP-based approach is presented to find the optimal application-to-core assignment such that the computation demand is met and the chip temperature is minimized. At last, if the minimized temperature still exceeds the safe temperature\u00a0\u2026", "To satisfy the ever increasing performance requirement of applications, Multiprocessor System-on-Chip (MPSoC) plays an irreplaceable role in embedded system these days. It is significant to effectively optimize communication for achieving maximum parallelism on MPSoC, especially on Network-on-Chip (NoC) based architectures. The problem of how to make an arbitration of communication congestion is remained unsolved. In this paper, we propose a reasonable Unified Priority-Based Scheduling (UPS) algorithm for task and communication co-scheduling with communication contention, which is based on a novel Task Communication Graph (TCG) model of an application. The proposed method is more accurate and effective to describe the overall process of applications. The experimental results show that the performance is improved by 31.1% on average of scheduling generated by our algorithm. It verifies\u00a0\u2026", "Reducing feature sizes and power supply voltage allows integrating more processing units (PUs) on multiprocessor system on chip (MPSoC) to satisfy the increasing demands of applications. However, it also makes MPSoC more susceptible to various reliability threats, such as high temperature and power/ground (P/G) noise. As the scale and complexity of MPSoC continuously increase, monitoring and mitigating reliability threats at runtime could offer better performance, scalability, and flexibility for MPSoC designs. In this paper, we propose a systematic approach, on-chip sensor network (SENoC), to collaboratively predict, detect, report, and alleviate runtime threats in MPSoC. SENoC not only detects reliability threats and shares related information among PUs, but also plans and coordinates the reactions of related PUs in MPSoC. SENoC is used to alleviate the impacts of simultaneous switching noise in MPSoC\u00a0\u2026", "Ternary Neural Networks (TNNs) and mixed-precision Ternary Binary Networks (TBNs) have demonstrated higher accuracy compared to Binary Neural Networks (BNNs) while providing fast, low-power, and memory-efficient inference. Related works have improved the accuracy of TNNs and TBNs, but overlooked their optimizations on CPU and GPU platforms. First, there is no unified encoding for the binary and ternary values in TNNs and TBNs. Second, existing works store the 2-bit quantized data sequentially in 32/64-bit integers, resulting in bit-extraction overhead. Last, adopting standard 2-bit multiplications for ternary values leads to a complex computation pipeline, and efficient mixed-precision multiplication between ternary and binary values is unavailable. In this article, we propose TAB as a unified and optimized inference method for ternary, binary, and mixed-precision neural networks. TAB includes unified\u00a0\u2026", "Sparse matrix-vector multiplication (SpMV) is of paramount importance in both scientific and engineering applications. The main workload of SpMV is multiplications between randomly distributed nonzero elements in sparse matrices and their corresponding vector elements. Due to irregular data access patterns of vector elements and the limited memory bandwidth, the computational throughput of CPUs and GPUs is lower than the peak performance offered by FPGAs. FPGA's large on-chip memory allows the input vector to be buffered on-chip and hence the off-chip memory bandwidth is only utilized to transfer the nonzero elements' values, column indices, and row indices. Multiple nonzero elements are transmitted to FPGA and then their corresponding vector elements are accessed per cycle. However, typical on-chip block RAMs (BRAM) in FPGAs only have two access ports. The mismatch between off-chip\u00a0\u2026", "Hardware systems integrated with deep neural networks (DNNs) are deemed to pave the way for future artificial intelligence (AI). However, manually designing efficient DNNs involves nontrivial computation resources since significant trial-and-errors are required to finalize the network configuration. To this end, we, in this article, introduce a novel hardware-aware neural architecture search (NAS) framework, namely, GoldenNAS, to automate the design of efficient DNNs. To begin with, we present a novel technique, called dynamic channel scaling, to enable the channel-level search since the number of channels has non-negligible impacts on both accuracy and efficiency. Besides, we introduce an efficient progressive space shrinking method to raise the awareness of the search space toward target hardware and alleviate the search overheads as well. Moreover, we propose an effective hardware performance\u00a0\u2026", "As an emerging role in on-chip communication, the optical networks-on-chip (ONoCs) can provide ultra-high bandwidth, low latency and low power dissipation for the data transfer. However, the thermo-optic effects of the photonic devices have a great impact on the operating performance and reliability of ONoCs, where the thermal-aware control is used to alleviate it. Furthermore, the temperature-sensitive ONoCs are prone to be attacked by the hardware Trojans (HTs) covertly embedded in the integrated circuits (ICs) from the malicious third-party components, leading to performance degradation, denial of service (DoS), or even permanent damages. In this paper, we focus on the tampering attacks on optical sampling during the thermal sensing process in ONoCs. Corresponding approaches are proposed to mitigate the negative impacts from HT attacks. Evaluation results indicate that our approach can\u00a0\u2026", "A scalp-recording electroencephalography (EEG)-based brain-computer interface (BCI) system can greatly improve the quality of life for people who suffer from motor disabilities. Deep neural networks consisting of multiple convolutional, LSTM and fully-connected layers are created to decode EEG signals to maximize the human intention recognition accuracy. However, prior FPGA, ASIC, ReRAM and photonic accelerators cannot maintain sufficient battery lifetime when processing realtime intention recognition. In this paper, we propose an ultra-low-power photonic accelerator, MindReading, for human intention recognition by only low bit-width addition and shift operations. Compared to prior neural network accelerators, to maintain the real-time processing throughput, MindReading reduces the power consumption by 62.7% and improves the throughput per Watt by 168%.", "Timing analysis of real-time tasks under preemptive scheduling must take cache-related preemption delay (CRPD) into account. Typically, a task may be preempted more than once during the execution in each period. To bound the total CRPD of     preemptions, existing CRPD analysis techniques estimate the CRPD at each program point, and use the sum of the    -largest CRPD among all program points as the total CRPD upper bound. In this paper, we disclose that the above-mentioned approach, although works well for instruction caches, leads to significant overestimation when dealing with data caches. This is because on data caches, the CRPD of preemptions at different program points may have correlations, and the total CRPD of multiple preemptions is in general smaller than the simple sum of the worst-case CRPD of each preemption. To address this problem, we propose a new technique to efficiently\u00a0\u2026", "Real-Time Calculus (RTC) is a powerful framework for modeling and worst-case performance analysis of networked systems. GPC and AND are two fundamental components in RTC, which model priority-based resource arbitration and synchronization operations, respectively. In this paper, we revisit GPC and AND. For GPC, we develop tighter output arrival curves to more precisely characterize the output event streams. For AND, we first identify a problem in the existing analysis method that may lead to negative values in the output curves, and present corrections to the problem. Then we generalize AND to synchronize more than two input event streams. We implement our new theoretical results and conduct experiments to evaluate their performance. Experiment results show significant improvement of our new methods in analysis precision and efficiency.", "Multiprocessor systems are becoming ubiquitous in today\u2019s embedded systems design. In this article, we address the problem of mapping an application represented by a Homogeneous Synchronous Dataflow (HSDF) graph onto a real-time multiprocessor platform with the objective of maximizing total throughput. We propose that the optimal solution to the problem is composed of three components: actor-to-processor mapping, retiming, and actor ordering on each processor. The entire problem is systematically modeled into a Boolean Satisfiability (SAT) problem such that the optimal solution can be guaranteed theoretically. In order to explore the vast solution space more efficiently, we develop a specific HSDF theory solver based on the special characteristics of the timed HSDF, and integrate it into the general search framework of the SAT solver. Two alternative integration methods based on branch-and-bound\u00a0\u2026", "Optical network-on-chip (ONoC) can be used as the communication backbone for high performance chip multiprocessors (CMPs). Fat tree based ONoC shows high throughput, small delay and low power consumption. However, the traditional floorplan design of fat tree based ONoC has a large number of waveguide crossings because of the fat tree topology. In this paper, we present an optimized floorplan with the least number of waveguide crossings that has been reported. The average number of waveguide crossings per optical path in the optimized floorplan is 87% less than that in traditional floorplan for a 64-core CMP. We also find the optimal aspect ratio of cores to minimize the end-to-end delay. These work could help to ease the physical implementation of fat tree based ONoC for CMP.", "Reducing feature sizes and power supply voltage allows integrating more processing units (PUs) on multiprocessor system-on-chip (MPSoC) to satisfy the increasing demands of applications. However, it also makes MPSoC more susceptible to various reliability threats, such as high temperature and power/ground (P/G) noise. As the scale and complexity of MPSoC continuously increase, monitoring and mitigating reliability threats at run time could offer better performance, scalability, and flexibility for MPSoC designs. In this paper, we propose a systematic approach, on-chip sensor network (SENoC), to collaboratively detect, report, and alleviate run-time threats in MPSoC. SENoC not only detects reliability threats and shares related information among PUs, but also plans and coordinates the reactions of related PUs in MPSoC. SENoC is used and explained in our case study to alleviate the impacts of simultaneous\u00a0\u2026", "To improve the efficiency and scalability of conflict detection for multi-dimensional classifiers, a new algorithm, based on grid of trie (GoT) algorithm, was proposed. The new algorithm uses Patricia trie, constricts the length of Internet protocol (IP) prefix in order to use Hashing technology, and improves the performance of the algorithm by adding ingress and egress of firewall for each filter.", "Person re-identification (ReID) remains an open-ended research topic, with its variety of substantial applications such as tracking, searching, etc. Existing methods mostly explore the highest-semantic feature embedding, ignoring the insights hidden among the earlier layers. Moreover, owing to the misalignment and pose variations, pose-related information is of great significance and needs to be comprehensively utilized. In this paper, we present a novel person ReID framework called Pose-aware Multi-semantic Fusion Network (PMFN). First, taking into account multiple semantics, we propose Multi-semantic Fusion Network (MFN) as the backbone, employing several shortcuts to reserve bypass feature maps for subsequent fusion. Second, to learn a pose-sensitive embedding, pose-aware clues are considered, forming the complete PMFN and investigating the well-aligned global and local body regions. Finally\u00a0\u2026", "SMART, a recently proposed dynamically reconfigurable NoC, enables single-cycle long-distance communication by building single-bypass paths. However, such a single-cycle single-bypass path will be broken when contention occurs. Thus, lower-priority packets will be buffered at intermediate routers with blocking latency from higher-priority packets, and extra router-stage latency to rebuild remaining path, reducing the bypassing benefits that SMART offers. In this paper, we for the first time propose an effective routing strategy to achieve nearly contention-free bypassing in SMART NoC. Specifically, we identify two different routes for communication pairs: direct route, with which data can reach the destination in a single bypass; and indirect route, with which data can reach the destination in two bypasses via an intermediate router. If a direct route is not found, we would alternatively resort to an indirect route in\u00a0\u2026", "In the era of big data, the demand for secure data storage is rapidly increasing. To accelerate the complex encryption computation, both specific instructions and hardware accelerators are adopted in a large number of scenarios. However, the hardware accelerators are not so effective especially for small volume data due to the induced invocation costs, while the AES-NI (Intel\u00aeadvanced encryption standard new instructions) is not so energy efficiency for big data. To satisfy the diversity performance/energy requirements for intensive data encryptions, a collaborative solution is proposed in this paper. We proposed a feasible hardware-software co-design methodology based on the stack file system eCryptfs, with quick assist technology, which is named adaptive crypto acceleration for secure data storage (ACA-SDS). ACA-SDS is able to choose the optimal encryption solution dynamically according to file operation\u00a0\u2026", "Although SMART NoC, as an emerging dynamically reconfigurable NoC architecture, is able to improve the communication efficiency significantly when scheduling real-time flows, it introduces uncertainty due to the nondeterministic latency. In this regard, we first study the schedulability of a set of arbitrary-deadline flows with given priorities. Based on schedulability analysis, an efficient priority assignment algorithm is proposed to minimize deadline misses. To our best knowledge, this is the first work of arbitrary-deadline flow scheduling on SMART NoC, which involves sophisticated computation of the worst case traversal time.", "The Network-on-chip (NoC) based multiprocessor system-on-chip (MPSoCs) is becoming a promising architecture to meet modern applications' ever-increasing demands for computing capability under limited power budget. NoC traffic patterns are essential tools for NoC performance assessment and architecture design exploration. In this paper, we present a systematic NoC traffic modeling and generation methodology and a set of realistic NoC traffic patterns called MCSL, which are generated through the methodology. The proposed methodology can faithfully capture both the communication behaviors of real applications in NoCs and the temporal dependencies among them. And it optimizes application memory requirements, mapping and scheduling to maximize overall system performance and utilization before extracting traffic patterns through cycle-level simulations. Extensive experiments are conducted to\u00a0\u2026", "Differentiable neural architecture search (NAS) is an emerging paradigm to automate the design of top-performing convolutional neural networks (CNNs). Nonetheless, existing differentiable NAS methods suffer from several crucial weaknesses, such as inaccurate gradient estimation, high memory consumption, search fairness,  etc . In this work, we introduce a novel hardware-aware differentiable NAS framework, namely SurgeNAS, in which we leverage the one-level optimization to avoid inaccuracy in gradient estimation. To this end, we propose an effective identity mapping regularization to alleviate the over-selecting issue. Besides, to mitigate the memory bottleneck, we propose an ordered differentiable sampling approach, which significantly reduces the search memory consumption to the single-path level, thereby allowing to directly search on target tasks instead of small proxy tasks. Meanwhile, it guarantees\u00a0\u2026", "As an emerging role in new-generation on-chip communication, optical networks-on-chip (ONoCs) provide ultra-high bandwidth, low latency, and low power dissipation for data transfers. However, the thermo-optic effects of the photonic devices have a great impact on the operating performance and reliability of ONoCs, where the thermal-aware control with accurate measurements, e.g., thermal sensing, is typically applied to alleviate it. Besides, the temperature-sensitive ONoCs are prone to be attacked by the hardware Trojans (HTs) covertly embedded in the counterfeit integrated circuits (ICs) from the malicious third-party vendors, leading to performance degradation, denial-of-service (DoS), or even permanent damages. In this article, we focus on the tampering and snooping attacks during the thermal sensing via micro-ring resonator (MR) in ONoCs. Based on the provided workflow and attack model, a new\u00a0\u2026", "Optical network-on-chip (ONoC) is an emerging communication architecture for manycore systems due to low latency, high bandwidth, and low power dissipation. However, a major concern lies in its thermal susceptibility - under onchip temperature variations, functional nanophotonic devices, especially microring resonator (MR)-based devices, suffer from significant thermal-induced optical power loss, which potentially counteracts the power advantages of ONoCs and even cause functional failures. Considering the fact that temperature gradients are typically found on many-core systems, effective thermal monitoring, performing as the foundation of thermal-aware management, is critical on ONoCs. In this paper, a lightweight thermal monitoring scheme is proposed for ONoCs. We first design a temperature measurement module based on generic optical routers. It introduces trivial overheads in chip area by reusing\u00a0\u2026", "Timing analysis of real-time systems must consider cache-related pre-emption delay (CRPD) costs when pre-emptive scheduling is used. While most previous work on CRPD analysis only considers instruction caches, the CRPD incurred on data caches is actually more significant. The state-of-the-art CRPD analysis methods are based on useful cache block (UCB) calculation. Unfortunately, as shown in this article, directly extending the existing UCB calculation techniques from instruction caches to data caches will lead to both unsoundness and significant imprecision. To solve these problems, we develop a new UCB calculation technique for data caches, which redefines the analysis unit (to address the unsoundness in the existing method) and precisely captures the dynamic cache access behavior by taking the temporal scopes of memory blocks into consideration. The experimental results show that our new\u00a0\u2026", "In the past few years, the extinction of Moore's Law makes people reconsider the solutions for dealing with the low computing resource utilization of applications on multicore processor systems. However, making good use of computing resources in multi-core processors systems is not easy due to the differences between single-core and multi-core architecture. Nowadays short video apps like Instagram and Tik Tok have successfully caught people's eyes by fascinating short videos, typically just 10 to 30 seconds long, uploaded by the users of apps. And almost all of these videos are recorded by their mobile devices, which are typically HD (High Definition) or FHD (Full High Definition) videos, which prefer to be encoded/decoded by H.264/AVC rather then HEVC (High Efficiency Video Coding) on mobile devices in view of the energy consumption and decoding speed. How to dive the huge potential of the computing\u00a0\u2026", "Mobile applications are becoming more and more powerful but also dependent on large main memories, which consume a large portion of system energy. Swapping to byte-addressable, non-volatile memory (NVRAM) is a promising solution to this problem. However, most NVRAMs have limited write endurance. To make it practical, the design of an NVRAM based swapping system must also consider endurance. In this paper, we target at prolonging the lifetime of NVRAM based swap area in mobile devices. Different from traditional wisdom, such as wear leveling and hot/cold data identification, we propose to build a system called nCode, which exploits the fact that code pages are easy to identify, read-only, and therefore a perfect candidate for swapping. Utilizing NVRAM's byte-addressability, we support execute-in-place (XIP) of the code pages in the swap area, without copying them back to DRAM based main\u00a0\u2026", "As transistor density continues to increase with the advent of nanotechnology, reliability issues raised by the more frequent appearance of soft errors are becoming critical for future embedded multiprocessor systems design. State-of-the-art techniques for soft error protections targeting multiprocessor systems result either high chip cost and area overhead or high performance degradation and energy consumption, and do not fulfill the increasing requirements for high performance and dependability. In this article we present a systematic approach, that is, the Sensor Networks-on-Chip (SENoC), to collaboratively and efficiently manage on-chip applications and overcome reliability threats to Multiprocessor Systems-on-Chip (MPSoC). A hardware-software collaborative approach is proposed to solve soft error problems: a hardware-based on-chip sensor network is built for soft error detection, and a software-based\u00a0\u2026", "Synchronous dataflow (SDF) is a widely-used model of computation for digital signal processing and multimedia applications. In this letter, we propose an automatic approach to synthesize efficient software from SDF models with improved runtime efficiency. Our synthesis technique is based on dynamic single-appearance scheduling (dynSAS), which generates software with minimized code size, the same as traditional single-appearance schedule (SAS), while requires much less buffer memory space. We enhance dynSAS systematically to reduce control flow overhead and increase memory utilization. Experiment results show that our approach can generate efficient software with enhanced runtime performance compared to related techniques.", "Scaling down the resolution of input images can greatly reduce the computational overhead of convolutional neural networks (CNNs), which is promising for edge AI. However, as an image usually contains much spatial redundancy, e.g., background pixels, directly shrinking the whole image will lose important features of the foreground object and lead to severe accuracy degradation. In this paper, we propose a dynamic image cropping framework to reduce the spatial redundancy by accurately cropping the foreground object from images. To achieve the instance-aware fine cropping, we introduce a lightweight foreground predictor to efficiently localize and crop the foreground of an image. The finely cropped images can be correctly recognized even at a small resolution. Meanwhile, computational redundancy also exists in CNN architectures. To pursue higher execution efficiency on resource-constrained\u00a0\u2026", "Benefiting from the search efficiency, differentiable neural architecture search (NAS) has evolved as the most dominant alternative to automatically design competitive deep neural networks (DNNs). We note that DNNs must be executed under strictly hard performance constraints in real-world scenarios, for example, the runtime latency on autonomous vehicles. However, to obtain the architecture that meets the given performance constraint, previous hardware-aware differentiable NAS methods have to repeat a plethora of search runs to manually tune the hyper-parameters by trial and error, and thus the total design cost increases proportionally. To resolve this, we introduce a lightweight hardware-aware differentiable NAS framework dubbed LightNAS, striving to find the required architecture that satisfies various performance constraints through a one-time search (i.e., you only search once). Extensive experiments\u00a0\u2026", "Suspension-based locks are widely used in real-time systems to coordinate simultaneous accesses to exclusive shared resources. Although suspension-based locks have been well studied for  sequential  real-time tasks, little work has been done on this topic for  parallel  real-time tasks. This article for the first time studies the problem of how to extend existing sequential-task locking protocols and their analysis techniques to the parallel task model. More specifically, we extend two locking protocols OMLP and OMIP, which were designed for clustered scheduling of  sequential  real-time tasks, to federated scheduling of  parallel  real-time tasks. We present corresponding blocking analysis techniques, and develop  path-oriented  techniques to analyze and count blocking time. Schedulability tests with different efficiency and accuracy are further developed. Experiments are conducted to evaluate the performance of\u00a0\u2026", "As the power density of modern CPUs is gradually increasing, thermal management has become one of the primary concerns for multicore systems, where task scheduling and dynamic voltage/frequency scaling (DVFS) play a pivotal role in effectively managing the system temperature. In this article, we propose  CARTAD , a new reinforcement learning (RL)-based task scheduling and DVFS method for temperature minimization and latency guarantee on multicore systems. The novelty of  CARTAD  framework is that we exploit the machine learning technique to analyze the applications\u2019 intermediate representations (IRs) generated by a compiler and identify an important feature which is critical for predicting the application\u2019s performance. With the newly explored feature, we construct an RL-based scheduler with the more effective state representation and reward function such that the system temperature can be\u00a0\u2026", "Entering the Big Data era leads to the rapid development of web applications which provide high-performance sensitive access on large cloud data centers. HTTPS has been widely deployed as an extension of HTTP by adding an encryption layer of SSL/TLS protocol for secure communication over the Internet. To accelerate the complex crypto computation, specific acceleration instruction set and hardware accelerator are adopted. However, energy consumption has been ignored in the rush for performance. Actually, energy efficiency has become a challenge with the increasing demands for performance and energy saving in data centers. In this paper, we present the EECA, an Energy-Efficient Crypto Acceleration system for HTTPS with OpenSSL. It provides high energy-efficient encryption through HW/SW co-design. The essential idea is to make full use of system resource to exert the superiorities of different\u00a0\u2026", "Emerging Non-Volatile Memory (NVM) has many advantages, such as near-DRAM speed, byte-addressability, and persistence. Modern computer systems contain many memory slots, which are exposed as a unified storage interface by shared address space. Since NVM has limited write endurance, many wear-leveling techniques are implemented in hardware. However, existing hardware techniques can only effective in a single NVM slot, which cannot ensure wear-leveling among multiple NVM slots. This paper explores how to optimize a storage system with multiple NVM slots in terms of performance and lifetime. We show that simple integration of multiple NVMs in traditional memory policies results in poor reliability. We also reveal that existing hardware wear-leveling technologies are ineffective for a system with multiple NVM slots. In this paper, we propose a common wear-aware memory management\u00a0\u2026", "Along with the explosive growth of network data, security is becoming increasingly important for web transactions. The SSL/TLS protocol has been widely adopted as one of the effective solutions for sensitive access. Although OpenSSL could provide a freely available implementation of the SSL/TLS protocol, the crypto functions, such as symmetric key ciphers, are extremely compute-intensive operations. These expensive computations through software implementations may not be able to compete with the increasing need for speed and secure connection. Although there are lots of excellent works with the objective of SSL/TLS hardware acceleration, they focus on the dedicated hardware design of accelerators. Hardly of them presented how to utilize them efficiently. Actually, for some application scenarios, the performance improvement may not be comparable with AES-NI, due to the induced invocation cost for hardware engines. Therefore, we proposed the research to take full advantages of both accelerators and CPUs for security HTTP accesses in big data. We not only proposed optimal strategies such as data aggregation to advance the contribution with hardware crypto engines, but also presented an Adaptive Crypto System based on Accelerators (ACSA) with software and hardware codesign. ACSA is able to adopt crypto mode adaptively and dynamically according to the request character and system load. Through the establishment of 40 Gbps networking on TAISHAN Web Server, we evaluated the system performance in real applications with a high workload. For the encryption algorithm 3DES, which is not supported in AES-NI, we\u00a0\u2026", "Mobile devices such as smartphones, tablets and various tiny smart equipment are widely subjected to the limit of energy consumption. Moreover, user experience has become an up-to-the-moment research topic in mobile devices. In most mobile devices, the processor is usually set in a higher frequency level to provide better performance, which would cause the increment of energy consumption. In order to address this issue, in this paper, we propose a novel task scheduling model to harvest the energy saving and user experience improvement in energy-sensitive mobile devices. In our task scheduling model, we introduce the concept of user-centric task, and present tow judgmental principles to determine user-centric tasks (i.e., foreground/interactive tasks). For enhancing user experience, we reduce slack time of the user-centric tasks properly to achieve a shorter response time. We then present two algorithms\u00a0\u2026", "SystemC is a widely used electronic system-level (ESL) design language that can be used to model both hardware and software at different stages of system design. There has been a lot of research on behavior synthesis of hardware from SystemC, but relatively little work on synthesizing embedded software for SystemC designs. In this letter, we present an approach to automatic software synthesis from SystemC-based on coroutines instead of the traditional approaches based on real-time operating system (RTOS) threads. Performance evaluation results on some realistic applications show that our approach results in impressive reduction of runtime overheads compared to the thread-based approaches.", "Deep learning applications have been widely adopted on edge devices, to mitigate the privacy and latency issues of accessing cloud servers. Deciding the number of neurons during the design of a deep neural network to maximize performance is not intuitive. Particularly, many application scenarios are real-time and have a strict latency constraint, while conventional neural network optimization methods do not directly change the temporal cost of model inference for latency-critical edge systems. In this work, we propose a latency-oriented neural network learning method to optimize models for high accuracy while fulfilling the latency constraint. For efficiency, we also introduce a universal hardware-customized latency predictor to optimize this procedure to learn a model that satisfies the latency constraint by only a one-shot training process. The experiment results reveal that, compared to state-of-the-art methods\u00a0\u2026", "Adder Neural Network (AdderNet) is a new type of Convolutional Neural Networks (CNNs) that replaces the computational-intensive multiplications in convolution layers with lightweight additions and subtractions. As a result, AdderNet preserves high accuracy with adder convolution kernels and achieves high speed and power efficiency. In-Memory Computing (IMC) is known as the next-generation artificial-intelligence computing paradigm that has been widely adopted for accelerating binary and ternary CNNs. As AdderNet has much higher accuracy than binary and ternary CNNs, accelerating AdderNet using IMC can obtain both performance and accuracy benefits. However, existing IMC devices have no dedicated subtraction function, and adding subtraction logic may bring larger area, higher power, and degraded addition performance. In this paper, we propose iMAD as an in-memory accelerator for AdderNet\u00a0\u2026", "Model scaling is an effective way to improve the accuracy of deep neural networks (DNNs) by increasing the model capacity. However, existing approaches seldom consider the underlying hardware, causing inefficient utilization of hardware resources and consequently high inference latency. In this paper, we propose HACScale, a hardware-aware model scaling strategy to fully exploit hardware resources for higher accuracy. In HACScale, different dimensions of DNNs are jointly scaled with consideration of their contributions to hardware utilization and accuracy. To improve the efficiency of width scaling, we introduce importance-aware width scaling in HACScale, which computes the importance of each layer to the accuracy and scales each layer accordingly to optimize the trade-off between accuracy and model parameters. Experiments show that HACScale improves the hardware utilization by 1.92\u00d7 on\u00a0\u2026", "Network-on-chip (NoC) is a promising solution to connect more than hundreds of processing elements (PEs). As the number of PEs increases, the high communication latency caused by the burst traffic hampers the speedup gained by computation acceleration. Although parallel multipath transmission is an effective method to reduce transmission latency, its advantages have not been fully exploited in previous works, especially for emerging point-to-point NoCs since: (1) Previous static message splitting strategy increases contentions when traffic loads are heavy, degrading NoC performance. (2) Only limited shortest paths are chosen, ignoring other possible paths without contentions. (3) The optimization of hardware that supports parallel multipath transmission is missing, resulting in additional overhead. Thus, we propose a software and hardware collaborated design to reduce latency in point-to-point NoCs\u00a0\u2026", "With the trend towards automated driving, Controller Area Network (CAN) is migrating to CAN with Flexible Data-Rate (CAN-FD), where frame packing (i.e., packing signals of various periods, deadlines, and payloads into frames following the standard CAN- FD format) is critical to address the high bandwidth demand with limited resources. Existing works have applied Integer Linear Programming (ILP), which easily gets intractable as the number of signals to be packed increases, or proposed heuristics, which are not able to obtain the optimal solution. In addition, the security model employed does not meet the AUTOSAR SecOC specification. This paper reports a novel frame packing approach for CAN-FD with an AUTOSAR-compliant security model. We establish the theory that extending the existing frame to pack signals with the same period leads to shorter WCTT (worst-case transmission time) and thus lower\u00a0\u2026", "Optical network-on-chip (ONoC) architecture is an emerging communication paradigm that upgrades the traditional electronic NoCs with low latency, ultra-high bandwidth, and good scalability. Processor cores on ONoCs often suffer from overheating problems and it is vital to precisely monitor the temperature of every individual core to perform task scheduling, for ensuring system reliability. In this paper, we propose an on-chip temperature sensing technique. It is implemented by utilizing the existing data communications on ONoCs and the thermo-optic effect of nanophotonic devices. Based on the free communication resources on ONoCs, we propose a polynomial-time algorithm to build auxiliary paths. Combined with the existing data communication paths, we can successfully obtain the on-chip temperature distribution without requiring additional hardware support. Simulation results based on a large number of\u00a0\u2026", "Recently, drones have been widely used for a variety of purposes, such as surveillance, journalism, environmental protection, disaster management and various leisure activities. However, due to the noneffective monitoring of drones, the accidents of drones interfere with low-flying aircrafts and civil aviations emerge in an endless stream, resulting in many issues in safety. In this paper, we have designed the Dynamic No-fly Zone, which is based on a sphere centered on the current flight with a radius, to accurately model the no-fly zone of drones. Furthermore, in order to deal with the big data produced by the dynamically changed positions of flights and aircrafts, we have presented a Two-Level Dynamic Alert Zone. On top of it, a machine learning algorithm named Positive Logic Model (PLM) is proposed for the realization of the Dynamic No-fly Zone for drones. Without extra hardware support, our heuristic model and\u00a0\u2026", "Checkpointing is a key enabler of hibernation, live migration and fault-tolerance for virtual machines (VMs) in mobile devices. However, checkpointing a VM is usually heavyweight: the VM's entire memory needs to be dumped to storage, which induces a significant amount of (slow) I/O operations, degrading system performance and user experience. In this paper, we propose FLIC, a fast and lightweight checkpointing machinery for virtualized mobile devices by taking advantages of recent byte-addressable, non-volatile memory (NVRAM). Instead of saving the VM's entire memory to storage, we store its working set pages in NVRAM, avoiding accessing slow flash memory (compared to server-grade SSDs). To further reduce the write activities to flash memory, we propose an energy-efficient data deduplication to eliminate redundant data in VM snapshot and save storage space. Experimental results based on an\u00a0\u2026", "Multiprocessor systems-on-chip (MPSoCs) make an attractive platform for high-performance applications. Networks-on-chip (NoCs) can improve the on-chip communication bandwidth of MPSoCs. However, traditional metallic interconnects consume a significant amount of power to deliver even higher communication bandwidth required in the near future. Optical NoCs are based on CMOS-compatible optical waveguides and microresonators, and promise significant bandwidth and power advantages. This work proposes a fat tree-based optical NoC (FONoC) including its topology, floorplan, protocols, and a low-power and low-cost optical router, optical turnaround router (OTAR). Different from other optical NoCs, FONoC does not require building a separate electronic NoC for network control. It carries both payload data and network control data on the same optical network, while using circuit switching for\u00a0\u2026", "Incoherent optical DNN accelerators (OAs) are booming thanks to unparalleled performance-per-watt and excellent scalability. To boost their innovative development, a recent work revolutionarily proposed automatic OA search. However, the robustness and the acceleration performance of the generated OAs are below expectation, because the impacts of inter-tile data transfer and fabrication process & thermal variations (i.e., PTVs) on OAs were ignored. Both hinder OA design automation from being a reality. To resolve theses challenges, we develop FIONA, a novel framework for Fine-grained Incoherent Optical DNN Accelerator search towards both superior acceleration efficiency and inference robustness. Compared against 5 state-of-the-art incoherent OAs on 9 DNN benchmarks, extensive experiments and ablation studies validate the effectiveness of FIONA, achieving up to 198.01\u00d7 acceleration efficiency\u00a0\u2026", "The Gustavson's algorithm (i.e., the row-wise product algorithm) shows its potential as the backbone algorithm for sparse matrix-matrix multiplication (SpMM) on hardware accelerators. However, it still suffers from irregular memory accesses and thus its performance is bounded by the off-chip memory traffic. Previous works mainly focus on high bandwidth memory-based architectures and are not suitable for embedded FPGAs with traditional DDR. In this work, we propose an efficient Gustavson-based SpMM accelerator on embedded FPGAs with element-wise parallelism and access pattern-aware caches. First of all, we analyze the parallelism of the Gustavson's algorithm and propose to perform the algorithm with element-wise parallelism, which reduces the idle time of processing elements caused by synchronization. Further, we show a counter-intuitive example that the traditional cache leads to worse\u00a0\u2026", "Crossbar-based In-Memory Computing (IMC) accelerators preload the entire Deep Neural Network (DNN) into crossbars before inference. However, devices with limited crossbars cannot infer increasingly complex models. IMC-pruning can reduce the usage of crossbars, but current methods need expensive extra hardware for data alignment. Meanwhile, quantization can represent weights of DNNs by integers, but they employ non-integer scaling factors to ensure accuracy, requiring costly multipliers. In this paper, we first propose crossbar-aligned pruning to reduce the usage of crossbars without hardware overhead. Then, we introduce a quantization scheme to avoid multipliers in IMC devices. Finally, we design a learning method to complete above two schemes and cultivate an optimal compact DNN with high accuracy and large sparsity during training. Experiments demonstrate that our framework, compared to\u00a0\u2026", "Federated Learning (FL) empowers multiple clients to collaboratively learn a model, enlarging the training data of each client for high accuracy while protecting data privacy. However, when deploying FL in real-time edge systems, the heterogeneity of devices among systems has a severe impact on the performance of the inferred model. Existing optimizations on FL focus on improving the training efficiency but fail to speed up inference, especially when there is a latency constraint. In this work, we propose Collate, a novel training framework that collaboratively learns heterogeneous models to meet the latency constraints of multiple edge systems simultaneously. We design a dynamic zeroizing-recovering method to adjust each local model architecture for high accuracy under its latency constraint. A proto-corrected federated aggregation scheme is also introduced to aggregate all heterogeneous local models\u00a0\u2026", "Many modern real-time parallel applications can be modeled as a directed acyclic graph (DAG) task. Recent studies show that the worst-case response time (WCRT) bound of a DAG task can be significantly reduced when the execution order of the vertices is determined by the priority assigned to each vertex of the DAG. How to obtain the optimal vertex priority assignment, and how far from the best-known WCRT bound of a DAG task to the minimum WCRT bound are still open problems. In this article, we aim to construct the optimal vertex priority assignment and derive the minimum WCRT bound for the DAG task. We encode the priority assignment problem into an integer linear programming (ILP) formulation. To solve the ILP model efficiently, we do not involve all variables or constraints. Instead, we solve the ILP model iteratively, i.e., we initially solve the ILP model with only a few primary variables and constraints\u00a0\u2026", "Heterogeneous computing systems (HCSs), which consist of various processing elements (PEs) that vary in their processing ability, are usually facilitated by the network-on-chip (NoC) to interconnect its components. The emerging point-to-point NoCs which support single-cycle-multi-hop transmission, reduce or eliminate the latency dependence on distance, addressing the scalability concern raised by high latency for long-distance transmission and enlarging the design space of the routing algorithm to search the non-shortest paths. For such point-to-point NoC-based HCSs, resource management strategies which are managed by compilers, scheduler, or controllers, e.g., mapping and routing, are complicated for the following reasons: (i) Due to the heterogeneity, mapping and routing need to optimize computation and communication concurrently (for homogeneous computing systems, only communication). (ii\u00a0\u2026", "SMART (Single-cycle Multi-hop Asynchronous Repeated Traversal) Network-on-Chip (NoC), a recently proposed dynamically reconfigurable NoC, enables single-cycle long-distance communication by building single-bypass paths directly between distant communication pairs. However, such a single-cycle single-bypass path will be readily broken when contention occurs. Thus, packets will be buffered at intermediate routers with blocking latency from other contending packets, and extra router-stage latency to rebuild the remaining path when available, reducing the bypassing benefits that SMART NoC offers. In this article, we  for the first time  propose an effective contention-minimized routing algorithm to achieve maximal bypassing in SMART NoCs. Specifically, we identify two potential routes for packets:  direct route , with which packets can reach the destination in a single bypass; and  indirect route , with which\u00a0\u2026", "Due to the increasing performance requirement of cyber-physical systems, many-core processors with high parallelism are gaining wide utilization, where network-on-chip (NoC) is a prevalent choice for inter-core communication. Unfortunately, the contention on NoCs introduces large timing uncertainties, which complicates the response time estimation. To address this problem, for real-time applications modeled as a directed acyclic graph (DAG), we introduce DAG-Order, a partial order based time-predictable scheduling paradigm, resulting in real-time NoCs. Specifically, DAG-Order is built upon an existing single-cycle long-range traversal (SLT) NoC that is to simplify the process of validation and verification. Then, DAG-Order is proposed based on a dynamic scheduling approach, which jointly considers communication as well as computation workloads, and matches SLT NoC. DAG-Order achieves provably\u00a0\u2026", "Stackable Cryptographic File Systems have been adopted as one of the dominant solutions to transparently improve data security. However, how to reduce the performance degradation induced by encryption-operations is still an open problem. To solve the performance degradation problem, Load-aware Adaptive Cache Management (LACM) scheme is proposed, which utilizes a load-aware dynamic scheduling strategy to improve cache efficiency from two aspects: load-aware redundancy elimination and non-redundant cache conversion. Experimental results show that the proposed solution can provide 20.03%~34.39% latency decrease, and supply 12.82%~34.77% performance improvement for application-level workloads. LACM can also be easily adapted to other stackable cryptographic/compressed file systems, such as NCryptfs, stackable compress file system and etc.", "As chip multiprocessors keep growing in capability, on-chip communication efficiency is crucial to the overall performance. However, on-chip networks based on electronic switches suffer from excessive power consumption and limited performance. In order to take advantages of optical interconnect for large-scale on-chip communication in chip multiprocessors, we propose a design of hierarchical Clos-Benes optical network-on-chip (NoC) with an optimized control and routing scheme. The proposed control and routing scheme includes a priority based round-robin virtual output queue selection and a Q-learning based heuristic routing algorithm for the Clos network, and a traffic-aware adaptive routing for the intra-switch Benes network. By taking network load and runtime path allocation into account, the proposed Q-learning based heuristic routing can finally predict the best alternative path among all possible\u00a0\u2026", "Heterogeneous Multi-Core Mobile Systems has been widely used to improve performance. However, it faces with the challenge of tradeoff between energy saving and user experience. ARM big. LITTLE architecture, a heterogeneous computing architecture, is a power-optimization technology. In most big. LITTLE devices, however, it still cannot achieve excellent user experience and higher energy saving. In this paper, we propose an improved task scheduling (UCES-GTS) by introducing the concept of user-centric task on big. LITTLE mobile device. In order to enhance user experience, the response time of user-centric tasks is shortened with reducing slack time of them properly. We then present a detailed algorithm to compute appropriate frequency and allocate the CPU resources to each task. The experimental evaluation results show that our improved global task scheduling model can achieve 17 % and 8\u00a0\u2026", "Optical network-on-chip (ONoC) architecture offers excellent communication performance for unconflicted messages. However, extra communication delays and energy overheads will be incurred by communication contention, significantly diminishing the benefits offered by ONoC. Thermal reliability is also a potential issue in ONoC designs due to the intrinsic thermal sensitivity of nanophotonic devices. In order to achieve communication optimization with guaranteed thermal reliability, we employ local thermal tuning at the device level to guarantee system reliability, and further propose two routing approaches that include a mixed-integer linear programming (MILP) based approach and a contention-aware routing (CAR) heuristic for the thermal-reliable ONoCs. By jointly considering communication conflict and the energy consumption caused by thermal tuning under chip thermal variations, our approaches can\u00a0\u2026", "Although SMART NoC, as an emerging dynamically reconfigurable NoC architecture, is able to improve the communication efficiency significantly when scheduling real-time flows, it introduces uncertainty due to the nondeterministic latency. In this regard, we first study the schedulability of a set of arbitrary-deadline flows with given priorities. Based on schedulability analysis, an efficient priority assignment algorithm is proposed to minimize deadline misses. To our best knowledge, this is the first work of arbitrary-deadline flow scheduling on SMART NoC, which involves sophisticated computation of the worst case traversal time.", "According to the International Technology Roadmap for Semiconductors, improving characteristics of metal wires will no longer satisfy performance requirements, and new interconnect paradigms are needed. Radio frequency interconnect (RF-I) enjoys better CMOS compatibility compared with other alternatives, and is exploited as express shortcuts overlaid traditional network-on-chip (NoC) topologies. However, the efficient utilization of on-chip communication bandwidth provided by RF interconnects still remains an open problem. To make effective use of scarce on-chip RF-I for different traffic patterns, system model of NoC with shared RF-I (SRFNoC) is constructed first time in this paper, along with detailed design methodology. A light-weighted arbitration mechanism is utilized for sharing resource allocation, and a new mapping algorithm communication weight and simulated annealing is proposed for topology\u00a0\u2026", "There is a phenomenon that hardware technology has developed ahead of software technology in recent years. Companies lack of software techniques that can fully utilize the modern multi-core computing resources, mainly due to the difficulty of investigating the inherent parallelism inside a software. This problem exists in products ranging from energy-sensitive smartphones to performance-eager data centers. In this paper, we present a case study on the parallelization of the complex industry standard H.264 HDTV decoder application in multi-core systems. An optimal schedule of the tasks is obtained and implemented by a carefully-defined software parallelization framework (SPF). The parallel software framework is proposed together with a set of rules to direct parallel software programming (PSPR). A pre-processing phase based on the rules is applied to the source code to make the SPF applicable. The task\u00a0\u2026", "As transistor density continues to increase with the advent of nanotechnology, reliability issues raised by more frequently appeared soft errors are becoming critical tasks for future embedded multiprocessor systems design. State-of-the-art techniques for soft error protections targeting multiprocessor systems involve either high chip cost and area overhead or much performance degradation and energy consumption, and do not fulfill the increasing requirement of high performance and reliability. In this paper, we present a hardware-software collaborated approach to efficiently manage application execution and overcome reliability threats for Multiprocessor Systems-on-Chip (MPSoC). A hardware-based on-chip sensor network is built for soft error detection, and a software-based recovery mechanism is applied for soft error correction. This strategy only introduces trivial overhead on hardware design and much lower\u00a0\u2026", "Addition is a fundamental computer arithmetic operation that is widely performed in microprocessors, digital signal processors, and application-specific processors. The design of a high-speed and energy-efficient adder is thus useful and important for practical applications. In this context, this paper presents the designs of novel asynchronous carry look-ahead adders (CLAs) viz. a standard CLA (SCLA) and a block CLA (BCLA). The proposed CLAs are monotonic, dual-rail encoded, and are realized according to return-to-zero handshake (RZH) and return-to-one handshake (ROH) protocols using a 28-nm CMOS process technology. The proposed BCLA has a slight edge over the proposed SCLA, and the proposed BCLA reports the following optimizations in design metrics such as cycle time (delay), area, and power compared to a recently presented state-of-the-art asynchronous CLA for a 32-bit addition: (i) 32.6% reduction in cycle time, 29% reduction in area, 4.3% reduction in power, and 35.5% reduction in energy for RZH, and (ii) 31.4% reduction in cycle time, 28.9% reduction in area, 4.4% reduction in power, and 34.4% reduction in energy for ROH. Also, the proposed BCLA reports reductions in cycle time and power/energy compared to many other asynchronous adders.", "Edge devices are increasingly utilized for deploying deep learning applications on embedded systems. The real-time nature of many applications and the limited resources of edge devices necessitate latency-targeted neural network compression. However, measuring latency on real devices is challenging and expensive. Therefore, this letter presents a novel and efficient framework, named EvoLP, to accurately predict the inference latency of models on edge devices. This predictor can evolve to achieve higher latency prediction precision during the network compression process. Experimental results demonstrate that EvoLP outperforms previous state-of-the-art approaches by being evaluated on three edge devices and four model variants. Moreover, when incorporated into a model compression framework, it effectively guides the compression process for higher model accuracy while satisfying strict latency\u00a0\u2026", "Crossbar-based In-Memory Processing (IMP) accelerators have been widely adopted to achieve high-speed and low-power computing, especially for deep neural network (DNN) models with numerous weights and high computational complexity. However, the floating-point (FP) arithmetic is not compatible with crossbar architectures. Also, redundant weights of current DNN models occupy too many crossbars, limiting the efficiency of crossbar accelerators. Meanwhile, due to the inherent non-ideal behavior of crossbar devices, like write variations, pre-trained DNN models suffer from accuracy degradation when it is deployed on a crossbar-based IMP accelerator for inference. Although some approaches are proposed to address these issues, they often fail to consider the interaction among these issues, and introduce significant hardware overhead for solving each issue. To deploy complex models on IMP\u00a0\u2026", "Thanks to unparalleled performance-per-watt and superior scalability, noncoherent optical accelerators (OAs) based on micro-resonator (MR) banks are particularly promising to promote green deep learning and enable ubiquitous DNN-powered intelligence. To boost the achievable acceleration efficiency and development speed of such hardware, we develop a systematized framework to achieve automated OA architecture search, which integrates three efficient components, including a fine-grained OA Search Space, an OA Performance Predictor and an OA Search Engine. Extensive evaluations and ablation studies demonstrate the effectiveness of all these enablers and the outstanding efficiency of auto-generated OAs.", "Edge intelligence systems, the intersection of edge computing and artificial intelligence (AI), are pushing the frontier of AI applications. However, the complexity of deep learning models and heterogeneity of edge devices make the design of edge intelligence systems a challenging task. Hardware-agnostic methods face some limitations when implementing edge systems. Thus, hardware-aware methods are attracting more attention recently. In this paper, we present our recent endeavors in hardware-aware design and optimization for edge intelligence. We delve into techniques such as model compression and neural architecture search to achieve efficient and effective system designs. We also discuss some challenges in hardware-aware paradigm.", "Ternary Neural Networks (TNNs) achieve an excellent trade-off between model size, speed, and accuracy, quantizing weights and activations into ternary values {+1, 0, -1}. The ternary multiplication operations in TNNs equal light-weight bitwise operations, favorably in In-Memory Computing (IMC) platforms. Therefore, many IMC-based TNN accelerators have been proposed. They build dedicated ternary multiplication cells or utilize efficient bitwise operations on IMC architectures. However, existing ternary value accumulation schemes on IMC architectures are inefficient. They extend the sign bit of integer operands or conduct two-round accumulation with specially designed encoding, bringing long latency and extra memory write overhead. Moreover, existing IMC-based TNN accelerators overlook TNNs' sparsity and conduct operations on zero weights, resulting in unnecessary power consumption and latency. In\u00a0\u2026", "Remarkable breakthroughs but daunting complexities of deep learning have aroused widespread interest in dedicated DNN acceleration hardware, among which optical accelerators (OAs) are particularly promising thanks to their unprecedentedly high performance-per-watt. However, the development of OAs is much slower than that of electrical accelerators due to threefold challenges. First, the OA design space is ample and discrete, making it tough for OA optimization; Second, the ecosystem that facilitates OA development is still in its infancy. Techniques to support OA design remain less explored, limiting both the achievable performance and the innovative development of OAs. Third, OAs are highly sensitive to fabrication-induced process variations and thermal fluctuations (i.e., PTVs), which degrades OAs\u2019 inference robustness and even renders them unusable in practice. In this paper, we develop AutOAS\u00a0\u2026", "In this paper, we propose TECO, a multi-dimensional pruning framework to collaboratively prune the three dimensions (depth, width, and resolution) of convolutional neural networks (CNNs) for better execution efficiency on embedded hardware. In TECO, we first introduce a two-stage importance evaluation framework, which efficiently and comprehensively evaluates each pruning unit according to both the local importance inside each dimension and the global importance across different dimensions. Based on the evaluation framework, we present a heuristic pruning algorithm to progressively prune the three dimensions of CNNs towards the optimal trade-off between accuracy and efficiency. Experiments on multiple benchmarks validate the advantages of TECO over existing state-of-the-art (SOTA) approaches. The code and pre-trained models are available anonymously at https://github.com/ntuliuteam/Teco.", "Sparse-matrix sparse-matrix multiplication (SpMM) is an important kernel in multiple areas, e.g., data analytics and machine learning. Due to the low on-chip memory requirement, the consistent data format, and the simplified control logic, the Gustavson\u2019s algorithm is a promising backbone algorithm for SpMM on hardware accelerators. However, the off-chip memory traffic still limits the performance of the algorithm, especially on embedded FPGAs. Previous researchers optimize the Gustavson\u2019s algorithm targeting high bandwidth memory-based architectures and their solutions cannot be directly applied to embedded FPGAs with traditional DDRs. In this work, we propose an efficient Gustavson-based sparse matrix-matrix multiplication accelerator on embedded FPGAs. The proposed design fully considers the feature of off-chip memory access on embedded FPGAs and the dataflow of the Gustavson\u2019s algorithm. At\u00a0\u2026", "Convolutional neural networks (CNNs) have demonstrated encouraging results in image classification tasks. However, the prohibitive computational cost of CNNs hinders the deployment of CNNs onto resource-constrained embedded devices. To address this issue, we propose, a comprehensive compression framework to reduce the computational overhead of CNNs. In, we first introduce dynamic image cropping, where we design a lightweight foreground predictor to accurately crop the most informative foreground object of input images for inference, which avoids redundant computation on background regions. Subsequently, we present compound shrinking to collaboratively compress the three dimensions (depth, width, and resolution) of CNNs according to their contribution to accuracy and model computation. Dynamic image cropping and compound shrinking together constitute a multi-dimensional CNN\u00a0\u2026", "In this paper, we propose a multi-dimensional pruning framework, EMNAPE, to jointly prune the three dimensions (depth, width, and resolution) of convolutional neural networks (CNNs) for better execution efficiency on embedded hardware. In EMNAPE, we introduce a two-stage evaluation strategy to evaluate the importance of each pruning unit and identify the computational redundancy in the three dimensions. Based on the evaluation strategy, we further present a heuristic pruning algorithm to progressively prune redundant units from the three dimensions for better accuracy and efficiency. Experiments demonstrate the superiority of EMNAPE over existing methods.", "Current communication infrastructures for convolutional neural networks (CNNs) only focus on specific transmission patterns, not applicable to benefit the whole system if the dataflow changes or different dataflows run in one system. To reduce data movement, various CNN dataflows are presented. For these dataflows, parameters and results are delivered using different traffic patterns, i.e., multicast, unicast, and gather, preventing dataflow-specific communication backbones from benefiting the entire system if the dataflow changes or different dataflows run in the same system. Thus, in this paper, we propose MUG-NoC to support typical traffic patterns and accelerate them, therefore boosting multiple dataflows. Specifically, (i) we for the first time support multicast in 2D-mesh software configurable NoC by revising router configuration and proposing the efficient multicast routing; (ii) we decrease unicast latency by\u00a0\u2026", "Existing nonvolatile memory (NVM)-based file systems can fully leverage the characteristics of NVM to obtain better performance than traditional disk-based file systems. It has the potential capacity to efficiently manage metadata and perform fast metadata operations. However, most NVM-based file systems mainly focus on managing file metadata (inode), while pay little attention to directory metadata (dentry), which also has a noticeable impact on the file system performance. Besides, the traditional journaling technique that guarantees metadata consistency may not yield satisfactory performance on NVM-based file systems. To solve these problems, in this article we propose a fast and low overhead metadata operation mechanism, called FLOMO. It first adopts a novel slotted-paging structure in NVM to reorganize dentry for efficiently performing dentry operations, and utilizes the red\u2013black tree in DRAM to accelerate dentry lookup\u00a0\u2026", "Neural architecture search (NAS) is an emerging paradigm to automate the design of top-performing deep neural networks (DNNs). Specifically, the increasing success of NAS is attributed to the reliable performance estimation of different architectures. Despite significant progress to date, previous relevant methods suffer from prohibitive computational overheads. To avoid this, we propose an effective yet computationally efficient proxy, namely Trained Batchwise Estimation (TBE), to reliably estimate the performance of different architectures using the early batchwise training statistics. We then integrate TBE into the hardware-aware NAS scenario to search for hardware-efficient architecture solutions. Experimental results clearly show the superiority of TBE over previous relevant state-of-the-art approaches.", "Network-on-chip (NoC) is an emerging paradigm that is able to connect a significant amount of processing elements (PEs). However, as a distributed subsystem, NoC resources have not been exploited to the fullest. Multipath parallel transmission, which splits one message into multiple parts and sends them simultaneously, shows its efficiency in utilizing NoC resources and further reducing the transmission latency. However, this method is not fully optimized in previous works, especially for emerging point-to-point NoCs due to the following reasons: 1) only limited shortest paths are chosen; 2) static message splitting strategy without considering NoC utilization state increases contentions; and 3) the optimization of hardware that supports multipath parallel transmission is missing, resulting in additional overheads. Thus, we propose LAMP, a software and hardware collaborated design to efficiently utilize resources\u00a0\u2026", "By combining silicon photonics and NoC architecture, optical network-on-chip (ONoC) architecture [1, 2] provides an innovative solution to satisfy the communication requirements on highbandwidth, low-latency, and low-power dissipation. The employment of wavelength division multiplexing (WDM) technology further multiplies the bandwidth of optical communications. We take a 2D-mesh based ONoC as an example in Figure 6.1 (a). Vertically on top of processing elements, a photonic network provides optical interconnects between optical routers for interprocessor bulk data transmission. An electronic network comprised of control routers and metallic interconnects is designed to perform logical control. The photonic and electronic networks together constitute an ONoC. In this chapter, we consider WDM-based ONoCs with 2D-mesh topology", "Emerging file systems have been designed for fully exploring NVM's advanced features. However, with the development of big data, these file systems suffer from the performance degradation in highly concurrent environment, which are caused by serious access conflicts in space management. To solve this problem, we propose an efficient concurrency-oriented space management scheme named as COSMA. Along with novel data structure design, COSMA is able to greatly reduce request congestion among multiple threads through hierarchical space allocation scheme. Furthermore, COSMA provides 3 reclamation strategies to improve space utilization, and can also adapt to different systems which varied in NVM capacities. To ensure the system reliability, COSMA is capable of keeping wear leveling among multiple NVMs slots. We implement COSMA in a representative persistent file system, PMFS\u00a0\u2026", "Emerging byte-addressable non-volatile memory (NVM) has the advantages of fast, cheap and persistent, and is considered as the next generation of persistent memory. However, existing NVM-based filesystems cannot adapt well for mobile devices, and not to mention the consideration for mobile application characteristics. In this paper, we propose an efficient and durable in-memory file system named as Mobi-PMFS for mobile devices. Proposed Mobi-PMFS is not only adaptive to ARM architecture, but also customized according to mobile application features. A wear-aware three-list space management scheme including a switching allocation algorithm is proposed to provide optimum performance for mobile systems while keeping the durability of NVM. Experimental results show that Mobi-PMFS is 8x times and 1.2x faster than EXT4-SSD and EXT4-DAX, and provides 11x wear-leveling improvement compared\u00a0\u2026", "Heterogenerous multi-cores utilize the strength of different architectures for executing particular types of workload, and usually offer higher performance and energy efficiency. In this paper, we study the worst-case response time (WCRT) analysis of typed scheduling of parallel DAG tasks on heterogeneous multi-cores, where the workload of each vertex in the DAG is only allowed to execute on a particular type of cores. The only known WCRT bound for this problem is grossly pessimistic and suffers the non-self-sustainability problem. In this paper, we propose two new WCRT bounds. The first new bound has the same time complexity as the existing bound, but is more precise and solves its non-self-sustainability problem. The second new bound explores more detailed task graph structure information to greatly improve the precision, but is computationally more expensive. We prove that the problem of computing the\u00a0\u2026", "Optical network-on-chip (ONoC) architecture offers excellent communication performance for unconflicted messages. However, extra communication delays and energy overheads will be incurred by communication contention, significantly diminishing the benefits offered by ONoC. Thermal reliability is also a potential issue in ONoC designs due to the intrinsic thermal sensitivity of nanophotonic devices. In order to achieve communication optimization with guaranteed thermal reliability, we employ local thermal tuning at the device level to guarantee system reliability, and further propose two routing approaches that include a mixed-integer linear programming (MILP) based approach and a contention-aware routing (CAR) heuristic for the thermal-reliable ONoCs. By jointly considering communication conflict and the energy consumption caused by thermal tuning under chip thermal variations, our approaches can\u00a0\u2026", "System-level thermal management techniques normally map applications on non-adjacent cores to guarantee the safe temperature in many-core systems, while the communication efficiency will be oppositely affected by long-distance data transmission over conventional Network-on-Chips (NoC). SMART NoC has enabled single-cycle multi-hop bypass channels between distant cores, which can significantly reduce inter-processor communication latency. However, communication efficiency of SMART will be significantly diminished by express bypass break due to communication conflict. In order to achieve communication optimization with guaranteed system thermal reliability, we propose a dynamic reconfiguration method for logical interconnection topology through task mapping on top of SMART NoC. Active cores are physically decentralized on chip for better heat dissipation, while communication overhead\u00a0\u2026", "A fraction of a many-core chip has to become powered off in order to maintain allowable power budget and safe temperature in the dark silicon era. Techniques have been developed to selectively activate cores in distributed physical locations to avoid temperature hotspot. It results in the unexpected increase of communication overhead due to longer average distance between active cores on Network-on-Chip (NoC). We propose a physical and logical isolated framework based on Folded Torus-like NoC for heterogeneous many-core systems to achieve the guaranteed temperature reliability and satisfied application performance requirement. Physically distributed cores are interconnected through folded torus-like NoC and organized in clusters to enable logically condensed intercommunications within it. Compared to traditional mesh-like systems, the proposed folded torus-like organization can achieve on\u00a0\u2026", "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems publication \ninformation Page 1 Editor-in-Chief DAVID ATIENZA Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne \n(EPFL) Embedded Systems Laboratory (ESL) EPFL-STI-IEM-ESL, Station 11 1015 Lausanne, \nSwitzerland david.atienza@epfl.ch Deputy Editor-in-Chief AYSE K. COSKUN Boston University \n8 Saint Mary\u2019s Street, Boston, MA 02215, USA acoskun@bu.edu Managing Editor SARA \nDAILEY IEEE CEDA Oakdale, MN, USA saradailey1@gmail.com TCAD Webmaster ING-CHAO \nLIN Dept. of Computer Science and Information Engineering National Cheng Kung University \nNo. 1, University Road, Tainan City, Taiwan 701 ROC iclin@mail.ncku.edu.tw Associate Editors \n3D Design & Optimization CHENG ZHUO Zheijang University, CN zhuocheng@gmail.com \nVASILIS PAVLIDIS Aristotle University of Thessaloniki (AUTh) Thessaloniki, \u2026"]}, "collaboration_network": {"target": ["Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Jiang Xu", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Nan Guan", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Mengquan Li", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Wei Zhang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Lei Yang", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Di Liu", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Mahdi Nikdast", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Zhehui Wang", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Hao Kong", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Duo Liu", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Shuo Huai", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Weiwen Jiang", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Hui Chen", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Zonghua Gu", "Luan HK Duong", "Luan HK Duong", "Luan HK Duong", "Luan HK Duong", "Luan HK Duong", "Luan HK Duong", "Yu Wang (\u6c6a\u7389)", "Yu Wang (\u6c6a\u7389)", "Yu Wang (\u6c6a\u7389)", "Yu Wang (\u6c6a\u7389)", "Yu Wang (\u6c6a\u7389)", "Kan Zhong", "Kan Zhong", "Kan Zhong", "Kan Zhong", "Kan Zhong", "Wang Yi", "Wang Yi", "Wang Yi", "Wang Yi", "Liang Feng", "Liang Feng", "Liang Feng", "Xue (Steve) Liu", "Xue (Steve) Liu", "Xue (Steve) Liu", "Xue (Steve) Liu", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Shiqing Li", "Lei Jiang", "Lei Jiang", "Lei Jiang", "Lei Jiang", "Chao Chen (\u9648\u8d85)", "Chao Chen (\u9648\u8d85)", "Chao Chen (\u9648\u8d85)", "Qian Lou", "Qian Lou", "Qian Lou", "Shien Zhu", "Shien Zhu", "Shien Zhu", "Shien Zhu", "Shien Zhu", "Shien Zhu", "WENYANG LIU", "WENYANG LIU", "WENYANG LIU", "Huazhong Yang", "Huazhong Yang", "Huazhong Yang", "Huazhong Yang", "Weigang Hou", "Weigang Hou", "Weigang Hou", "Qingqiang He (\u4f55\u9752\u5f3a)", "Qingqiang He (\u4f55\u9752\u5f3a)", "Qingqiang He (\u4f55\u9752\u5f3a)", "Ravi Iyer", "Ravi Iyer", "Ravi Iyer", "Ramesh Illikkal", "Ramesh Illikkal", "Ramesh Illikkal", "Bin Li", "Bin Li", "Bin Li", "Tianzheng Wang", "Tianzheng Wang", "Mingsong Lv", "Mingsong Lv", "Zhiwei Feng", "Zhiwei Feng", "Xiuqiang He", "Xiuqiang He", "Qi Li", "Zili Shao", "Zili Shao", "Jinghao Sun", "Jinghao Sun", "Jinghao Sun", "Nikil Dutt", "Nikil Dutt", "Yichen Ye", "Jogesh K. Muppala", "Jin Cui", "Jin Cui", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "Xiaowen Wu", "QF  Zhuge", "QF  Zhuge", "QF  Zhuge", "QF  Zhuge"], "target_id": ["IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "IxOQVaEAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "3C7SPAgAAAAJ", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "7sRcJiDSFv8C", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "1nl6hScAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "UTTE_wEAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "3e9kkccAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "y48KryIAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "oztI8WgAAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "CBLdvP4AAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "LSmCSQsAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "HWwI12YAAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "62oDIG4AAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "3cCzJvEAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "RJXo0ggAAAAJ", "V0vB3MQAAAAJ", "V0vB3MQAAAAJ", "V0vB3MQAAAAJ", "V0vB3MQAAAAJ", "V0vB3MQAAAAJ", "V0vB3MQAAAAJ", "j8JGVvoAAAAJ", "j8JGVvoAAAAJ", "j8JGVvoAAAAJ", "j8JGVvoAAAAJ", "j8JGVvoAAAAJ", "NhMgNbAAAAAJ", "NhMgNbAAAAAJ", "NhMgNbAAAAAJ", "NhMgNbAAAAAJ", "NhMgNbAAAAAJ", "_ynjrUUAAAAJ", "_ynjrUUAAAAJ", "_ynjrUUAAAAJ", "_ynjrUUAAAAJ", "vUFmMrQAAAAJ", "vUFmMrQAAAAJ", "vUFmMrQAAAAJ", "rfLIRakAAAAJ", "rfLIRakAAAAJ", "rfLIRakAAAAJ", "rfLIRakAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "LiO9y6EAAAAJ", "-1sXorAAAAAJ", "-1sXorAAAAAJ", "-1sXorAAAAAJ", "-1sXorAAAAAJ", "6luJjFQAAAAJ", "6luJjFQAAAAJ", "6luJjFQAAAAJ", "SBYgXLoAAAAJ", "SBYgXLoAAAAJ", "SBYgXLoAAAAJ", "w1VKhL0AAAAJ", "w1VKhL0AAAAJ", "w1VKhL0AAAAJ", "w1VKhL0AAAAJ", "w1VKhL0AAAAJ", "w1VKhL0AAAAJ", "gksRZlMAAAAJ", "gksRZlMAAAAJ", "gksRZlMAAAAJ", "3m8I0XAAAAAJ", "3m8I0XAAAAAJ", "3m8I0XAAAAAJ", "3m8I0XAAAAAJ", "5g5cY5AAAAAJ", "5g5cY5AAAAAJ", "5g5cY5AAAAAJ", "z4-C17kAAAAJ", "z4-C17kAAAAJ", "z4-C17kAAAAJ", "2rO3ZvEAAAAJ", "2rO3ZvEAAAAJ", "2rO3ZvEAAAAJ", "jBHCsZIAAAAJ", "jBHCsZIAAAAJ", "jBHCsZIAAAAJ", "CLzoFY4AAAAJ", "CLzoFY4AAAAJ", "CLzoFY4AAAAJ", "tACpr20AAAAJ", "tACpr20AAAAJ", "-xU4mQ4AAAAJ", "-xU4mQ4AAAAJ", "Et7AS1IAAAAJ", "Et7AS1IAAAAJ", "3lprwmsAAAAJ", "3lprwmsAAAAJ", "yCV_sRYAAAAJ", "HlxIVWYAAAAJ", "HlxIVWYAAAAJ", "fZijmAcAAAAJ", "fZijmAcAAAAJ", "fZijmAcAAAAJ", "CpBXPVoAAAAJ", "CpBXPVoAAAAJ", "-SYDm8cAAAAJ", "cG0My4kAAAAJ", "nWvIgocAAAAJ", "nWvIgocAAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "f4hWeB4AAAAJ", "XFs1cCEAAAAJ", "XFs1cCEAAAAJ", "XFs1cCEAAAAJ", "XFs1cCEAAAAJ"], "type": ["Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"], "location": ["Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "City University of Hong Kong", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hunan University", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "Hong Kong University of Science and Technology", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Norwegian University of Science and Technology", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "Colorado State University", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "George Mason University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Ume\u00e5 University", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Tsinghua University", "Tsinghua University", "Tsinghua University", "Tsinghua University", "Tsinghua University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Chongqing University", "Uppsala University", "Uppsala University", "Uppsala University", "Uppsala University", "Chongqing University", "Chongqing University", "Chongqing University", "McGill Univ", "McGill Univ", "McGill Univ", "McGill Univ", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Indiana University Bloomington", "Indiana University Bloomington", "Indiana University Bloomington", "Indiana University Bloomington", "Chongqing University", "Chongqing University", "Chongqing University", "University of Central Florida", "University of Central Florida", "University of Central Florida", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Tsinghua University", "Tsinghua University", "Tsinghua University", "Tsinghua University", "Northeastern University", "Northeastern University", "Northeastern University", "Hong Kong Polytechnic University", "Hong Kong Polytechnic University", "Hong Kong Polytechnic University", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Intel Corporation", "Simon Fraser University", "Simon Fraser University", "Northeastern University", "Northeastern University", "Northeastern University", "Northeastern University", "Unknown", "Unknown", "Unknown", "Chinese University of Hong Kong", "Chinese University of Hong Kong", "Dalian University of Technology", "Dalian University of Technology", "Dalian University of Technology", "University of California, Irvine", "University of California, Irvine", "Southwest University", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"], "year": [2015, 2012, 2014, 2012, 2011, 2009, 2009, 2014, 2017, 2010, 2009, 2014, 2013, 2011, 2009, 2012, 2010, 2013, 2010, 2009, 2012, 2012, 2010, 2013, 2011, 2011, 2010, 2019, 2007, 2021, 2019, 2019, 2020, 2020, 2017, 2018, 2018, 2018, 2019, 2017, 2018, 2018, 2019, 2018, 2019, 2021, 2019, 2017, 2019, 2019, 2019, 2017, 2020, 2021, 2017, 2017, 2017, 2019, 2018, 2017, 2020, 2020, 2018, 2021, 2017, 2018, 2020, 2020, 2018, 2019, 2018, 2016, 2017, 2015, 2023, 2015, 2018, 2021, 2019, 2018, 2020, 2023, 2017, 2021, 2019, 2020, 2017, 2017, 2015, 2020, 2017, 2017, 2023, 2015, 2014, 2012, 2014, 2012, 2011, 2010, 2018, 2011, 2012, 2012, 2010, 2012, 2012, 2016, 2010, 2013, 2011, 2011, 2018, 2017, 2018, 2020, 2020, 2018, 2019, 2020, 2018, 2016, 2017, 2018, 2015, 2015, 2018, 2018, 2018, 2014, 2017, 2020, 2017, 2017, 2015, 2017, 2014, 2017, 2021, 2023, 2023, 2023, 2021, 2020, 2022, 2019, 2022, 2022, 2022, 2019, 2021, 2023, 2022, 2022, 2021, 2021, 2022, 2023, 2023, 2021, 2023, 2021, 2021, 2019, 2012, 2014, 2012, 2014, 2013, 2012, 2012, 2011, 2011, 2012, 2011, 2010, 2012, 2014, 2013, 2012, 2012, 2011, 2011, 2012, 2011, 2014, 2023, 2023, 2021, 2023, 2022, 2023, 2022, 2023, 2021, 2020, 2021, 2022, 2022, 2022, 2022, 2022, 2023, 2018, 2015, 2019, 2014, 2019, 2018, 2014, 2018, 2014, 2015, 2015, 2014, 2014, 2023, 2023, 2023, 2022, 2022, 2022, 2022, 2021, 2023, 2022, 2023, 2021, 2021, 2023, 2022, 2023, 2022, 2023, 2023, 2023, 2021, 2023, 2020, 2017, 2016, 2017, 2018, 2014, 2015, 2015, 2014, 2017, 2021, 2023, 2020, 2021, 2022, 2021, 2022, 2023, 2022, 2021, 2021, 2022, 2021, 2021, 2022, 2021, 2015, 2007, 2008, 2009, 2022, 2007, 2010, 2009, 2009, 2019, 2020, 2022, 2020, 2020, 2021, 2009, 2011, 2009, 2009, 2010, 2015, 2014, 2018, 2014, 2014, 2019, 2017, 2018, 2020, 2020, 2018, 2018, 2019, 2018, 2017, 2008, 2021, 2023, 2020, 2021, 2022, 2021, 2021, 2023, 2023, 2020, 2020, 2019, 2019, 2017, 2018, 2018, 2020, 2020, 2019, 2021, 2020, 2021, 2022, 2023, 2022, 2019, 2020, 2018, 2013, 2010, 2009, 2009, 2019, 2019, 2021, 2018, 2019, 2019, 2017, 2014, 2014, 2017, 2014, 2014, 2017, 2014, 2014, 2014, 2014, 2018, 2017, 2018, 2017, 2009, 2008, 2010, 2018, 2014, 2022, 2018, 2019, 2018, 2018, 2019, 2011, 2009, 2007, 2012, 2014, 2012, 2010, 2010, 2011, 2012, 2011, 2010, 2015, 2014, 2015, 2015], "title": ["Distributed sensor network-on-chip for performance optimization of soft-error-tolerant multiprocessor system-on-chip", "Formal worst-case analysis of crosstalk noise in mesh-based optical networks-on-chip", "On-chip sensor networks for soft-error tolerant real-time multiprocessor systems-on-chip", "Thermal analysis for 3D optical network-on-chip based on a novel low-cost 6\u00d7 6 optical router", "Modeling and analysis of thermal effects in optical networks-on-chip", "Efficient Software Synthesis for Dynamic Single Appearance Scheduling of Synchronous Dataflow", "An efficient technique for analysis of minimal buffer requirements of synchronous dataflow graphs with model checking", "A systematic network-on-chip traffic modeling and generation methodology", "A Systematic and Realistic Network-on-Chip Traffic Modeling and Generation Technique for Emerging Many-Core Systems", "Union: A unified inter/intra-chip optical network for chip multiprocessors", "Efficient algorithms for 2D area management and online task placement on runtime reconfigurable FPGAs", "A case study on the communication and computation behaviors of real applications in NoC-based MPSoCs", "FONoC: A Fat Tree Based Optical Network-on-Chip for Multiprocessor System-on-Chip", "A Hardware-Software Collaborated Method for Soft-Error Tolerant MPSoC", "On-line mpsoc scheduling considering power gating induced power/ground noise", "A novel low-waveguide-crossing floorplan for fat tree based optical networks-on-chip", "Crosstalk noise and bit error rate analysis for optical network-on-chip", "On-Chip Sensor Network for Efficient Management of Power Gating-Induced Power/Ground Noise in Multiprocessor System on Chip", "Satisfiability modulo graph theory for task mapping and scheduling on multiprocessor systems", "A case study of on-chip sensor network in multiprocessor system-on-chip", "System-level modeling and analysis of thermal effects in optical networks-on-chip", "A torus-based hierarchical optical-electronic network-on-chip for multiprocessor system-on-chip", "A hierarchical hybrid optical-electronic network-on-chip", "3-D mesh-based optical network-on-chip for multiprocessor system-on-chip", "Coroutine-Based Synthesis of Efficient Embedded Software From SystemC Models", "A NoC Traffic Suite Based on Real Applications", "Power Gating Aware Task Scheduling in MPSoC", "Scope-Aware Useful Cache Block Calculation for Cache-Related Pre-Emption Delay Analysis With Set-Associative Data Caches", "Improved schedulability analysis of edf scheduling on reconfigurable hardware devices", "Contention minimization in emerging smart NoC via direct and indirect routes", "Analyzing GEDF Scheduling for Parallel Real-Time Tasks with Arbitrary Deadlines", "Timing-Anomaly Free Dynamic Scheduling of Conditional DAG Tasks on Multi-Core Systems", "Priority assignment on partitioned multiprocessor systems with shared resources", "Reduced Worst-Case Communication Latency Using Single-Cycle Multihop Traversal Network-on-Chip", "Efficient drone hijacking detection using onboard motion sensors", "Communication optimization for thermal reliable optical network-on-chip: work-in-progress", "Analyzing Data Cache Related Preemption Delay With Multiple Preemptions", "Work-in-Progress: Communication Optimization for Thermal Reliable Optical Network-on-Chip", "Routing in optical network-on-chip: minimizing contention with guaranteed thermal reliability", "Work-in-progress: fixed priority scheduling of real-time flows with arbitrary deadlines on SMART NoCs", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "Work-in-Progress: Response Time Bounds for Typed DAG Parallel Tasks on Heterogeneous Multi-cores", "Suspension-Based Locking Protocols for Parallel Real-Time Tasks", "Optimal application mapping and scheduling for network-on-chips with computation in STT-RAM based router", "Response time bounds for typed dag parallel tasks on heterogeneous multi-cores", "Partial order based non-preemptive communication scheduling towards real-time networks-on-chip", "Hardware-Software Collaborative Thermal Sensing in Optical Network-on-Chip--based Manycore Systems", "Task mapping on smart noc: Contention matters, not the distance", "Leaking your engine speed by spectrum analysis of real-Time scheduling sequences", "Scheduling and Analysis of Parallel Real-Time Tasks with Semaphores", "Thermal Sensing Using Micro-ring Resonators in Optical Network-on-Chip", "Revisiting gpc and and connector in real-time calculus", "Contention Minimized Bypassing in SMART NoC", "Locking protocols for parallel real-time tasks with semaphores under federated scheduling", "Dark silicon-aware hardware-software collaborated design for heterogeneous many-core systems", "Fixed priority scheduling of real-time flows with arbitrary deadlines on smart NoCs: work-in-progress", "Quantitative Modeling of Thermo-Optic Effects in Optical Networks-on-Chip", "Real-Time Scheduling of DAG Tasks with Arbitrary Deadlines", "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit", "Communication optimization for thermal reliable many-core systems: work-in-progress", "On the Analysis of Parallel Real-Time Tasks with Spin Locks", "Autonomous temperature sensing for optical network-on-chip", "Energy-efficient application mapping and scheduling for lifetime guaranteed MPSoCs", "Contention minimization in emerging smart NoC via direct and indirect routes", "Hardware-software collaboration for dark silicon heterogeneous many-core systems", "User Experience-Enhanced and Energy-Efficient Task Scheduling on Heterogeneous Multi-Core Mobile Systems", "Contention-Aware Routing for Thermal-Reliable Optical Networks-on-Chip", "Reduced Worst-Case Communication Latency Using Single-Cycle Multihop Traversal Network-on-Chip", "Communication optimization for thermal reliable optical network-on-chip: work-in-progress", "Routing in optical network-on-chip: minimizing contention with guaranteed thermal reliability", "Work-in-Progress: Communication Optimization for Thermal Reliable Optical Network-on-Chip", "Application mapping and scheduling for network-on-chip-based multiprocessor system-on-chip with fine-grain communication optimization", "Work-in-progress: fixed priority scheduling of real-time flows with arbitrary deadlines on SMART NoCs", "Isolation of Physical and Logical Views of Dark-Silicon Many-Core Systems for Reliability and Performance Co-Optimization", "Automated Optical Accelerator Search Toward Superior Acceleration Efficiency, Inference Robustness and Development Speed", "Traffic-aware application mapping for network-on-chip based multiprocessor system-on-chip", "Chip temperature optimization for dark silicon many-core systems", "Attack Mitigation of Hardware Trojans for Thermal Sensing via Micro-ring Resonator in Optical NoCs", "Hardware-Software Collaborative Thermal Sensing in Optical Network-on-Chip--based Manycore Systems", "Fine-Grained Task-Level Parallel and Low Power H. 264 Decoding in Multi-Core Systems", "Mitigation of Tampering Attacks for MR-Based Thermal Sensing in Optical NoCs", "Automated Optical Accelerator Search: Expediting Green and Ubiquitous DNN-Powered Intelligence", "Task mapping on smart noc: Contention matters, not the distance", "Thermal Reliability and Communication Performance Co-optimization for WDM-Based Optical Networks-on-Chip", "Thermal Sensing Using Micro-ring Resonators in Optical Network-on-Chip", "Contention Minimized Bypassing in SMART NoC", "Dark silicon-aware hardware-software collaborated design for heterogeneous many-core systems", "Fotonoc: A folded torus-like network-on-chip based many-core systems-on-chip in the dark silicon era", "An efficient technique for chip temperature optimization of multiprocessor systems in the dark silicon era", "Lightweight Thermal Monitoring in Optical Networks-on-Chip via Router Reuse", "Fixed priority scheduling of real-time flows with arbitrary deadlines on smart NoCs: work-in-progress", "Quantitative Modeling of Thermo-Optic Effects in Optical Networks-on-Chip", "FIONA: Fine-grained Incoherent Optical DNN Accelerator Search for Superior Efficiency and Robustness", "Distributed sensor network-on-chip for performance optimization of soft-error-tolerant multiprocessor system-on-chip", "UNION: A Unified Inter/Intrachip Optical Network for Chip Multiprocessors", "Formal worst-case analysis of crosstalk noise in mesh-based optical networks-on-chip", "On-chip sensor networks for soft-error tolerant real-time multiprocessor systems-on-chip", "Thermal analysis for 3D optical network-on-chip based on a novel low-cost 6\u00d7 6 optical router", "Modeling and analysis of thermal effects in optical networks-on-chip", "Union: A unified inter/intra-chip optical network for chip multiprocessors", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "A Hardware-Software Collaborated Method for Soft-Error Tolerant MPSoC", "A novel low-waveguide-crossing floorplan for fat tree based optical networks-on-chip", "An efficient soft error protection scheme for MPSoC and FPGA-based verification", "Crosstalk noise and bit error rate analysis for optical network-on-chip", "System-level modeling and analysis of thermal effects in optical networks-on-chip", "A torus-based hierarchical optical-electronic network-on-chip for multiprocessor system-on-chip", "Thermal-Aware Task Scheduling for 3D-Network-on-Chip: A Bottom to Top Scheme", "A hierarchical hybrid optical-electronic network-on-chip", "3-D mesh-based optical network-on-chip for multiprocessor system-on-chip", "Coroutine-Based Synthesis of Efficient Embedded Software From SystemC Models", "A NoC Traffic Suite Based on Real Applications", "Energy-efficient application mapping and scheduling for lifetime guaranteed MPSoCs", "Hardware-software collaboration for dark silicon heterogeneous many-core systems", "User Experience-Enhanced and Energy-Efficient Task Scheduling on Heterogeneous Multi-Core Mobile Systems", "Contention-Aware Routing for Thermal-Reliable Optical Networks-on-Chip", "Reduced Worst-Case Communication Latency Using Single-Cycle Multihop Traversal Network-on-Chip", "Communication optimization for thermal reliable optical network-on-chip: work-in-progress", "Routing in optical network-on-chip: minimizing contention with guaranteed thermal reliability", "Co-exploring neural architecture and network-on-chip design for real-time artificial intelligence", "Work-in-Progress: Communication Optimization for Thermal Reliable Optical Network-on-Chip", "Application mapping and scheduling for network-on-chip-based multiprocessor system-on-chip with fine-grain communication optimization", "Work-in-progress: fixed priority scheduling of real-time flows with arbitrary deadlines on SMART NoCs", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "Isolation of Physical and Logical Views of Dark-Silicon Many-Core Systems for Reliability and Performance Co-Optimization", "Traffic-aware application mapping for network-on-chip based multiprocessor system-on-chip", "Chip temperature optimization for dark silicon many-core systems", "Optimal application mapping and scheduling for network-on-chips with computation in STT-RAM based router", "Fine-Grained Task-Level Parallel and Low Power H. 264 Decoding in Multi-Core Systems", "An improved thermal model for static optimization of application mapping and scheduling in multiprocessor system-on-chip", "Task mapping on smart noc: Contention matters, not the distance", "Contention Minimized Bypassing in SMART NoC", "Dark silicon-aware hardware-software collaborated design for heterogeneous many-core systems", "Fotonoc: A folded torus-like network-on-chip based many-core systems-on-chip in the dark silicon era", "An efficient technique for chip temperature optimization of multiprocessor systems in the dark silicon era", "Fixed priority scheduling of real-time flows with arbitrary deadlines on smart NoCs: work-in-progress", "Contention-aware task and communication co-scheduling for network-on-chip based multiprocessor system-on-chip", "Communication optimization for thermal reliable many-core systems: work-in-progress", "Optimized Data Reuse via Reordering for Sparse Matrix-Vector Multiplication on FPGAs", "EMNAPE: Efficient Multi-Dimensional Neural Architecture Pruning for EdgeAI", "Latency-constrained DNN architecture learning for edge systems using zerorized batch normalization", "Towards Efficient Convolutional Neural Network for Embedded Hardware via Multi-Dimensional Pruning", "Bringing AI to edge: From deep learning\u2019s perspective", "Edgenas: Discovering efficient neural architectures for edge systems", "You only search once: on lightweight differentiable architecture search for resource-constrained embedded platforms", "Analyzing GEDF Scheduling for Parallel Real-Time Tasks with Arbitrary Deadlines", "SurgeNAS: a comprehensive surgery on hardware-aware differentiable neural architecture search", "Collate: Collaborative Neural Network Learning for Latency-Critical Edge Systems", "LightNAS: On Lightweight and Scalable Neural Architecture Search for Embedded Platforms", "CASS: Criticality-Aware Standby-Sparing for real-time systems", "EDLAB: A benchmark for edge deep learning accelerators", "On Hardware-Aware Design and Optimization of Edge Intelligence", "HACScale: Hardware-Aware Compound Scaling for Resource-Efficient DNNs", "Work-in-Progress: What to Expect of Early Training Statistics? An Investigation on Hardware-Aware Neural Architecture Search", "HSCoNAS: Hardware-software co-design of efficient dnns via neural architecture search", "ZeroBN: Learning Compact Neural Networks For Latency-Critical Edge Systems", "Smart Scissor: Coupling Spatial Redundancy Reduction and CNN Compression for Embedded Hardware", "MUGNoC: A Software-Configured Multicast-Unicast-Gather NoC for Accelerating CNN Dataflows", "Crossbar-Aligned & Integer-Only Neural Network Compression for Efficient in-Memory Acceleration", "Partial order based non-preemptive communication scheduling towards real-time networks-on-chip", "EdgeCompress: Coupling Multi-Dimensional Model Compression and Dynamic Inference for EdgeAI", "CARTAD: Compiler-Assisted Reinforcement Learning for Thermal-Aware Task Scheduling and DVFS on Multicores", "Designing Efficient DNNs via Hardware-Aware Neural Architecture Search and Beyond", "Real-Time Scheduling of DAG Tasks with Arbitrary Deadlines", "A torus-based hierarchical optical-electronic network-on-chip for multiprocessor system-on-chip", "UNION: A Unified Inter/Intrachip Optical Network for Chip Multiprocessors", "Formal worst-case analysis of crosstalk noise in mesh-based optical networks-on-chip", "On-chip sensor networks for soft-error tolerant real-time multiprocessor systems-on-chip", "3-D mesh-based optical network-on-chip for multiprocessor system-on-chip", "System-level modeling and analysis of thermal effects in optical networks-on-chip", "Thermal analysis for 3D optical network-on-chip based on a novel low-cost 6\u00d7 6 optical router", "A Hardware-Software Collaborated Method for Soft-Error Tolerant MPSoC", "Modeling and analysis of thermal effects in optical networks-on-chip", "A novel low-waveguide-crossing floorplan for fat tree based optical networks-on-chip", "A NoC Traffic Suite Based on Real Applications", "Crosstalk noise and bit error rate analysis for optical network-on-chip", "Formal worst-case analysis of crosstalk noise in mesh-based optical networks-on-chip", "On-chip sensor networks for soft-error tolerant real-time multiprocessor systems-on-chip", "3-D mesh-based optical network-on-chip for multiprocessor system-on-chip", "System-level modeling and analysis of thermal effects in optical networks-on-chip", "Thermal analysis for 3D optical network-on-chip based on a novel low-cost 6\u00d7 6 optical router", "Modeling and analysis of thermal effects in optical networks-on-chip", "A Hardware-Software Collaborated Method for Soft-Error Tolerant MPSoC", "A novel low-waveguide-crossing floorplan for fat tree based optical networks-on-chip", "A NoC Traffic Suite Based on Real Applications", "A systematic network-on-chip traffic modeling and generation methodology", "EMNAPE: Efficient Multi-Dimensional Neural Architecture Pruning for EdgeAI", "Latency-constrained DNN architecture learning for edge systems using zerorized batch normalization", "EDLAB: A benchmark for edge deep learning accelerators", "On Hardware-Aware Design and Optimization of Edge Intelligence", "HACScale: Hardware-Aware Compound Scaling for Resource-Efficient DNNs", "CRIMP: Compact & Reliable DNN Inference on In-Memory Processing via Crossbar-Aligned Compression and Non-ideality Adaptation", "Work-in-Progress: What to Expect of Early Training Statistics? An Investigation on Hardware-Aware Neural Architecture Search", "Towards Efficient Convolutional Neural Network for Embedded Hardware via Multi-Dimensional Pruning", "Bringing AI to edge: From deep learning\u2019s perspective", "Edgenas: Discovering efficient neural architectures for edge systems", "Designing Efficient DNNs via Hardware-Aware Neural Architecture Search and Beyond", "SurgeNAS: a comprehensive surgery on hardware-aware differentiable neural architecture search", "You only search once: on lightweight differentiable architecture search for resource-constrained embedded platforms", "Collate: Collaborative Neural Network Learning for Latency-Critical Edge Systems", "LightNAS: On Lightweight and Scalable Neural Architecture Search for Embedded Platforms", "Smart Scissor: Coupling Spatial Redundancy Reduction and CNN Compression for Embedded Hardware", "EdgeCompress: Coupling Multi-Dimensional Model Compression and Dynamic Inference for EdgeAI", "Taijinet: Towards partial binarized convolutional neural network for embedded systems", "nCode: Limiting harmful writes to emerging mobile NVRAM through code swapping", "Wear-aware Memory Management Scheme for Balancing Lifetime and Performance of Multiple NVM Slots", "Contention-aware task and communication co-scheduling for network-on-chip based multiprocessor system-on-chip", "Routing in optical network-on-chip: minimizing contention with guaranteed thermal reliability", "Hardware/Software Adaptive Cryptographic Acceleration for Big Data Processing", "DR. Swap: Energy-efficient paging for smartphones", "Towards Fast and Lightweight Checkpointing for Mobile Virtualization Using NVRAM", "An improved thermal model for static optimization of application mapping and scheduling in multiprocessor system-on-chip", "Realistic Task Parallelization of the H. 264 Decoding Algorithm for Multiprocessors", "Traffic-aware application mapping for network-on-chip based multiprocessor system-on-chip", "Enhancing lifetime of NVM-based main memory with bit shifting and flipping", "Building high-performance smartphones via non-volatile memory: The swap approach", "EMNAPE: Efficient Multi-Dimensional Neural Architecture Pruning for EdgeAI", "Latency-constrained DNN architecture learning for edge systems using zerorized batch normalization", "Towards Efficient Convolutional Neural Network for Embedded Hardware via Multi-Dimensional Pruning", "You only search once: on lightweight differentiable architecture search for resource-constrained embedded platforms", "Collate: Collaborative Neural Network Learning for Latency-Critical Edge Systems", "SurgeNAS: a comprehensive surgery on hardware-aware differentiable neural architecture search", "LightNAS: On Lightweight and Scalable Neural Architecture Search for Embedded Platforms", "EDLAB: A benchmark for edge deep learning accelerators", "On Hardware-Aware Design and Optimization of Edge Intelligence", "Work-in-Progress: What to Expect of Early Training Statistics? An Investigation on Hardware-Aware Neural Architecture Search", "EvoLP: Self-Evolving Latency Predictor for Model Compression in Real-Time Edge Systems", "HSCoNAS: Hardware-software co-design of efficient dnns via neural architecture search", "ZeroBN: Learning Compact Neural Networks For Latency-Critical Edge Systems", "An Efficient Gustavson-based Sparse Matrix-matrix Multiplication Accelerator on Embedded FPGAs", "Smart Scissor: Coupling Spatial Redundancy Reduction and CNN Compression for Embedded Hardware", "MUGNoC: A Software-Configured Multicast-Unicast-Gather NoC for Accelerating CNN Dataflows", "LAMP: Load-Balanced Multipath Parallel Transmission in Point-to-Point NoCs", "Crossbar-Aligned & Integer-Only Neural Network Compression for Efficient in-Memory Acceleration", "EdgeCompress: Coupling Multi-Dimensional Model Compression and Dynamic Inference for EdgeAI", "CRIMP: Compact & Reliable DNN Inference on In-Memory Processing via Crossbar-Aligned Compression and Non-ideality Adaptation", "Designing Efficient DNNs via Hardware-Aware Neural Architecture Search and Beyond", "iMAT: Energy-Efficient In-Memory Acceleration for Ternary Neural Networks With Sparse Dot Product", "Co-exploring neural architecture and network-on-chip design for real-time artificial intelligence", "Hardware-software collaboration for dark silicon heterogeneous many-core systems", "Application mapping and scheduling for network-on-chip-based multiprocessor system-on-chip with fine-grain communication optimization", "Fotonoc: A folded torus-like network-on-chip based many-core systems-on-chip in the dark silicon era", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "An improved thermal model for static optimization of application mapping and scheduling in multiprocessor system-on-chip", "Isolation of Physical and Logical Views of Dark-Silicon Many-Core Systems for Reliability and Performance Co-Optimization", "Traffic-aware application mapping for network-on-chip based multiprocessor system-on-chip", "Contention-aware task and communication co-scheduling for network-on-chip based multiprocessor system-on-chip", "Communication optimization for thermal reliable many-core systems: work-in-progress", "Parallel Multipath Transmission for Burst Traffic Optimization in Point-to-Point NoCs", "MUGNoC: A Software-Configured Multicast-Unicast-Gather NoC for Accelerating CNN Dataflows", "Reduced Worst-Case Communication Latency Using Single-Cycle Multihop Traversal Network-on-Chip", "EDLAB: A benchmark for edge deep learning accelerators", "LAMP: Load-Balanced Multipath Parallel Transmission in Point-to-Point NoCs", "Contention minimization in emerging smart NoC via direct and indirect routes", "Work-in-Progress: What to Expect of Early Training Statistics? An Investigation on Hardware-Aware Neural Architecture Search", "Crossbar-Aligned & Integer-Only Neural Network Compression for Efficient in-Memory Acceleration", "You only search once: on lightweight differentiable architecture search for resource-constrained embedded platforms", "Partial order based non-preemptive communication scheduling towards real-time networks-on-chip", "Designing Efficient DNNs via Hardware-Aware Neural Architecture Search and Beyond", "SurgeNAS: a comprehensive surgery on hardware-aware differentiable neural architecture search", "MARCO: A High-performance Task Mapping and Routing Co-optimization Framework for Point-to-Point NoC-based Heterogeneous Computing Systems", "O-Star: An Optical Switching Architecture Featuring Mode and Wavelength-Division Multiplexing for On-Chip Many-Core Systems", "LightNAS: On Lightweight and Scalable Neural Architecture Search for Embedded Platforms", "ArSMART: An Improved SMART NoC Design Supporting Arbitrary-Turn Transmission", "Efficient SAT-based application mapping and scheduling on multiprocessor systems for throughput maximization", "Improved schedulability analysis of edf scheduling on reconfigurable hardware devices", "Efficient SAT-based mapping and scheduling of homogeneous synchronous dataflow graphs for throughput optimization", "Efficient algorithms for 2D area management and online task placement on runtime reconfigurable FPGAs", "Toward Minimum WCRT Bound for DAG Tasks Under Prioritized List Scheduling Algorithms", "An efficient algorithm for online soft real-time task placement on reconfigurable hardware devices", "Satisfiability modulo graph theory for task mapping and scheduling on multiprocessor systems", "Efficient Software Synthesis for Dynamic Single Appearance Scheduling of Synchronous Dataflow", "An efficient technique for analysis of minimal buffer requirements of synchronous dataflow graphs with model checking", "Fault-tolerant routing mechanism in 3D optical network-on-chip based on node reuse", "Person re-identification via pose-aware multi-semantic learning", "TAB: Unified and Optimized Ternary, Binary, and Mixed-precision Neural Network Inference on the Edge", "XOR-Net: An Efficient Computation Pipeline for Binary Neural Network Inference on Edge Devices", "Contention-Aware Routing for Thermal-Reliable Optical Networks-on-Chip", "ArSMART: An Improved SMART NoC Design Supporting Arbitrary-Turn Transmission", "A case study of on-chip sensor network in multiprocessor system-on-chip", "A Hardware-Software Collaborated Method for Soft-Error Tolerant MPSoC", "On-line mpsoc scheduling considering power gating induced power/ground noise", "An efficient technique for analysis of minimal buffer requirements of synchronous dataflow graphs with model checking", "Power Gating Aware Task Scheduling in MPSoC", "nCode: Limiting harmful writes to emerging mobile NVRAM through code swapping", "DR. Swap: Energy-efficient paging for smartphones", "Towards Fast and Lightweight Checkpointing for Mobile Virtualization Using NVRAM", "Enhancing lifetime of NVM-based main memory with bit shifting and flipping", "Building high-performance smartphones via non-volatile memory: The swap approach", "Leaking your engine speed by spectrum analysis of real-Time scheduling sequences", "Revisiting gpc and and connector in real-time calculus", "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit", "On the Analysis of Parallel Real-Time Tasks with Spin Locks", "Solving dynamic multiobjective problem via autoencoding evolutionary search", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "TripImputor: real-time imputing taxi trip purpose leveraging multi-sourced urban data", "Leaking your engine speed by spectrum analysis of real-Time scheduling sequences", "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit", "Efficient drone hijacking detection using onboard motion sensors", "Efficient SAT-based mapping and scheduling of homogeneous synchronous dataflow graphs for throughput optimization", "Optimized Data Reuse via Reordering for Sparse Matrix-Vector Multiplication on FPGAs", "MUGNoC: A Software-Configured Multicast-Unicast-Gather NoC for Accelerating CNN Dataflows", "Reduced Worst-Case Communication Latency Using Single-Cycle Multihop Traversal Network-on-Chip", "EDLAB: A benchmark for edge deep learning accelerators", "iMAD: An In-Memory Accelerator for AdderNet with Efficient 8-bit Addition and Subtraction Operations", "Partial order based non-preemptive communication scheduling towards real-time networks-on-chip", "MARCO: A High-performance Task Mapping and Routing Co-optimization Framework for Point-to-Point NoC-based Heterogeneous Computing Systems", "Accelerating Gustavson-based SpMM on Embedded FPGAs with Element-wise Parallelism and Access Pattern-aware Caches", "An Efficient Gustavson-based Sparse Matrix-matrix Multiplication Accelerator on Embedded FPGAs", "LightBulb: A Photonic-Nonvolatile-Memory-based Accelerator for Binarized Convolutional Neural Networks", "MindReading: An Ultra-Low-Power Photonic Accelerator for EEG-based Human Intention Recognition", "HolyLight: A Nanophotonic Accelerator for Deep Learning in Data Centers", "Thermal Sensing Using Micro-ring Resonators in Optical Network-on-Chip", "Hardware-software collaboration for dark silicon heterogeneous many-core systems", "TripImputor: real-time imputing taxi trip purpose leveraging multi-sourced urban data", "Chip temperature optimization for dark silicon many-core systems", "LightBulb: A Photonic-Nonvolatile-Memory-based Accelerator for Binarized Convolutional Neural Networks", "MindReading: An Ultra-Low-Power Photonic Accelerator for EEG-based Human Intention Recognition", "HolyLight: A Nanophotonic Accelerator for Deep Learning in Data Centers", "Parallel Multipath Transmission for Burst Traffic Optimization in Point-to-Point NoCs", "XOR-Net: An Efficient Computation Pipeline for Binary Neural Network Inference on Edge Devices", "EDLAB: A benchmark for edge deep learning accelerators", "iMAD: An In-Memory Accelerator for AdderNet with Efficient 8-bit Addition and Subtraction Operations", "iMAT: Energy-Efficient In-Memory Acceleration for Ternary Neural Networks With Sparse Dot Product", "TAB: Unified and Optimized Ternary, Binary, and Mixed-precision Neural Network Inference on the Edge", "HolyLight: A Nanophotonic Accelerator for Deep Learning in Data Centers", "MindReading: An Ultra-Low-Power Photonic Accelerator for EEG-based Human Intention Recognition", "Fine-Grained Task-Level Parallel and Low Power H. 264 Decoding in Multi-Core Systems", "On-Chip Sensor Network for Efficient Management of Power Gating-Induced Power/Ground Noise in Multiprocessor System on Chip", "Power Gating Aware Task Scheduling in MPSoC", "On-line mpsoc scheduling considering power gating induced power/ground noise", "A case study of on-chip sensor network in multiprocessor system-on-chip", "WDM-MDM Silicon-Based Optical Switching for Data Center Networks", "Fault-tolerant routing mechanism in 3D optical network-on-chip based on node reuse", "O-Star: An Optical Switching Architecture Featuring Mode and Wavelength-Division Multiplexing for On-Chip Many-Core Systems", "Work-in-Progress: Response Time Bounds for Typed DAG Parallel Tasks on Heterogeneous Multi-cores", "Timing-Anomaly Free Dynamic Scheduling of Conditional DAG Tasks on Multi-Core Systems", "Response time bounds for typed dag parallel tasks on heterogeneous multi-cores", "A Systematic and Realistic Network-on-Chip Traffic Modeling and Generation Technique for Emerging Many-Core Systems", "A case study on the communication and computation behaviors of real applications in NoC-based MPSoCs", "A systematic network-on-chip traffic modeling and generation methodology", "A Systematic and Realistic Network-on-Chip Traffic Modeling and Generation Technique for Emerging Many-Core Systems", "A case study on the communication and computation behaviors of real applications in NoC-based MPSoCs", "A systematic network-on-chip traffic modeling and generation methodology", "A Systematic and Realistic Network-on-Chip Traffic Modeling and Generation Technique for Emerging Many-Core Systems", "A case study on the communication and computation behaviors of real applications in NoC-based MPSoCs", "A systematic network-on-chip traffic modeling and generation methodology", "DR. Swap: Energy-efficient paging for smartphones", "Building high-performance smartphones via non-volatile memory: The swap approach", "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit", "Efficient drone hijacking detection using onboard motion sensors", "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit", "Efficient drone hijacking detection using onboard motion sensors", "Efficient algorithms for 2D area management and online task placement on runtime reconfigurable FPGAs", "Efficient SAT-based mapping and scheduling of homogeneous synchronous dataflow graphs for throughput optimization", "Crosstalk noise and bit error rate analysis for optical network-on-chip", "Towards Fast and Lightweight Checkpointing for Mobile Virtualization Using NVRAM", "Building high-performance smartphones via non-volatile memory: The swap approach", "Toward Minimum WCRT Bound for DAG Tasks Under Prioritized List Scheduling Algorithms", "Work-in-Progress: Response Time Bounds for Typed DAG Parallel Tasks on Heterogeneous Multi-cores", "Response time bounds for typed dag parallel tasks on heterogeneous multi-cores", "Thermal-Aware Task Mapping on Dynamically Reconfigurable Network-on-Chip Based Multiprocessor System-on-Chip", "Optimal application mapping and scheduling for network-on-chips with computation in STT-RAM based router", "HolyLight: A Nanophotonic Accelerator for Deep Learning in Data Centers", "Coroutine-Based Synthesis of Efficient Embedded Software From SystemC Models", "Efficient algorithms for 2D area management and online task placement on runtime reconfigurable FPGAs", "An efficient algorithm for online soft real-time task placement on reconfigurable hardware devices", "A torus-based hierarchical optical-electronic network-on-chip for multiprocessor system-on-chip", "UNION: A Unified Inter/Intrachip Optical Network for Chip Multiprocessors", "Formal worst-case analysis of crosstalk noise in mesh-based optical networks-on-chip", "Satisfiability modulo graph theory for task mapping and scheduling on multiprocessor systems", "A hierarchical hybrid optical-electronic network-on-chip", "Modeling and analysis of thermal effects in optical networks-on-chip", "System-level modeling and analysis of thermal effects in optical networks-on-chip", "A NoC Traffic Suite Based on Real Applications", "Crosstalk noise and bit error rate analysis for optical network-on-chip", "nCode: Limiting harmful writes to emerging mobile NVRAM through code swapping", "Contention-aware task and communication co-scheduling for network-on-chip based multiprocessor system-on-chip", "Realistic Task Parallelization of the H. 264 Decoding Algorithm for Multiprocessors", "User experience enhanced task scheduling and processor frequency scaling for energy-sensitive mobile devices"], "link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:12oLulcdP1kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:S_0nULq340kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w2v21TepJGQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:B4wWq2ztVNgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:yHoQYHXJRqAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ent5SSDJ8eoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wsYPZf_qF0UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:GKX6TSFDq9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:nFloTcPoiwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:CgSwehex2-EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TLwS_1sUIYkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:RiW20FJDrgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Jxy3h8XkNu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:HklM7qHXWrUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:END1nS_e-6cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Yeq4f8IuGg4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:teyi7TG2FwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cdM53WF7QocC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:EvHYAMKeY9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4ZjPyBmb-CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:2yHMXrjStuAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:eNpUmiHIC2gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:RjbMpExGKWAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:RDd164uRGEsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:7E1sdDGsGRMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0nST21YUXoUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:327GGIiaIgIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:1UYbAEPjJNAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TmI2AlsRohcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ic8hN12bw4QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:3eo-xq64HD0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:sduUCncrepAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:PBekU-LVBrQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UWSlATeI89AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:U5I91ptAnUUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:QuPaituDtm8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:fkjBimb5U_kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:x3zuONe3eqIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oFWWKr2Zb18C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:MdMr--dQ_pMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WeWrUA-9SBMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:aUNTuf31cPIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0wD49__q8KEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:I6TX2FUo6loC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:UlSRQUDYeUMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TKVID9p7UpsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:ZD92IwzDgOkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:hN_26_r6h7cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Yeq4f8IuGg4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ULSBFf147LAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:B_SudGh4-BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cUWptXWc3MAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4ZjPyBmb-CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:eNpUmiHIC2gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:7E1sdDGsGRMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:RDd164uRGEsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:utCHnwRdBgEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0nST21YUXoUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NXjrwPNzFTMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:CRQ797xmLJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Fv7Qhv_DOnIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:62L9AWR-SnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7-gQGTwtAzQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:sduUCncrepAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w1G5vK4DiEkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4I90hQsHr_gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:TKTY8N1AUUAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:PBekU-LVBrQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:IxBLoz_EsGYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:QuPaituDtm8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:x3zuONe3eqIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:MdMr--dQ_pMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:n3sXDxCj2GoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ZXswLDrTefgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7DTIKO_nxaIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WeWrUA-9SBMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:aUNTuf31cPIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:RaRNlNDkcy8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:12oLulcdP1kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:4w9WtRFcIoYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:S_0nULq340kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w2v21TepJGQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:B4wWq2ztVNgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:CgSwehex2-EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:8s_vhd3wPlUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:RiW20FJDrgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TdcqFaaFpGIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Jxy3h8XkNu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:HklM7qHXWrUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:hN_26_r6h7cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ULSBFf147LAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:B_SudGh4-BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cUWptXWc3MAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4ZjPyBmb-CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:eNpUmiHIC2gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:7E1sdDGsGRMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:rGOK5rmJZT0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:RDd164uRGEsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:utCHnwRdBgEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0nST21YUXoUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NXjrwPNzFTMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Fv7Qhv_DOnIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:62L9AWR-SnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TmI2AlsRohcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w1G5vK4DiEkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ib87rSy7x5MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:PBekU-LVBrQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:x3zuONe3eqIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:MdMr--dQ_pMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:n3sXDxCj2GoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ZXswLDrTefgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WeWrUA-9SBMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4G0aqHQeUQIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:UlSRQUDYeUMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:w9EjUEod0xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Uwzdpet-joYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:STWYWLtSq6gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VBbLNo9YSJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:tVg3zZbtnc0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:bGIpCNGh66kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:qfTKKVVEecAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:teyi7TG2FwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:SpbQ_efOBbkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:jKffii5DqX8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:T64LSalLz9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wlh7PBhwZ8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:EpUiTTZsFn8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:prKdS1S5QkMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WgBxaE7EUScC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ItgTnG0mAXQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zI9YInTrFVIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oKUQpTv76aEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uwWlEQcBbEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:FjmlLC3huY4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:3eo-xq64HD0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:QDEWnZBrHwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:FP-YCU5gdjEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yG6gRY0c4kQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:0wD49__q8KEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:4w9WtRFcIoYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:S_0nULq340kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w2v21TepJGQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Jxy3h8XkNu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:RiW20FJDrgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:B4wWq2ztVNgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:CgSwehex2-EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:S_0nULq340kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w2v21TepJGQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Jxy3h8XkNu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:RiW20FJDrgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:B4wWq2ztVNgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:CgSwehex2-EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ent5SSDJ8eoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Uwzdpet-joYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:STWYWLtSq6gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:EpUiTTZsFn8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:prKdS1S5QkMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:6biGW3np0psC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WgBxaE7EUScC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VBbLNo9YSJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:tVg3zZbtnc0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:bGIpCNGh66kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yG6gRY0c4kQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:SpbQ_efOBbkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:qfTKKVVEecAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:jKffii5DqX8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:T64LSalLz9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oKUQpTv76aEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:QDEWnZBrHwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:OkCShBBh3G8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:-EqDysdaREAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:ClN-LZ0IzgkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4G0aqHQeUQIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:7E1sdDGsGRMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:g4gGp8M7V98C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:h-OLoDDdPfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uPwIINvFgpoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ib87rSy7x5MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:LNbnizmRdgkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Fv7Qhv_DOnIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:rhSvDnGaX0QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:SsmmYIE5d0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Uwzdpet-joYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:STWYWLtSq6gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VBbLNo9YSJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:qfTKKVVEecAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:jKffii5DqX8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:SpbQ_efOBbkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:T64LSalLz9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:EpUiTTZsFn8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WgBxaE7EUScC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VyewGSb6xwwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ItgTnG0mAXQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zI9YInTrFVIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VJOaslTFpLQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:oKUQpTv76aEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uwWlEQcBbEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7rVtnTjEZJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:FjmlLC3huY4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:QDEWnZBrHwAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:6biGW3np0psC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yG6gRY0c4kQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Nw5Pwe77XXAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:rGOK5rmJZT0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ULSBFf147LAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:utCHnwRdBgEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:n3sXDxCj2GoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ib87rSy7x5MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NXjrwPNzFTMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Fv7Qhv_DOnIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4G0aqHQeUQIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:UlSRQUDYeUMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uENYxwZKF5gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uwWlEQcBbEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4ZjPyBmb-CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:7rVtnTjEZJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Yeq4f8IuGg4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:WgBxaE7EUScC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:FjmlLC3huY4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:qfTKKVVEecAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:3eo-xq64HD0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yG6gRY0c4kQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:SpbQ_efOBbkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:V0QqM0Py3VsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ZjmTu7HDCaEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:T64LSalLz9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:X8aq8RHJ9bUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:m7gEShFDljgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:btULBOGQ_gcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:yHoQYHXJRqAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:cFcI8uaobsAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:IjbvboqL_eAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:-e1qr6N6M9MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:spwacExez6wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cUWptXWc3MAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:X8aq8RHJ9bUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:-EqDysdaREAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:h-OLoDDdPfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uPwIINvFgpoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:rhSvDnGaX0QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:SsmmYIE5d0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UWSlATeI89AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:fkjBimb5U_kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:I6TX2FUo6loC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TKVID9p7UpsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:eIWZJKaDF6kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:KvGcghnThk8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:UWSlATeI89AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:I6TX2FUo6loC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:2yHMXrjStuAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:w9EjUEod0xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uwWlEQcBbEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4ZjPyBmb-CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NAkivslCrNUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:3eo-xq64HD0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:V0QqM0Py3VsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Dq1jD5C1HUoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:VJOaslTFpLQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:NYu48kWxaQAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yRL2jD08WzAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:5n9gSBKMxCsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:QuPaituDtm8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ULSBFf147LAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:KvGcghnThk8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:62L9AWR-SnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:NYu48kWxaQAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yRL2jD08WzAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:5n9gSBKMxCsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uENYxwZKF5gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:spwacExez6wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:66S1BDY1aroC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:NAkivslCrNUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:Nw5Pwe77XXAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:-e1qr6N6M9MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:5n9gSBKMxCsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:yRL2jD08WzAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:w1G5vK4DiEkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TLwS_1sUIYkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:uwohsRgU7yoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:cFcI8uaobsAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ZjmTu7HDCaEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:327GGIiaIgIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:cdM53WF7QocC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ic8hN12bw4QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wsYPZf_qF0UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:GKX6TSFDq9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ent5SSDJ8eoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wsYPZf_qF0UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:GKX6TSFDq9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ent5SSDJ8eoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:wsYPZf_qF0UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:GKX6TSFDq9oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ent5SSDJ8eoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:h-OLoDDdPfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:SsmmYIE5d0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:I6TX2FUo6loC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:2yHMXrjStuAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:I6TX2FUo6loC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:2yHMXrjStuAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:uPwIINvFgpoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:SsmmYIE5d0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:btULBOGQ_gcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:327GGIiaIgIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:ic8hN12bw4QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:5mL_tC_eHSoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:TmI2AlsRohcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:5n9gSBKMxCsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:HklM7qHXWrUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:4w9WtRFcIoYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:S_0nULq340kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:RiW20FJDrgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&citation_for_view=UozjxW8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:-EqDysdaREAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=20&pagesize=80&citation_for_view=UozjxW8AAAAJ:4G0aqHQeUQIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:LNbnizmRdgkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UozjxW8AAAAJ&cstart=100&pagesize=100&citation_for_view=UozjxW8AAAAJ:zLla2nKXDtwC"]}, "published_by_year": {"Year": ["2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Publications": [1, 2, 1, 5, 5, 4, 6, 3, 10, 8, 6, 11, 17, 20, 19, 17, 12, 16, 1]}, "citations_by_year": {"Year": ["2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Citations": [0, 4, 6, 9, 18, 35, 69, 95, 132, 126, 196, 210, 207, 246, 284, 365, 376, 356, 9]}, "all_time_h_index": 30, "all_time_i10_index": 65, "all_time_i20_index": 37, "h_index_by_year": {"Year": [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [0, 1, 2, 2, 4, 5, 7, 9, 11, 14, 14, 16, 18, 20, 21, 23, 26, 30]}, "h_index_by_publication_year": {"Publication Year": [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [1, 2, 1, 4, 5, 3, 5, 2, 7, 4, 5, 7, 7, 11, 9, 6, 3, 1]}, "avg_citations_by_publication_year": {"Publication Year": [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "Avg Citations per Publication": [6.0, 21.0, 60.0, 12.2, 74.2, 45.25, 42.5, 43.333333333333336, 25.1, 5.625, 13.833333333333334, 15.636363636363637, 18.529411764705884, 16.55, 12.789473684210526, 8.882352941176471, 2.6666666666666665, 0.3125]}, "h_index_by_years_from_publication_year": {"Publication Year": [2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2021, 2021, 2021, 2022, 2022, 2023], "Year": [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2018, 2019, 2020, 2021, 2022, 2023, 2019, 2020, 2021, 2022, 2023, 2020, 2021, 2022, 2023, 2021, 2022, 2023, 2022, 2023, 2023], "h-index": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 5, 5, 6, 6, 6, 7, 7, 7, 0, 2, 3, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 5, 5, 5, 5, 3, 4, 5, 6, 6, 6, 7, 2, 4, 5, 7, 7, 7, 2, 5, 8, 10, 11, 2, 5, 7, 9, 3, 5, 6, 2, 3, 1]}}