{"full_name": "Guan Cuntai", "email": "ctguan@ntu.edu.sg", "google_scholar": "https://scholar.google.com/citations?hl=en&user=sg4vxPoAAAAJ", "dr_ntu": "https://dr.ntu.edu.sg/cris/rp/rp01023", "designation": "Professor, School of Computer Science and Engineering", "image_path": "./profile_img/guan_cuntai.jpg", "biography": "Prof Guan is a President's Chair Professor in Computer Science and Engineering at Nanyang Technological University (NTU), Singapore. He is the Director of the Artificial Intelligence Research Institute (AI.R) of NTU. He is the Co-Director, S-Lab for Advanced Intelligence (S-Lab), NTU. He is the Director of the Centre for Brain-Computing Research (CBCR). He initiated and served as the Co-Director of the Rehabilitation Research Institute of Singapore (RRIS), 2015-2018. Prior to joining NTU in 2016, he was the founding Department Head of the Neural & Biomedical Technology Department at the Institute for Infocomm Research (I2R), Agency for Science, Technology, and Research (A*SATR), Singapore.  His research interests are in the fields of Brain-Computer Interfaces (BCI), Machine Learning, Neural Signal & Image Processing, Data Analytics, and Artificial Intelligence. He published 400 refereed journal and conference papers and holds 25 granted patents and patent applications. He licensed 15 patents/technologies to five companies in Singapore and USA. He delivered more than 70 keynote speeches and invited talks (including the keynote, Brain-Computer Interfaces for Stroke Rehabilitation, at the opening ceremony of the 7th International BCI Meeting, Asilomar, USA, May 2018). He is a recipient of the Annual BCI Research Award, the King Salman Award for Disability Research, the IES Prestigious Engineering Achievement Award, the Achiever of the Year (Research) Award, the Finalist of the President Technology Award, and the winner of BCI Competitions. He has been an Associate Editor for IEEE Transactions on Biomedical Engineering, IEEE Transactions on Artificial Intelligence, Pattern Recognition, Neurocomputing, Brain-Computer Interfaces, Frontiers in Neuroscience, Frontiers in Human Neuroscience, etc. He is on the Advisory Board of IEEE Open Access Journal of Engineering in Medicine and Biology (OJEMB). He was on the IEEE Fellow Evaluation Committee for EMBS Society. He was an APSIPA Distinguished Lecturer, 2017-2018.  He served as the General Co-Chair for IEEE ICAA\u20192018, Conference Chair for the Internet of Things (IoT) Asia 2015, and General Chair for the IEEE HealthCom 2008. He was the President of the Pattern Recognition and Machine Intelligence Association (PREMIA), Singapore, 2008-2010.He is an elected Fellow of the Singapore Academy of Engineering (SAEng), Fellow of NAI (National Academy of Inventors, USA), Fellow of IEEE (the Institute of Electrical and Electronics Engineers), and Fellow of AIMBE (the American Institute for Medical and Biological Engineering).", "orcid": null, "other_websites": ["https://personal.ntu.edu.sg/ctguan"], "bachelor_degree": null, "masters": null, "phd": null, "name": "Guan Cuntai", "id": "rp01023", "publications": {"Publication Year": ["2008", "2021", "2010", "2012", "2007", "2015", "2010", "2018", "2011", "2007", "2006", "2010", "2007", "2014", "2008", "2011", "2010", "2009", "2010", "2013", "2019", "2020", "2013", "2012", "2021", "2015", "2017", "2004", "2008", "2020", "2012", "2019", "2009", "2010", "2021", "2006", "2021", "2009", "2014", "2015", "2013", "2015", "2015", "2014", "2013", "2020", "2009", "2021", "2020", "2013", "2013", "2009", "2009", "2013", "2012", "2020", "2010", "2020", "2006", "2015", "2020", "2012", "2010", "2009", "2004", "2010", "2020", "2011", "2013", "2013", "2007", "2022", "2017", "2018", "2009", "2019", "2008", "2013", "2020", "2019", "2013", "2013", "2019", "2011", "2022", "2021", "2019", "2022", "2014", "2017", "2013", "2021", "2020", "2012", "2010", "2015", "2008", "2008", "2021", "2006", "2019", "2016", "2013", "2017", "2014", "2008", "2019", "2015", "2020", "2011", "2009", "2017", "2011", "2021", "2002", "2015", "2014", "2013", "2011", "2007", "2006", "2018", "2012", "2005", "2016", "2010", "2008", "2022", "2021", "2017", "2014", "2012", "2009", "2022", "2020", "2015", "2012", "2018", "2018", "2013", "2011", "2007", "2021", "2018", "2014", "2012", "2008", "2021", "2017", "2010", "2010", "2021", "2018", "2015", "2008", "2021", "2012", "2006", "2020", "2019", "2016", "2011", "2011", "2010", "2006", "2023", "2022", "2022", "2021", "2021", "2018", "2016", "2015", "2012", "2012", "2011", "2006", "2014", "2013", "2012", "2019", "2019", "2019", "2015", "2014", "2012", "2020", "2017", "2012", "2010", "2008", "2018", "2017", "2013", "2012", "2010", "2009", "2002", "2022", "2017", "2014", "2013", "2012", "2011", "2008", "2008", "2004", "2023", "2020", "2020", "2020", "2017", "2014", "2014", "2013", "2008", "2006", "2021", "2021", "2020", "2014", "2012", "2022", "2022", "2019", "2013", "2009", "2023", "2022", "2019", "2016", "2016", "2015", "2015", "2013", "2011", "2010", "2010", "2006", "2006", "2006", "2006", "1993", "2019", "2018", "2015", "2013", "2013", "2007"], "Title": ["Filter bank common spatial pattern (FBCSP) in brain-computer interface", "A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI", "Regularizing common spatial patterns to improve BCI designs: unified theory and new algorithms", "Filter bank common spatial pattern algorithm on BCI competition iv datasets 2a and 2b", "Temporal classification of multichannel near-infrared spectroscopy signals of motor imagery for developing a brain\u2013computer interface", "A randomized controlled trial of EEG-based motor imagery brain-computer interface robotic rehabilitation for stroke", "A brain controlled wheelchair to navigate in familiar environments", "Learning Temporal Information for Brain-Computer Interface using Convolutional Neural Networks", "Optimizing the channel selection and classification accuracy in EEG-based BCI", "Sub-band common spatial pattern (SBCSP) for brain-computer interface", "Robust classification of EEG signal for brain-computer interface", "An EEG-based BCI system for 2-D cursor control by combining Mu/Beta rhythm and P300 potential", "Controlling a wheelchair indoors using thought", "Brain-computer interface-based robotic end effector system for wrist and hand rehabilitation: results of a three-armed randomized controlled trial for chronic stroke", "A self-training semi-supervised SVM algorithm and its application in an EEG-based brain computer interface speller system", "A large clinical study on the ability of stroke patients to use an EEG-based motor imagery brain-computer interface", "Regularized common spatial pattern with aggregation for EEG classification in small-sample setting", "A new discriminative common spatial pattern method for motor imagery brain\u2013computer interfaces", "Clinical study of neurorehabilitation in stroke using EEG-based motor imagery brain-computer interface with robotic feedback", "Resting state changes in functional connectivity correlate with movement recovery for BCI and robot-assisted upper-extremity training after stroke", "A review on EMG-based motor intention prediction of continuous human upper limb motion for human-robot collaboration", "Subject-Independent Brain-Computer Interfaces Based on Deep Convolutional Neural Networks", "Brain-computer interface in stroke rehabilitation", "A Brain-Computer Interface Based Attention Training Program for Treating Attention Deficit Hyperactivity Disorder", "An Attention-based Deep Learning Approach for Sleep Stage Classification with Single-Channel EEG", "On the use of convolutional neural networks and augmented CSP features for multi-class motor imagery of EEG signals classification", "EEG-based Strategies to Detect Motor Imagery for Control and Rehabilitation", "High performance P300 speller for brain-computer interface", "Asynchronous P300-based brain--computer interfaces: A computational approach with statistical models", "BCI for Stroke Rehabilitation: Motor and Beyond", "Mutual information-based selection of optimal spatial\u2013temporal patterns for single-trial EEG-based BCIs", "Inter-subject transfer learning with end-to-end deep convolutional neural network for EEG-based BCI", "A clinical study of motor imagery-based brain-computer interface for upper limb robotic rehabilitation", "Learning from other subjects helps reducing brain-computer interface calibration time", "Time-Series Representation Learning via Temporal and Contextual Contrasting", "A brain-controlled wheelchair based on P300 and path guidance", "Adaptive transfer learning for EEG motor imagery classification with deep Convolutional Neural Network", "Unsupervised brain computer interface based on intersubject information and online adaptation", "Cluster-based Analysis for Personalized Stress Evaluation using Physiological Signals", "Facilitating effects of transcranial direct current stimulation on motor imagery brain-computer interface with robotic feedback for stroke rehabilitation", "Optimizing Spatial Filters by Minimizing-Within-Class Dissimilarities in Electroencephalogram-Based Brain-Computer Interface", "Parallel convolutional-linear neural network for motor imagery classification", "Brain\u2013Computer Interface for Neurorehabilitation of Upper Limb After Stroke", "Hybrid fNIRS-EEG based classification of auditory and visual perception processes", "EEG-based Classification of Fast and Slow Hand Movements Using Wavelet-CSP Algorithm", "Assessment of the Efficacy of EEG-based MI-BCI with Visual Feedback and EEG Correlates of Mental Fatigue for Upper-Limb Stroke Rehabilitation", "Multi-class filter bank common spatial pattern for four-class motor imagery BCI", "Generative Adversarial Networks-Based Data Augmentation for Brain\u2013Computer Interface", "Machine Learning Driven Synthesis of Carbon Dots with Enhanced Quantum Yields", "A brain-computer interface based cognitive training system for healthy elderly: a randomized control pilot study for usability and preliminary efficacy", "eT2FIS: An evolving type-2 neural fuzzy inference system", "Voxel selection in fMRI data analysis based on sparse representation", "Learning EEG-based spectral-spatial patterns for attention level measurement", "EEG Data Space Adaptation to Reduce Intersession Nonstationarity in Brain-Computer Interface", "Asymmetric spatial pattern for EEG-based emotion detection", "Federated Transfer Learning for EEG Signal Classification", "Optimum spatio-spectral filtering network for brain\u2013computer interface", "Decoding Movement-Related Cortical Potentials based on Subject-Dependent and Section-Wise Spectral Filtering", "An extended EM algorithm for joint feature extraction and classification in brain-computer interfaces", "Electrocorticographic Representations of Segmental Features in Continuous Speech", "Brain-computer Interface-based Soft Robotic Glove Rehabilitation for Stroke", "Transcranial direct current stimulation and EEG-based motor imagery BCI for upper limb stroke rehabilitation", "Spatially regularized common spatial patterns for EEG classification", "Comparison of designs towards a subject-independent brain-computer interface based on motor imagery", "High accuracy classification of EEG signal", "Effectiveness of a brain-computer interface based programme for the treatment of ADHD: a pilot study", "A Subject-Transfer Framework based on Single-Trial EMG Analysis using Convolutional Neural Networks", "Brain computer interface based 3D game for attention training and rehabilitation", "Bayesian Learning for Spatial Filtering in an EEG-Based Brain--Computer Interface", "Dynamically weighted ensemble classification for non-stationary EEG processing", "Controlling a wheelchair using a BCI with low information transfer rate", "Spatio-Spectral Feature Representation for Motor Imagery Classification Using Convolutional Neural Networks", "Brain plasticity following MI-BCI training combined with tDCS in a randomized trial in chronic subcortical stroke subjects: a preliminary study", "Brain-computer-interface-based intervention re-normalizes brain functional network topology in children with attention deficit/hyperactivity disorder", "A feasibility study of non-invasive motor-imagery BCI-based robotic rehabilitation for stroke patients", "A closed-loop, music-based brain-computer interface for emotion mediation", "Joint feature re-extraction and classification using an iterative semi-supervised support vector machine algorithm", "Multi-class EEG classification of voluntary hand movement directions", "Machine learning-guided synthesis of advanced inorganic materials", "Prognostic and Monitory EEG-Biomarkers for BCI Upper-limb Stroke Rehabilitation", "Design of an online EEG based neurofeedback game for enhancing attention and memory", "Motor imagery BCI for upper limb stroke rehabilitation: An evaluation of the EEG recordings using coherence analysis", "Large-scale brain functional network topology disruptions underlie symptom heterogeneity in children with attention-deficit/hyperactivity disorder", "SaFIN: A self-adaptive fuzzy inference network", "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification", "Enhancing EEG-Based Classification of Depression Patients using Spatial Information", "A Randomized Controlled Trial of a Brain-Computer Interface based Attention Training Program for ADHD", "TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition", "The predictive role of pre-cue EEG rhythms on MI-based BCI classification performance", "Convolutional neural network-based transfer learning and knowledge distillation using multi-subject data in motor imagery BCI", "Quantifying Limb Movements in Epileptic Seizures through Color-based Video Analysis", "WiFi-Sleep: Sleep Stage Monitoring Using Commodity Wi-Fi Devices", "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "BCI competition IV \u2013 data set I: learning discriminative patterns for self-paced EEG-based motor imagery detection", "A covariate shift minimisation method to alleviate non-stationarity effects for an adaptive brain-computer interface", "A subject-independent pattern-based brain-computer interface", "An adaptive filter bank for motor imagery based brain computer interface", "An EEG-based BCI system for 2D cursor control", "FBCNet: A multi-view convolutional neural network for brain-computer interface", "P300 brain-computer interface design for communication and control applications", "Actigraphy studies and clinical and biobehavioural correlates in schizophrenia: a systematic review", "Facilitating motor imagery-based brain\u2013computer interface for stroke patients using passive movement", "Enhancement of attention and cognitive skills using EEG based neurofeedback game", "Automatic EEG artifact removal techniques by detecting influential independent components", "Detection of variations in cognitive workload using multi-modality physiological sensors and a large margin unbiased regression machine", "A clinical evaluation of non-invasive motor imagery-based brain-computer interface in stroke", "Towards EEG generation using GANs for BCI applications", "Shrinkage estimator based regularization for EEG motor imagery classification", "A Multi-view CNN with Novel Variance Layer for Motor Imagery Brain Computer Interface", "Adaptive tracking of discriminative frequency components in electroencephalograms for a robust brain\u2013computer interface", "An efficient P300-based brain-computer interface with minimal calibration time", "Discriminative Ocular Artifact Correction for Feature Learning in EEG Analysis", "Spatially sparsed common spatial pattern to improve BCI performance", "DSAL: Deeply Supervised Active Learning from Strong and Weak Labelers for Biomedical Image Segmentation", "Multilingual speech recognition with language identification.", "Adaptive estimation of hand movement trajectory in an EEG based brain\u2013computer interface system", "Detection of motor imagery of swallow EEG signals based on the dual-tree complex wavelet transform and adaptive model selection", "Common frequency pattern for music preference identification using frontal EEG", "Filter Bank Common Spatial Pattern (FBCSP) algorithm using online adaptive and semi-supervised learning", "Feature selection based on fisher ratio and mutual information analyses for robust brain computer interface", "Probability estimation for recoverability analysis of blind source separation based on sparse representation", "A novel method of emergency situation detection for a brain-controlled vehicle by combining EEG signals with surrounding information", "A new EC\u2013PC threshold estimation method for in vivo neural spike detection", "Near Infrared Spectroscopy based Brain-Computer Interface", "Independent mobility achieved through a wireless brain-machine interface", "Post-acute stroke patients use brain-computer interface to activate electrical stimulation", "Hybrid P300 and Mu-Beta brain computer interface to operate a brain controlled wheelchair", "Structural and diffusion MRI based schizophrenia classification using 2D pretrained and 3D naive Convolutional Neural Networks", "MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels", "A New Variational Method for Bias Correction and its Applications to Rodent Brain Extraction", "Heart rate estimation from FBG sensors using cepstrum analysis and sensor fusion", "Speaking mode recognition from functional near infrared spectroscopy", "Robust filter bank common spatial pattern (RFBCSP) in motor-imagery-based brain-computer interface", "Quantifying Explainability of Saliency Methods in Deep Neural Networks with a Synthetic Dataset", "Brain MRI-based 3D Convolutional Neural Networks for Classification of Schizophrenia and Controls", "A pilot randomized controlled trial using eeg-based brain\u2013computer interface training for a Chinese-speaking group of healthy elderly", "Robust EEG channel selection across sessions in brain-computer interface involving stroke patients", "Wavlet phase-locking based binary classification of hand movement directions from EEG", "Effectiveness of a Personalized Brain-Computer Interface System for Cognitive Training in Healthy Elderly: A Randomized Controlled Trial", "Improving session-to-session transfer performance of motor imagery-based BCI using adaptive extreme learning machine", "A Wavelet-CSP method to classify hand movement directions in EEG based BCI system", "A self-training semi-supervised support vector machine algorithm and its applications in brain computer interface", "Hierarchical consistency regularized mean teacher for semi-supervised 3d left atrium segmentation", "EEG Source Imaging of Movement Decoding: The State of the Art and Future Directions", "A BCI speller based on SSVEP using high frequency stimuli design", "Dynamic initiation and dual-tree complex wavelet feature-based classification of motor imagery of swallow EEG signals", "A clinical evaluation on the spatial patterns of non-invasive motor imagery-based brain-computer interface in stroke", "Neurorehabilitation from a distance: can intelligent technology support decentralized access to quality therapy?", "EEG source space analysis of the supervised factor analytic approach for the classification of multi-directional arm movement", "Digital signal processing and machine learning", "A brain-computer interface for mental arithmetic task from single-trial near-infrared spectroscopy brain signals", "Machine Learning Driven Synthesis of Few-Layered WTe2 with Geometrical Control", "Robust Nonlinear Causality Analysis of Non-Stationary Multivariate Physiological Time Series", "Device and method for generating a representation of a subject's attention level", "Multiclass voluntary facial expression classification based on filter bank common spatial pattern", "Emerging Trends in BCI-Robotics for Motor Control and Rehabilitation", "Online semi-supervised learning with KL distance weighting for motor imagery-based BCI", "A semi-supervised SVM learning algorithm for joint feature extraction and classification in brain computer interfaces", "Using Transcranial Direct Current Stimulation to Augment the Effect of Motor Imagery-Assisted Brain-Computer Interface Training in Chronic Stroke Patients\u2013Cortical\u00a0\u2026", "EEG representation in deep convolutional neural networks for classification of motor imagery", "Neural and cortical analysis of swallowing and detection of motor imagery of swallow for dysphagia rehabilitation\u2014A review", "Calibrating EEG-based motor imagery brain-computer interface from passive movement", "Artifact removal for intracranial pressure monitoring signals: a robust solution with signal decomposition", "Online performance evaluation of motor imagery BCI with augmented-reality virtual hand feedback", "Electrocorticographic signal classification based on time-frequency decomposition and nonparametric statistical modeling", "ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with Iterative Self-Training", "ME-PLAN: A deep prototypical learning with local attention network for dynamic micro-expression recognition", "Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor Imagery Classification", "An end-to-end 3D convolutional neural network for decoding attentive mental state", "Decoding Single-Hand and Both-Hand Movement Directions from Noninvasive Neural Signals", "Quantitative EEG as Biomarkers for the Monitoring of Post-Stroke Motor Recovery in BCI and tDCS Rehabilitation", "Real-time subject-independent pattern classification of overt and covert movements from fNIRS signals", "A 16-Channel Nonparametric Spike Detection ASIC Based on EC-PC Decomposition", "Impact of obstructive sleep apnea on sleep-wake stage ratio", "Extracting and selecting discriminative features from high density NIRS-based BCI for numerical cognition", "iSyNCC: An intelligent system for patient monitoring & clinical decision support in neuro-critical-care", "Optimization of BCI speller based on P300 potential", "Adaptation of motor imagery EEG classification model based on tensor decomposition", "A multimodal fNIRS and EEG-based BCI study on motor imagery and passive movement", "Cross-subject classification of speaking modes using fNIRS", "Enhancing the Extraction of Interpretable Information for Ischemic Stroke Imaging from Deep Neural Networks", "A Comparative Study of Mental States in 2D and 3D Virtual Environments Using EEG", "A VR combined with MI-BCI application for upper limb rehabilitation of stroke", "An analysis on driver drowsiness based on reaction time and EEG band power", "Detection of motor imagery of brisk walking from electroencephalogram", "Fast emotion detection from EEG using asymmetric spatial filtering", "Interpreting Mechanisms of Prediction for Skin Cancer Diagnosis Using Multi-Task Learning", "A closed-loop Brain-Computer Music Interface for continuous affective interaction", "A modified wavelet-common spatial pattern method for decoding hand movement directions in brain computer interfaces.", "EEG Channel Selection Using Decision Tree in Brain-Computer Interface", "Performance evaluation and fusion of methods for early detection of Alzheimer Disease", "Motor imagery-assisted brain-computer interface for gait retraining in neurorehabilitation in chronic stroke", "Personalized features for attention detection in children with Attention Deficit Hyperactivity Disorder", "MAXIMUM DEPENDENCY AND MINIMUM REDUNDANCY-BASED CHANNEL SELECTION FOR MOTOR IMAGERY OF WALKING EEG SIGNAL DETECTION", "Omitting the intra-session calibration in EEG-based brain computer interface used for stroke rehabilitation", "A hybrid BCI system for 2-d asynchronous cursor control", "Spatio-spectral feature selection based on robust mutual information estimate for brain computer interfaces", "Low data transmission rate and intelligible speech communication", "Visual-to-EEG cross-modal knowledge distillation for continuous emotion recognition", "A Unified Fisher's Ratio Learning Method for Spatial Filter Optimization", "On the asynchronously continuous control of mobile robot movement by motor cortical spiking activity", "Hand movement trajectory reconstruction from EEG for brain-computer interface systems", "Extracting effective features from high density nirs-based BCI for assessing numerical cognition", "Artificial neural network based intracranial pressure mean forecast algorithm for medical decision support", "Equivalence probability and sparsity of two sparse solutions in sparse representation", "Augmenting cognitive processes in robot-assisted motor rehabilitation", "Effect of ocular artifact removal in brain computer interface accuracy", "LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface", "Automatic Identification of High-Risk Autism Spectrum Disorder: A Feasibility Study Using Video and Audio Data under the Still-Face Paradigm", "Deep Learning for Neuroimaging Segmentation with a Novel Data Augmentation Strategy", "A Context-aware Locality Measure for Inlier Pool Enrichment in Stepwise Image Registration", "Brain-computer interface system and method", "Automatic sleep onset detection using single EEG sensor", "Selection of effective EEG channels in brain computer interfaces based on inconsistencies of classifiers", "Mutual information-based optimization of sparse spatio-spectral filters in brain\u2013computer interface", "Unsupervised brain computer interface based on inter-subject information", "A statistical model of brain signals with application to brain-computer interface", "Continuous Emotion Recognition With Audio-Visual Leader-Follower Attentive Fusion", "Task-related brain functional network reconfigurations relate to motor recovery in chronic subcortical stroke", "A Brain\u2013Computer Interface Framework Based on Compressive Sensing and Deep Learning", "On the robustness of EC\u2013PC spike detection method for online neural recording", "Prefrontal cortical activation during arithmetic processing differentiated by cultures: A preliminary fNIRS study", "Continuous Emotion Recognition using Visual-audio-linguistic information: A Technical Report for ABAW3", "Design a novel BCI for neurorehabilitation using concurrent LFP and EEG features: a case study", "A Framework on Optimization Strategy for EEG Motor Imagery Recognition", "2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)", "Discriminative filterbank selection and EEG information fusion for brain computer interface", "E-Key: an EEG-Based Biometric Authentication and Driving Fatigue Detection System", "Scalp EEG-based Pain Detection using Convolutional Neural Network", "Three-class motor imagery classification based on fbcsp combined with voting mechanism", "Multi-direction hand movement classification using EEG-based source space analysis", "Multiway analysis of EEG artifacts based on block term decomposition", "Cortical source localization for analysing single-trial motor imagery EEG", "Can we play with ADHD? An alternative game-based treatment for inattentive symptoms in attention-deficit/hyperactivity disorder", "Discriminative Learning of Propagation and Spatial Pattern for Motor Imagery EEG Analysis", "A linear discriminant analysis method based on mutual information maximization", "A maximum mutual information approach for constructing a 1D continuous control signal at a self-paced brain\u2013computer interface", "Optimizing EEG channel selection by regularized spatial filtering and multi band signal decomposition", "Expectation-maximization method for EEG-based continuous cursor control", "A kernel-based signal localization method for nirs brain-computer interfaces", "A brain control wheelchair with a P300 based bci and a path following controller", "Enhancing feature extraction with sparse component analysis for brain-computer interface", "Direct modulation on LPC coefficients with application to speech enhancement and improving the performance of speech recognition in noise", "Exposure Therapy With Personalized Real-Time Arousal Detection and Feedback to Alleviate Social Anxiety Symptoms in an Analogue Adult Sample: Pilot Proof-of-Concept Randomized\u00a0\u2026", "Spectrum and Phase Adaptive CCA for SSVEP-based Brain Computer Interface", "Towards improvement of MI-BCI performance of subjects with BCI deficiency", "A clinical study of motor imagery BCI performance in stroke by including calibration data from passive movement", "System and method for processing brain signals in a BCI system", "Introduction to NeuroComm: A platform for developing real-time EEG-based brain-computer interface applications"], "Link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:LTdYzzxxQecC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:MKvDIwB-zewC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:eflP2zaiRacC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:f4T9rk490XkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:LkGwnXOMwfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:CLPBug3NTQYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:maZDTaKrznsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:0D9gKr9vLLUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:zA6iFVUQeVQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:Wp0gIr-vW9MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:mvPsJ3kp5DgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:5qu0sgD3nvwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:mqGkWRiPAHEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:R6aXIXmdpM0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:WqliGbK-hY8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:QBJtjoHflPwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bKwnt0rjkrwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:mZB2-lCpWbQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:_8B_re9sV0EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:KxtntwgDAa4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:QppYajJO_VYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:5nxA0vEk-isC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:JkxM1axsR-IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Lmuc1furtc4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:W7OEmFMy1HYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ziW8EwMpto0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:G-26V_K0F8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:W5xh706n7nkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:0q7iQwrhYWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:SPgoriM2DtkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:d4paSpBSrDQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZfRJV9d4-WMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:xoH8P16vUNYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:TQgYirikUcIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:KaRcLhEUy5UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:H8Dy_DhitWcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:q3CdL3IzO_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:eJXPG6dFmWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:_FxGoFyzp5QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fEOibwPWpKIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bnK-pcrLprsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:LoiWQfKZB3kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:hMod-77fHWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:XX7pGhTe5MgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:8o7LCxyMrhgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:gmhHX4scLhsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZuybSZzF8UAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:L8Ckcad2t8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:MXK_kJrjxJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:nrtMV_XWKgEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bEWYMUwI8FkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:jq7mLYt49woC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:xtRiw3GOFMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:evX43VCCuoAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:35r97b3x0nAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Fla6ZGMkO9sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:oR5SthnA400C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:_5pobawY6TYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ML0RJ9NH7IQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZLdq17c_vQkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:0EnyYjriUFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:M7yex6snE4oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:nvAonm6-wpUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:vCSeWdjOjw8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PoWvk5oyLR8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:i2xiXl-TujoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:E8M3ZPqbjf0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fQNAKQ3IYiAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ktX0m338QuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:EupYgYwc-6gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fZtrMt_Z7PsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:yKZlB_2wKysC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:IT5EXw6i2GUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:84Dmd_oSKgsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:UHK10RUVsp4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:L8oS6_awjPoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:zVd9Rc0DoukC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PELIpwtuRlgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:r0BpntZqJG4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PRLG7g5oK-wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:BUYA1_V_uYcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:e5wmG9Sq2KIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Sipo1f_CKiIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:J6qkoyn5ZssC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Q3_nmhWTCy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EXDW3tg14iEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:53uzXsUip0wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_8F20clBW_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9N3KX2BFTccC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qjuL_XCUnM8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FXgMSCUEOHUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GnPB-g6toBAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:mB3voiENLucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dpaHy1TF288C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NhqRSupF_l8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GsgvGxwuA5UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Se3iqnhoufwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8NHCvSvNRCIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HHUT0vUrEqMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FnaCo-ypupUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:CHSYGLWDkRkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hFOr9nPyWt4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zPkyA21Y468C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1qzjygNMrQYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KlAtU1dfN6UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QaLwMs-zPFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:fveVehIkgekC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ns9cj8rnVeAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7_FrD3gH8REC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:UBnQDr5gPskC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NNXJ2mIwlScC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vs4DU1qUSb8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LjlpjdlvIbIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-f6ydRqryjwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:10ZmGoIvuzkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:sk-5v2XeZBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lLPirIASiZEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:t6usbXjVLHcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:E9iozgzfyhkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KVD38NuK74kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Dip1O2bNi0gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BrmTIyaxlBUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:kNdYIx-mwKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QUYzkoTeugQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:JtjtGO9FvpUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hTqO-V9ugBQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HE397vMXCloC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4DMP91E08xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hMwNgRnlwaMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LAaCg2gyLagC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RGFaLdJalmkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:OU6Ihb5iCvQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1GSnt3Xtl_sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8LfMcXwVQboC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K3LRdlH-MEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ULOm3_A8WrAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2hfDYGh-f1UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:PR6Y55bgFSsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:YOwf2qJgpHMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:D8wXzuvKacYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6IwoDg2IE1oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:l07DEcJES74C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:5Ul4iDaHHb8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tS2w5q8j5-wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:D03iK_w7-QYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7PzlFSSx8tAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RVsengBWOnMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dXBh7-90p_YC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:3YIFwf-X_CwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KFIQUvoPKFAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VfMbra648c4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:nlmsuG0oqtYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:auQHJw8QJBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tai-Ft5GzhwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:N5tVd3kTz84C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:WA5NYHcadZ8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:pyW8ca7W8N0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qUcmZB5y_30C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:J4wmHkHhN-kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:M3zsPnPgUlUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ye4kPcJQO24C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:YpRCXavlr0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:r_W8SUTUyowC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ZIQyR8VWHtoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GzlcqhCAosUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Y6EZgx1ah38C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eMMeJKvmdy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lvi_KyGYEDoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bzhzIcV5SW4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:5ugPr518TE4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:prvsfHNhuEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:J_g5lzvAfSwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:jgpk9vOjLEcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eTOb990cMygC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:URolC5Kub84C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1yQoGdGgb4wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:UxriW0iASnsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:IWHjjKOFINEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:3fE2CSJIrl8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:rblf-tZpB2YC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9Pw2l-cN0AIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:cCmJLe1CRJUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bcT4vkklUMwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Y5dfb0dijaUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:XiSMed-E-HIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HDshCWvjkbEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QIV2ME_5wuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9Nmd_mFXekcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:JjPkQosUWiAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lg5bARUibhcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bB6ab1qDjH0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:H7P4rdOtXtsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:P5F9QuxV20EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vlMkzkLhH4wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7T_dCfhhGW4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RsqFu5Siv-AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_kc_bZDykSQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8Fucociq1QoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:PBZ9sWDp-nEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8RJSsxxtMAkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FSHXWovK7t4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VL0QpB8kHFEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Efx6ZPdPmuEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:T_m5ky3rny8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:fh7vmlWxvT0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8v7czoltWYsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:k_IJM867U9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Yv3O0rUKnT0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zDMysJqCCKgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:U6twwk6Vgq8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:0KZCP5UExFUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9hNLEifDsrsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:22I2CSi1iVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vlECJaBXBlQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KUbvn5osdkgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lSLTfruPkqcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:blknAaTinKkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:j3f4tGmQtD8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tzM49s52ZIMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:i_ypWuZoRC8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_Qo2XoVZTnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:aqlVkmm33-oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6uOcHTua4cQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GZelqfngyKEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:X-Dm1JipzzIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:S16KYo8Pm5AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_xSYboBqXhAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dhFuZR0502QC"], "Topic": ["Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Computer Interaction", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Computer Interaction", "Others", "Others", "Federated Learning", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Biomedical Informatic", "Others", "Others", "Others", "Others", "Others", "Federated Learning", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Artificial Intelligenc", "Federated Learning", "Artificial Intelligenc", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Federated Learning", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Computer Interaction", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Federated Learning", "Computer Interaction", "Others", "Others", "Others", "Computer Interaction", "Federated Learning", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others"], "# of Citations": [1330, 1195, 1056, 1039, 717, 533, 489, 464, 435, 364, 358, 356, 344, 325, 309, 305, 307, 296, 296, 278, 264, 243, 243, 231, 227, 230, 222, 214, 211, 199, 199, 196, 187, 182, 169, 169, 152, 153, 149, 143, 146, 134, 132, 128, 128, 127, 125, 117, 118, 114, 113, 110, 111, 101, 100, 100, 92, 91, 87, 86, 82, 81, 80, 81, 79, 80, 77, 78, 77, 76, 75, 73, 73, 72, 70, 68, 68, 67, 64, 63, 62, 60, 59, 57, 56, 55, 54, 53, 54, 54, 53, 52, 51, 51, 52, 51, 51, 50, 48, 50, 49, 49, 47, 47, 46, 46, 45, 45, 44, 44, 44, 42, 43, 41, 42, 41, 41, 39, 40, 39, 38, 35, 35, 36, 35, 34, 34, 32, 33, 33, 32, 33, 32, 27, 31, 31, 31, 29, 28, 30, 30, 30, 28, 27, 27, 28, 27, 27, 27, 27, 27, 26, 26, 24, 26, 24, 25, 25, 24, 24, 24, 24, 24, 24, 24, 22, 20, 21, 22, 21, 22, 22, 22, 21, 22, 21, 22, 21, 20, 21, 19, 20, 20, 20, 20, 20, 19, 18, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 16, 17, 17, 16, 17, 17, 17, 17, 17, 13, 15, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 14, 14, 14, 13, 14, 14, 14, 13, 11, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 11, 11, 12], "Description": ["In motor imagery-based Brain Computer Interfaces (BCI), discriminative patterns can be extracted from the electroencephalogram (EEG) using the Common Spatial Pattern (CSP) algorithm. However, the performance of this spatial filter depends on the operational frequency band of the EEG. Thus, setting a broad frequency range, or manually selecting a subject-specific frequency range, are commonly used with the CSP algorithm. To address this problem, this paper proposes a novel Filter Bank Common Spatial Pattern (FBCSP) to perform autonomous selection of key temporal-spatial discriminative EEG characteristics. After the EEG measurements have been bandpass-filtered into multiple frequency bands, CSP features are extracted from each of these bands. A feature selection algorithm is then used to automatically select discriminative pairs of frequency bands and corresponding CSP features. A classification\u00a0\u2026", "Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in\u00a0\u2026", "One of the most popular feature extraction algorithms for brain-computer interfaces (BCI) is common spatial patterns (CSPs). Despite its known efficiency and widespread use, CSP is also known to be very sensitive to noise and prone to overfitting. To address this issue, it has been recently proposed to regularize CSP. In this paper, we present a simple and unifying theoretical framework to design such a regularized CSP (RCSP). We then present a review of existing RCSP algorithms and describe how to cast them in this framework. We also propose four new RCSP algorithms. Finally, we compare the performances of 11 different RCSP (including the four new ones and the original CSP), on electroencephalography data from 17 subjects, from BCI competition datasets. Results showed that the best RCSP methods can outperform CSP by nearly 10% in median classification accuracy and lead to more\u00a0\u2026", "The Common Spatial Pattern (CSP) algorithm is an effective and popular method for classifying 2-class motor imagery electroencephalogram (EEG) data, but its effectiveness depends on the subject-specific frequency band. This paper presents the Filter Bank Common Spatial Pattern (FBCSP) algorithm to optimize the subject-specific frequency band for CSP on Datasets 2a and 2b of the Brain-Computer Interface (BCI) Competition IV. Dataset 2a comprised 4 classes of 22 channels EEG data from 9 subjects, and Dataset 2b comprised 2 classes of 3 bipolar channels EEG data from 9 subjects. Multi-class extensions to FBCSP are also presented to handle the 4-class EEG data in Dataset 2a, namely, Divide-and-Conquer (DC), Pair-Wise (PW), and One-Versus-Rest (OVR) approaches. Two feature selection algorithms are also presented to select discriminative CSP features on Dataset 2b, namely, the Mutual Information-based Best Individual Feature (MIBIF) algorithm, and the Mutual Information-based Rough Set Reduction (MIRSR) algorithm. The single-trial classification accuracies were presented using 10\u2009\u00d7\u200910-fold cross-validations on the training data and session-to-session transfer on the evaluation data from both datasets. Disclosure of the test data labels after the BCI Competition IV showed that the FBCSP algorithm performed relatively the best among the other submitted algorithms and yielded a mean kappa value of 0.569 and 0.600 across all subjects in Datasets 2a and 2b respectively.", "There has been an increase in research interest for brain\u2013computer interface (BCI) technology as an alternate mode of communication and environmental control for the disabled, such as patients suffering from amyotrophic lateral sclerosis (ALS), brainstem stroke and spinal cord injury. Disabled patients with appropriate physical care and cognitive ability to communicate with their social environment continue to live with a reasonable quality of life over extended periods of time. Near-infrared spectroscopy is a non-invasive technique which utilizes light in the near-infrared range (700 to 1000\u00a0nm) to determine cerebral oxygenation, blood flow and metabolic status of localized regions of the brain. In this paper, we describe a study conducted to test the feasibility of using multichannel NIRS in the development of a BCI. We used a continuous wave 20-channel NIRS system over the motor cortex of 5 healthy volunteers to\u00a0\u2026", "Electroencephalography (EEG)\u2013based motor imagery (MI) brain-computer interface (BCI) technology has the potential to restore motor function by inducing activity-dependent brain plasticity. The purpose of this study was to investigate the efficacy of an EEG-based MI BCI system coupled with MIT-Manus shoulder-elbow robotic feedback (BCI-Manus) for subjects with chronic stroke with upper-limb hemiparesis. In this single-blind, randomized trial, 26 hemiplegic subjects (Fugl-Meyer Assessment of Motor Recovery After Stroke [FMMA] score, 4-40; 16 men; mean age, 51.4 years; mean stroke duration, 297.4 days), prescreened with the ability to use the MI BCI, were randomly allocated to BCI-Manus or Manus therapy, lasting 18 hours over 4 weeks. Efficacy was measured using upper-extremity FMMA scores at weeks 0, 2, 4 and 12. ElEG data from subjects allocated to BCI-Manus were quantified using the revised\u00a0\u2026", "While brain-computer interfaces (BCIs) can provide communication to people who are locked-in, they suffer from a very low information transfer rate. Further, using a BCI requires a concentration effort and using it continuously can be tiring. The brain controlled wheelchair (BCW) described in this paper aims at providing mobility to BCI users despite these limitations, in a safe and efficient way. Using a slow but reliable P300 based BCI, the user selects a destination amongst a list of predefined locations. While the wheelchair moves on virtual guiding paths ensuring smooth, safe, and predictable trajectories, the user can stop the wheelchair by using a faster BCI. Experiments with nondisabled subjects demonstrated the efficiency of this strategy. Brain control was not affected when the wheelchair was in motion, and the BCW enabled the users to move to various locations in less time and with significantly less control\u00a0\u2026", "Deep learning (DL) methods and architectures have been the state-of-the-art classification algorithms for computer vision and natural language processing problems. However, the successful application of these methods in motor imagery (MI) brain-computer interfaces (BCIs), in order to boost classification performance, is still limited. In this paper, we propose a classification framework for MI data by introducing a new temporal representation of the data and also utilizing a convolutional neural network (CNN) architecture for classification. The new representation is generated from modifying the filter-bank common spatial patterns method, and the CNN is designed and optimized accordingly for the representation. Our framework outperforms the best classification method in the literature on the BCI competition IV-2a 4-class MI data set by 7% increase in average subject accuracy. Furthermore, by studying the\u00a0\u2026", "Multichannel EEG is generally used in brain-computer interfaces (BCIs), whereby performing EEG channel selection 1) improves BCI performance by removing irrelevant or noisy channels and 2) enhances user convenience from the use of lesser channels. This paper proposes a novel sparse common spatial pattern (SCSP) algorithm for EEG channel selection. The proposed SCSP algorithm is formulated as an optimization problem to select the least number of channels within a constraint of classification accuracy. As such, the proposed approach can be customized to yield the best classification accuracy by removing the noisy and irrelevant channels, or retain the least number of channels without compromising the classification accuracy obtained by using all the channels. The proposed SCSP algorithm is evaluated using two motor imagery datasets, one with a moderate number of channels and another with a\u00a0\u2026", "Brain-computer interface (BCI) is a system to translate humans thoughts into commands. For electroencephalography (EEG) based BCI, motor imagery is considered as one of the most effective ways. Different imagery activities can be classified based on the changes in mu and/or beta rhythms and their spatial distributions. However, the change in these rhythmic patterns varies from one subject to another. This causes an unavoidable time-consuming fine-tuning process in building a BCI for every subject. To address this issue, we propose a new method called sub-band common spatial pattern (SBCSP) to solve the problem. First, we decompose the EEG signals into sub-bands using a filter bank. Subsequently, we apply a discriminative analysis to extract SBCSP features. The SBCSP features are then fed into linear discriminant analyzers (LDA) to obtain scores which reflect the classification capability of each\u00a0\u2026", "We report the implementation of a text input application (speller) based on the P300 event related potential. We obtain high accuracies by using an SVM classifier and a novel feature. These techniques enable us to maintain fast performance without sacrificing the accuracy, thus making the speller usable in an online mode. In order to further improve the usability, we perform various studies on the data with a view to minimizing the training time required. We present data collected from nine healthy subjects, along with the high accuracies (of the order of 95% or more) measured online. We show that the training time can be further reduced by a factor of two from its current value of about 20 min. High accuracy, fast learning, and online performance make this P300 speller a potential communication tool for severely disabled individuals, who have lost all other means of communication and are otherwise cut off from the\u00a0\u2026", "Two-dimensional cursor control is an important and challenging issue in EEG-based brain-computer interfaces (BCIs). To address this issue, here we propose a new approach by combining two brain signals including Mu/Beta rhythm during motor imagery and P300 potential. In particular, a motor imagery detection mechanism and a P300 potential detection mechanism are devised and integrated such that the user is able to use the two signals to control, respectively, simultaneously, and independently, the horizontal and the vertical movements of the cursor in a specially designed graphic user interface. A real-time BCI system based on this approach is implemented and evaluated through an online experiment involving six subjects performing 2-D control tasks. The results attest to the efficacy of obtaining two independent control signals by the proposed approach. Furthermore, the results show that the system has\u00a0\u2026", "The idea of controlling objects or machines through thought is moving from science fiction to reality. This article presents the first working prototype of a brain-controlled wheelchair that can navigate in a typical office or hospital environment. The wheelchair is based on a slow but safe brain-controlled interface using the P300 signal detected from electroencephalography. The authors adapted the system's control strategy to the interface's measured performance. To circumvent the problem caused by the interface's low information rate, a motion guidance strategy provides safe, efficient control without complex sensors or sensor processing. Experiments demonstrated that healthy subjects can safely control the wheelchair in an office-like environment without training.This article is part of a special issue on Interacting with Autonomy.", "The objective of this study was to investigate the efficacy of an Electroencephalography (EEG)-based Motor Imagery (MI) Brain-Computer Interface (BCI) coupled with a Haptic Knob (HK) robot for arm rehabilitation in stroke patients. In this three-arm, single-blind, randomized controlled trial; 21 chronic hemiplegic stroke patients (Fugl-Meyer Motor Assessment (FMMA) score 10\u201350), recruited after pre-screening for MI BCI ability, were randomly allocated to BCI-HK, HK or Standard Arm Therapy (SAT) groups. All groups received 18 sessions of intervention over 6 weeks, 3 sessions per week, 90 min per session. The BCI-HK group received 1 h of BCI coupled with HK intervention, and the HK group received 1 h of HK intervention per session. Both BCI-HK and HK groups received 120 trials of robot-assisted hand grasping and knob manipulation followed by 30 min of therapist-assisted arm mobilization. The SAT group received 1.5 h of therapist-assisted arm mobilization and forearm pronation-supination movements incorporating wrist control and grasp-release functions. In all, 14 males, 7 females, mean age 54.2 years, mean stroke duration 385.1 days, with baseline FMMA score 27.0 were recruited. The primary outcome measure was upper extremity FMMA scores measured mid-intervention at week 3, end-intervention at week 6, and follow-up at weeks 12 and 24. Seven, 8 and 7 subjects underwent BCI-HK, HK and SAT interventions respectively. FMMA score improved in all groups, but no intergroup differences were found at any time points. Significantly larger motor gains were observed in the BCI-HK group compared to the SAT group at weeks 3\u00a0\u2026", "In this paper, we first present a self-training semi-supervised support vector machine (SVM) algorithm and its corresponding model selection method, which are designed to train a classifier with small training data. Next, we prove the convergence of this algorithm. Two examples are presented to demonstrate the validity of our algorithm with model selection. Finally, we apply our algorithm to a data set collected from a P300-based brain computer interface (BCI) speller. This algorithm is shown to be able to significantly reduce training effort of the P300-based BCI speller.", "Brain-computer interface (BCI) technology has the prospects of helping stroke survivors by enabling the interaction with their environment through brain signals rather than through muscles, and restoring motor function by inducing activity-dependent brain plasticity. This paper presents a clinical study on the extent of detectable brain signals from a large population of stroke patients in using EEG-based motor imagery BCI.EEG data were collected from 54 stroke patients whereby finger tapping and motor imagery of the stroke-affected hand were performed by 8 and 46 patients, respectively. EEG data from 11 patients who gave further consent to perform motor imagery were also collected for second calibration and third independent test sessions conducted on separate days. Off-line accuracies of classifying the two classes of EEG from finger tapping or motor imagery of the stroke-affected hand versus the EEG from\u00a0\u2026", "Common spatial pattern (CSP) is a popular algorithm for classifying electroencephalogram (EEG) signals in the context of brain-computer interfaces (BCIs). This paper presents a regularization and aggregation technique for CSP in a small-sample setting (SSS). Conventional CSP is based on a sample-based covariance-matrix estimation. Hence, its performance in EEG classification deteriorates if the number of training samples is small. To address this concern, a regularized CSP (R-CSP) algorithm is proposed, where the covariance-matrix estimation is regularized by two parameters to lower the estimation variance while reducing the estimation bias. To tackle the problem of regularization parameter determination, R-CSP with aggregation (R-CSP-A) is further proposed, where a number of R-CSPs are aggregated to give an ensemble-based solution. The proposed algorithm is evaluated on data set IVa of BCI\u00a0\u2026", "Event-related desynchronization/synchronization patterns during right/left motor imagery (MI) are effective features for an electroencephalogram-based brain-computer interface (BCI). As MI tasks are subject-specific, selection of subject-specific discriminative frequency components play a vital role in distinguishing these patterns. This paper proposes a new discriminative filter bank (FB) common spatial pattern algorithm to extract subject-specific FB for MI classification. The proposed method enhances the classification accuracy in BCI competition III dataset IVa and competition IV dataset IIb. Compared to the performance offered by the existing FB-based method, the proposed algorithm offers error rate reductions of 17.42% and 8.9% for BCI competition datasets III and IV, respectively.", "This clinical study investigates the ability of hemiparetic stroke patients in operating EEG-based motor imagery brain-computer interface (MI-BCI). It also assesses the efficacy in motor improvements on the stroke-affected upper limb using EEG-based MI-BCI with robotic feedback neurorehabilitation compared to robotic rehabilitation that delivers movement therapy. 54 hemiparetic stroke patients with mean age of 51.8 and baseline Fugl-Meyer Assessment (FMA) 14.9 (out of 66, higher = better) were recruited. Results showed that 48 subjects (89%) operated EEG-based MI-BCI better than at chance level, and their ability to operate EEG-based MI-BCI is not correlated to their baseline FMA (r=0.358). Those subjects who gave consent are randomly assigned to each group (N=11 and 14) for 12 1-hour rehabilitation sessions for 4 weeks. Significant gains in FMA scores were observed in both groups at post-rehabilitation\u00a0\u2026", "Background. Robot-assisted training may improve motor function in some hemiparetic patients after stroke, but no physiological predictor of rehabilitation progress is reliable. Resting state functional magnetic resonance imaging (RS-fMRI) may serve as a method to assess and predict changes in the motor network. Objective. The authors examined the effects of upper-extremity robot-assisted rehabilitation (MANUS) versus an electroencephalography-based brain computer interface setup with motor imagery (MI EEG-BCI) and compared pretreatment and posttreatment RS-fMRI. Methods. In all, 9 adults with upper-extremity paresis were trained for 4 weeks with a MANUS shoulder-elbow robotic rehabilitation paradigm. In 3 participants, robot-assisted movement began if no voluntary movement was initiated within 2 s. In 6 participants, MI-BCI\u2013based movement was initiated if motor imagery was detected. RS-fMRI and\u00a0\u2026", "Electromyography (EMG) signal is one of the widely used biological signals for human motor intention prediction, which is an essential element in human-robot collaboration systems. Studies on motor intention prediction from EMG signal have been concentrated on classification and regression models, and there are numerous review and survey papers on classification models. However, to the best of our knowledge, there is no review paper on regression models or continuous motion prediction from EMG signal. Therefore, in this paper, we provide a comprehensive review of EMG-based motor intention prediction of continuous human upper limb motion. This review will cover the models and approaches used in continuous motion estimation, the kinematic motion parameters estimated from EMG signal, and the performance metrics utilized for system validation. From the review, we will provide some insights into\u00a0\u2026", "For a brain-computer interface (BCI) system, a calibration procedure is required for each individual user before he/she can use the BCI. This procedure requires approximately 20-30 min to collect enough data to build a reliable decoder. It is, therefore, an interesting topic to build a calibration-free, or subject-independent, BCI. In this article, we construct a large motor imagery (MI)-based electroencephalography (EEG) database and propose a subject-independent framework based on deep convolutional neural networks (CNNs). The database is composed of 54 subjects performing the left- and right-hand MI on two different days, resulting in 21 600 trials for the MI task. In our framework, we formulated the discriminative feature representation as a combination of the spectral-spatial input embedding the diversity of the EEG signals, as well as a feature representation learned from the CNN through a fusion technique\u00a0\u2026", "Recent advances in computer science enabled people with severe motor disabilities to use brain-computer interfaces (BCI) for communication, control, and even to restore their motor disabilities. This paper reviews the most recent works of BCI in stroke rehabilitation with a focus on methodology that reported on data collected from stroke patients and clinical studies that reported on the motor improvements of stroke patients. Both types of studies are important as the former advances the technology of BCI for stroke, and the latter demonstrates the clinical efficacy of BCI in stroke. Finally some challenges are discussed.", "Attention deficit hyperactivity disorder (ADHD) symptoms can be difficult to treat. We previously reported that a 20-session brain-computer interface (BCI) attention training programme improved ADHD symptoms. Here, we investigated a new more intensive BCI-based attention training game system on 20 unmedicated ADHD children (16 males, 4 females) with significant inattentive symptoms (combined and inattentive ADHD subtypes). This new system monitored attention through a head band with dry EEG sensors, which was used to drive a feed forward game. The system was calibrated for each user by measuring the EEG parameters during a Stroop task. Treatment consisted of an 8-week training comprising 24 sessions followed by 3 once-monthly booster training sessions. Following intervention, both parent-rated inattentive and hyperactive-impulsive symptoms on the ADHD Rating Scale showed significant improvement. At week 8, the mean improvement was \u22124.6 (5.9) and \u22124.7 (5.6) respectively for inattentive symptoms and hyperactive-impulsive symptoms (both p<0.01). Cohen\u2019s d effect size for inattentive symptoms was large at 0.78 at week 8 and 0.84 at week 24 (post-boosters). Further analysis showed that the change in the EEG based BCI ADHD severity measure correlated with the change ADHD Rating Scale scores. The BCI-based attention training game system is a potential new treatment for ADHD. Trial Registration ClinicalTrials.gov NCT01344044", "Automatic sleep stage mymargin classification is of great importance to measure sleep quality. In this paper, we propose a novel attention-based deep learning architecture called AttnSleep to classify sleep stages using single channel EEG signals. This architecture starts with the feature extraction module based on multi-resolution convolutional neural network (MRCNN) and adaptive feature recalibration (AFR). The MRCNN can extract low and high frequency features and the AFR is able to improve the quality of the extracted features by modeling the inter-dependencies between the features. The second module is the temporal context encoder (TCE) that leverages a multi-head attention mechanism to capture the temporal dependencies among the extracted features. Particularly, the multi-head attention deploys causal convolutions to model the temporal relations in the input features. We evaluate the performance\u00a0\u2026", "Learning the deep structures and unknown correlations is important for the detection of motor imagery of EEG signals (MI-EEG). This study investigates the use of convolutional neural networks (CNNs) for the classification of multi-class MI-EEG signals. Augmented common spatial pattern (ACSP) features are generated based on pair-wise projection matrices, which covers various frequency ranges. We propose a frequency complementary feature map selection (FCMS) scheme by constraining the dependency among frequency bands. Experiments are conducted on BCI competition IV dataset IIa with 9 subjects. Averaged cross-validation accuracy of 68.45% and 69.27% is achieved for FCMS and all feature maps, respectively, which is significantly higher (4.53% and 5.34%) than random map selection and higher (1.44% and 2.26%) than filter-bank CSP (FBCSP). The results demonstrate that the CNNs are capable\u00a0\u2026", null, "P300 speller is a communication tool with which one can input texts or commands to a computer by thought. The amplitude of the P300 evoked potential is inversely proportional to the probability of infrequent or task-related stimulus. In existing P300 spellers, rows and columns of a matrix are intensified successively and randomly, resulting in a stimulus frequency of 1/N (N is the number of rows or columns of the matrix). We propose a new paradigm to display each single character randomly and individually (therefore reducing the stimulus frequency to 1/(N*N)). On-line experiments showed that this new speller significantly improved the performance. Specifically, the new speller can reduce character classification error rate by up to 80% or double the information transfer rate compared to the existing P300 spellers.", "Asynchronous control is an important issue for brain--computer interfaces (BCIs) working in real-life settings, where the machine should determine from brain signals not only the desired command but also when the user wants to input it. In this paper, we propose a novel computational approach for robust asynchronous control using electroencephalogram (EEG) and a P300-based oddball paradigm. In this approach, we first address the mathematical modeling of target P300, nontarget P300, and noncontrol signals, by using Gaussian distribution models in a support vector margin space. Furthermore, we derive a method to compute the likelihood of control state in a time window of EEG. Finally, we devise a recursive algorithm to detect control states in ongoing EEG for online application. We conducted experiments with four subjects to study both the asynchronous BCI's receiver operating characteristics and its\u00a0\u2026", "Stroke is one of the leading causes of long-term disability among adults and contributes to major socio-economic burden globally. Stroke frequently results in multifaceted impairments including motor, cognitive and emotion deficits. In recent years, brain\u2013computer interface (BCI)-based therapy has shown promising results for post-stroke motor rehabilitation. In spite of the success received by BCI-based interventions in the motor domain, non-motor impairments are yet to receive similar attention in research and clinical settings. Some preliminary encouraging results in post-stroke cognitive rehabilitation using BCI seem to suggest that it may also hold potential for treating non-motor deficits such as cognitive and emotion impairments. Moreover, past studies have shown an intricate relationship between motor, cognitive and emotion functions which might influence the overall post-stroke rehabilitation outcome. A\u00a0\u2026", "The common spatial pattern (CSP) algorithm is effective in decoding the spatial patterns of the corresponding neuronal activities from electroencephalogram (EEG) signal patterns in brain\u2013computer interfaces (BCIs). However, its effectiveness depends on the subject-specific time segment relative to the visual cue and on the temporal frequency band that is often selected manually or heuristically. This paper presents a novel statistical method to automatically select the optimal subject-specific time segment and temporal frequency band based on the mutual information between the spatial\u2013temporal patterns from the EEG signals and the corresponding neuronal activities. The proposed method comprises four progressive stages: multi-time segment and temporal frequency band-pass filtering, CSP spatial filtering, mutual information-based feature selection and na\u00efve Bayesian classification. The proposed mutual\u00a0\u2026", "Objective Despite the effective application of deep learning (DL) in brain\u2013computer interface (BCI) systems, the successful execution of this technique, especially for inter-subject classification, in cognitive BCI has not been accomplished yet. In this paper, we propose a framework based on the deep convolutional neural network (CNN) to detect the attentive mental state from single-channel raw electroencephalography (EEG) data. Approach We develop an end-to-end deep CNN to decode the attentional information from an EEG time series. We also explore the consequences of input representations on the performance of deep CNN by feeding three different EEG representations into the network. To ensure the practical application of the proposed framework and avoid time-consuming re-training, we perform inter-subject transfer learning techniques as a classification strategy. Eventually, to interpret the learned\u00a0\u2026", "Non-invasive EEG-based motor imagery brain-computer interface (MI-BCI) holds promise to effectively restore motor control to stroke survivors. This clinical study investigates the effects of MI-BCI for upper limb robotic rehabilitation compared to standard robotic rehabilitation. The subjects are hemiparetic stroke patients with mean age of 50.2 and baseline Fugl-Meyer (FM) score 29.7 (out of 66, higher = better) randomly assigned to each group respectively (N=8 and 10). Each subject underwent 12 sessions of 1-hour rehabilitation for 4 weeks. Significant gains in FM scores were observed in both groups at post-rehabilitation (4.9, p=0.001) and 2-month post-rehabilitation (4.9, p=0.002). The experimental group yielded higher 2-month post-rehabilitation gain than the control (6.0 versus 4.0) but no significance was found (p=0.475). However, among subjects with positive gain (N=6 and 7), the initial difference of 2.8\u00a0\u2026", "A major limitation of Brain-Computer Interfaces (BCI) is their long calibration time, as much data from the user must be collected in order to tune the BCI for this target user. In this paper, we propose a new method to reduce this calibration time by using data from other subjects. More precisely, we propose an algorithm to regularize the Common Spatial Patterns (CSP) and Linear Discriminant Analysis (LDA) algorithms based on the data from a subset of automatically selected subjects. An evaluation of our approach showed that our method significantly outperformed the standard BCI design especially when the amount of data from the target user is small. Thus, our approach helps in reducing the amount of data needed to achieve a given performance level.", "Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw time-series data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classifier on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efficiency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC.", "This paper presents the first working prototype of a brain controlled wheelchair able to navigate inside a typical office or hospital environment. This brain controlled wheelchair (BCW) is based on a slow but safe P300 interface. To circumvent the problem caused by the low information rate of the EEG signal, we propose a motion guidance strategy providing safe and efficient control without complex sensors or sensor processing. Experiments demonstrated that healthy subjects could safely control the wheelchair in an office like environment, without any training", "In recent years, deep learning has emerged as a powerful tool for developing Brain\u2013Computer Interface (BCI) systems. However, for deep learning models trained entirely on the data from a specific individual, the performance increase has only been marginal owing to the limited availability of subject-specific data. To overcome this, many transfer-based approaches have been proposed, in which deep networks are trained using pre-existing data from other subjects and evaluated on new target subjects. This mode of transfer learning however faces the challenge of substantial inter-subject variability in brain data. Addressing this, in this paper, we propose 5 schemes for adaptation of a deep convolutional neural network (CNN) based electroencephalography (EEG)-BCI system for decoding hand motor imagery (MI). Each scheme fine-tunes an extensively trained, pre-trained model and adapt it to enhance the\u00a0\u2026", "Conventional brain computer interfaces rely on a guided calibration procedure to address the problem of considerable variations in electroencephalography (EEG) across human subjects. This calibration, however, implies inconvenience to the end users. In this paper, we propose an online-adaptive-learning method to address this problem for P300-based brain computer interfaces. By automatically capturing subject-specific EEG characteristics during online operation, this method allows a new user to start operating a P300-based brain-computer interface without guided (supervised) calibration. The basic principle is to first learn a generic model termed  subject-independent model  offline from EEG of a pool of subjects to capture common P300 characteristics. For a new user, a new model termed  subject-specific model  is then adapted online based on EEG recorded from the new subject and the corresponding\u00a0\u2026", "Technology development in wearable sensors and biosignal processing has made it possible to detect human stress from the physiological features. However, the intersubject difference in stress responses presents a major challenge for reliable and accurate stress estimation. This research proposes a novel cluster-based analysis method to measure perceived stress using physiological signals, which accounts for the intersubject differences. The physiological data are collected when human subjects undergo a series of task-rest cycles, incurring varying levels of stress that is indicated by an index of the State Trait Anxiety Inventory. Next, a quantitative measurement of stress is developed by analyzing the physiological features in two steps: 1) a k-means clustering process to divide subjects into different categories (clusters), and 2) cluster-wise stress evaluation using the general regression neural network\u00a0\u2026", "ObjectiveTo investigate the efficacy and effects of transcranial direct current stimulation (tDCS) on motor imagery brain-computer interface (MI-BCI) with robotic feedback for stroke rehabilitation.DesignA sham-controlled, randomized controlled trial.SettingPatients recruited through a hospital stroke rehabilitation program.ParticipantsSubjects (N=19) who incurred a stroke 0.8 to 4.3 years prior, with moderate to severe upper extremity functional impairment, and passed BCI screening.InterventionsTen sessions of 20 minutes of tDCS or sham before 1 hour of MI-BCI with robotic feedback upper limb stroke rehabilitation for 2 weeks. Each rehabilitation session comprised 8 minutes of evaluation and 1 hour of therapy.Main Outcome MeasuresUpper extremity Fugl-Meyer Motor Assessment (FMMA) scores measured end-intervention at week 2 and follow-up at week 4, online BCI accuracies from the evaluation part, and\u00a0\u2026", "A major challenge in electroencephalogram (EEG)-based brain-computer interfaces (BCIs) is the inherent nonstationarities in the EEG data. Variations of the signal properties from intra and inter sessions often lead to deteriorated BCI performances, as features extracted by methods such as common spatial patterns (CSP) are not invariant against the changes. To extract features that are robust and invariant, this paper proposes a novel spatial filtering algorithm called Kullback-Leibler (KL) CSP. The CSP algorithm only considers the discrimination between the means of the classes, but does not consider within-class scatters information. In contrast, the proposed KLCSP algorithm simultaneously maximizes the discrimination between the class means, and minimizes the within-class dissimilarities measured by a loss function based on the KL divergence. The performance of the proposed KLCSP algorithm is\u00a0\u2026", "Deep learning, recently, has been successfully applied to image classification, object recognition and speech recognition. However, the benefits of deep learning and accompanying architectures have been largely unknown for BCI applications. In motor imagery-based BCI, an energy-based feature, typically after spatial filtering, is commonly used for classification. Although this feature corresponds to the estimate of event-related synchronization/desynchronization in the brain, it neglects energy dynamics which may contain valuable discriminative information. Because traditional classiication methods, such as SVM, cannot handle this dynamical property, we proposed an architecture that inputs a dynamic energy representation of EEG data and utilizes convolutional neural networks for classification. By combining this network with a static energy network, we saw a significant increase in performance. We evaluated\u00a0\u2026", "Current rehabilitation therapies for stroke rely on physical practice (PP) by the patients. Motor imagery (MI), the imagination of movements without physical action, presents an alternate neurorehabilitation for stroke patients without relying on residue movements. However, MI is an endogenous mental process that is not physically observable. Recently, advances in brain-computer interface (BCI) technology have enabled the objective detection of MI that spearheaded this alternate neurorehabilitation for stroke. In this review, we present two strategies of using BCI for neurorehabilitation after stroke: detecting MI to trigger a feedback, and detecting MI with a robot to provide concomitant MI and PP. We also present three randomized control trials that employed these two strategies for upper limb rehabilitation. A total of 125 chronic stroke patients were screened over six years. The BCI screening revealed that 103 (82\u00a0\u2026", "For multimodal Human-Computer Interaction (HCI), it is very useful to identify the modalities on which the user is currently processing information. This would enable a system to select complementary output modalities to reduce the user's workload. In this paper, we develop a hybrid Brain-Computer Interface (BCI) which uses Electroencephalography (EEG) and functional Near Infrared Spectroscopy (fNIRS) to discriminate and detect visual and auditory stimulus processing. We describe the experimental setup we used for collection of our data corpus with 12 subjects. On this data, we performed cross-validation evaluation, of which we report accuracy for different classification conditions. The results show that the subject-dependent systems achieved a classification accuracy of 97.8% for discriminating visual and auditory perception processes from each other and a classification accuracy of up to 94.8% for detecting modality-specific processes independently of other cognitive activity. The same classification conditions could also be discriminated in a subject-independent fashion with accuracy of up to 94.6 and 86.7%, respectively. We also look at the contributions of the two signal types and show that the fusion of classifiers using different features significantly increases accuracy.", "A brain-computer interface (BCI) acquires brain signals, extracts informative features, and translates these features to commands to control an external device. This paper investigates the application of a noninvasive electroencephalography (EEG)based BCI to identify brain signal features in regard to actual hand movement speed. This provides a more refined control for a BCI system in terms of movement parameters. An experiment was performed to collect EEG data from subjects while they performed right-hand movement at two different speeds, namely fast and slow, in four different directions. The informative features from the data were obtained using the Wavelet-Common Spatial Pattern (W-CSP) algorithm that provided high-temporal-spatial-spectral resolution. The applicability of these features to classify the two speeds and to reconstruct the speed profile was studied. The results for classifying speed across\u00a0\u2026", "Objective This single-arm multisite trial investigates the efficacy of the neurostyle brain exercise therapy towards enhanced recovery (nBETTER) system, an electroencephalogram (EEG)-based motor imagery brain-computer interface (MI-BCI) employing visual feedback for upper-limb stroke rehabilitation, and the presence of EEG correlates of mental fatigue during BCI usage. Methods A total of 13 recruited stroke patients underwent thrice-weekly nBETTER therapy coupled with standard arm therapy over six weeks. Upper-extremity Fugl-Meyer motor assessment (FMA) scores were measured at baseline (week 0), post-intervention (week 6), and follow-ups (weeks 12 and 24). In total, 11/13 patients (mean age 55.2 years old, mean post-stroke duration 333.7 days, mean baseline FMA 35.5) completed the study. Results Significant FMA gains relative to baseline were observed at weeks 6 and 24. Retrospectively\u00a0\u2026", "This paper investigates the classification of multi-class motor imagery for electroencephalogram (EEG)-based Brain-Computer Interface (BCI) using the Filter Bank Common Spatial Pattern (FBCSP) algorithm. The FBCSP algorithm classifies EEG measurements from features constructed using subject-specific temporal-spatial filters. However, the FBCSP algorithm is limited to binary-class motor imagery. Hence, this paper proposes 3 approaches of multi-class extension to the FBCSP algorithm: One-versus-Rest, Pair-Wise and Divide-and-Conquer. These approaches decompose the multi-class problem into several binary-class problems. The study is conducted on the BCI Competition IV dataset IIa, which comprises single-trial EEG data from 9 subjects performing 4-class motor imagery of left-hand, right-hand, foot and tongue actions. The results showed that the multi-class FBCSP algorithm could extract features\u00a0\u2026", "The performance of a classifier in a brain-computer interface (BCI) system is highly dependent on the quality and quantity of training data. Typically, the training data are collected in a laboratory where the users perform tasks in a controlled environment. However, users' attention may be diverted in real-life BCI applications and this may decrease the performance of the classifier. To improve the robustness of the classifier, additional data can be acquired in such conditions, but it is not practical to record electroencephalogram (EEG) data over several long calibration sessions. A potentially time- and cost-efficient solution is artificial data generation. Hence, in this study, we proposed a framework based on the deep convolutional generative adversarial networks (DCGANs) for generating artificial EEG to augment the training set in order to improve the performance of a BCI classifier. To make a comparative investigation\u00a0\u2026", "Knowing the correlation of reaction parameters in the preparation process of carbon dots (CDs) is essential for optimizing the synthesis strategy, exploring exotic properties, and exploiting potential applications. However, the integrated screening experimental data on the synthesis of CDs are huge and noisy. Machine learning (ML) has recently been successfully used for the screening of high-performance materials. Here, we demonstrate how ML-based techniques can offer insight into the successful prediction, optimization, and acceleration of CDs\u2019 synthesis process. A regression ML model on hydrothermal-synthesized CDs is established capable of revealing the relationship between various synthesis parameters and experimental outcomes as well as enhancing the process-related properties such as the fluorescent quantum yield (QY). CDs exhibiting a strong green emission with QY up to 39.3% are obtained\u00a0\u2026", "Cognitive decline in aging is a pressing issue associated with significant healthcare costs and deterioration in quality of life. Previously, we reported the successful use of a novel brain-computer interface (BCI) training system in improving symptoms of attention deficit hyperactivity disorder. Here, we examine the feasibility of the BCI system with a new game that incorporates memory training in improving memory and attention in a pilot sample of healthy elderly. This study investigates the safety, usability and acceptability of our BCI system to elderly, and obtains an efficacy estimate to warrant a phase III trial. Thirty-one healthy elderly were randomized into intervention (n\u200a=\u200a15) and waitlist control arms (n\u200a=\u200a16). Intervention consisted of an 8-week training comprising 24 half-hour sessions. A usability and acceptability questionnaire was administered at the end of training. Safety was investigated by querying users about adverse events after every session. Efficacy of the system was measured by the change of total score from the Repeatable Battery for the Assessment of Neuropsychological Status (RBANS) before and after training. Feedback on the usability and acceptability questionnaire was positive. No adverse events were reported for all participants across all sessions. Though the median difference in the RBANS change scores between arms was not statistically significant, an effect size of 0.6SD was obtained, which reflects potential clinical utility according to Simon\u2019s randomized phase II trial design. Pooled data from both arms also showed that the median change in total scores pre and post-training was statistically significant (Mdn\u00a0\u2026", "There are two main approaches to design a neural fuzzy system; namely, through expert knowledge, and through numerical data. While the computational structure of a system is manually crafted by human experts in the former case, self-organizing neural fuzzy systems that are able to automatically extract generalized knowledge from batches of numerical training data are proposed for the latter. Nevertheless, both of these approaches are static where only parameters of a system are updated during training. On the other hand, the demands and complexities of real-life applications often require a neural fuzzy system to adapt both its parameters and structure to model the changing dynamics of the environment. To counter these modeling bottlenecks, intense research efforts are subsequently channeled into the studies of evolving/online neural fuzzy systems. There are generally two classes of evolving neural fuzzy\u00a0\u2026", "Multivariate pattern analysis approaches toward detection of brain regions from fMRI data have been gaining attention recently. In this study, we introduce an iterative sparse-representation-based algorithm for detection of voxels in functional MRI (fMRI) data with task relevant information. In each iteration of the algorithm, a linear programming problem is solved and a sparse weight vector is subsequently obtained. The final weight vector is the mean of those obtained in all iterations. The characteristics of our algorithm are as follows: 1) the weight vector (output) is sparse; 2) the magnitude of each entry of the weight vector represents the significance of its corresponding variable or feature in a classification or regression problem; and 3) due to the convergence of this algorithm, a stable weight vector is obtained. To demonstrate the validity of our algorithm and illustrate its application, we apply the algorithm to the\u00a0\u2026", "In our every day life, our brain is constantly processing information and paying attention, reacting accordingly, to all sorts of sensory inputs (auditory, visual, etc.). In some cases, there is a need to accurately measure a person's level of attention to monitor a sportsman performance, to detect Attention Deficit Hyperactivity Disorder (ADHD) in children, to evaluate the effectiveness of neuro-feedback treatment, etc.", "A major challenge in EEG-based brain-computer interfaces (BCIs) is the intersession nonstationarity in the EEG data that often leads to deteriorated BCI performances. To address this issue, this letter proposes a novel data space adaptation technique, EEG data space adaptation (EEG-DSA), to linearly transform the EEG data from the target space (evaluation session), such that the distribution difference to the source space (training session) is minimized. Using the Kullback-Leibler (KL) divergence criterion, we propose two versions of the EEG-DSA algorithm: the supervised version, when labeled data are available in the evaluation session, and the unsupervised version, when labeled data are not available. The performance of the proposed EEG-DSA algorithm is evaluated on the publicly available BCI Competition IV data set IIa and a data set recorded from 16 subjects performing motor imagery tasks on\u00a0\u2026", "Feature extraction has been a crucial and challenging task for EEG-based BCI applications mainly due to the problems of high-dimensionality and high noise level of EEG signals. In this paper we developed a novel feature extraction algorithm for EEG-based emotion detection problem. The proposed algorithm is derived from viewing EEG signals as the activation/deactivation of sources specific to the brain activities of interest. For binary classification problem, to be more specific, we consider the EEG signals for the two types of brain activities as characterized by the activation/deactivation of two discriminatory sources in the brain, with one source activated and the other one deactivated for one particular type of brain activities. The proposed algorithm, termed Asymmetric Spatial Pattern (ASP), extracts pairs of spatial filters, with each filter corresponding to only one of the two sources. The idea of ASP is\u00a0\u2026", "The success of deep learning (DL) methods in the Brain-Computer Interfaces (BCI) field for classification of electroencephalographic (EEG) recordings has been restricted by the lack of large datasets. Privacy concerns associated with EEG signals limit the possibility of constructing a large EEG-BCI dataset by the conglomeration of multiple small ones for jointly training machine learning models. Hence, in this paper, we propose a novel privacy-preserving DL architecture named federated transfer learning (FTL) for EEG classification that is based on the federated learning framework. Working with the single-trial covariance matrix, the proposed architecture extracts common discriminative information from multi-subject EEG data with the help of domain adaptation techniques. We evaluate the performance of the proposed architecture on the PhysioNet dataset for 2-class motor imagery classification. While avoiding the\u00a0\u2026", "This paper proposes a feature extraction method for motor imagery brain-computer interface (BCI) using electroencephalogram. We consider the primary neurophysiologic phenomenon of motor imagery, termed event-related desynchronization, and formulate the learning task for feature extraction as maximizing the mutual information between the spatio-spectral filtering parameters and the class labels. After introducing a nonparametric estimate of mutual information, a gradient-based learning algorithm is devised to efficiently optimize the spatial filters in conjunction with a band-pass filter. The proposed method is compared with two existing methods on real data: a BCI Competition IV dataset as well as our data collected from seven human subjects. The results indicate the superior performance of the method for motor imagery classification, as it produced higher classification accuracy with statistical significance\u00a0\u2026", "An important challenge in developing a movement-related cortical potential (MRCP)-based brain-machine interface (BMI) is an accurate decoding of the user intention for real-world environments. However, the performance remains insufficient for real-time decoding owing to the endogenous signal characteristics compared to other BMI paradigms. This study aims to enhance the MRCP decoding performance from the perspective of preprocessing techniques (i.e., spectral filtering). To the best of our knowledge,existing MRCP studies have used spectral filters with a fixed frequency bandwidth for all subjects. Hence, we propose a subject-dependent and section-wise spectral filtering (SSSF) method that considers the subjects' individual MRCP characteristics for two different temporal sections. In this study, MRCP data were acquired under a powered exoskeleton environments in which the subjects conducted self\u00a0\u2026", "For many electroencephalogram (EEG)-based brain-computer interfaces (BCIs), a tedious and time-consuming training process is needed to set parameters. In BCI Competition 2005, reducing the training process was explicitly proposed as a task. Furthermore, an effective BCI system needs to be adaptive to dynamic variations of brain signals; that is, its parameters need to be adjusted online. In this article, we introduce an extended expectation maximization (EM) algorithm, where the extraction and classification of common spatial pattern (CSP) features are performed jointly and iteratively. In each iteration, the training data set is updated using all or part of the test data and the labels predicted in the previous iteration. Based on the updated training data set, the CSP features are reextracted and classified using a standard EM algorithm. Since the training data set is updated frequently, the initial training data set can\u00a0\u2026", "Acoustic speech output results from coordinated articulation of dozens of muscles, bones and cartilages of the vocal mechanism. While we commonly take the fluency and speed of our speech productions for granted, the neural mechanisms facilitating the requisite muscular control are not completely understood. Previous neuroimaging and electrophysiology studies of speech sensorimotor control has typically concentrated on speech sounds (i.e., phonemes, syllables and words) in isolation; sentence-length investigations have largely been used to inform coincident linguistic processing. In this study, we examined the neural representations of segmental features (place and manner of articulation, and voicing status) in the context of fluent, continuous speech production. We used recordings from the cortical surface [electrocorticography (ECoG)] to simultaneously evaluate the spatial topography and temporal dynamics of the neural correlates of speech articulation that may mediate the generation of hypothesized gestural or articulatory scores. We found that the representation of place of articulation involved broad networks of brain regions during all phases of speech production: preparation, execution and monitoring. In contrast, manner of articulation and voicing status were dominated by auditory cortical responses after speech had been initiated. These results provide a new insight into the articulatory and auditory processes underlying speech production in terms of their motor requirements and acoustic correlates.", "Objective This randomized controlled feasibility study investigates the ability for clinical application of the Brain-Computer Interface-based Soft Robotic Glove (BCI-SRG) incorporating activities of daily living (ADL)-oriented tasks for stroke rehabilitation. Methods Eleven recruited chronic stroke patients were randomized into BCI-SRG or Soft Robotic Glove (SRG) group. Each group underwent 120-minute intervention per session comprising 30-minute standard arm therapy and 90-minute experimental therapy (BCI-SRG or SRG). To perform ADL tasks, BCI-SRG group used motor imagery-BCI and SRG, while SRG group used SRG without motor imagery-BCI. Both groups received 18 sessions of intervention over 6 weeks. Fugl-Meyer Motor Assessment (FMA) and Action Research Arm Test (ARAT) scores were measured at baseline (week 0), post- intervention (week 6), and follow-ups (week 12 and 24). In total, 10/11\u00a0\u2026", "Clinical studies had shown that EEG-based motor imagery Brain-Computer Interface (MI-BCI) combined with robotic feedback is effective in upper limb stroke rehabilitation, and transcranial Direct Current Stimulation (tDCS) combined with other rehabilitation techniques further enhanced the facilitating effect of tDCS. This motivated the current clinical study to investigate the effects of combining tDCS with MI-BCI and robotic feedback compared to sham-tDCS for upper limb stroke rehabilitation. The stroke patients recruited were randomized to receive 20 minutes of tDCS or sham-tDCS prior to 10 sessions of 1-hour MI-BCI with robotic feedback for 2 weeks. The online accuracies of detecting motor imagery from idle condition were assessed and offline accuracies of classifying motor imagery from background rest condition were assessed from the EEG of the evaluation and therapy parts of the 10 rehabilitation sessions\u00a0\u2026", "In this paper, we propose a new algorithm for Brain-Computer Interface (BCI): Spatially Regularized Common Spatial Patterns (SRCSP). SRCSP is an extension of the famous CSP algorithm which includes spatial a priori in the learning process, by adding a regularization term which penalizes spatially non smooth filters. We compared SRCSP and CSP algorithms on data of 14 subjects from BCI competitions. Results suggested that SRCSP can improve performances, around 10% more in classification accuracy, for subjects with poor CSP performances. They also suggested that SRCSP leads to more physiologically relevant filters than CSP.", "A major limitation of current Brain-Computer Interfaces (BCI) based on Motor Imagery (MI) is that they are subject-specific BCI, which require data recording and system training for each new user. This process is time consuming and inconvenient, especially for casual users or portable BCI with limited computational resources. In this paper, we explore the design of a Subject-Independent (SI) MI-based BCI, i.e., a BCI that can be used immediately by any new user without training the BCI with the user's data. This is achieved by training the BCI on data acquired from several other subjects. In order to assess the possibility to build such a BCI, we compared several designs based on different features and classifiers, on data from 9 subjects. Our results suggested that linear classifiers were the most appropriate for the design of MI-based SI-BCI. We also proposed a filter bank common spatial patterns feature extraction\u00a0\u2026", "Improving classification accuracy is a key issue to advancing brain computer interface (BCI) research from laboratory to real world applications. This work presents a high accuracy EEG signal classification method using single trial EEC signal to detect left and right finger movement. We apply an optimal temporal filter to remove irrelevant signal and subsequently extract key features from spatial patterns of EEG signal to perform classification. Specifically, the proposed method transforms the original EEG signal into a spatial pattern and applies the RBF feature selection method to generate robust feature. Classification is performed by the SVM and our experimental result shows that the classification accuracy of the proposed method reaches 90% as compared to the current reported best accuracy of 84%.", "Majority of children with attention deficit hyperactivity disorder (ADHD) have significant inattentive symptoms. We developed a progressive series of activities involving brain-computer interface-based games which could train users to improve their concentration. This pilot study investigated if the intervention could be utilized in children and if it could improve inattentive symptoms of ADHD. Ten medication-naive children aged 7 to 12 diagnosed with ADHD (combined or inattentive subtypes) received 20 sessions of therapy over a 10-week period. They were compared with age-and gendermatched controls. Both parent and teacher-rated inattentive score on the ADHD Rating Scale-IV improved more in the intervention group. A larger scale trial is warranted to further investigate the efficacy of our treatment programme in treating ADHD. Psychopharmacology Bulletin. 2010; 43 (1): 73\u201382.", "In recent years, electromyography (EMG)-based practical myoelectric interfaces have been developed to improve the quality of daily life for people with physical disabilities. With these interfaces, it is very important to decode a user's movement intention, to properly control the external devices. However, improving the performance of these interfaces is difficult due to the high variations in the EMG signal patterns caused by intra-user variability. Therefore, this paper proposes a novel subject-transfer framework for decoding hand movements, which is robust in terms of intra-user variability. In the proposed framework, supportive convolutional neural network (CNN) classifiers, which are pre-trained using the EMG data of several subjects, are selected and fine-tuned for the target subject via single-trial analysis. Then, the target subject's hand movements are classified by voting the outputs of the supportive CNN\u00a0\u2026", "This paper presents a novel approach which uses brain computer interface (BCI) technology to translate the user's mental conditions, especially the attention state, into game control. Leveraging on BCI engine to measure a user's attention level to control a virtual hand's movement and utilizing 3D animation technique, the proposed system is significant for training those who suffering from Attention Deficit Hyperactivity Disorder (ADHD). Comparing to robotic based system, the proposed system is cost-effective, interesting, and ease of use. It also can be extended for rehabilitating the people with neurological disorders, such as those debilitating traumatic events. Potentially, millions people may benefit from the system. The system structure and experimental results will be illustrated in this paper. To our knowledge, no same system is reported yet.", "Spatial filtering for EEG feature extraction and classification is an important tool in brain-computer interface. However, there is generally no established theory that links spatial filtering directly to Bayes classification error. To address this issue, this paper proposes and studies a Bayesian analysis theory for spatial filtering in relation to Bayes error. Following the maximum entropy principle, we introduce a gamma probability model for describing single-trial EEG power features. We then formulate and analyze the theoretical relationship between Bayes classification error and the so-called Rayleigh quotient, which is a function of spatial filters and basically measures the ratio in power features between two classes. This paper also reports our extensive study that examines the theory and its use in classification, using three publicly available EEG data sets and state-of-the-art spatial filtering techniques and various\u00a0\u2026", "Objective The non-stationary nature of EEG poses a major challenge to robust operation of brain\u2013computer interfaces (BCIs). The objective of this paper is to propose and investigate a computational method to address non-stationarity in EEG classification. Approach We developed a novel dynamically weighted ensemble classification (DWEC) framework whereby an ensemble of multiple classifiers are trained on clustered features. The decisions from these multiple classifiers are dynamically combined based on the distances of the cluster centres to each test data sample being classified. Main Results The clusters of the feature space from the second session spanned a different space compared to the clusters of the feature space from the first session which highlights the processes of session-to-session non-stationarity. The session-to-session performance of the proposed DWEC method was evaluated on two\u00a0\u2026", "This paper describes a control hierarchy to drive a wheelchair using an interface with asynchronous and very low information transfer rate signal. Path guiding assistance allows the user to bring his or her wheelchair in a building environment, from one destination to the next destination. The user can stop the wheelchair voluntarily during movement, or through a reflex elicited by sensors. Decisions are simplified by presenting only the possible selections on the GUI, in a context dependent menu. This system is implemented on a conventional wheelchair with a P300 Brain Machine Interface. Tests with healthy subjects show that this system can move the wheelchair in a typical building environment according to the wishes of its user, and that the brain control is not disturbed by the movement.", "Convolutional neural networks (CNNs) have recently been applied to electroencephalogram (EEG)-based brain\u2013computer interfaces (BCIs). EEG is a noninvasive neuroimaging technique, which can be used to decode user intentions. Because the feature space of EEG data is highly dimensional and signal patterns are specific to the subject, appropriate methods for feature representation are required to enhance the decoding accuracy of the CNN model. Furthermore, neural changes exhibit high variability between sessions, subjects within a single session, and trials within a single subject, resulting in major issues during the modeling stage. In addition, there are many subject-dependent factors, such as frequency ranges, time intervals, and spatial locations at which the signal occurs, which prevent the derivation of a robust model that can achieve the parameterization of these factors for a wide range of subjects\u00a0\u2026", "Brain-computer interface-assisted motor imagery (MI-BCI) or transcranial direct current stimulation (tDCS) has been used in stroke rehabilitation, though their combinatory effect is unknown. We investigated brain plasticity following a combined MI-BCI and tDCS intervention in chronic subcortical stroke patients with unilateral upper limb disability. Nineteen patients were randomized into tDCS and sham-tDCS groups. Diffusion and perfusion MRI, and transcranial magnetic stimulation were used to study structural connectivity, cerebral blood flow (CBF), and corticospinal excitability, respectively, before and 4 weeks after the 2-week intervention. After quality control, thirteen subjects were included in the CBF analysis. Eleven healthy controls underwent 2 sessions of MRI for reproducibility study. Whereas motor performance showed comparable improvement, long-lasting neuroplasticity can only be detected in the tDCS\u00a0\u2026", "A brain-computer-interface (BCI)-based attention training game system has shown promise for treating attention deficit/hyperactivity disorder (ADHD) children with inattentive symptoms. However, little is known about brain network organizational changes underlying behavior improvement following BCI-based training. To cover this gap, we aimed to examine the topological alterations of large-scale brain functional networks induced by the 8-week BCI-based attention intervention in ADHD boys using resting-state functional magnetic resonance imaging method. Compared to the non-intervention (ADHD-NI) group, the intervention group (ADHD-I) showed greater reduction of inattention symptoms accompanied with differential brain network reorganizations after training. Specifically, the ADHD-NI group had increased functional connectivity (FC) within the salience/ventral attention network (SVN) and increased FC\u00a0\u2026", "This paper describes an initial study of non-invasive electroencephalograph (EEG)-based Brain Computer Interface (BCI) application on Stroke patients. The purpose of this study is to combine BCI and robotic arm for after-stroke rehabilitation exercises. A clinically-proven MANUS robotic rehabilitation shell is integrated with the NeuroComm BCI platform, whereby the robotic control mechanism is complemented by the motor imagery of the patient. 8 hemiparetic stroke patients with varying degrees of paralysis on the unilateral upper extremity are recruited for this study. The results show that most BCI-na\u00efve hemiparetic stroke patients are capable of operating the BCI effectively, hence motivates further clinical studies on the extent of how BCI-based robotic rehabilitation are comparable with the control group that uses only robotic rehabilitation.", "Emotions play a critical role in rational and intelligent behavior; a better fundamental knowledge of them is indispensable for understanding higher order brain function. We propose a non-invasive brain-computer interface (BCI) system to feedback a person\u2019s affective state such that a closed-loop interaction between the participant\u2019s brain responses and the musical stimuli is established. We realized this concept technically in a functional prototype of an algorithm that generates continuous and controllable patterns of synthesized affective music in real-time, which is embedded within a BCI architecture. We evaluated our concept in two separate studies. In the first study, we tested the efficacy of our music algorithm by measuring subjective affective responses from 11 participants. In a second pilot study, the algorithm was embedded in a real-time BCI architecture to investigate affective closed-loop interactions in 5 participants. Preliminary results suggested that participants were able to intentionally modulate the musical feedback by self-inducing emotions (e.g., by recalling memories), suggesting that the system was able not only to capture the listener\u2019s current affective state in real-time, but also potentially provide a tool for listeners to mediate their own emotions by interacting with music. The proposed concept offers a tool to study emotions in the loop, promising to cast a complementary light on emotion-related brain research, particularly in terms of clarifying the interactive, spatio-temporal dynamics underlying affective processing in the brain.", "The focus of this paper is on joint feature re-extraction and classification in cases when the training data set is small. An iterative semi-supervised support vector machine (SVM) algorithm is proposed, where each iteration consists both feature re-extraction and classification, and the feature re-extraction is based on the classification results from the previous iteration. Feature extraction is first discussed in the framework of Rayleigh coefficient maximization. The effectiveness of common spatial pattern (CSP) feature, which is commonly used in Electroencephalogram (EEG) data analysis and EEG-based brain computer interfaces (BCIs), can be explained by Rayleigh coefficient maximization. Two other features are also defined using the Rayleigh coefficient. These features are effective for discriminating two classes with different means or different variances. If we extract features based on Rayleigh coefficient\u00a0\u2026", "Objective Studies have shown that low frequency components of brain recordings provide information on voluntary hand movement directions. However, non-invasive techniques face more challenges compared to invasive techniques. Approach This study presents a novel signal processing technique to extract features from non-invasive electroencephalography (EEG) recordings for classifying voluntary hand movement directions. The proposed technique comprises the regularized wavelet-common spatial pattern algorithm to extract the features, mutual information-based feature selection, and multi-class classification using the Fisher linear discriminant. EEG data from seven healthy human subjects were collected while they performed voluntary right hand center-out movement in four orthogonal directions. In this study, the movement direction dependent signal-to-noise ratio is used as a parameter to denote the\u00a0\u2026", "Synthesis of materials with minimum number of trials is of paramount importance towards the acceleration of advanced materials development. The enormous complexity involved in existing multi-variable synthesis methods leads to high uncertainty, numerous trials and exorbitant cost. Recently, machine learning (ML) has demonstrated tremendous potential for material discovery and property enhancement. Here, we extend the application of ML to guide material synthesis process through the establishment of the methodology including model construction, optimization, and progressive adaptive model (PAM). Two representative multi-variable systems are studied. A classification ML model on chemical vapor grown MoS2 is developed, capable of optimizing the synthesis conditions to achieve a higher success rate. And a regression model is constructed on the hydrothermal-grown carbon quantum dots, to enhance\u00a0\u2026", "With the availability of multiple rehabilitative interventions, identifying the one that elicits the best motor outcome based on the unique neuro-clinical profile of the stroke survivor is a challenging task. Predicting the potential of recovery using biomarkers specific to an intervention hence becomes important. To address this, we investigate intervention-specific prognostic and monitory biomarkers of motor function improvements using quantitative electroencephalography (QEEG) features in 19 chronic stroke patients following two different upper extremity rehabilitative interventions viz. Brain-computer interface (BCI) and transcranial direct current stimulation coupled BCI (tDCS-BCI). Brain symmetry index was found to be the best prognostic QEEG for clinical gains following BCI intervention (r = -0.80, p = 0.02), whereas power ratio index (PRI) was observed to be the best predictor for tDCS-BCI (r = -0.96, p = 0.004\u00a0\u2026", "Brain-Computer Interface (BCI) is an alternative communication and control channel between brain and computer which finds applications in neuroprosthetics, brain wave controlled computer games etc. This paper proposes an Electroencephalogram (EEG) based neurofeedback computer game that allows the player to control the game with the help of attention based brain signals. The proposed game protocol requires the player to memorize a set of numbers in a matrix, and to correctly fill the matrix using his attention. The attention level of the player is quantified using sample entropy features of EEG. The statistically significant performance improvement of five healthy subjects after playing a number of game sessions demonstrates the effectiveness of the proposed game in enhancing their concentration and memory skills.", "Brain-computer interface (BCI) technology has the potential as a post-stroke rehabilitation tool, and the efficacy of the technology is most often demonstrated through output peripherals such as robots, orthosis and computers. In this study, the EEG signals recorded during the course of upper limb stroke rehabilitaion using motor imagery BCI were analyzed to better understand the effect of BCI therapy for post-stroke rehabilitation. The stroke patients recruited underwent 10 sessions of 1-hour BCI with robotic feedback for 2 weeks, 5 times a week. The analysis was performed by computing the coherences of the EEG in the lesion and contralesion side of the hemisphere from each session, and the coherence index of the lesion hemisphere (0 \u2264 CI \u2264 1) was computed. The coherence index represents the rate of activation of the lesion hemisphere, and the correlation with the Fugl-Meyer assessment (FMA) before and\u00a0\u2026", "Accumulating evidence suggests brain network dysfunction in attention-deficit/hyperactivity disorder (ADHD). Whether large-scale brain network connectivity patterns reflect clinical heterogeneity in ADHD remains to be fully understood. This study aimed to characterize the differential within- and between-network functional connectivity (FC) changes in children with ADHD combined (ADHD-C) or inattentive (ADHD-I) subtypes and their associations with ADHD symptoms. We studied the task-free functional magnetic resonance imaging (fMRI) data of 58 boys with ADHD and 28 demographically matched healthy controls. We measured within- and between-network connectivity of both low-level (sensorimotor) and high-level (cognitive) large-scale intrinsic connectivity networks and network modularity. We found that children with ADHD-C but not those with ADHD-I exhibited hyper-connectivity within the anterior default\u00a0\u2026", "There are generally two approaches to the design of a neural fuzzy system: (1) design by human experts, and (2) design through a self-organization of the numerical training data. While the former approach is highly subjective, the latter is commonly plagued by one or more of the following major problems: (1) an inconsistent rulebase; (2) the need for prior knowledge such as the number of clusters to be computed; (3) heuristically designed knowledge acquisition methodologies; and (4) the stability-plasticity tradeoff of the system. This paper presents a novel self-organizing neural fuzzy system, named Self-Adaptive Fuzzy Inference Network (SaFIN), to address the aforementioned deficiencies. The proposed SaFIN model employs a new clustering technique referred to as categorical learning-induced partitioning (CLIP), which draws inspiration from the behavioral category learning process demonstrated by humans\u00a0\u2026", "Objective  Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs) allow control of several applications by decoding neurophysiological phenomena, which are usually recorded by electroencephalography (EEG) using a non-invasive technique. Despite significant advances in MI-based BCI, EEG rhythms are specific to a subject and various changes over time. These issues point to significant challenges to enhance the classification performance, especially in a subject-independent manner.  Methods  To overcome these challenges, we propose MIN2Net, a novel end-to-end multi-task learning to tackle this task. We integrate deep metric learning into a multi-task autoencoder to learn a compact and discriminative latent representation from EEG and perform classification simultaneously.  Results  This approach reduces the complexity in pre-processing, results in significant performance\u00a0\u2026", "Background Depression has become a leading mental disorder worldwide. Evidence has shown that subjects with depression exhibit different spatial responses in neurophysiological signals from the healthy controls when they are exposed to positive and negative stimuli. Methods We proposed an effective electroencephalogram-based detection method for depression classification using spatial information. A face-in-the-crowd task, including positive and negative emotional facial expressions, was presented to 30 participants, including 16 depression patients and 14 healthy controls. Differential entropy and the genetic algorithm were used for feature extraction and selection, and a support vector machine was used for classification. A task-related common spatial pattern (TCSP) was proposed to enhance the spatial differences before the feature extraction. Results and discussion We achieved a leave-one-subject\u00a0\u2026", "Objective The use of brain-computer interface in neurofeedback therapy for attention deficit hyperactivity disorder (ADHD) is a relatively new approach. We conducted a randomized controlled trial (RCT) to determine whether an 8-week brain computer interface (BCI)-based attention training program improved inattentive symptoms in children with ADHD compared to a waitlist-control group, and the effects of a subsequent 12-week lower-intensity training. Study design We randomized 172 children aged 6\u201312 attending an outpatient child psychiatry clinic diagnosed with inattentive or combined subtypes of ADHD and not receiving concurrent pharmacotherapy or behavioral intervention to either the intervention or waitlist-control group. Intervention involved 3 sessions of BCI-based training for 8 weeks, followed by 3 training sessions per month over the subsequent 12 weeks. The waitlist-control group received similar 20-week intervention after a wait-time of 8 weeks. Results The participants\u2019 mean age was 8.6 years (SD = 1.51), with 147 males (85.5%) and 25 females (14.5%). Modified intention to treat analyzes conducted on 163 participants with at least one follow-up rating showed that at 8 weeks, clinician-rated inattentive symptoms on the ADHD-Rating Scale (ADHD-RS) was reduced by 3.5 (SD 3.97) in the intervention group compared to 1.9 (SD 4.42) in the waitlist-control group (between-group difference of 1.6; 95% CI 0.3 to 2.9 p = 0.0177). At the end of the full 20-week treatment, the mean reduction (pre-post BCI) of the pooled group was 3.2 (95% CI 2.4 to 4.1). Conclusion The results suggest that the BCI-based attention training\u00a0\u2026", "The high temporal resolution and the asymmetric spatial activations are essential attributes of electroencephalogram (EEG) underlying emotional processes in the brain. To learn the temporal dynamics and spatial asymmetry of EEG towards accurate and generalized emotion recognition, we propose TSception, a multi-scale convolutional neural network that can classify emotions from EEG. TSception consists of dynamic temporal, asymmetric spatial, and high-level fusion layers, which learn discriminative representations in the time and channel dimensions simultaneously. The dynamic temporal layer consists of multi-scale 1D convolutional kernels whose lengths are related to the sampling rate of EEG, which learns the dynamic temporal and frequency representations of EEG. The asymmetric spatial layer takes advantage of the asymmetric EEG patterns for emotion, learning the discriminative global and\u00a0\u2026", "BackgroundOne of the main issues in motor imagery-based (MI-based) brain\u2013computer interface (BCI) systems is a large variation in the classification performance of BCI users. However, the exact reason of low performance of some users is still under investigation. Having some prior knowledge about the performance of users may be helpful in understanding possible reasons of performance variations.New methodIn this study a novel coefficient from pre-cue EEG rhythms is proposed. The proposed coefficient is computed from the spectral power of pre-cue EEG data for specific rhythms over different regions of the brain. The feasibility of predicting the classification performance of the MI-based BCI users from the proposed coefficient is investigated.ResultsGroup level analysis on N\u00a0=\u00a017 healthy subjects showed that there is a significant correlation r\u00a0=\u00a00.53 (p\u00a0=\u00a00.02) between the proposed coefficient and the cross\u00a0\u2026", "In Brain Computer Interfaces (BCIs), with multiple recordings from different subjects in hand, a question arises regarding whether the knowledge of previously recorded subjects can be transferred to a new subject. In this study, we explore the possibility of transferring knowledge by using a convolutional network model trained on multiple subjects and fine-tuning the model on a small amount of data from a new subject, thus, reducing the calibration time by reducing the time needed to record data and train a model. Our results show a significant increase in 4-class classification accuracy on the BCI IV-2a competition data, even when a small subset of the data is provided for training.", "This paper proposes a color-based video analytic system for quantifying limb movements in epileptic seizure monitoring. The system utilizes colored pyjamas to facilitate limb segmentation and tracking. Thus, it is unobtrusive and requires no sensor/marker attached to patient's body. We employ Gaussian mixture models in background/foreground modeling and detect limbs through a coarse-to-fine paradigm with graph-cut-based segmentation. Next, we estimate limb parameters with domain knowledge guidance and extract displacement and oscillation features from movement trajectories for seizure detection/analysis. We report studies on sequences captured in an epilepsy monitoring unit. Experimental evaluations show that the proposed system has achieved comparable performance to EEG-based systems in detecting motor seizures.", "Sleep monitoring is essential to people's health and wellbeing, which can also assist in the diagnosis and treatment of sleep disorder. Compared with contact-based solutions, contactless sleep monitoring does not attach any device to the human body; hence, it has attracted increasing attention in recent years. Inspired by the recent advances in Wi-Fi-based sensing, this article proposes a low-cost and nonintrusive sleep monitoring system using commodity Wi-Fi devices, namely, WiFi-Sleep. We leverage the fine-grained channel state information from multiple antennas and propose advanced fusion and signal processing methods to extract accurate respiration and body movement information. We introduce a deep learning method combined with clinical sleep medicine prior knowledge to achieve four-stage sleep monitoring with limited data sources (i.e., only respiration and body movement information). We\u00a0\u2026", "In this paper, we propose a deep learning framework, TSception, for emotion detection from electroencephalogram (EEG). TSception consists of temporal and spatial convolutional layers, which learn discriminative representations in the time and channel domains simultaneously. The temporal learner consists of multi-scale 1D convolutional kernels whose lengths are related to the sampling rate of the EEG signal, which learns multiple temporal and frequency representations. The spatial learner takes advantage of the asymmetry property of emotion responses at the frontal brain area to learn the discriminative representations from the left and right hemispheres of the brain. In our study, a system is designed to study the emotional arousal in an immersive virtual reality (VR) environment. EEG data were collected from 18 healthy subjects using this system to evaluate the performance of the proposed deep learning\u00a0\u2026", "Detecting motor imagery activities versus non-control in brain signals is the basis of self-paced brain-computer interfaces (BCIs), but also poses a considerable challenge to signal processing due to the complex and non-stationary characteristics of motor imagery as well as non-control. This paper presents a self-paced BCI based on a robust learning mechanism that extracts and selects spatio-spectral features for differentiating multiple EEG classes. It also employs a non-linear regression and post-processing technique for predicting the time-series of class labels from the spatio-spectral features. The method was validated in the BCI Competition IV on Dataset I where it produced the lowest prediction error of class labels continuously. This report also presents and discusses analysis of the method using the competition data set.", "The non-stationary nature of the electroencephalogram (EEG) poses a major challenge for the successful operation of a brain-computer interface (BCI) when deployed over multiple sessions. The changes between the early training measurements and the proceeding multiple sessions can originate as a result of alterations in the subject's brain process, new cortical activities, change of recording conditions and/or change of operation strategies by the subject. These differences and alterations over multiple sessions cause deterioration in BCI system performance if periodic or continuous adaptation to the signal processing is not carried out. In this work, the covariate shift is analyzed over multiple sessions to determine the non-stationarity effects and an unsupervised adaptation approach is employed to account for the degrading effects this might have on performance. To improve the system's online performance, we\u00a0\u2026", "While earlier Brain-Computer Interface (BCI) studies have mostly focused on modulating specific brain regions or signals, new developments in pattern classification of brain states are enabling real-time decoding and modulation of an entire functional network. The present study proposes a new method for real-time pattern classification and neurofeedback of brain states from electroencephalographic (EEG) signals. It involves the creation of a fused classification model based on the method of Common Spatial Patterns (CSPs) from data of several healthy individuals. The subject-independent model is then used to classify EEG data in real-time and provide feedback to new individuals. In a series of offline experiments involving training and testing of the classifier with individual data from 27 healthy subjects, a mean classification accuracy of 75.30% was achieved, demonstrating that the classification system at hand can reliably decode two types of imagery used in our experiments, i.e., happy emotional imagery and motor imagery. In a subsequent experiment it is shown that the classifier can be used to provide neurofeedback to new subjects, and that these subjects learn to \u201cmatch\u201d their brain pattern to that of the fused classification model in a few days of neurofeedback training. This finding can have important implications for future studies on neurofeedback and its clinical applications on neuropsychiatric disorders.", "Brain Computer Interface (BCI) provides an alternative communication and control method for people with severe motor disabilities. Motor imagery patterns are widely used in Electroencephalogram (EEG) based BCIs. These motor imagery activities are associated with variation in alpha and beta band power of EEG signals called Event Related Desynchronization/synchronization (ERD/ERS). The dominant frequency bands are subject-specific and therefore performance of motor imagery based BCIs are sensitive to both temporal filtering and spatial filtering. As the optimum filter is strongly subject-dependent, we propose a method that selects the subject-specific discriminative frequency components using time-frequency plots of Fisher ratio of two-class motor imagery patterns. We also propose a low complexity adaptive Finite Impulse Response (FIR) filter bank system based on coefficient decimation technique\u00a0\u2026", "In this paper, an electroencephalogram (EEG)-based brain computer interface (BCI) is proposed for two dimensional cursor control. The horizontal and vertical movements of the cursor are controlled by mu/beta rhythm and P300 potential respectively. The main advantages of this system are: (i) two almost independent control signals are produced simultaneously; (ii) the cursor can be moved from a random position to another random position in a screen. These advantages have been demonstrated in our experiment and data analysis.", "Lack of adequate training samples and noisy high-dimensional features are key challenges faced by Motor Imagery (MI) decoding algorithms for electroencephalogram (EEG) based Brain-Computer Interface (BCI). To address these challenges, inspired from neuro-physiological signatures of MI, this paper proposes a novel Filter-Bank Convolutional Network (FBCNet) for MI classification. FBCNet employs a multi-view data representation followed by spatial filtering to extract spectro-spatially discriminative features. This multistage approach enables efficient training of the network even when limited training data is available. More significantly, in FBCNet, we propose a novel Variance layer that effectively aggregates the EEG time-domain information. With this design, we compare FBCNet with state-of-the-art (SOTA) BCI algorithm on four MI datasets: The BCI competition IV dataset 2a (BCIC-IV-2a), the OpenBMI dataset, and two large datasets from chronic stroke patients. The results show that, by achieving 76.20% 4-class classification accuracy, FBCNet sets a new SOTA for BCIC-IV-2a dataset. On the other three datasets, FBCNet yields up to 8% higher binary classification accuracies. Additionally, using explainable AI techniques we present one of the first reports about the differences in discriminative EEG features between healthy subjects and stroke patients. Also, the FBCNet source code is available at https://github.com/ravikiran-mane/FBCNet.", "This paper introduces the design of a P300-based Brain-Computer Interface (BCI) system. Based on this system, two applications are implemented: a word speller and a remote control device, which are to assist physically disabled people to communicate and control. A number of specific implementation techniques are proposed to achieve good performance in terms of accuracy and reliability. The word speller can achieve a spelling rate of up to 4-6 letters per minute, while both applications achieve 99% accuracy in our experiments with healthy subjects.", "Actigraphy is a non-invasive method of monitoring circadian rhythms and motor activity. We systematically reviewed extant evidence until September 2018 pertaining to actigraphy use in schizophrenia, its clinical/biological correlates and posit future research directions. Within 38 included studies involving 2700 subjects, patients with schizophrenia generally have lower motor activity levels, poorer sleep quality and efficiency, increased sleep fragmentation and duration compared with healthy controls. Lowered motor activity and longer sleep duration in patients were associated with greater severity of negative symptoms. Less structured motor activity and decreased sleep quality were associated with greater severity of positive symptoms, worse cognitive functioning involving attention and processing speed, illness chronicity, higher antipsychotic dose, and poorer quality of life. Correlations of actigraphic\u00a0\u2026", "Motor imagery-based brain\u2013computer interface (MI-BCI) has been proposed as a rehabilitation tool to facilitate motor recovery in stroke. However, the calibration of a BCI system is a time-consuming and fatiguing process for stroke patients, which leaves reduced time for actual therapeutic interaction. Studies have shown that passive movement (PM) (i.e., the execution of a movement by an external agency without any voluntary motions) and motor imagery (MI) (i.e., the mental rehearsal of a movement without any activation of the muscles) induce similar EEG patterns over the motor cortex. Since performing PM is less fatiguing for the patients, this paper investigates the effectiveness of calibrating MI-BCIs from PM for stroke subjects in terms of classification accuracy. For this purpose, a new adaptive algorithm called filter bank data space adaptation (FB-DSA) is proposed. The FB-DSA algorithm linearly\u00a0\u2026", "Neurofeedback, the self-regulation of brain signals recorded using Electroencephalogram (EEG), allows Brain-Computer Interface (BCI) users to enhance cognitive as well as motor functions using specific training strategies. Therapeutic effects of neurofeedback (by the induction of neuroplasticity) on treatment of people with neurological disorders such as Attention-Deficit Hyperactive Disorder (ADHD), dementia and stroke have been reported in literature. In this paper, we investigate the impact of a neurofeedback based BCI game on the enhancement of attention and cognitive skills of healthy subjects. The BCI game is controlled by player's attention-related EEG signal. In the proposed training paradigm, subjects play the neurofeedback game regularly for a period of 5 days. The experimental analysis of player's attention level (measured by entropy values of EEG) and the comparison of cognitive test results\u00a0\u2026", "Electroencephalography (EEG) data are used to design useful indicators that act as proxies for detecting humans' mental activities. However, these electrical signals are susceptible to different forms of interferences-known as artifacts-from voluntarily and involuntarily muscle movements that greatly obscure the information in the signal. It is pertinent to design effective artifact removal techniques (ARTs) capable of removing or reducing the impact of these artifacts. However, most ARTs have been focusing on handling a few specific types, or a single type, of EEG artifacts. EEG processing that generalizes to multiple types of artifacts remains a major challenge. In this paper, we investigate a variety of eight different and typical artifacts that occur in practice. We characterize the spatiotemporal-frequency influence of these EEG artifacts and offer two heuristics. The proposed heuristics extend influential independent\u00a0\u2026", "Physiological sensor based workload estimation technology provides a real-time means for assessing cognitive workload and has a broad range of applications in cognitive ergonomics, mental health monitoring, etc. In this paper we report a study on detecting changes in workload using multi-modality physiological sensors and a novel feature extraction and classification algorithm. We conducted a cognitive workload experiment involving multiple subjects and collected an extensive data set of EEG, ECG and GSR signals. We show that the GSR signal is consistent with the variations of cognitive workload in 75% of the samples. To explore cardiac patterns in ECG that are potentially correlated with the cognitive workload process, we computed various heart-rate-variability features. To extract neuronal activity patterns in EEG related to cognitive workload, we introduced a filter bank common spatial pattern filtering\u00a0\u2026", "This clinical study investigates whether the performance of hemiparetic stroke patients operating a non-invasive Motor Imagery-based Brain-Computer Interface (MI-BCI) is comparable to healthy subjects. The study is performed on 8 healthy subjects and 35 BCI-na\u00efve hemiparetic stroke patients. This study also investigates whether the performance of the stroke patients in operating MI-BCI correlates with the extent of neurological disability. The performance is objectively computed from the 10\u00d710-fold cross-validation accuracy of employing the Filter Bank Common Spatial Pattern (FBCSP) algorithm on their EEG measurements. The neurological disability is subjectively estimated using the Fugl-Meyer Assessment (FMA) of the upper extremity. The results show that the performance of BCI-na\u00efve hemiparetic stroke patients is comparable to healthy subjects, and no correlation is found between the accuracy of their\u00a0\u2026", "Brain-computer interface has been always facing serious data-related problems such as lack of the sufficient data and data corruption. Artificial data generation is a potential solution to address these issues. Among generative techniques, the method of generative adversarial networks (GANs) with the successful applications in image processing has gained a lot of attention. The application of GANs for time-series data generation is a recent growing topic that first of all its feasibility needs to be assessed. In the present study, we investigate the performance of GANs in generating artificial electroencephalogram (EEG) signals. The results suggest that the generated EEG signals by GANs resemble the temporal, spectral, and spatial characteristics of real EEG. It thus opens new perspectives for further research in this area.", "Electroencephalography (EEG) based motor imagery Brain-Computer Interface (MI-BCI) paradigm is used to communicate with external device by people who lost peripheral nerve control, or perform neuro-rehabilitation for stroke patients. BCI systems based on motor imagery often employ feature extraction algorithms based on Common Spatial Patterns (CSP). CSP is capable of discriminating two classes, but it is sensitive to outliers and noisy trials. Therefore, regularisation is often deployed to improve the robustness and accuracy of CSP estimation. In this paper, a novel regularisation approach based on shrinkage estimation is presented in order to handle small sample problem and retain subject-specific discriminative features. In this method, an analytical solution for shrinkage estimation is provided, which not only is computationally tractable, but also overcomes the heuristic approach of traditional cross\u00a0\u2026", "Accurate and robust classification of Motor Imagery (MI) from Electroencephalography (EEG) signals is among the most challenging tasks in Brain-Computer Interface (BCI) field. To address this challenge, this paper proposes a novel, neuro-physiologically inspired convolutional neural network (CNN) named Filter-Bank Convolutional Network (FBCNet) for MI classification. Capturing neurophysiological signatures of MI, FBCNet first creates a multi-view representation of the data by bandpass-filtering the EEG into multiple frequency bands. Next, spatially discriminative patterns for each view are learned using a CNN layer. Finally, the temporal information is aggregated using a new variance layer and a fully connected layer classifies the resultant features into MI classes. We evaluate the performance of FBCNet on a publicly available dataset from Korea University for classification of left vs right hand MI in a subject\u00a0\u2026", "In an electroencephalogram (EEG)-based brain\u2013computer interface (BCI), motor imagery has been successfully used as a communication strategy. Motor imagery causes detectable amplitude changes in certain frequency bands of EEGs, which are dubbed event-related desynchronization\\synchronization. The frequency components that give effective discrimination between different types of motor imagery are subject specific and identification of these subject-specific discriminative frequency components (DFCs) is important for the accurate classification of motor imagery activities. In this paper, we propose a new method to estimate the DFC using the Fisher criterion and investigate the variability of these DFCs over multiple sessions of EEG recording. Observing the variability of DFC over sessions in the analysis, a new BCI approach called the Adaptively Weighted Spectral-Spatial Patterns (AWSSP) algorithm is\u00a0\u2026", "In this paper we propose a new design for P300-based BCI, in order to reduce the calibration time of the system. Our BCI is based on Regularized Canonical Correlation Analysis for feature extraction and Regularized Linear Discriminant Analysis for classification. Evaluations suggested that this design can reach good P300 detection performances while using much less training examples than current approaches, hence effectively reducing the calibration time.", "Electrooculogram (EOG) artifact contamination is a common critical issue in general electroencephalogram (EEG) studies as well as in brain-computer interface (BCI) research. It is especially challenging when dedicated EOG channels are unavailable or when there are very few EEG channels available for independent component analysis based ocular artifact removal. It is even more challenging to avoid loss of the signal of interest during the artifact correction process, where the signal of interest can be multiple magnitudes weaker than the artifact. To address these issues, we propose a novel discriminative ocular artifact correction approach for feature learning in EEG analysis. Without extra ocular movement measurements, the artifact is extracted from raw EEG data, which is totally automatic and requires no visual inspection of artifacts. Then, artifact correction is optimized jointly with feature extraction by\u00a0\u2026", "Common Spatial Pattern (CSP) is widely used in discriminating two classes of EEG in Brain Computer Interface applications. However, the performance of the CSP algorithm is affected by noise and artifacts, and the problem is more pronounced in small training data. To overcome these draw-backs, this paper proposes a new Spatially Sparsed CSP (SS-CSP) algorithm by inducing sparsity in the spatial filters. The proposed algorithm optimizes the spatial filters to emphasize the regions that have high variances between classes, and attenuates the regions with low or irregular variances which can be due to noise or artifacts. The experimental results on 14 subjects from publicly available BCI competition datasets showed that the proposed SSCSP algorithm significantly improved the performance of the subjects with poor CSP accuracy by an average of 11%. The results also showed that the obtained sparse spatial\u00a0\u2026", "Image segmentation is one of the most essential biomedical image processing problems for different imaging modalities, including microscopy and X-ray in the Internet-of-Medical-Things (IoMT) domain. However, annotating biomedical images is knowledge-driven, time-consuming, and labor-intensive, making it difficult to obtain abundant labels with limited costs. Active learning strategies come into ease the burden of human annotation, which queries only a subset of training data for annotation. Despite receiving attention, most of active learning methods still require huge computational costs and utilize unlabeled data inefficiently. They also tend to ignore the intermediate knowledge within networks. In this work, we propose a deep active semi-supervised learning framework, DSAL, combining active learning and semi-supervised learning strategies. In DSAL, a new criterion based on deep supervision mechanism\u00a0\u2026", "This paper presents a new approach to multilingual speech recognition. The proposed algorithm combines both language identification (LID) and speech recognition into a single process. It is shown to be effective for multilingual grammarbased speech recognition where the language information is not available prior to recognition. The idea is to make use of acoustic-phonetic and lexical information in each language to reduce possible mismatch caused by potential difference in acoustic and recording conditions when the training utterances for each language were collected. By doing so, it is shown that, with the help of LID information, the word error rate of a mixed Mandarin and English speech recognition system is greatly reduced. The same formulation can also be used to enhance language identification accuracy.", "Objective The various parameters that define a hand movement such as its trajectory, speed, etc, are encoded in distinct brain activities. Decoding this information from neurophysiological recordings is a less explored area of brain\u2013computer interface (BCI) research. Applying non-invasive recordings such as electroencephalography (EEG) for decoding makes the problem more challenging, as the encoding is assumed to be deep within the brain and not easily accessible by scalp recordings. Approach EEG based BCI systems can be developed to identify the neural features underlying movement parameters that can be further utilized to provide a detailed and well defined control command set to a BCI output device. A real-time continuous control is better suited for practical BCI systems, and can be achieved by continuous adaptive reconstruction of movement trajectory than discrete brain activity classifications. In this\u00a0\u2026", "Objective Detection of motor imagery of hand/arm has been extensively studied for stroke rehabilitation. This paper firstly investigates the detection of motor imagery of swallow (MI-SW) and motor imagery of tongue protrusion (MI-Ton) in an attempt to find a novel solution for post-stroke dysphagia rehabilitation. Detection of MI-SW from a simple yet relevant modality such as MI-Ton is then investigated, motivated by the similarity in activation patterns between tongue movements and swallowing and there being fewer movement artifacts in performing tongue movements compared to swallowing. Approach Novel features were extracted based on the coefficients of the dual-tree complex wavelet transform to build multiple training models for detecting MI-SW. The session-to-session classification accuracy was boosted by adaptively selecting the training model to maximize the ratio of between-classes distances versus\u00a0\u2026", "In this paper, we investigate the use of 2-channel frontal EEG signal to classify two music preferences: like and dislike. The hypothesis for this investigation is that the frontal EEG signal contains sufficient information on the mental state of a subject for discriminating the preference of music of the subject. An experiment is performed to collect 2-channel frontal EEG data from 12 subjects by playing various types of music pieces and asking whether they like or dislike the music in order to obtain the true labels of their music preferences. We then propose a frequency band optimization method called common frequency pattern (CFP) for feature extraction and Linear SVM for classification to identify the music preference of the subjects from the 2-channel frontal EEG. The results of using the proposed method yield an average classification accuracy of 74.77% for a trial length of 30 s over the 12 subjects. Hence the\u00a0\u2026", "The Filter Bank Common Spatial Pattern (FBCSP) algorithm employs multiple spatial filters to automatically select key temporal-spatial discriminative EEG characteristics and the Na\u00efve Bayesian Parzen Window (NBPW) classifier using offline learning in EEG-based Brain-Computer Interfaces (BCI). However, it has yet to address the non-stationarity inherent in the EEG between the initial calibration session and subsequent online sessions. This paper presents the FBCSP that employs the NBPW classifier using online adaptive learning that augments the training data with available labeled data during online sessions. However, employing semi-supervised learning that simply augments the training data with available data using predicted labels can be detrimental to the classification accuracy. Hence, this paper presents the FBCSP using online semi-supervised learning that augments the training data with available\u00a0\u2026", "This paper proposes a novel feature selection method based on two-stage analysis of Fisher ratio and mutual information for robust brain computer interface. This method decomposes multichannel brain signals into subbands. The spatial filtering and feature extraction is then processed in each subband. The two-stage analysis of Fisher ratio and mutual information is carried out in the feature domain to reject the noisy feature indexes and select the most informative combination from the remaining. In the approach, we develop two practical solutions, avoiding the difficulties of using high dimensional mutual information in the application, that are the feature indexes clustering using cross mutual information and the latter estimation based on conditional empirical PDF. We test the proposed feature selection method on two BCI data sets and the results are at least comparable to the best results in the literature. The\u00a0\u2026", "An important application of sparse representation is underdetermined blind source separation (BSS), where the number of sources is greater than the number of observations. Within the stochastic framework, this paper discusses recoverability of underdetermined BSS based on a two-stage sparse representation approach. The two-stage approach is effective when the source matrix is sufficiently sparse. The first stage of the two-stage approach is to estimate the mixing matrix, and the second is to estimate the source matrix by minimizing the 1-norms of the source vectors subject to some constraints. After estimating the mixing matrix and fixing the number of nonzero entries of a source vector, we estimate the recoverability probability (i.e., the probability that the source vector can be recovered). A general case is then considered where the number of nonzero entries of the source vector is fixed and the mixing matrix is\u00a0\u2026", "In this paper, to address the safety of brain-controlled vehicles under emergency situations, we propose a novel method of emergency situation detection by fusing driver electroencephalography (EEG) signals with surrounding information. We first build a novel EEG-based detection model of driver emergency braking intention. We then recognize emergency situations by fusing the result of the proposed EEG-based intention detection model with that of the obstacle detection model based on surrounding information. The real-time detection system of driver emergency braking intention is implemented on an embedded system, and the driver-and-hardware-in-the-loop-experiment of the proposed detection method of emergency situations is performed. Experimental results show that the proposed method can detect emergency situations with the system accuracy of 94.89%, false alarm rate of 0.05%, and response\u00a0\u2026", "This paper models in vivo neural signals and noise for extracellular spike detection. Although the recorded data approximately follow Gaussian distribution, they clearly deviate from white Gaussian noise due to neuronal synchronization and sparse distribution of spike energy. Our study predicts the coexistence of two components embedded in neural data dynamics, one in the exponential form (noise) and the other in the power form (neural spikes). The prediction of the two components has been confirmed in experiments of in vivo sequences recorded from the hippocampus, cortex surface, and spinal cord; both acute and long-term recordings; and sleep and awake states. These two components are further used as references for threshold estimation. Different from the conventional wisdom of setting a threshold at 3\u00d7 RMS, the estimated threshold exhibits a significant variation. When our algorithm was tested on\u00a0\u2026", null, "Individuals with tetraplegia lack independent mobility, making them highly dependent on others to move from one place to another. Here, we describe how two macaques were able to use a wireless integrated system to control a robotic platform, over which they were sitting, to achieve independent mobility using the neuronal activity in their motor cortices. The activity of populations of single neurons was recorded using multiple electrode arrays implanted in the arm region of primary motor cortex, and decoded to achieve brain control of the platform. We found that free-running brain control of the platform (which was not equipped with any machine intelligence) was fast and accurate, resembling the performance achieved using joystick control. The decoding algorithms can be trained in the absence of joystick movements, as would be required for use by tetraplegic individuals, demonstrating that the non-human primate model is a good pre-clinical model for developing such a cortically-controlled movement prosthetic. Interestingly, we found that the response properties of some neurons differed greatly depending on the mode of control (joystick or brain control), suggesting different roles for these neurons in encoding movement intention and movement execution. These results demonstrate that independent mobility can be achieved without first training on prescribed motor movements, opening the door for the implementation of this technology in persons with tetraplegia.", "Through certain mental actions, our electroencephalogram (EEG) can be regulated to operate a brain-computer interface (BCI), which translates the EEG patterns into commands that can be used to operate devices such as prostheses. This allows paralyzed persons to gain direct brain control of the paretic limb, which could open up many possibilities for rehabilitative and assistive applications. When using a BCI neuroprosthesis in stroke, one question that has surfaced is whether stroke patients are able to produce a sufficient change in EEG that can be used as a control signal to operate a prosthesis.", "This paper describes a control strategy to drive a wheelchair in a building environment by thought. The user selects the destination in a list of predefined locations of interest using a slow but safe P300 EEG interface. The robotic wheelchair navigates autonomously toward destination following virtual guiding paths. Along the way the user has the possibility to stop the movement using a fast \u03bc\u03b2-rhythm BCI. Experiments demonstrate how healthy subjects can navigate safely in an home-like environment using this novel hybrid BCI.", "The ability of automatic feature learning makes Convolutional Neural Network (CNN) potentially suitable to uncover the complex and widespread brain changes in schizophrenia. Despite that, limited studies have been done on schizophrenia identification using interpretable deep learning approaches on multimodal neuroimaging data. Here, we developed a deep feature approach based on pre-trained 2D CNN and naive 3D CNN models trained from scratch for schizophrenia classification by integrating 3D structural and diffusion magnetic resonance imaging (MRI) data. We found that the naive 3D CNN models outperformed the pretrained 2D CNN models and the handcrafted feature-based machine learning approach using support vector machine during both cross-validation and testing on an independent dataset. Multimodal neuroimaging-based models accomplished performance superior to models based on\u00a0\u2026", "The success of deep convolutional neural networks (DCNNs) benefits from high volumes of annotated data. However, annotating medical images is laborious, expensive, and requires human expertise, which induces the label scarcity problem. Especially When encountering the domain shift, the problem becomes more serious. Although deep unsupervised domain adaptation (UDA) can leverage well-established source domain annotations and abundant target domain data to facilitate cross-modality image segmentation and also mitigate the label paucity problem on the target domain, the conventional UDA methods suffer from severe performance degradation when source domain annotations are scarce. In this paper, we explore a challenging UDA setting - limited source domain annotations. We aim to investigate how to efficiently leverage unlabeled data from the source and target domains with limited\u00a0\u2026", null, "This paper presents a method of estimating heart rate from arrays of fiber Bragg grating (FBG) sensors embedded in a mat. A cepstral domain signal analysis technique is proposed to characterize Ballistocardiogram (BCG) signals. With this technique, the average heart beat intervals can be estimated by detecting the dominant peaks in the cepstrum, and the signals of multiple sensors can be fused together to obtain higher signal to noise ratio than each individual sensor. Experiments were conducted with 10 human subjects lying on 2 different postures on a bed. The estimated heart rate from BCG was compared with heart rate ground truth from ECG, and the mean error of estimation obtained is below 1 beat per minute (BPM). The results show that the proposed fusion method can achieve promising heart rate measurement accuracy and robustness against various sensor contact conditions.", "Speech is our most natural form of communication and even though functional Near Infrared Spectroscopy (fNIRS) is an increasingly popular modality for Brain Computer Interfaces (BCIs), there are, to the best of our knowledge, no previous studies on speech related tasks in fNIRS-based BCI. We conducted experiments on 5 subjects producing audible, silently uttered and imagined speech or do not produce any speech. For each of these speaking modes, we recorded fNIRS signals from the subjects performing these tasks and distinguish segments containing speech from those not containing speech, solely based on the fNIRS signals. Accuracies between 69% and 88% were achieved using support vector machines and a Mutual Information based Best Individual Feature approach. We are also able to discriminate the three speaking modes with 61% classification accuracy. We thereby demonstrate that speech is\u00a0\u2026", "The filter bank common spatial pattern (FBCSP) algorithm performs autonomous selection of key temporal-spatial discriminative EEG characteristics in motor imagery-based brain computer interfaces (MI-BCI). However, FBCSP is sensitive to outliers because it involves multiple estimations of covariance matrices from EEG measurements. This paper proposes a Robust FBCSP (RFBCSP) algorithm whereby the estimates of the covariance matrices are replaced with the robust minimum covariance determinant (MCD) estimator. The performance of RFBCSP is investigated on a publicly available dataset and compared against FBCSP using 10times10-fold cross-validation accuracies on training data, and session-to-session transfer kappa values on independent test data. The results showed that RFBCSP yielded improvements in certain subjects and slight improvement in overall performance across subjects. Analysis\u00a0\u2026", "Post-hoc analysis is a popular category in eXplainable artificial intelligence (XAI) study. In particular, methods that generate heatmaps have been used to explain the deep neural network (DNN), a black-box model. Heatmaps can be appealing due to the intuitive and visual ways to understand them but assessing their qualities might not be straightforward. Different ways to assess heatmaps' quality have their own merits and shortcomings. This paper introduces a synthetic dataset that can be generated adhoc along with the ground-truth heatmaps for more objective quantitative assessment. Each sample data is an image of a cell with easily recognized features that are distinguished from localization ground-truth mask, hence facilitating a more transparent assessment of different XAI methods. Comparison and recommendations are made, shortcomings are clarified along with suggestions for future research\u00a0\u2026", "Convolutional Neural Network (CNN) has been successfully applied on classification of both natural images and medical images but limited studies applied it to differentiate patients with schizophrenia from healthy controls. Given the subtle, mixed, and sparsely distributed brain atrophy patterns of schizophrenia, the capability of automatic feature learning makes CNN a powerful tool for classifying schizophrenia from controls as it removes the subjectivity in selecting relevant spatial features. To examine the feasibility of applying CNN to classification of schizophrenia and controls based on structural Magnetic Resonance Imaging (MRI), we built 3D CNN models with different architectures and compared their performance with a handcrafted feature-based machine learning approach. Support vector machine (SVM) was used as classifier and Voxel-based Morphometry (VBM) was used as feature for handcrafted\u00a0\u2026", "BackgroundThere is growing evidence that cognitive training (CT) can improve the cognitive functioning of the elderly. CT may be influenced by cultural and linguistic factors, but research examining CT programs has mostly been conducted on Western populations. We have developed an innovative electroencephalography (EEG)-based brain\u2013computer interface (BCI) CT program that has shown preliminary efficacy in improving cognition in 32 healthy English-speaking elderly adults in Singapore. In this second pilot trial, we examine the acceptability, safety, and preliminary efficacy of our BCI CT program in healthy Chinese-speaking Singaporean elderly.MethodsThirty-nine elderly participants were randomized into intervention (n=21) and wait-list control (n=18) arms. Intervention consisted of 24 half-hour sessions with our BCI-based CT training system to be completed in 8 weeks; the control arm received the\u00a0\u2026", "Brain-computer interface (BCI) technology has shown the capability of improving the quality of life for people with severe motor disabilities. To improve the portability and practicability of BCI systems, it is crucial to reduce the number of EEG channels as well as to have a good reliability. However, a relatively neglected issue in the EEG channel selection studies is the robustness of selected channels across sessions. This paper investigates whether the selected channels from first session is also useful for subsequent sessions on other days for a stroke patient. For this purpose, a new robust sparse common spatial pattern (RSCSP) algorithm is proposed for optimal EEG channel selection. Thereafter, the robustness of the proposed algorithm as well as 5 existing channel selection algorithms is investigated across 12 sessions data from 11 stroke patients who performed motor imagery based-BCI rehabilitation. The\u00a0\u2026", "Objective Brain signals can be used to extract relevant features to decode various limb movement parameters such as the direction of upper limb movements. Amplitude based feature extraction techniques have been used to study such motor activity of upper limbs whereas phase synchrony, used to estimate functional relationship between signals, has rarely been used to study single hand movements in different directions. Approach In this paper, a novel phase-locking-based feature extraction method, called wavelet phase-locking value (W-PLV) is proposed to analyse synchronous EEG channel-pairs and classify hand movement directions. EEG data collected from seven subjects performing right hand movements in four orthogonal directions in the horizontal plane is used for this analysis. Main results Our proposed W-PLV based method achieves a mean binary classification accuracy of 76.85% over seven\u00a0\u2026", "Background: Cognitive training has been demonstrated to improve cognitive performance in older adults. To date, no study has explored personalized training that targets the brain activity of each individual. Objective: This is the first large-scale trial that examines the usefulness of personalized n eurofeedback cognitive training. Methods: We conducted a randomized-controlled trial with participants who were 60\u201380 years old, with Clinical Dementia Rating (CDR) score of 0\u20130.5, Mini-Mental State Examination (MMSE) score of 24 and above, and with no neuropsychiatric diagnosis. Participants were randomly assigned to the Intervention or Waitlist-Control group. The training system, BRAINMEM, has attention, working memory, and delayed recall game components. The intervention schedule comprised 24 sessions over eight weeks and three monthly booster sessions. The primary outcome was the Repeatable\u00a0\u2026", "Non-stationarity of electroencephalograph (EEG) data from session-to-session transfer is one of the challenges for EEG-based brain-computer interface systems, which can inversely affect their performance. Among methods proposed to address non-stationarity, adaptation is a promising method. In this study, an adaptive extreme learning machine (AELM) is proposed to update the initial classifier from the calibration session by using chunks of EEG data from the evaluation session whereby the common spatial pattern (CSP) algorithm is used to extract the most discriminative features. The effectiveness of the proposed algorithm is on motor imagery data collected from 12 healthy subjects during a calibration session and an evaluation session on a separate day. The results from the proposed AELM were compared with non-adaptive ELM and SVM classifiers. The results showed that AELM was significantly better (p\u00a0\u2026", "The Electroencephalogram (EEG) based Brain Computer Interface (BCI) is a non-invasive system to acquire, decode and convert brain signals into control signals for an external device. The Motor-Imagery based BCI (MI-BCI) efficiently decodes the brain signals from the imagination of movement but the performance is limited by the number of commands such as right and left hand motor imageries. However, other parameters of an actual voluntary movement, such as the direction of movement, speed and extent, are encoded in the brain signals. This paper investigates the EEG brain signals from directional changes in actual hand movement. The Wavelet-Common Spatial Pattern algorithm is proposed to extract discriminative features of the brain signals that carries the direction-related information. The experiment performed on two subjects yielded a mean classification accuracy of 87.85% in decoding two classes\u00a0\u2026", "In this paper, we analyze the convergence of an iterative self-training semi-supervised support vector machine (SVM) algorithm, which is designed for classification in small training data case. This algorithm converges fast and has low computational burden. Its effectiveness is also demonstrated by our data analysis results. Furthermore, we illustrate that this algorithm can be used to significantly reduce training effort and improve adaptability of a brain computer interface (BCI) system, a P300-based speller.", "Deep learning has achieved promising segmentation performance on 3D left atrium MR images. However, annotations for segmentation tasks are expensive, costly and difficult to obtain. In this paper, we introduce a novel hierarchical consistency regularized mean teacher framework for 3D left atrium segmentation. In each iteration, the student model is optimized by multi-scale deep supervision and hierarchical consistency regularization, concurrently. Extensive experiments have shown that our method achieves competitive performance as compared with full annotation, outperforming other state-of-the-art semi-supervised segmentation methods.", "In this article, we provide an overview of electroencephalography (EEG) source imaging (ESI) of movement decoding for brain-computer interface (BCI) applications. The current state-of-the-art neuroimaging modality-functional magnetic resonance imaging (fMRI)-is expensive and nonportable and has poor temporal resolution. EEG, however, offers an attractive choice as a portable and cost-effective neuroimaging technique that delivers excellent temporal resolution, especially in reading dynamic human motor behavior.", "We developed and studied a Steady-State Visual Evoked Potential (SSVEP) based BCI system using a high frequency visual stimuli (>25Hz) design for reducing visual fatigue. Existing SSVEP based BCI designs primarily use low frequency visual stimuli (<;20Hz) for eliciting relatively higher SSVEP signal, while the low frequency stimuli can provocate photosensitivity epileptic seizure. On the other hand, high frequency stimuli are visually more comfortable and cause less visual fatigue and seizure. To detect the weak high frequency SSVEP signal, we used multi-channel EEG and introduced canonical correlation analysis to identify the elicited SSVEP frequency. We designed and built a 30-character SSVEP BCI speller system without calibration and evaluated the performance metrics including classification accuracy and subjective fatigue ratings, in both high-frequency and low frequency SSVEP modes. The result\u00a0\u2026", "The use of motor imagery-based brain computer interface has recently been shown to have potential for rehabilitation. This paper proposes a novel scheme to detect motor imagery of swallow from electroencephalography (EEG) signals for dysphagia rehabilitation. The proposed scheme extracts features from the coefficients of dual-tree complex wavelet transform (DT-CWT). A novel sliding window-based peak localization scheme is proposed to dynamically locate the initiation of tongue movement from Electromyography (EMG) signal. Subsequently, effective time segments are extracted from EEG signal for classification based on the detected dynamic initiation location. Comparisons are made between our proposed scheme with that of the three existing approaches. The results based on six healthy subjects show that an increase in averaged accuracy of 9.95% is achieved. Further, an increase in averaged\u00a0\u2026", "This clinical study investigates whether the spatial patterns of hemiparetic stroke patients operating a non-invasive Motor Imagery-based Brain Computer Interface (MI-BCI) is comparable to healthy subjects. The spatial patterns for a specific frequency range are generated using the common spatial pattern (CSP) algorithm, of which is highly successful for discriminating two classes of EEG measurements in MI-BCI. The spatial patterns illustrate how the presumed sources project on the scalp and are effective in verifying the neurophysiological plausibility of the computed solution. The spatial patterns show focused activity in ipsilateral as well as contralateral hemisphere with respect to the hand by tapping or motor imagery in 2 BCI-artful healthy subjects and 12 BCI-na\u00efve hemiparetic stroke patients. The results also show that neurophysiologically interpretable spatial patterns is more common in performing motor\u00a0\u2026", "Current neurorehabilitation models primarily rely on extended hospital stays and regular therapy sessions requiring close physical interactions between rehabilitation professionals and patients. The current COVID-19 pandemic has challenged this model, as strict physical distancing rules and a shift in the allocation of hospital resources resulted in many neurological patients not receiving essential therapy. Accordingly, a recent survey revealed that the majority of European healthcare professionals involved in stroke care are concerned that this lack of care will have a noticeable negative impact on functional outcomes. COVID-19 highlights an urgent need to rethink conventional neurorehabilitation and develop alternative approaches to provide high-quality therapy while minimizing hospital stays and visits. Technology-based solutions, such as, robotics bear high potential to enable such a paradigm shift. While robot-assisted therapy is already established in clinics, the future challenge is to enable physically assisted therapy and assessments in a minimally supervized and decentralized manner, ideally at the patient\u2019s home. Key enablers are new rehabilitation devices that are portable, scalable and equipped with clinical intelligence, remote monitoring and coaching capabilities. In this perspective article, we discuss clinical and technological requirements for the development and deployment of minimally supervized, robot-assisted neurorehabilitation technologies in patient\u2019s homes. We elaborate on key principles to ensure feasibility and acceptance, and on how artificial intelligence can be leveraged for embedding clinical knowledge for safe\u00a0\u2026", "Objective In electroencephalography (EEG)-based brain\u2013computer interface (BCI) systems for motor control tasks the conventional practice is to decode motor intentions by using scalp EEG. However, scalp EEG only reveals certain limited information about the complex tasks of movement with a higher degree of freedom. Therefore, our objective is to investigate the effectiveness of source-space EEG in extracting relevant features that discriminate arm movement in multiple directions. Approach We have proposed a novel feature extraction algorithm based on supervised factor analysis that models the data from source-space EEG. To this end, we computed the features from the source dipoles confined to Brodmann areas of interest (BA4a, BA4p and BA6). Further, we embedded class-wise labels of multi-direction (multi-class) source-space EEG to an unsupervised factor analysis to make it into a supervised learning\u00a0\u2026", "Any brain\u2013computer interface (BCI) system must translate signals from the users brain into messages or commands (see Fig. 1). Many signal processing and machine learning techniques have been developed for this signal translation, and this chapter reviews the most common ones. Although these techniques are often illustrated using electroencephalography (EEG) signals in this chapter, they are also suitable for other brain signals.", "Near-infrared spectroscopy (NIRS) enables non-invasive recording of cortical hemoglobin oxygenation in human subjects through the intact skull using light in the near-infrared range to determine. Recently, NIRS-based brain-computer interfaces are introduced for discriminating left and right-hand motor imagery. A neuroimaging study has also revealed event-related hemodynamic responses associated with the performance of mental arithmetic tasks. This paper proposes a novel BCI for detecting changes resulting from increases in the magnitude of operands used in a mental arithmetic task, using data from single-trial NIRS brain signals. We measured hemoglobin responses from 20 healthy subjects as they solved mental arithmetic problems with three difficulty levels. Accuracy in recognizing one difficulty level from another is then presented using 5\u00d75-fold cross-validations on the data collected. The results\u00a0\u2026", "Reducing the lateral scale of two-dimensional (2D) materials to one-dimensional (1D) has attracted substantial research interest not only to achieve competitive electronic applications but also for the exploration of fundamental physical properties. Controllable synthesis of high-quality 1D nanoribbons (NRs) is thus highly desirable and essential for further study. Here, we report the implementation of supervised machine learning (ML) for the chemical vapor deposition (CVD) synthesis of high-quality quasi-1D few-layered WTe2 NRs. Feature importance analysis indicates that H2 gas flow rate has a profound influence on the formation of WTe2, and the source ratio governs the sample morphology. Notably, the growth mechanism of 1T\u2032 few-layered WTe2 NRs is further proposed, which provides new insights for the growth of intriguing 2D and 1D tellurides and may inspire the growth strategies for other 1D\u00a0\u2026", null, "A device and method for generating a representation of a subject's attention level. The device measures brain signals from the subject; extracts temporal features from the brain signals; classifies the extracted temporal features using a classifier to give a score X 1; extracts spectral-spatial features from the brain signals; selects spectral-spatial features containing discriminative information between concentration and non-concentration states from the set of extracted spectral-spatial features; classifies the selected spectral-spatial features using a classifier to give a score X 2; combines the scores X 1 and X 2 to give a single score; and presents the score to the subject.", "This paper investigates the classification of voluntary facial expressions from electroencephalogram (EEG) and electromyogram (EMG) signals using the Filter Bank Common Spatial Pattern (FBCSP) algorithm. The FBCSP algorithm is an autonomous and effective machine learning approach for classifying two classes of EEG measurements in motor imagery-based Brain Computer Interface (BCI). However, the problem of facial expression recognition typically involves more than just two classes of measurements. Hence, this paper proposes an extension of FBCSP to the multiclass paradigm using a decision threshold-based classifier for classifying facial expressions from EEG and EMG measurements. A study is conducted using the proposed Multiclass FBCSP on 4 subjects who performed 6 different facial expressions. The results show that the Multiclass FBCSP is effective in classifying multiple facial expressions\u00a0\u2026", "Neuroengineering research over the last two decades has demonstrated promising evidence on the use of brain-computer interface (BCI) to enhance functional recovery and independence in individuals with motor impairments. By translating brain activity, BCI bypasses the impaired neuromotor system, to control computers/machines. BCI-controlled robots are designed for motor assistance to aid paralyzed patients as well as for rehabilitation to enhance motor recovery. In this article, we review the advances in BCI and brain controlled robotics for rehabilitation and assistance of upper and lower limb motor functions over the last five years. The article emphasizes on the emerging trends in BCI-controlled robotics to expand its intervention capabilities as well as to resolve existing challenges hindering its widespread clinical use.", "Studies had shown that Motor Imagery-based Brain Computer Interface (MI-based BCI) system can be used as a therapeutic tool such as for stroke rehabilitation, but had shown that not all subjects could perform MI well. Studies had also shown that MI and passive movement (PM) could similarly activate the motor system. Although the idea of calibrating MI-based BCI system from PM data is promising, there is an inherent difference between features extracted from MI and PM. Therefore, there is a need for online learning to alleviate the difference and improve the performance. Hence, in this study we propose an online batch mode semi-supervised learning with KL distance weighting to update the model trained from the calibration session by using unlabeled data from the online test session. In this study, the Filter Bank Common Spatial Pattern (FBCSP) algorithm is used to compute the most discriminative features\u00a0\u2026", "In machine learning based Brain Computer Interfaces (BCIs), it is a challenge to use only a small amount of labelled data to build a classifier for a specific subject. This challenge was specifically addressed in BCI Competition 2005 [3]. Moreover, an effective BCI system should be adaptive to tackle the dynamic variations in brain signal. One of the solutions is to have its parameters adjustable while the system is used online. In this paper we introduce a new semi-supervised support vector machine (SVM) learning algorithm. In this method, the feature extraction and classification are jointly performed in iterations. This method allows us to use a small training set to train the classifier while maintaining high performance. Therefore, the tedious initial calibration process is shortened. This algorithm can be used online to make the BCI system robust to possible signal changes. We analyze two important issues of the\u00a0\u2026", "Introduction: Transcranial direct current stimulation (tDCS) has been shown to modulate cortical plasticity, enhance motor learning and post-stroke upper extremity motor recovery. It has also been demonstrated to facilitate activation of brain-computer interface (BCI) in stroke patients. We had previously demonstrated that BCI-assisted motor imagery (MI-BCI) can improve upper extremity impairment in chronic stroke participants. This study was carried out to investigate the effects of priming with tDCS prior to MI-BCI training in chronic stroke patients with moderate to severe upper extremity paresis and to investigate the cortical activity changes associated with training. Methods: This is a double-blinded randomized clinical trial. Participants were randomized to receive 10 sessions of 20-min 1 mA tDCS or sham-tDCS before MI-BCI, with the anode applied to the ipsilesional, and the cathode to the contralesional primary motor cortex (M1). Upper extremity sub-scale of the Fugl-Meyer Assessment (UE-FM) and corticospinal excitability measured by transcranial magnetic stimulation (TMS) were assessed before, after and 4 weeks after intervention. Results: Ten participants received real tDCS and nine received sham tDCS. UE-FM improved significantly in both groups after intervention. Of those with unrecordable motor evoked potential (MEP-) to the ipsilesional M1, significant improvement in UE-FM was found in the real-tDCS group, but not in the sham group. Resting motor threshold (RMT) of ipsilesional M1 decreased significantly after intervention in the real-tDCS group. Short intra-cortical inhibition (SICI) in the contralesional M1 was reduced\u00a0\u2026", "With deep learning emerging as a powerful machine learning tool to build Brain Computer Interface (BCI) systems, researchers are investigating the use of different type of networks architectures and representations of brain activity to attain superior classification accuracy compared to state-of-the-art machine learning approaches, that rely on processed signal and optimally extracted features. This paper presents a deep learning driven electroencephalography (EEG) -BCI system to perform decoding of hand motor imagery using deep convolution neural network architecture, with spectrally localized time-domain representation of multi-channel EEG as input. A significant increase in decoding performance in terms of accuracy of +6.47% is obtained compared to a wideband EEG representation. We further illustrate the movement class specific feature patterns for both the architectures and demonstrate that higher\u00a0\u2026", "Swallowing is an essential function in our daily life; nevertheless, stroke or other neurodegenerative diseases can cause the malfunction of swallowing function, ie, dysphagia. The objectives of this review are to understand the neural and cortical basis of swallowing and tongue, and review the latest techniques on the detection of motor imagery of swallow (MI-SW) and motor imagery of tongue movements (MI-TM), so that a practical system can be developed for the rehabilitation of poststroke dysphagia patients. Specifically, we firstly describe the swallowing process and how the swallowing function is assessed clinically. Secondly, we review the techniques that performed the neural and cortical analysis of swallowing and tongue based on different modalities such as functional magnetic resonance imaging, positron emission tomography, near-infrared spectroscopy (NIRS), and magnetoencephalography. Thirdly\u00a0\u2026", "EEG data from performing motor imagery are usually collected to calibrate a subject-specific model for classifying the EEG data during the evaluation phase of motor imagery Brain-Computer Interface (BCI). However, there is no direct objective measure to determine if a subject is performing motor imagery correctly for proper calibration. Studies have shown that passive movement, which is directly observable, induces Event-Related Synchronization patterns that are similar to those induced from motor imagery. Hence, this paper investigates the feasibility of calibrating EEG-based motor imagery BCI from passive movement. EEG data of 12 healthy subjects were collected during motor imagery and passive movement of the hand by a haptic knob robot. The calibration models using the Filter Bank Common Spatial Pattern algorithm on the EEG data from motor imagery were compared against using the EEG data from\u00a0\u2026", "Intracranial Pressure (ICP) monitoring signal collected in Neuro Intensive Care Units often contains large amount of artifacts. The artifacts not only directly lead to false alarms in automatic Intracranial Hypertension (IH) alert systems, and they also severely contaminate the characteristics of the underlying signal, which makes accurate forecasting of impending IH impossible. Therefore, in this paper, we propose a novel solution to effectively remove artifacts from ICP monitoring signals. The proposed method effectively detects artifacts by decomposing the ICP monitoring signal with Empirical Mode Decomposition (EMD) method. An iterative filtering method is also proposed to extract artifacts from the decomposed components of ICP signals. The proposed filter is robust. That is, the parameters of the iterative filter are estimated with robust statistics, which ensures the performance of the proposed filter will not be unduly\u00a0\u2026", "The online performance of a motor imagery-based Brain-Computer Interface (MI-BCI) influences its effectiveness and usability in real-world clinical applications such as the restoration of motor control. The online performance depends on factors such as the different feedback techniques and motivation of the subject. This paper investigates the online performance of the MI-BCI with an augmented-reality (AR) 3D virtual hand feedback. The subject experiences the interaction with 3D virtual hands, which have been superimposed onto his real hands and displayed on the computer monitor from a first person point-of-view. While performing motor imagery, he receives continuous visual feedback from the MI-BCI in the form of different degrees of reaching and grasping actions of the 3D virtual hands with other virtual objects. The AR feedback is compared with the conventional horizontal bar feedback on 8 subjects, of\u00a0\u2026", "In this paper, we propose a novel statistical framework based on time-frequency decomposition and nonparametric modelling of electrocortical (ECoG) signals in the context of a Brain Computer Interface. The proposed method decomposes the ECoG signals into subbands (with no down-sampling) using Gabor filters. The subband signals are then encoded using a nonparametric statistical modeling and the distance between the resulting empirical distributions is as used as the classification criterion. Cross-validation experiments were carried out to pre-select the channel (from the multi-channel sources) and subbands which can archive the best classification scores. The proposed framework has been evaluated using Data Set I from the BCI Competition III and results indicate a superiority over conventional vector quantization method particularly when the number of training samples is small. It was found that the\u00a0\u2026", "Sleep staging is of great importance in the diagnosis and treatment of sleep disorders. Recently, numerous data-driven deep learning models have been proposed for automatic sleep staging. They mainly train the model on a large public labeled sleep dataset and test it on a smaller one with subjects of interest. However, they usually assume that the train and test data are drawn from the same distribution, which may not hold in real-world scenarios. Unsupervised domain adaption (UDA) has been recently developed to handle this domain shift problem. However, previous UDA methods applied for sleep staging have two main limitations. First, they rely on a totally shared model for the domain alignment, which may lose the domain-specific information during feature extraction. Second, they only align the source and target distributions globally without considering the class information in the target domain, which\u00a0\u2026", "As one of the important psychological stress reactions, Micro-expressions\u00a0(MEs) are spontaneous and subtle facial movements, which usually occur in a high-stake situation and can reveal genuine human feelings and cognition. ME, Recognition\u00a0(MER) has essential applications in many fields such as lie detection, criminal investigation, and psychological healing. However, due to the challenges of learning discriminative ME features via fleeting facial subtle reactions as well as the shortage of available MEs data, this research topic is still far from well-studied. To this end, in this paper, we propose a deep prototypical learning framework, namely ME-PLAN, with a local attention mechanism for the MER problem. Specifically, ME-PLAN consists of two components, i.e., a 3D residual prototypical network and a local-wise attention module, where the former aims to learn the precise ME feature prototypes through\u00a0\u2026", "Deep learning (DL) has been widely investigated in a vast majority of applications in electroencephalography (EEG)-based brain\u2013computer interfaces (BCIs), especially for motor imagery (MI) classification in the past five years. The mainstream DL methodology for the MI-EEG classification exploits the temporospatial patterns of EEG signals using convolutional neural networks (CNNs), which have been particularly successful in visual images. However, since the statistical characteristics of visual images depart radically from EEG signals, a natural question arises whether an alternative network architecture exists apart from CNNs. To address this question, we propose a novel geometric DL (GDL) framework called Tensor-CSPNet, which characterizes spatial covariance matrices derived from EEG signals on symmetric positive definite (SPD) manifolds and fully captures the temporospatiofrequency patterns using\u00a0\u2026", "The detection of attentive mental state plays an essential role in the neurofeedback process and the treatment of Attention Deficit and Hyperactivity Disorder (ADHD). However, the performance of the detection methods is still not satisfactory. One of the challenges is to find a proper representation for the electroencephalogram (EEG) data, which could preserve the temporal information and maintain the spatial topological characteristics. Inspired by the deep learning (DL) methods in the research of brain\u2013computer interface (BCI) field, a 3D representation of EEG signal was introduced into attention detection task, and a 3D convolutional neural network model with cascade and parallel convolution operations was proposed. The model utilized three cascade blocks, each consisting of two parallel 3D convolution branches, to simultaneously extract the multi-scale features. Evaluated on a public dataset containing twenty\u00a0\u2026", "Decoding human movement parameters from electroencephalograms (EEG) signals is of great value for human-machine collaboration. However, existing studies on hand movement direction decoding concentrate on the decoding of a single-hand movement direction from EEG signals given the opposite hand is maintained still. In practice, the cooperative movement of both hands is common. In this paper, we investigated the neural signatures and decoding of single-hand and both-hand movement directions from EEG signals. The potentials of EEG signals and power sums in the low frequency band of EEG signals from 24 channels were used as decoding features. The linear discriminant analysis (LDA) and support vector machine (SVM) classifiers were used for decoding. Experimental results showed a significant difference in the negative offset maximums of movement-related cortical potentials (MRCPs) at\u00a0\u2026", "This study investigates the neurological changes in the brain activity of chronic stroke patients undergoing different types of motor rehabilitative interventions and their relationship with the clinical recovery using the Quantitative Electroencephalography (QEEG) features. Over a period of two weeks, 19 hemiplegic chronic stroke patients underwent 10 sessions of upper extremity motor rehabilitation using a brain-computer interface paradigm (BCI group, n=9) and transcranial direct current stimulation coupled BCI paradigm (tDCS group, n=10). The pre- and post-treatment brain activations, as well as the intervention-induced changes in the neuronal activity, were quantified using 11 QEEG features and their relationship with clinical motor improvement was investigated. Significant treatment-induced change in the relative theta power was observed in the BCI group and the change was significantly correlated with the\u00a0\u2026", "Recently, studies have reported the use of Near Infrared Spectroscopy (NIRS) for developing Brain\u2013Computer Interface (BCI) by applying online pattern classification of brain states from subject-specific fNIRS signals. The purpose of the present study was to develop and test a real-time method for subject-specific and subject-independent classification of multi-channel fNIRS signals using support-vector machines (SVM), so as to determine its feasibility as an online neurofeedback system. Towards this goal, we used left versus right hand movement execution and movement imagery as study paradigms in a series of experiments. In the first two experiments, activations in the motor cortex during movement execution and movement imagery were used to develop subject-dependent models that obtained high classification accuracies thereby indicating the robustness of our classification method. In the third experiment, a generalized classifier-model was developed from the first two experimental data, which was then applied for subject-independent neurofeedback training. Application of this method in new participants showed mean classification accuracy of 63% for movement imagery tasks and 80% for movement execution tasks. These results, and their corresponding offline analysis reported in this study demonstrate that SVM based real-time subject-independent classification of fNIRS signals is feasible. This method has important applications in the field of hemodynamic BCIs, and neuro-rehabilitation where patients can be trained to learn spatio-temporal patterns of healthy brain activity.", "In extracellular neural recording experiments, detecting neural spikes is an important step for reliable information decoding. A successful implementation in integrated circuits can achieve substantial data volume reduction, potentially enabling a wireless operation and closed-loop system. In this paper, we report a 16-channel neural spike detection chip based on a customized spike detection method named as exponential component-polynomial component (EC-PC) algorithm. This algorithm features a reliable prediction of spikes by applying a probability threshold. The chip takes raw data as input and outputs three data streams simultaneously: field potentials, band-pass filtered neural data, and spiking probability maps. The algorithm parameters are on-chip configured automatically based on input data, which avoids manual parameter tuning. The chip has been tested with both in vivo experiments for functional\u00a0\u2026", "Patients with obstructive sleep apnea (OSA) experience fragmented sleep and exhibit different sleep architectures. While polysomnographic metrics for quantifying sleep architecture are studied, there is little information about the impact of OSA on the ratio of different sleep-wake stages (wake, W; rapid eye movement, REM; non-REM stages 1 to 3, N1 to N3). This study, therefore, aims to investigate the relationship between apnea-hypopnea index (AHI, a measure of OSA severity) and all possible ratios of sleep-wake stages. Sleep architectures of 24 adult subjects with suspected OSA were constructed according to the American Academy of Sleep Medicine scoring manual, and subsequently analyzed through various correlation (Pearson, Spearman, and Kendall) and regression (linear, logarithmic, exponential, and power-law) approaches. Results show a statistically significant positive, linear and monotonic\u00a0\u2026", "Near-Infrared Spectroscopy (NIRS)-based Brain-Computer Interface (BCI) was recently studied for numerical cognition. This study presents a study using high density 348 channels NIRS-based BCI from 8 healthy subjects while solving mental arithmetic problems with two difficulty levels and the rest condition. The existing feature extraction and selection methods on the existing study were presented only for low density 16 channels NIRS-based BCI, and required the specification on the number of features to select to yield desirable performance. This paper presents a method of extracting discriminative features from high density single-trial NIRS data using common average reference spatial filtering and single-trial baseline reference, and a method of automatically selecting a set of discriminative and non-redundant features using the Mutual Information-based Rough Set Reduction (MIRSR) and Supervised\u00a0\u2026", "Close monitoring and timely treatment are extremely crucial in Neuro Intensive/Critical Care Units (NICUs) to prevent patients from secondary brain damages. However, the current clinical practice is labor-intensive, prone to human errors and ineffective. To address this, we developed an integrated and intelligent system, namely iSyNCC, to enhance the effectiveness of patient monitoring and clinical decision makings in NICUs. The requirements of the system were investigated through interviews and discussions with neurosurgeons, neuroclinicians and nurses. Based on the summarized requirements, a modular 2-tier system is developed. iSyNCC integrates and stores crucial patient information ranging from demographic details, clinical & treatment records to continuous physiological monitoring data. iSyNCC enables remote and centralized patient monitoring and provides computational intelligence to facilitate\u00a0\u2026", "We report our studies on a Brain Computer Interface (BCI) speller application with an aim to optimize its performance and usability. We study the dependence of the spelling accuracy as a function of (a) the number of visual stimuli (repetitions) presented to the user, (b) the P300 segment length used, (c) the number of channels used, and (d) the amount of data used in training, in terms of the number of characters and repetitions. Reducing the number of repetitions results in a direct reduction of the time needed to spell a character, while minimizing the number of channels translates to shorter subject preparation time and thus improves the usability of the system. The usability is further enhanced by decreasing the training required, while maintaining the accuarcy. We show that very high accuracies of the order of 99% can be achieved with a short training session of less than 10 minutes using only about 10 channels\u00a0\u2026", "Objective Session-to-session nonstationarity is inherent in brain\u2013computer interfaces based on electroencephalography. The objective of this paper is to quantify the mismatch between the training model and test data caused by nonstationarity and to adapt the model towards minimizing the mismatch. Approach We employ a tensor model to estimate the mismatch in a semi-supervised manner, and the estimate is regularized in the discriminative objective function. Main results The performance of the proposed adaptation method was evaluated on a dataset recorded from 16 subjects performing motor imagery tasks on different days. The classification results validated the advantage of the proposed method in comparison with other regularization-based or spatial filter adaptation approaches. Experimental results also showed that there is a significant correlation between the quantified mismatch and the classification\u00a0\u2026", "In EEG-based motor imagery Brain-Computer interface (BCI), EEG data collected in the calibration phase is used as a subject-specific model to classify the EEG data in the evaluation phase. Previous study has shown the feasibility of calibrating EEG-based BCI from passive movement. This paper investigates the primary sensorimotor area activation from fNIRS on 4 subjects using multimodal NIRS and EEG-based BCI system while performing motor imagery and passive movement of the hand by a Haptic Knob robot. NIRS_SPM is used to compute the changes in hemoglobin response and to generate brain activation map based on the contrasts of motor imagery versus idle and passive movement versus idle. The results on the contrasts showed that passive movement versus idle yielded significant differences compared to motor imagery versus idle. In addition, the results of classifying the NIRS and EEG data\u00a0\u2026", "In Brain-Computer Interface (BCI) research, subject and session specific training data is usually used to ensure satisfying classification results. In this paper, we show that neural responses to different speaking tasks recorded with functional Near Infrared spectroscopy (fNIRS) are consistent enough across speakers to robustly classify speaking modes with models trained exclusively on other subjects. Our study thereby suggests that future fNIRS-based BCIs can be designed without time-consuming training, which, besides being cumbersome, might be impossible for users with disabilities. Accuracies of 71% and 61% were achieved in distinguishing segments containing overt speech and silent speech from segments in which subjects were not speaking, without using any of the subject\u2019s data for training. To rule out artifact contamination, we filtered the data rigorously. To the best of our knowledge\u00a0\u2026", "We implement a visual interpretability method Layer-wise Relevance Propagation (LRP) on top of 3D U-Net trained to perform lesion segmentation on the small dataset of multi-modal images provided by ISLES 2017 competition. We demonstrate that LRP modifications could provide more sensible visual explanations to an otherwise highly noise-skewed saliency map. We also link amplitude of modified signals to useful information content. High amplitude localized signals appear to constitute the noise that undermines the interpretability capacity of LRP. Furthermore, mathematical framework for possible analysis of function approximation is developed by analogy.", "There is growing evidence that virtual reality (VR) can be used as an optional therapy method for stress relief and treatment of mental disorders such as a variety of anxiety disorders, depression and psychosis. However, more systematic studies to quantity the effects of VR for emotion elicitation and compare the effects of 3D and 2D environment for the same is necessary to design feasible and effective treatments. In this study, we design a cross-over experiment protocol comprising of two emotion eliciting environments relaxation and arousal that is presented to the participant either in a 2D monitor or a 3D head-mounted (HMD) VR display. The EEG data is collected during the experiment and analyzed offline to classify emotion elicited by low and high arousal environments using SVM classification of band power features. A 10-fold cross validation is performed and classification accuracy for each subject is computed\u00a0\u2026", "Virtual Reality (VR) is expected to significantly improve the motor function for stroke as a rehabilitation intervention technique. VR can provide a simulated world comparable to the real world that allows clients to interact with the virtual environment (VE), and provides real-time feedback. The principle of rehabilitation method based on motor imagery (MI) brain-computer interface (BCI) is to train the motor nerves directly through MI to promote the plasticity of the central nervous system. To rehabilitate the upper limb function of stroke patients, a rehabilitation system based on VR and MI-BCI is developed in this paper, which integrates the real-life scenario into the monotonous rehabilitation training. The rehabilitation system provides 6 training scenarios and 9 training movements. The system will provide real-time visual, auditory and haptic multisensory-feedback, which makes training more interesting, promotes motor\u00a0\u2026", "Falling asleep during driving is a serious problem that has resulted in fatal accidents worldwide. Thus, there is a need to detect driver drowsiness to counter it. This study analyzes the changes in the electroencephalography (EEG) collected from 4 subjects driving under monotonous road conditions using a driving simulator. The drowsiness level of the subjects is inferred from the time taken to react to events. The results from the analysis of the reaction time shows that drowsiness occurs in cycles, which correspond to short sleep cycles known as `microsleeps'. The results from a time-frequency analysis of the four frequency bands' power reveals differences between trials with fast and slow reaction times; greater beta band power is present in all subjects, greater alpha power in 2 subjects, greater theta power in 2 subjects, and greater delta power in 3 subjects, for fast reaction trials. Overall, this study shows that\u00a0\u2026", "Rehabilitation of lower limbs is equally as important as that of upper limbs. This paper presented a study to detect motor imagery of walking (MI-Walking) from background idle state. Broad overlapping neuronal networks involved in reorganization following motor imagery introduce redundancy. We hypothesized that MI-Walking could be robustly detected by constraining dependency among selected features and class separations. Hence, we proposed to jointly select channels and frequency bands involved in MI-Walking by optimizing/regularizing the objective function formulated on the dependency between features and class labels, redundancy between to-be-selected with selected features, and separations between classes, namely, \u201cregularized maximum dependency with minimum redundancy-based joint channel and frequency band selection (RMDR-JCFS)\u201d. Evaluated on electroencephalography (EEG) data\u00a0\u2026", "The injection of emotional intelligence in human-computer interfaces is necessary for computer applications to appear intelligent when interacting with people. With the recent development of brain imaging techniques and brain-computer interfaces, computers can actually take a look inside users' head to observe their emotional states. This paper presents an EEG-based emotion detection system which detects emotional states based on short EEG segments of 1s. A novel feature extraction algorithm termed asymmetric spatial filtering is proposed to extract features from high dimensional EEG data. The effectiveness of the proposed method is tested for two types of emotion detection problems on data from five subjects.", "One of the key issues in deep learning is the difficulty in the interpretation of mechanisms for the final predictions. Hence the real-world application of deep learning in skin cancer still proves limited, in spite of the solid performances achieved. We present a way to better interpret predictions on a skin lesion dataset by the use of a multi-task learning framework and a set of learnable gates. The model detects a set of clinically significant attributes in addition to the final diagnosis and learns the association between tasks by selecting which features to share among them. Conventional multi-task learning algorithms generally share all the features among tasks and lack a way of determining the amount of sharing between tasks. On the other hand, this method provides a simple way to inspect which features are being shared between tasks in the form of gates that can be learned in an end-to-end fashion. Experiments have been carried out on the publicly available Derm7pt dataset, which provides diagnosis information as well as the attributes needed for the well-known 7-point checklist method.", "Research on human emotions and underlying brain processes is mostly performed open-loop, e.g. by presenting emotional stimuli and measuring subject's brain responses. Investigating human emotions in interaction with emotional stimuli (closed-loop) significantly complicates experimental setups and has so far rarely been proposed. We present concept and technical realization of an electroencephalography (EEG)-based affective Brain-Computer Interface (BCI) to study emotional brain processes in continuous closed-loop interaction. Our BCI consists of an algorithm generating continuous patterns of synthesized affective music, embedded in an online BCI architecture. An initial calibration is employed to obtain user-specific models associating EEG patterns with affective content in musical patterns. These models are then used in online application to translate the user's affect into a continuous musical\u00a0\u2026", "The decoding of hand movement kinematics using non-invasive data acquisition techniques is a recent area of research in Brain Computer Interface (BCI). In this work, we use an Electroencephalography (EEG) based BCI to decode directional information from the brain data collected during an actual hand movement experiment. The objective is to find the discriminative features of movement related potential that can classify any two directions out of the four orthogonal directions in which subject performs right hand movement. The performance using Wavelet-Common Spatial Pattern (W-CSP) algorithm and its variations in terms of spatial regularization is studied and compared. The work further analyzes the involvement of frontal, parietal and motor regions in carrying movement kinematics information with the help of spatial plots given by CSP. The performance variability for different directions in various subjects\u00a0\u2026", "Interface (BCI) applications helps to improve the usability and the performance of the BCI as some channels are contaminated by noise or contain irrelevant information. This paper proposes a method of using decision trees to select appropriate channels in EEG-based BCI applications. The proposed method selects the best subset of appropriate channels by considering the correlation information between them using Decision Tree. The performance of the proposed method is compared with several other methods of channel selection, such as Fisher Criterion, Mutual Information, Support Vector Machine and Common Spatial Pattern coefficients. The performances of these methods are evaluated in terms of using publicly available BCI Competition IV dataset IIa. Experimental results show that the proposed method outperforms the existing channel selection methods specifically in the case where the number of selected channels is relatively small.", "The number of people that develop Alzheimer's Disease (AD) is rapidly rising, while the initial diagnosis and care of AD patients typically falls on non-specialist and still taking up to 3-5 years before being referred to specialists. An urgent need thus exists to develop methods to extract accurate and robust biomarkers from low-cost and non intrusive modalities such as electroencephalograms (EEGs). Contributions of this paper are three-fold. First we review 8 promising methods for early diagnosis of AD and undertake a performance evaluation using ROC analysis. We find that fractal dimension (AUC = 0.989), zero crossing interval (AUC = 0.980) and spectrum analysis of power alpha/theta ratio (Pwr alpha,thetas )(AUC = 0.975) perform best, with all three having sensitivity and specificity higher than 94%. We plot ROC curve with 95% confidence contours because of the small size of our data set (17 AD and 24 NOLD\u00a0\u2026", "Introduction/BackgroundStroke is the most common cause for physical disability and impairments to lower limb function remain one of its most debilitating symptom. Motor imagery (MI), as a safe, self-paced technique, has been shown to effectively facilitating the effects of motor practice. When combined with brain-computer interface (MI-BCI), it also demonstrates an improvement in stroke motor recovery. A feasibility trial was carried out to investigate the effect of MI-BCI neurofeedback in chronic hemiplegic lower limb rehabilitation. The neurophysiological correlates to clinical outcomes was also studied by using, transcranial magnetic stimulation (TMS).Material and methodSubjects (n\u00a0=\u00a013) with more than 9 months post-stroke and Functional Ambulation Category 3\u20134 underwent 12 sessions of MI-BCI gait training, at a frequency of thrice a week. Subjects were instructed to perform a MI task whereby they imagined\u00a0\u2026", "Measuring attention from electroencephalogram (EEG) has found applications in the treatment of Attention Deficit Hyperactivity Disorder (ADHD). It is of great interest to understand what features in EEG are most representative of attention. Intensive research has been done in the past and it has been proven that frequency band powers and their ratios are effective features in detecting attention. However, there are still unanswered questions, like, what features in EEG are most discriminative between attentive and non-attentive states? Are these features common among all subjects or are they subject-specific and must be optimized for each subject? Using Mutual Information (MI) to perform subject-specific feature selection on a large data set including 120 ADHD children, we found that besides theta beta ratio (TBR) which is commonly used in attention detection and neurofeedback, the relative beta power and theta\u00a0\u2026", "This paper proposes a novel method to detect motor imagery of walking for the rehabilitation of stroke patients using the Laplacian derivatives (LAD) of power averaged across frequency bands as the feature. We propose to select the most correlated channels by jointly considering the mutual information between the LAD power features of the channels and the class labels, and the redundancy between the LAD power features of the channel with that of the selected channels. Experiments are conducted on the EEG data collected for 11 healthy subjects using proposed method and compared with existing methods. The results show that the proposed method yielded an average classification accuracy of 67.19% by selecting as few as 4 LAD channels. An improved result of 71.45% and 73.23% are achieved by selecting 10 and 22 LAD channels, respectively. Comparison results revealed significantly superior\u00a0\u2026", "Brain-computer interface (BCI) as a rehabilitation tool has been used in restoring motor functions in patients with moderate to sever stroke impairments. To achieve the best possible outcome in such an application, it is highly desirable to have a stable and accurate operation of BCI. However, since electroencephalogram (EEG) signals considerably vary between sessions of even the same user, typically a long calibration session is recorded at the beginning of each session. This process is time-consuming and inconvenient for stroke patients who undergo long-term BCI sessions with repeating same mental tasks. This paper investigates the possibility of omitting the intra-session calibration for BCI-based stroke rehabilitation when large data recorded from the same user are available. For this purpose, a large dataset of EEG signals from 11 stroke patients performing 12 BCI-based stroke rehabilitation sessions over\u00a0\u2026", "In this paper, a hybrid EEG-based brain computer interface (BCI) is designed for two-dimensional cursor control. In our approach, two brain activity patterns, i.e., motor imagery and P300 potential, are used for controlling the horizontal and the vertical movements of the cursor respectively. A real-time BCI system based on this approach is implemented and evaluated through an online experiment. Six subjects attending this experiment can perform 2-D cursor control effectively. Our experimental results show that the system has the following merits compared with prior systems: 1) it does not rely on intensive user training; 2) it allows cursor movement between arbitrary positions.", "This paper addresses the issue of selecting optimal spatio-spectral features, which is key to high performance motor imagery (MI) classification that is in turn one of the central topics in EEG-based brain computer interfaces. In particular, this work proposes a novel method which first formulates the selection of features as maximizing mutual information between class labels and features. It then uses a robust estimate of mutual information, within a filter-bank and common spatial pattern feature extraction framework, to select an effective feature set. We have assessed the proposed method on both BCI Competition IV Set I and a separate data set collected in our lab from 7 healthy subjects. The results indicate the method is effective in selecting optimal spatial-spectral features for classification.", "A method of processing speech representative of ideograms for speech communication using an asynchronous communication channel (21) is disclosed. The method includes the step of processing speech units of a speech and data indicative of the speech units. Each speech unit is representative of an ideogram or a plurality of semantically related ideograms (500-508). The data indicative of the speech units is discretely communicable on the asynchronous communication channel (21). By communicating the data indicative of the speech units, a substantially low data transmission rate and intelligible speech communication is achieved.", "Visual modality is one of the most dominant modalities for current continuous emotion recognition methods. Compared to which the EEG modality is relatively less sound due to its intrinsic limitation such as subject bias and low spatial resolution. This work attempts to improve the continuous prediction of the EEG modality by using the dark knowledge from the visual modality. The teacher model is built by a cascade convolutional neural network-temporal convolutional network (CNN-TCN) architecture, and the student model is built by TCNs. They are fed by video frames and EEG average band power features, respectively. Two data partitioning schemes are employed, ie, the trial-level random shuffling (TRS) and the leave-one-subject-out (LOSO). The standalone teacher and student can produce continuous prediction superior to the baseline method, and the employment of the visual-to-EEG cross-modal KD further\u00a0\u2026", null, "This paper presents an asynchronously intracortical brain-computer interface (BCI) which allows the subject to continuously drive a mobile robot. This system has a great implication for disabled patients to move around. By carefully designing a multiclass support vector machine (SVM), the subject's self-paced instantaneous movement intents are continuously decoded to control the mobile robot. In particular, we studied the stability of the neural representation of the movement directions. Experimental results on the nonhuman primate showed that the overt movement directions were stably represented in ensemble of recorded units, and our SVM classifier could successfully decode such movements continuously along the desired movement path. However, the neural representation of the stop state for the self-paced control was not stably represented and could drift.", "Decoding hand movement parameters (for example movement trajectory, speed etc.) from scalp recordings such as Electroencephalography (EEG) is a challenging and less explored area of research in the field of Brain Computer Interface (BCI) systems. By identifying neural features underlying movement parameters, a detailed and well defined control command set can be provided to the BCI output device. A continuous control to the output device is better suited for practical BCI systems, and can be achieved by continuous reconstruction of movement trajectory than discrete brain activity classifications. In this study, we attempt to reconstruct/estimate various parameters of hand movement trajectory from multi channel EEG recordings. The data for analysis is collected by performing an experiment that involved centre-out right hand movement tasks in four different directions at two different speeds in random order\u00a0\u2026", "Near-infrared spectroscopy (NIRS)-based Brain-Computer Interface (BCI) was recently proposed to assess level of numerical cognition in subjects. However, existing feature extraction method was only proposed for low density 16 channels NIRS-based BCI. This study investigates the performance of a high density 348 channels NIRS-based BCI on 8 healthy subjects while they solve mental arithmetic problems with two difficulty levels and the rest condition. A novel method of extracting effective features from high density single-trial NIRS data is proposed using common average reference spatial filtering and single-trial baseline reference. The performance of the proposed feature extraction method is presented using 5\u00d75-fold cross-validations on the single-trial NIRS data collected using mutual information-based feature selection and support vector machine classifier. The results yielded an overall average\u00a0\u2026", "Although the future mean of intracranial pressure (ICP) is of critical concern of many clinicians for timely medical treatment, the problem of forecasting the future ICP mean has not been addressed yet. In this paper, we present a nonlinear autoregressive with exogenous input artificial neural network based mean forecast algorithm (ANN NARX -MFA) to predict the ICP mean of the future windows based on features extracted from past windows and segmented sub-windows. We compare its performance with nonlinear autoregressive artificial neural network algorithm (ANN NAR ) without features extracted from window segmentation. Experimental results showed that, ANN NARX -MFA algorithm outperforms ANN NAR  algorithm in prediction accuracy, because additional features extracted from finer segmented sub-windows help to catch the subtle changes of ICP trends. This verifies the effectiveness of decomposing\u00a0\u2026", "This paper discusses the estimation and numerical calculation of the probability that the 0-norm and 1-norm solutions of underdetermined linear equations are equivalent in the case of sparse representation. First, we define the sparsity degree of a signal. Two equivalence probability estimates are obtained when the entries of the 0-norm solution have different sparsity degrees. One is for the case in which the basis matrix is given or estimated, and the other is for the case in which the basis matrix is random. However, the computational burden to calculate these probabilities increases exponentially as the number of columns of the basis matrix increases. This computational complexity problem can be avoided through a sampling method. Next, we analyze the sparsity degree of mixtures and establish the relationship between the equivalence probability and the sparsity degree of the mixtures. This relationship can be\u00a0\u2026", "Cognitive processes, such as motor intention, attention, and higher level motivational states are important factors that govern motor performance and learning. Current robot-assisted rehabilitative programs focus only on the physical aspects of training. In this paper, we propose a framework for motor rehabilitation based on the augmentation of cognitive channels of patient-robot interactions and using it to deliver a more optimal therapy. By examining the cognitive processes involved in motor control and adaptation, it is argued that optimal therapy needs to be considered in the context of a complete motor scheme consisting not only of sensorimotor signals, but also their interactions with cognitive operations, such as motor planning, attention, and motivation, which mediate motor learning. We outline a few BCI-based modules for the detection and monitoring of relevant cognitive processes, which provide inputs for\u00a0\u2026", "We report the effect of removing ocular artifacts on the performance of a word-processing application based on the event related potential P300. Various methods of removing artifacts have been reported. The efficiency of these algorithms are usually done by subjective visual comparisons. Noting that there is a direct correlation of artifact rectifying algorithms to the accuracy in a brain computer interface system's accuracy, we present this work as a means to compare different algorithms.", "Neuropsychological studies suggest that co-operative activities among different brain functional areas drive high-level cognitive processes. To learn the brain activities within and among different functional areas of the brain, we propose local-global-graph network (LGGNet), a novel neurologically inspired graph neural network (GNN), to learn local-global-graph (LGG) representations of electroencephalography (EEG) for brain\u2013computer interface (BCI). The input layer of LGGNet comprises a series of temporal convolutions with multiscale 1-D convolutional kernels and kernel-level attentive fusion. It captures temporal dynamics of EEG which then serves as input to the proposed local-and global-graph-filtering layers. Using a defined neurophysiologically meaningful set of local and global graphs, LGGNet models the complex relations within and among functional areas of the brain. Under the robust nested cross\u00a0\u2026", "It is reported that the symptoms of autism spectrum disorder (ASD) could be improved by effective early interventions, which arouses an urgent need for large-scale early identification of ASD. Until now, the screening of ASD has relied on the child psychiatrist to collect medical history and conduct behavioral observations with the help of psychological assessment tools. Such screening measures inevitably have some disadvantages, including strong subjectivity, relying on experts and low-efficiency. With the development of computer science, it is possible to realize a computer-aided screening for ASD and alleviate the disadvantages of manual evaluation. In this study, we propose a behavior-based automated screening method to identify high-risk ASD (HR-ASD) for babies aged 8-24 months. The still-face paradigm (SFP) was used to elicit baby's spontaneous social behavior through a face-to-face interaction, in\u00a0\u2026", "Brain insults such as cerebral ischemia and intracranial hemorrhage are critical stroke conditions with high mortality rates. Currently, medical image analysis for critical stroke conditions is still largely done manually, which is time-consuming and labor-intensive. While deep learning algorithms are increasingly being applied in medical image analysis, the performance of these methods still needs substantial improvement before they can be widely used in the clinical setting. Among other challenges, the lack of sufficient labelled data is one of the key problems that has limited the progress of deep learning methods in this domain. To mitigate this bottleneck, we propose an integrated method that includes a data augmentation framework using a conditional Generative Adversarial Network (cGAN) which is followed by a supervised segmentation with a Convolutional Neural Network (CNN). The adopted cGAN generates\u00a0\u2026", "We present a feature-based image registration method, the stepwise image registration (SIR), with a closed-form solution. Our SIR creates an inlier pool and a candidate pool as the initialization, and then gradually enriches the inlier pool and refines the transformation. In each step, the enriched correspondence exclusively tunes the transformation coefficient within the confirmed inlier pairs, instead of updating the mapping using the complete putative set. In turn, the refined transformation prunes inconsistent mismatches to alleviate the incoming matching ambiguity. The context-aware locality measure (CALM) is designed for dissimilarity measure. The capability of the CALM can be enhanced by the progressive inlier pool enrichment. Finally, a retrieval process is performed based on the finest CALM and alignment, by which the inlier pool is maximized. Extensive experiments of enrichment evaluation, feature\u00a0\u2026", "A method of training a classification algorithm for a Brain Computer Interface (BCI). The method includes the steps of: dividing a Electroencephalography (EEG) signal into a plurality of time segments; for each time segment, dividing a corresponding EEG signal portion into a plurality of frequency bands; for each frequency band, computing a spatial filtering projection matrix based on a Common Spatial Pattern (CSP) algorithm and a corresponding feature, and computing mutual information of each corresponding feature with respect to one or more motor imagery classes; for each time segment, summing the mutual information of all the corresponding features with respect to the respective classes; and selecting the corresponding features of the time segment with a maximum sum of mutual information for one class for training classifiers of the classification algorithm.", "Sleep has been shown to be imperative for the health and well-being of an individual. To design intelligent sleep management tools, such as the music-induce sleep-aid device, automatic detection of sleep onset is critical. In this work, we propose a simple yet accurate method for sleep onset prediction, which merely relies on Electroencephalogram (EEG) signal acquired from a single frontal electrode in a wireless headband. The proposed method first extracts energy power ratio of theta (4-8Hz) and alpha (8-12Hz) bands along a 3-second shifting window, then calculates the slow wave of each frequency band along the time domain. The resulting slow waves are then fed to a rule-based engine for sleep onset detection. To evaluate the effectiveness of the approach, polysomnographic (PSG) and headband EEG signals were obtained from 20 healthy adults, each of which underwent 2 sessions of sleep events. In\u00a0\u2026", "This paper proposed a novel method to select the effective Electroencephalography (EEG) channels for the motor imagery tasks based on the inconsistencies from multiple classifiers. The inconsistency criterion for channel selection was designed based on the fluctuation of the classification accuracies among different classifiers when the noisy channels were included. These noisy channels were then identified and removed till a required number of channels was selected or a predefined classification accuracy with reference to baseline was obtained. Experiments conducted on a data set of 13 healthy subjects performing hand grasping and idle revealed that the EEG channels from the motor area were most frequently selected. Furthermore, the mean increases of 4.07%, 3.10% and 1.77% of the averaged accuracies in comparison with the four existing channel selection methods were achieved for the non\u00a0\u2026", "Recently, neuro-rehabilitation based on brain\u2013computer interface (BCI) has been considered one of the important applications for BCI. A key challenge in this system is the accurate and reliable detection of motor imagery. In motor imagery-based BCIs, the common spatial patterns (CSP) algorithm is widely used to extract discriminative patterns from electroencephalography signals. However, the CSP algorithm is sensitive to noise and artifacts, and its performance depends on the operational frequency band. To address these issues, this paper proposes a novel optimized sparse spatio-spectral filtering (OSSSF) algorithm. The proposed OSSSF algorithm combines a filter bank framework with sparse CSP filters to automatically select subject-specific discriminative frequency bands as well as to robustify against noise and artifacts. The proposed algorithm directly selects the optimal regularization parameters\u00a0\u2026", "This paper presents an unsupervised subject modeling technique and its application to a P300-based word speller. Due to EEG variations across subjects, a special training procedure is required to learn a subject-specific classification model (SSCM). To deal with the inter-subject variation, we first study a subject independent classification model (SICM) that is learned from EEG of a pool of subjects. Next we further adapt the SICM by learning from a subset of the pooled EEG that is automatically selected based on its similarity to the EEG of a new subject. Experiments over ten healthy subjects show that the SICM learned from all pooled EEG outperforms the cross-subject models greatly. More importantly, the adapted SICM achieves virtually the same performance as the SSCM, hence removing the complicated and tedious training procedure.", "This paper presents a novel approach to improving the robustness of brain-computer interfaces by using a statistical model of brain signals - especially P300. We study the distributions of support vector machine scores for the signals and derive a posteriori probability model of P300/non-P300. We further derive a statistical model for multi-trial brain signals, and apply it to the rejection of undesired signals. Six subjects have been involved in an experimental study. The results demonstrate that the P300 model and the rejection method are appropriate and can help improve the robustness of the system significantly.", "We propose an audio-visual spatial-temporal deep neural network with:(1) a visual block containing a pretrained 2D-CNN followed by a temporal convolutional network (TCN);(2) an aural block containing several parallel TCNs; and (3) a leader-follower attentive fusion block combining the audio-visual information. The TCN with large history coverage enables our model to exploit spatial-temporal information within a much larger window length (ie, 300) than that from the baseline and state-of-the-art methods (ie, 36 or 48). The fusion block emphasizes the visual modality while exploits the noisy aural modality using the inter-modality attention mechanism. To make full use of the data and alleviate over-fitting, the cross-validation is carried out on the training and validation set. The concordance correlation coefficient (CCC) centering is used to merge the results from each fold. On the test (development) set of the Aff-Wild2 database, the achieved CCC is 0.463 (0.469) for valence and 0.492 (0.649) for arousal, which significantly outperforms the baseline method with the corresponding CCC of 0.200 (0.210) and 0.190 (0.230) for valence and arousal, respectively. The code will be published upon the acceptance of the paper.", "Stroke leads to both regional brain functional disruptions and network reorganization. However, how brain functional networks reconfigure as task demand increases in stroke patients and whether such reorganization at baseline would facilitate post-stroke motor recovery are largely unknown. To address this gap, brain functional connectivity (FC) were examined at rest and motor tasks in eighteen chronic subcortical stroke patients and eleven age-matched healthy controls. Stroke patients underwent a 2-week intervention using a motor imagery-assisted brain computer interface-based (MI-BCI) training with or without transcranial direct current stimulation (tDCS). Motor recovery was determined by calculating the changes of the upper extremity component of the Fugl\u2013Meyer Assessment (FMA) score between pre- and post-intervention divided by the pre-intervention FMA score. The results suggested that as task\u00a0\u2026", "Compression of brain-computer interface (BCI) signals is significant to reduce transmission bandwidth to cloud/remote servers and to minimize storage cost. Precise reconstruction of the compressed signal is also crucial as these data are further used for spike detection and/or classification. The conventional compressive sensing (CS) techniques to reconstruct the compressed BCI signals are computationally expensive. There are several existing techniques for CS reconstruction, including block-sparse Bayesian learning and block-based CS, which also work to replace a reconstruction methodology of CS in medical imaging with deep learning (DL) techniques. DL can be helpful in reconstructing compressed BCI signals, including Electroencephalography (EEG) and Electrocorticography (ECoG). Pertinent to that, in this work, a convolutional neural network (CNN) based reconstruction framework has been proposed\u00a0\u2026", "BackgroundOnline spike detection is an important step to compress neural data and perform real-time neural information decoding. An unsupervised, automatic, yet robust signal processing is strongly desired, thus it can support a wide range of applications. We have developed a novel spike detection algorithm called \u201cexponential component\u2013polynomial component\u201d (EC\u2013PC) spike detection.New methodWe firstly evaluate the robustness of the EC\u2013PC spike detector under different firing rates and SNRs. Secondly, we show that the detection Precision can be quantitatively derived without requiring additional user input parameters. We have realized the algorithm (including training) into a 0.13\u00a0\u03bcm CMOS chip, where an unsupervised, nonparametric operation has been demonstrated.ResultsBoth simulated data and real data are used to evaluate the method under different firing rates (FRs), SNRs. The results show\u00a0\u2026", "Understanding the neural basis of arithmetic processes could play an important role in improving mathematical education. This study investigates the prefrontal cortical activation among subjects from different cultural backgrounds while performing two difficulty levels of mental arithmetic tasks. The prefrontal cortical activation is measured using a high density 206 channels fNIRS. 8 healthy subjects, consisting of 5 Asians and 3 Europeans, are included in this study. NIRS-SPM is used to compute hemoglobin response changes and generate brain activation map based on two contrasts defined as Easy versus Rest and Hard versus Rest. Differences between the Asian group and the European group are found in both contrasts of Easy versus Rest and Hard versus Rest. The results suggest people with different cultural backgrounds engage different neural pathways during arithmetic processing.", "We propose a cross-modal co-attention model for continuous emotion recognition using visual-audio-linguistic information. The model consists of four blocks. The visual, audio, and linguistic blocks are used to learn the spatial-temporal features of the multi-modal input. A co-attention block is designed to fuse the learned features with the multi-head co-attention mechanism. The visual encoding from the visual block is concatenated with the attention feature to emphasize the visual information. To make full use of the data and alleviate over-fitting, cross-validation is carried out on the training and validation set. The concordance correlation coefficient (CCC) centering is used to merge the results from each fold. The achieved CCC on the test set is 0.520 for valence and 0.602 for arousal, which significantly outperforms the baseline method with the corresponding CCC of 0.180 and 0.170 for valence and arousal, respectively. The code is available at https://github. com/sucv/ABAW3.", "Objective  Brain-computer interfaces (BCI) that enables people with severe motor disabilities to use their brain signals for direct control of objects have attracted increased interest in rehabilitation. To date, no study has investigated feasibility of the BCI framework incorporating both intracortical and scalp signals.  Methods  Concurrent local field potential (LFP) from the hand-knob area and scalp EEG were recorded in a paraplegic patient undergoing a spike-based close-loop neurorehabilitation training. Based upon multimodal spatio-spectral feature extraction and Na\u00efve Bayes classification, we developed, for the first time, a novel LFP-EEG-BCI for motor intention decoding. A transfer learning (TL) approach was employed to further improve the feasibility. The performance of the proposed LFP-EEG-BCI for four-class upper-limb motor intention decoding was assessed.  Results  Using a decision fusion strategy, we\u00a0\u2026", "At present, in the process of encephalogram motor imagery decoding, facing the background of big data analysis, it has the necessity to design an effective system which is subject-independent. Pre-training is common to carry out before each experiment, which affects the practicability of the EEG system. In order to solve this problem, the most feasible method is to design a unified framework for deep learning optimization, which could capture the spatial and spectral dependence of original motor imagery EEG signals according to the features extracted by CNN and the temporal dependence extracted by RNN-LSTM. The framework is superimposed from both end-to-end and time-frequency domains so as to retain and learn interpretable motor imagery features. In addition, artificial EEG signals can be automatically generated by training the generated adversarial network, which can generate the feature distribution\u00a0\u2026", null, "Brain computer interface (BCI) provides a direct communication pathway between a human and an external device. In this paper, we propose a new dasiadiscriminative filterbank common spatial pattern (DFBCSP)psila algorithm to select the subject-specific filters automatically during training for a motor imagery based BCI. The subject-specific filters are selected using the fisher ratio values of filtered electroencephalogram (EEG) signal. The channel dasiaC3psila alone could give sufficient information to select the discriminative filterbank for the proposed system. We have also explored the possibility of boosting the system performance by including dynamic temporal features. Fusion of static and dynamic features in the proposed DFBCSP frame work gave an average test accuracy of 92.44%, which is significantly better than conventional filterbank based common spatial pattern algorithms.", "Due to the increasing fatal traffic accidents, there are strong desire for more effective and convenient techniques for driving fatigue detection. Here, we propose a unified framework E-Key to simultaneously perform personal identification (PI) and driving fatigue detection using a convolutional attention neural network (CNN-Attention). The performance was assessed using EEG data collected through a wearable dry-sensor system from 31 healthy subjects undergoing a 90-min simulated driving task. In comparison with three widely-used competitive models (including CNN, CNN-LSTM, and Attention), the proposed scheme achieved the best (p < 0.01) performance in both PI (98.5%) and fatigue detection (97.8%). Besides, the spatial-temporal structure of the proposed framework exhibits an optimal balance between classification performance and computational efficiency. Additional validation analyses were\u00a0\u2026", "Pain is an integrative phenomenon coupled with dynamic interactions between sensory and contextual processes in the brain, often associated with detectable neurophysiological changes. Recent advances in brain activity recording tools and machine learning technologies have intrigued research and development of neurocomputing techniques for objective and neurophysiology-based pain detection. This paper proposes a pain detection framework based on Electroencephalogram (EEG) and deep convolutional neural networks (CNN). The feasibility of CNN is investigated for distinguishing induced pain state from resting state in the recruitment of 10 chronic back pain patients. The experimental study recorded EEG signals in two phases: 1. movement stimulation (MS), where induces back pain by executing predefined movement tasks; 2. video stimulation (VS), where induces back pain perception by watching a\u00a0\u2026", "Common Spatial Pattern (CSP) is an effective algorithm in constructing optimal spatial filters, which is widely used to discriminate two classes of electroencephalogram (EEG) signal in Motor Imagery (MI) based Brain Computer Interface (BCI). To extend CSP algorithm to three-class motor imagery of left-hand, right-hand, both-feet, in this paper a three-class classification strategy based on Filter Bank Common Spatial Pattern (FBCSP) and voting mechanism is proposed. The strategy reduces a three-class problem to two binary-class problems. Two binary-class classifiers are constructed for the three-class classification, both-hands vs both-feet and left-hand vs right-hand. The result shows an average three-class classification accuracy of 68.6% with BCI competition IV Datasets 2a, which is an encouraging result in motor imagery pattern recognition. And demonstrated that both-hands can be considered as one class in\u00a0\u2026", "Recent advances in the brain-computer interfaces (BCIs) have demonstrated the inference of movement related activity using non-invasive EEG. However, most of the sensorspace approaches that study sensorimotor rhythms using EEG do not reveal the underlying neurophysiological phenomenon while executing or imagining the movement with finer control. Therefore, there is a need to examine feature extraction techniques in the cortical source space which can provide more information about the task compared to sensor-space. In this study, we extend the traditional sensor-space feature extraction method, Common Spatial Pattern (CSP), to the source space, using various regularization approaches. We use Weighted Minimum Norm Estimate (wMNE) as a source localization technique. We show that for a multi-direction hand movement classification problem, the source space features can result in an increase\u00a0\u2026", "Neural information recorded from electroencephalogram (EEG) provides new possibilities for diagnosis of brain abnormalities, cognitive monitoring, etc. However, many artifacts, such as eye blink and muscle movements, impact and contaminate EEG data. While traditional techniques proposed for artifact removal identified artifact on two-way data, (spatial x temporal), multidimensional nature of EEG data (spatial x temporal x spectral x condition x trial) is overlooked. In this work, we investigate the use of multiway analysis/tensor factorization on the extended EEG tensor (spatial x temporal x spectral), which is constructed from continuous wavelet transform, using Block Term Decomposition (BTD) of rank-(L r , L r , 1) for artifact removal. Eight different carefully designed experiments to study artifact typically produced by voluntarily, and sometimes involuntarily, behaviors using a subject were performed and analyzed\u00a0\u2026", "Electroencephalography (EEG) is the most widely used Brain-Computer Interface (BCI) modality to record brain signal. Unlike other neuroimaging modalities like fMRI and PET, EEG is not very effective in localizing the brain sources. However, with the advent of inverse modeling techniques for source localization, it is possible to use EEG as an alternative neuroimaging technique. In this paper, source localization using EEG signal is used to analyze single-trial movement imagination (MI) tasks. Wadsworth physiobank dataset of 109 subjects performing right hand vs left hand movement imagination is considered. Forward modeling based on 3 layered head geometry is co-registered with ICBM 152 template anatomy, which is a non-linear average of fMRI scans of 152 subjects. Inverse modeling is done with the help of Standardized Low Resolution Electromagnetic Tomography (sLORETA). The proposed method\u00a0\u2026", "Attention-deficit/hyperactivity disorder (ADHD) is a neurodevelopmental disorder presenting in early childhood with persistent, pervasive and impairing symptoms. It is also associated with other problematic mental health issues and negative outcomes, such as aggression, difficulties forming relationships and academic and occupational problems. Current standard treatments for ADHD include pharmacological treatments with stimulants and other medications, psychosocial interventions such as behavioural modifications, or a combination of both approaches (multi-modal approach consisting of parent education, medication and behaviour management for the child). There is interest in understanding effective non-pharmacological treatments for ADHD, given the temporary effects of medication and recent controversies on over-medicating children with ADHD. The use of neurofeedback treatment and\u00a0\u2026", "Effective learning and recovery of relevant source brain activity patterns is a major challenge to brain-computer interface using scalp EEG. Various spatial filtering solutions have been developed. Most current methods estimate an instantaneous demixing with the assumption of uncorrelatedness of the source signals. However, recent evidence in neuroscience suggests that multiple brain regions cooperate, especially during motor imagery, a major modality of brain activity for brain-computer interface. In this sense, methods that assume uncorrelatedness of the sources become inaccurate. Therefore, we are promoting a new methodology that considers both volume conduction effect and signal propagation between multiple brain regions. Specifically, we propose a novel discriminative algorithm for joint learning of propagation and spatial pattern with an iterative optimization solution. To validate the new\u00a0\u2026", "We present a new linear discriminant analysis method based on information theory, where the mutual information between linearly transformed input data and the class labels is maximized. First, we introduce a kernel-based estimate of mutual information with a variable kernel size. Furthermore, we devise a learning algorithm that maximizes the mutual information w.r.t. the linear transformation. Two experiments are conducted: the first one uses a toy problem to visualize and compare the transformation vectors in the original input space; the second one evaluates the performance of the method for classification by employing cross-validation tests on four datasets from the UCI repository. Various classifiers are investigated. Our results show that this method can significantly boost class separability over conventional methods, especially for nonlinear classification.", "This paper addresses an important issue in a self-paced brain\u2013computer interface (BCI): constructing subject-specific continuous control signal. To this end, we propose an alternative to the conventional regression/classification-based mechanism for building the transformation from EEG features into a univariate control signal. Based on information theory, the mechanism formulates the optimum transformation as maximizing the mutual information between the control signal and the mental state. We introduce a non-parametric mutual information estimate for general output distribution, and then develop a gradient-based algorithm to optimize the transformation using training data. We conduct an offline simulation study using motor imagery data from the BCI Competition IV Data Set I. The results show that the learning algorithm converged quickly, and the proposed method yielded significantly higher BCI\u00a0\u2026", "Appropriate choice of number of electrodes and their positions are essential in Brain-Computer Interface applications since using less electrodes collects insufficient information for classification purposes whereas using more collects redundant information that could degrade BCI performance. This paper proposes a novel method of optimizing EEG channel selection by using the regularized Common Spatial Pattern (CSP) algorithm to discard redundant channels and multi band signal decomposition to select subject-specific frequency range. The performance of the proposed method is compared with EEG channel selection using Fisher criterion, mutual information, support vector and CSP on 9 subjects for two motor imagery tasks. Experiment results show the proposed method yields the highest accuracy in selecting 4 to 10 channels compared with the methods studied as well as using all the channels. The results also illustrate the proposed method significantly improves by multi band filtering and can achieve an average of 47% reduction of channels with only an averaged drop of 1.04% in classification accuracy.", "To develop effective learning algorithms for continuous prediction of cursor movement using EEG signals is a challenging research issue in brain-computer interface (BCI). In this paper, we propose a novel statistical approach based on expectation-maximization (EM) method to learn the parameters of a classifier for EEG-based cursor control. To train a classifier for continuous prediction, trials in training data-set are first divided into segments. The difficulty is that the actual intention (label) at each time interval (segment) is unknown. To handle the uncertainty of the segment label, we treat the unknown labels as the hidden variables in the lower bound on the log posterior and maximize this lower bound via an EM-like algorithm. Experimental results have shown that the averaged accuracy of the proposed method is among the best.", null, null, "Feature extraction is very important to EEG-based brain computer interfaces (BCI) in helping achieve high classification accuracy. Preprocessing of EEG signals plays an important role, because an effective preprocessing method will help enhance the efficiency of the feature extraction. In this paper, sparse component analysis (SCA) is employed as a preprocessing method for EEG based BCI. A combined feature vector is constructed. This feature vector consists of a dynamical power feature and a dynamical common spatial pattern (CSP) feature. The dynamical power feature is extracted from selected SCA components, while the dynamical CSP feature is extracted from raw EEG data. Using the presented preprocessing and feature extraction method, we analyze the data for a cursor control BCI carried out at Wadsworth Center. Our results show that SCA preprocessing is the most effective in extracting a component\u00a0\u2026", "A novel method of noise reduction of speech based on direct modulation of LPC (linear predictive coding) coefficients is proposed. This method introduces higher-order derivatives of LPC coefficients with respect to the noise-to-signal energy ratio (NSR). With these derivatives, the noisy LPC coefficients are refined flexibly and efficiently to reduce noise contaminations. This method only needs the environmental NSR, and does not require knowledge of the probability distribution of the noise. This enhancement method is incorporated in an HMM (hidden Markov model)-based speech recognition system using LPC-derived cepstral features. A pronounced recognition error rate reduction is obtained after the speech enhancement.< >", "Background: Exposure therapy is highly effective for social anxiety disorder. However, there is room for improvement.Objective: This is a first attempt to examine the feasibility of an arousal feedback\u2013based exposure therapy to alleviate social anxiety symptoms in an analogue adult sample.Methods: A randomized, pilot, proof-of-concept trial was conducted to evaluate the acceptability, safety, and preliminary efficacy of our treatment program. Sessions were administered once a week for 4 weeks (1 hour each) to an analogue sample of 50 young adults who reported at least minimal social anxiety symptoms. Participants in both intervention and waitlist control groups completed assessments for social anxiety symptoms at the baseline, week 5, and week 10.Results: Most participants found the intervention acceptable (82.0%, 95% CI 69.0%-91.0%). Seven (14.9%, 95% CI 7.0%-28.0%) participants reported at least one mild adverse event over the course of study. No moderate or serious adverse events were reported. Participants in the intervention group demonstrated greater improvements on all outcome measures of public speaking anxiety from baseline to week 5 as compared to the waitlist control group (Cohen d= 0.61-1.39). Effect size of the difference in mean change on the overall Liebowitz Social Anxiety Scale was small (Cohen d= 0.13).Conclusions: Our results indicated that it is worthwhile to proceed to a larger trial for our treatment program. This new medium of administration for exposure therapy may be feasible for treating a subset of social anxiety symptoms. Additional studies are warranted to explore its therapeutic mechanisms.Trial\u00a0\u2026", "Among various brain activity patterns, Steady State Visual Evoked Potential (SSVEP) based Brain Computer Inter-face (BCI) requires the least training time while carrying the fastest information transfer rate, making it highly suitable for deploying efficient self-paced BCI systems. In this study, we propose a Spectrum and Phase Adaptive CCA (SPACCA) for subject-and device-specific SSVEP-based BCI. Cross subject heterogeneity of spectrum distribution is taken into consideration to improve the prediction accuracy. We design a library of phase shifting reference signals to accommodate subjective and device-related response time lag. With the flexible reference signal generating approach, the system can be optimized for any specific flickering source, include LED, computer screen and mobile devices. We evaluated the performance of SPACCA using three sets of data that use LED, computer screen and mobile\u00a0\u2026", "The subjects' performance in using a brain-computer interface (BCI) system controlled by motor imagery (MI) varies considerably. Poor subjects' performance, known as BCI deficiency, can be due to the subjects' inability to modulate their sensorimotor rhythms (SMRs). In this work, we investigated the feasibility of improving the BCI performance through neurofeedback (NF) training of the resting state alpha rhythm (8-13 Hz). Thirteen healthy subjects were recruited and randomly assigned to the experimental or the control group. The experimental group participated in a MI-BCI session, followed by 12 NF sessions, and a final MI-BCI sessions. The control group performed a MI-BCI session followed by a final MI-BCI session. The results showed that the performances of the experimental group after 12 sessions of NF significantly improved upon the initial MI-BCI performance (p=0.02) but not the control group (p=0.14\u00a0\u2026", "Electroencephalogram (EEG) data from performing motor imagery are usually used to calibrate a subject-specific model in Motor Imagery Brain-Computer Interface (MI-BCI). However, the performance of MI is not directly observable by another person. Studies that attempted to address this issue in order to improve subjects with low MI performance had shown that it is feasible to use calibration data from Passive Movement (PM) to detect MI in healthy subjects. This study investigates the feasibility of using calibration data from PM of stroke patients to detect MI. EEG data from 2 calibration runs of MI and PM by a robotic haptic knob, and 1 evaluation run of MI were collected in one session of recording from 34 hemiparetic stroke patients recruited in the clinical study. In each run, 40 trials of MI or PM and 40 trials of the background rest were collected. The off-line run-to-run transfer kappa values from the calibration runs\u00a0\u2026", "A system and method for processing brain signals in a BCI system. The method of processing brain signals in a BCI system includes the steps of processing the brain signals for control state detection to determine if a subject intends to use the BCI system; and processing the brain signals for command recognition if the control state detection method determines that the subject intends to use the BCI system.", "NeuroComm is a platform to develop real time brain computer interface (BCI) applications. This paper introduces the basic modules of this platform and discusses some implementation issues. With a user management module, our system is user friendly and suitable for multiple users. Also, with flexible configuration files and signal processing algorithm libraries, it is easier to integrate multiple BCI applications into one system. The NeuroComm platform also acts as a flexible tool for BCI research."]}, "collaboration_network": {"target": ["Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Kai Keng Ang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Haihong Zhang", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Vinod A Prasad", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Tihshih Lee", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Neethu Robinson", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Chai Quek", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Erico Tjoa", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Mahnaz Arvaneh", "Fabien Lotte", "Fabien Lotte", "Fabien Lotte", "Fabien Lotte", "Fabien Lotte", "Fabien Lotte", "Fabien Lotte", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Kavitha P Thomas", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Juan Helen Zhou", "Etienne Burdet", "Etienne Burdet", "Etienne Burdet", "Etienne Burdet", "Etienne Burdet", "Ranganatha Sitaram", "Ranganatha Sitaram", "Ranganatha Sitaram", "Ranganatha Sitaram", "Ranganatha Sitaram", "Niels Birbaumer", "Niels Birbaumer", "Niels Birbaumer", "Niels Birbaumer", "Niels Birbaumer", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Ziyuan (Jacob) ZHAO \u8d75\u5b50\u6e90", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Yi Ding", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Zeng Zeng", "Luzheng Bi", "Luzheng Bi", "Luzheng Bi", "Luzheng Bi", "Luzheng Bi", "Luzheng Bi", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Vikram Shenoy Handiru", "Wu Min", "Wu Min", "Wu Min", "Wu Min", "ZHENGHUA CHEN", "ZHENGHUA CHEN", "ZHENGHUA CHEN", "ZHENGHUA CHEN", "Emadeldeen Eldele", "Emadeldeen Eldele", "Emadeldeen Eldele", "Emadeldeen Eldele", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Mengling 'Mornin' Feng", "Xiaoli Li (\u674e\u6653\u9ece)", "Xiaoli Li (\u674e\u6653\u9ece)", "Xiaoli Li (\u674e\u6653\u9ece)", "Lu Shijian", "Lu Shijian", "Lu Shijian", "Lu Shijian", "Lu Shijian", "Ce Ju", "Ce Ju", "Ce Ju", "Ce Ju", "Christian Herff", "Christian Herff", "Christian Herff", "Christian Herff", "Tanja Schultz", "Tanja Schultz", "Tanja Schultz", "Tanja Schultz", "Zheng Liu", "Zheng Liu", "Bijun Tang", "Bijun Tang", "Lei Feng", "Lei Feng", "Lei Feng", "Novi Quadrianto", "Kat Agres", "Kat Agres", "Stefan K Ehrlich", "Stefan K Ehrlich", "Gordon Cheng", "Gordon Cheng", "Yu SUN", "Yu SUN", "Yu SUN", "Theerawit Wilaiprasitporn", "Theerawit Wilaiprasitporn", "Natalie Mrachacz-Kersting", "Gerwin Schalk", "Nicole Wenderoth", "Nicole Wenderoth", "Rea Lehner", "Rea Lehner", "Yangsong Zhang(\u5f20\u6768\u677e)", "Yangsong Zhang(\u5f20\u6768\u677e)", "Hsiao-ju Cheng", "Hsiao-ju Cheng", "Daqing Zhang, IEEE Fellow", "Seng Kwee Wee", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li", "Yuanqing Li"], "target_id": ["ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "ZR0P60cAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "0jbZBjAAAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "yhYd0_4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "GQhFah4AAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "RzmIFTkAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "Tj-KsfQAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "hh9WwAMAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "HBxF7nAAAAAJ", "bF8vZlQAAAAJ", "bF8vZlQAAAAJ", "bF8vZlQAAAAJ", "bF8vZlQAAAAJ", "bF8vZlQAAAAJ", "bF8vZlQAAAAJ", "bF8vZlQAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "1k0KaIkAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "4Z1S3_oAAAAJ", "1a7buCEAAAAJ", "1a7buCEAAAAJ", "1a7buCEAAAAJ", "1a7buCEAAAAJ", "1a7buCEAAAAJ", "2nUaSXEAAAAJ", "2nUaSXEAAAAJ", "2nUaSXEAAAAJ", "2nUaSXEAAAAJ", "2nUaSXEAAAAJ", "w0x8vm0AAAAJ", "w0x8vm0AAAAJ", "w0x8vm0AAAAJ", "w0x8vm0AAAAJ", "w0x8vm0AAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "2vL2XTsAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "8SYAgGIAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "ztBsejkAAAAJ", "7y-JUDQAAAAJ", "7y-JUDQAAAAJ", "7y-JUDQAAAAJ", "7y-JUDQAAAAJ", "7y-JUDQAAAAJ", "7y-JUDQAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "pncJGKMAAAAJ", "Hji1uWQAAAAJ", "Hji1uWQAAAAJ", "Hji1uWQAAAAJ", "Hji1uWQAAAAJ", "WUgu3nwAAAAJ", "WUgu3nwAAAAJ", "WUgu3nwAAAAJ", "WUgu3nwAAAAJ", "2LdeHIYAAAAJ", "2LdeHIYAAAAJ", "2LdeHIYAAAAJ", "2LdeHIYAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "F2ET1WsAAAAJ", "E3yQKloAAAAJ", "E3yQKloAAAAJ", "E3yQKloAAAAJ", "uYmK-A0AAAAJ", "uYmK-A0AAAAJ", "uYmK-A0AAAAJ", "uYmK-A0AAAAJ", "uYmK-A0AAAAJ", "9k60zP8AAAAJ", "9k60zP8AAAAJ", "9k60zP8AAAAJ", "9k60zP8AAAAJ", "n465ljAAAAAJ", "n465ljAAAAAJ", "n465ljAAAAAJ", "n465ljAAAAAJ", "CupDmmcAAAAJ", "CupDmmcAAAAJ", "CupDmmcAAAAJ", "CupDmmcAAAAJ", "tej8f-4AAAAJ", "tej8f-4AAAAJ", "qwXbP28AAAAJ", "qwXbP28AAAAJ", "DFhvO4cAAAAJ", "DFhvO4cAAAAJ", "DFhvO4cAAAAJ", "I-rLzGcAAAAJ", "oqasR7UAAAAJ", "oqasR7UAAAAJ", "V9xkbsgAAAAJ", "V9xkbsgAAAAJ", "km_K9awAAAAJ", "km_K9awAAAAJ", "PcXZ4O4AAAAJ", "PcXZ4O4AAAAJ", "PcXZ4O4AAAAJ", "U-L-iGIAAAAJ", "U-L-iGIAAAAJ", "nApQpKMAAAAJ", "RwLH9dsAAAAJ", "tpGTYkgAAAAJ", "tpGTYkgAAAAJ", "KWQEQegAAAAJ", "KWQEQegAAAAJ", "0m6nHjYAAAAJ", "0m6nHjYAAAAJ", "mxPeqyUAAAAJ", "mxPeqyUAAAAJ", "qn8CqEYAAAAJ", "rh3yJ_gAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ", "wN3v1coAAAAJ"], "type": ["Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "NTU", "NTU", "NTU", "NTU", "NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Outside NTU", "Unknown", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"], "location": ["A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "Stanford University", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "University of Sheffield", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "Imperial College London", "Imperial College London", "Imperial College London", "Imperial College London", "Imperial College London", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "University of T\u00fcbingen", "University of T\u00fcbingen", "University of T\u00fcbingen", "University of T\u00fcbingen", "University of T\u00fcbingen", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "A*STAR", "Beijing Institute of Technology", "Beijing Institute of Technology", "Beijing Institute of Technology", "Beijing Institute of Technology", "Beijing Institute of Technology", "Beijing Institute of Technology", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "National University of Singapore", "Unknown", "Unknown", "Unknown", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Unknown", "Unknown", "Unknown", "Unknown", "Maastricht University", "Maastricht University", "Maastricht University", "Maastricht University", "University of Bremen", "University of Bremen", "University of Bremen", "University of Bremen", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "National University of Singapore", "National University of Singapore", "National University of Singapore", "University of Sussex UK", "National University of Singapore", "National University of Singapore", "Unknown", "Unknown", "Technical University of Munich", "Technical University of Munich", "Zhejiang University", "Zhejiang University", "Zhejiang University", "Unknown", "Unknown", "Aalborg University", "Unknown", "ETH Zurich", "ETH Zurich", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Telecom SudParis", "Tan Tock Seng Hospital", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"], "year": [2017, 2015, 2009, 2013, "Unknown", 2015, 2008, 2013, 2016, 2019, 2015, 2013, 2017, 2015, 2011, 2015, 2017, 2011, 2021, 2012, 2011, 2010, 2017, 2011, 2011, 2017, 2014, 2010, 2015, 2013, 2014, 2013, 2020, 2014, 2014, 2014, 2008, 2016, 2012, 2013, 2017, 2012, 2013, 2012, 2013, 2012, 2009, 2013, 2018, 2009, 2009, 2015, 2015, 2020, 2015, 2013, 2021, 2012, 2017, 2009, 2012, 2011, 2015, 2010, 2019, 2010, 2020, 2014, 2018, 2010, 2012, 2016, 2008, 2018, 2013, 2013, 2022, 2013, 2014, 2012, 2016, 2011, 2014, 2021, 2014, 2010, 2012, 2018, 2022, 2018, 2012, 2009, 2022, 2009, 2013, 2014, 2015, 2013, 2012, 2021, 2010, 2013, 2015, 2014, 2014, 2016, 2011, 2009, 2023, 2009, 2012, 2020, 2010, 2011, 2018, 2010, 2013, 2012, 2010, 2011, 2013, 2012, 2010, 2013, 2012, 2013, 2013, 2008, 2012, 2021, 2013, 2012, 2012, 2014, 2014, 2016, 2017, 2013, 2008, 2017, 2011, 2008, 2008, 2013, 2008, 2019, 2014, 2011, 2015, 2013, 2006, 2008, 2011, 2011, 2007, 2006, 2015, 2008, 2016, 2012, 2009, 2018, 2007, 2010, 2009, 2009, 2011, 2023, 2013, 2022, 2017, 2015, 2009, 2008, 2010, 2006, 2010, 2008, 2008, 2015, 2019, 2019, 2021, 2015, 2010, 2015, 2008, 2019, 2013, 2018, 2013, 2009, 2010, 2010, 2012, 2014, 2007, 2017, 2014, 2014, 2012, 2009, 2010, 2015, 2011, 2014, 2008, 2021, 2012, 2022, 2014, 2021, 2019, 2014, 2007, 2011, 2017, 2009, 2012, 2010, 2010, 2007, 2006, 2006, 2014, 2007, 2012, 2008, 2022, 2008, 2014, 2006, 2012, 2012, 2013, 2010, 2014, 2013, 2008, 2018, 2015, 2013, 2009, 2009, 2018, 2016, 2017, 2013, 2016, 2014, 2020, 2013, 2017, 2010, 2011, 2011, 2014, 2018, 2013, 2013, 2021, 2019, 2015, 2015, 2020, 2019, 2015, 2018, 2013, 2020, 2018, 2019, 2015, 2010, 2015, 2018, 2018, 2018, 2015, 2017, 2013, 2015, 2012, 2019, 2019, 2021, 2019, 2015, 2020, 2013, 2017, 2021, 2014, 2020, 2016, 2021, 2021, 2019, 2022, 2011, 2019, 2018, 2013, 2013, 2021, 2021, 2019, 2021, 2015, 2016, 2012, 2012, 2013, 2011, 2011, 2009, 2011, 2020, 2012, 2015, 2013, 2010, 2013, 2009, 2012, 2022, 2021, 2022, 2021, 2023, 2023, 2019, 2022, 2020, 2023, 2013, 2011, 2012, 2010, 2011, 2012, 2016, 2013, 2010, 2013, 2012, 2009, 2010, 2009, 2010, 2015, 2010, 2010, 2008, 2013, 2009, 2009, 2011, 2010, 2013, 2014, 2013, 2018, 2020, 2021, 2018, 2021, 2020, 2020, 2019, 2022, 2007, 2008, 2010, 2007, 2006, 2007, 2016, 2013, 2015, 2016, 2007, 2016, 2013, 2015, 2016, 2021, 2023, 2022, 2022, 2021, 2022, 2021, 2023, 2023, 2023, 2022, 2020, 2021, 2022, 2023, 2023, 2019, 2023, 2022, 2023, 2021, 2022, 2021, 2023, 2022, 2022, 2021, 2022, 2021, 2023, 2022, 2021, 2018, 2023, 2019, 2018, 2022, 2018, 2015, 2017, 2017, 2016, 2017, 2015, 2016, 2023, 2021, 2023, 2021, 2023, 2021, 2023, 2021, 2021, 2021, 2023, 2023, 2011, 2012, 2011, 2011, 2012, 2012, 2011, 2012, 2023, 2021, 2021, 2014, 2008, 2009, 2008, 2008, 2022, 2023, 2020, 2022, 2013, 2012, 2014, 2012, 2013, 2012, 2014, 2012, 2020, 2021, 2020, 2021, 2018, 2015, 2013, 2007, 2019, 2019, 2019, 2017, 2019, 2017, 2023, 2023, 2022, 2022, 2023, 2021, 2015, 2021, 2021, 2021, 2021, 2021, 2023, 2021, 2021, 2021, 2021, 2011, 2006, 2006, 2007, 2010, 2008, 2009, 2006, 2008, 2010, 2006, 2006, 2009, 2008, 2010, 2008, 2006, 2004, 2006], "title": ["Discriminative Ocular Artifact Correction for Feature Learning in EEG Analysis", "Brain\u2013Computer Interface for Neurorehabilitation of Upper Limb After Stroke", "A new discriminative common spatial pattern method for motor imagery brain\u2013computer interfaces", "Dynamically weighted ensemble classification for non-stationary EEG processing", "Brain Connectivity and CBF Canges Fllowing Motor Training by MI-BCI Combined with TDCS in Stroke Patients", "Facilitating effects of transcranial direct current stimulation on motor imagery brain-computer interface with robotic feedback for stroke rehabilitation", "Augmenting cognitive processes in robot-assisted motor rehabilitation", "Discriminative Learning of Propagation and Spatial Pattern for Motor Imagery EEG Analysis", "Adaptive decoding using local field potentials in a brain-machine interface", "Towards EEG generation using GANs for BCI applications", "On the use of convolutional neural networks and augmented CSP features for multi-class motor imagery of EEG signals classification", "Facilitating effects of Transcranial Direct Current Stimulation on EEG-based motor imagery BCI for stroke rehabilitation", "EEG-based Strategies to Detect Motor Imagery for Control and Rehabilitation", "Device and method for generating a representation of a subject's attention level", "Filter Bank Common Spatial Pattern (FBCSP) algorithm using online adaptive and semi-supervised learning", "A randomized controlled trial of EEG-based motor imagery brain-computer interface robotic rehabilitation for stroke", "Effects of Transcranial Direct Current Stimulation on the Motor-Imagery Brain-Computer Interface for Stroke Recovery: An EEG Source-Space study", "Calibrating EEG-based motor imagery brain-computer interface from passive movement", "Generative Adversarial Networks-Based Data Augmentation for Brain\u2013Computer Interface", "Online semi-supervised learning with KL distance weighting for motor imagery-based BCI", "A large clinical study on the ability of stroke patients to use an EEG-based motor imagery brain-computer interface", "EEG Channel Selection Using Decision Tree in Brain-Computer Interface", "Boosting performance in brain-machine interface by classifier-level fusion based on accumulative training models from multi-day data", "Optimizing the channel selection and classification accuracy in EEG-based BCI", "Composite filter bank common spatial pattern for motor imagery-based brain-computer interface", "Personalized features for attention detection in children with Attention Deficit Hyperactivity Disorder", "Single-trial classification of NIRS data from prefrontal cortex during working memory tasks", "EEG signal separation for multi-class motor imagery using common spatial patterns based on Joint Approximate Diagonalization", "A subject-independent pattern-based brain-computer interface", "NEURAL DECODING OF MOVEMENT TARGETS BY UNSORTED SPIKE TRAINS", "On the asynchronously continuous control of mobile robot movement by motor cortical spiking activity", "Common frequency pattern for music preference identification using frontal EEG", "Method and system for using haptic device and brain-computer interface for rehabilitation", "Detection of motor imagery of swallow EEG signals based on the dual-tree complex wavelet transform and adaptive model selection", "Cortical activation of passive hand movement using Haptic Knob: A preliminary multi-channel fNIRS study", "Brain-computer interface-based robotic end effector system for wrist and hand rehabilitation: results of a three-armed randomized controlled trial for chronic stroke", "Filter bank common spatial pattern (FBCSP) in brain-computer interface", "Method and system for motor rehabilitation", "Prefrontal cortical activation during arithmetic processing differentiated by cultures: A preliminary fNIRS study", "Improving session-to-session transfer performance of motor imagery-based BCI using adaptive extreme learning machine", "Brain plasticity following MI-BCI training combined with tDCS in a randomized trial in chronic subcortical stroke subjects: a preliminary study", "Omitting the intra-session calibration in EEG-based brain computer interface used for stroke rehabilitation", "A multimodal fNIRS and EEG-based BCI study on motor imagery and passive movement", "Fast emotion detection from EEG using asymmetric spatial filtering", "Detection of motor imagery of swallow with model adaptation: swallow or tongue", "Robust EEG channel selection across sessions in brain-computer interface involving stroke patients", "Robust filter bank common spatial pattern (RFBCSP) in motor-imagery-based brain-computer interface", "Automatic selection of neuronal spike detection threshold via smoothed Teager energy histogram", "Differential Amplitude of Low-Frequency Fluctuations in brain networks after BCI Training with and without tDCS in Stroke", "Learning EEG-based spectral-spatial patterns for attention level measurement", "Spatio-spectral feature selection based on robust mutual information estimate for brain computer interfaces", "A measurement of motor recovery for motor imagery-based BCI using EEG coherence analysis", "Neural representations of movement intentions during brain-controlled self-motion", "Assessment of the Efficacy of EEG-based MI-BCI with Visual Feedback and EEG Correlates of Mental Fatigue for Upper-Limb Stroke Rehabilitation", "An analysis on driver drowsiness based on reaction time and EEG band power", "A novel hand strength assessment method integrated into haptic knob for stroke rehabilitation", "Task-related brain functional network reconfigurations relate to motor recovery in chronic subcortical stroke", "Transcranial direct current stimulation and EEG-based motor imagery BCI for upper limb stroke rehabilitation", "Brain-computer interface system and method", "A clinical study of motor imagery-based brain-computer interface for upper limb robotic rehabilitation", "Extracting effective features from high density nirs-based BCI for assessing numerical cognition", "Spatially sparsed common spatial pattern to improve BCI performance", "Towards improvement of MI-BCI performance of subjects with BCI deficiency", "Clinical study of neurorehabilitation in stroke using EEG-based motor imagery brain-computer interface with robotic feedback", "Prognostic and Monitory EEG-Biomarkers for BCI Upper-limb Stroke Rehabilitation", "Online performance evaluation of motor imagery BCI with augmented-reality virtual hand feedback", "Brain-computer Interface-based Soft Robotic Glove Rehabilitation for Stroke", "Detection of motor imagery of brisk walking from electroencephalogram", "Quantitative EEG as Biomarkers for the Monitoring of Post-Stroke Motor Recovery in BCI and tDCS Rehabilitation", "An information theoretic linear discriminant analysis method", "Combined transcranial direct current stimulation and brain-computer interface rehabilitation-A new approach to motor rehabilitation", "Independent mobility achieved through a wireless brain-machine interface", "A clinical evaluation of non-invasive motor imagery-based brain-computer interface in stroke", "Method and apparatus for real-time discriminative ocular artefact removal from eeg signals", "MAXIMUM DEPENDENCY AND MINIMUM REDUNDANCY-BASED CHANNEL SELECTION FOR MOTOR IMAGERY OF WALKING EEG SIGNAL DETECTION", "EEG Data Space Adaptation to Reduce Intersession Nonstationarity in Brain-Computer Interface", "Learning EEG Representations with Weighted Convolutional Siamese Network: A Large Multi-Session Post-Stroke Rehabilitation Study", "Resting state changes in functional connectivity correlate with movement recovery for BCI and robot-assisted upper-extremity training after stroke", "Brain-computer interface for neurorehabilitation: Looking beyond upper limbs", "Filter bank common spatial pattern algorithm on BCI competition iv datasets 2a and 2b", "Facilitating motor imagery-based brain\u2013computer interface for stroke patients using passive movement", "A Wavelet-CSP method to classify hand movement directions in EEG based BCI system", "Selection of effective EEG channels in brain computer interfaces based on inconsistencies of classifiers", "Brain functional changes in stroke following rehabilitation using brain-computer interface-assisted motor imagery with and without tDCS: a pilot study", "Adaptation of motor imagery EEG classification model based on tensor decomposition", "Application of rough set-based neuro-fuzzy system in NIRS-based BCI for assessing numerical cognition in classroom", "Seizure detection based on spatiotemporal correlation and frequency regularity of scalp EEG", "Spectrum and Phase Adaptive CCA for SSVEP-based Brain Computer Interface", "Online Adaptive CNN: a Session-to-session Transfer Learning Approach for Non-stationary EEG", "Wavlet phase-locking based binary classification of hand movement directions from EEG", "Asymmetric spatial pattern for EEG-based emotion detection", "A feasibility study of non-invasive motor-imagery BCI-based robotic rehabilitation for stroke patients", "System and method for detecting eye activity", "Comparison of designs towards a subject-independent brain-computer interface based on motor imagery", "Mutual information-based optimization of sparse spatio-spectral filters in brain\u2013computer interface", "Discriminative channel addition and reduction for filter bank common spatial pattern in motor imagery BCI", "Combining firing rate and spike-train synchrony features in the decoding of motor cortical activity", "Motor imagery BCI for upper limb stroke rehabilitation: An evaluation of the EEG recordings using coherence analysis", "Multi-frequency band common spatial pattern with sparse optimization in Brain-Computer Interface", "Signal processing system for brain machine interface and method performed by the system", "Digital signal processing and machine learning", "Feature consistency-based model adaptation in session-to-session classification: A study using motor imagery of swallow EEG signals", "Motor cortical adaptation induced by closed-loop BCI", "Quality assessment of EEG signals based on statistics of signal fluctuations", "Spatial filter adaptation based on geodesic-distance for motor EEG classification", "Neural and cortical analysis of swallowing and detection of motor imagery of swallow for dysphagia rehabilitation\u2014A review", "Filter Bank Feature Combination (FBFC) approach for brain-computer interface", "Classification of self-paced finger movements with EEG signals using neural network and evolutionary approaches", "Brain-Computer Interface for Stroke Rehabilitation", "Multi-class filter bank common spatial pattern for four-class motor imagery BCI", "Cluster impurity and forward-backward error maximization-based active learning for EEG signals classification", "Corrigendum: Using Transcranial Direct Current Stimulation to Augment the Effect of Motor Imagery-Assisted Brain-Computer Interface Training in Chronic Stroke Patients\u00a0\u2026", "Optimum spatio-spectral filtering network for brain\u2013computer interface", "Adaptive tracking of discriminative frequency components in electroencephalograms for a robust brain\u2013computer interface", "Motor imagery-assisted brain-computer interface for gait retraining in neurorehabilitation in chronic stroke", "Optimizing EEG channel selection by regularized spatial filtering and multi band signal decomposition", "Navigation in a virtual environment using multiclass motor imagery Brain-Computer Interface", "Mutual information-based selection of optimal spatial\u2013temporal patterns for single-trial EEG-based BCIs", "A brain-computer interface for mental arithmetic task from single-trial near-infrared spectroscopy brain signals", "Real coded GA-based SVM for motor imagery classification in a Brain-Computer Interface", "EEG-based Classification of Fast and Slow Hand Movements Using Wavelet-CSP Algorithm", "Iterative clustering and support vectors-based high-confidence query selection for motor imagery eeg signals classification", "Multi-class motor motion imagery using common spatial patterns based on joint approximate diagonalization", "Multi-class EEG classification of voluntary hand movement directions", "Extracting and selecting discriminative features from high density NIRS-based BCI for numerical cognition", "A clinical study of motor imagery BCI performance in stroke by including calibration data from passive movement", "Brain-computer interface in stroke rehabilitation", "Multiclass voluntary facial expression classification based on filter bank common spatial pattern", "Dynamically weighted classification with clustering to tackle non-stationarity in brain computer interfacing", "FBCNet: A multi-view convolutional neural network for brain-computer interface", "Optimizing low-frequency common spatial pattern features for multi-class classification of hand movement directions", "Brain-Computer Interface-based (BCI) based arm robotic rehabilitation for stroke: a feasibility study and randomized controlled trial", "Dynamic initiation and dual-tree complex wavelet feature-based classification of motor imagery of swallow EEG signals", "The predictive role of pre-cue EEG rhythms on MI-based BCI classification performance", "Spatial filter adaptation based on the divergence framework for motor imagery EEG classification", "On the correlations of motor imagery of swallow with motor imagery of tongue movements and actual swallow", "Stop state classification in intracortical brain-machine-interface", "JOINT SPATIAL-TEMPORAL FILTER DESIGN FOR ANALYSIS OF MOTOR IMAGERY EEG", "A clinical evaluation on the spatial patterns of non-invasive motor imagery-based brain-computer interface in stroke", "Discriminative Ocular Artifact Correction for Feature Learning in EEG Analysis", "A linear discriminant analysis method based on mutual information maximization", "Unsupervised brain computer interface based on inter-subject information", "Augmenting cognitive processes in robot-assisted motor rehabilitation", "Discriminative Learning of Propagation and Spatial Pattern for Motor Imagery EEG Analysis", "Arm flexion and extension exercises using a brain-computer interface and functional electrical stimulation", "Autodidactic cognitive training device and method thereof", "Heart rate estimation from FBG sensors using cepstrum analysis and sensor fusion", "Filter Bank Common Spatial Pattern (FBCSP) algorithm using online adaptive and semi-supervised learning", "Device and method for generating a representation of a subject's attention level", "Bayesian learning for spatial filtering in an EEG-based brain-computer interface.[J]", "A statistical model of brain signals with application to brain-computer interface", "Asynchronous P300-based brain--computer interfaces: A computational approach with statistical models", "A large clinical study on the ability of stroke patients to use an EEG-based motor imagery brain-computer interface", "Composite filter bank common spatial pattern for motor imagery-based brain-computer interface", "Time-variant spatial filtering for motor imagery classification", "A kernel-based signal localization method for nirs brain-computer interfaces", "Reduction in time-to-sleep through EEG based brain state detection and audio stimulation", "Filter bank common spatial pattern (FBCSP) in brain-computer interface", "Method and system for motor rehabilitation", "Fast emotion detection from EEG using asymmetric spatial filtering", "Robust filter bank common spatial pattern (RFBCSP) in motor-imagery-based brain-computer interface", "Effectiveness of a Personalized Brain-Computer Interface System for Cognitive Training in Healthy Elderly: A Randomized Controlled Trial", "Towards asynchronous brain-computer interfaces: a P300-based approach with statistical models", "Effectiveness of a brain-computer interface based programme for the treatment of ADHD: a pilot study", "Learning EEG-based spectral-spatial patterns for attention level measurement", "Spatio-spectral feature selection based on robust mutual information estimate for brain computer interfaces", "Brain computer interface based 3D game for attention training and rehabilitation", "ALERT VERSUS FATIGUE DISCRIMINATOR", "Method and system for detecting attention", "Identifying and extracting electroencephalogram signals", "Brain-computer interface system and method", "Method for assessing the treatment of attention-deficit/hyperactivity disorder", "A clinical study of motor imagery-based brain-computer interface for upper limb robotic rehabilitation", "An EEG-based BCI system for 2D cursor control", "Clinical study of neurorehabilitation in stroke using EEG-based motor imagery brain-computer interface with robotic feedback", "P300 brain-computer interface design for communication and control applications", "Towards optimum linear transformation under zero-mean Gaussian mixtures for detection of motor imagery EEG", "Learning adaptive subject-independent P300 models for EEG-based brain-computer interfaces", "A step towards discretized motion control of the upper limb using brain-computer interface and electrical stimulation", "An ocular artefacts correction method for discriminative EEG analysis based on logistic regression", "Multi-channel ballistocardiography with cepstrum smoothing and quality-based dynamic channel selection", "Exposure Therapy With Personalized Real-Time Arousal Detection and Feedback to Alleviate Social Anxiety Symptoms in an Analogue Adult Sample: Pilot Proof-of-Concept Randomized\u00a0\u2026", "Sleep profiling system with feature generation and auto-mapping", "A pilot randomized controlled trial using eeg-based brain\u2013computer interface training for a Chinese-speaking group of healthy elderly", "An information theoretic linear discriminant analysis method", "On robust extraction of pulse transit time from multimodal pulsatile signals", "A clinical evaluation of non-invasive motor imagery-based brain-computer interface in stroke", "Exploring Cortex Connectivity Signal in Sensory Response to Odors", "A brain-computer interface based cognitive training system for healthy elderly: a randomized control pilot study for usability and preliminary efficacy", "Method and apparatus for real-time discriminative ocular artefact removal from eeg signals", "System and method for processing brain signals in a BCI system", "Unsupervised brain computer interface based on intersubject information and online adaptation", "A hybrid BCI system for 2-d asynchronous cursor control", "A brain controlled wheelchair to navigate in familiar environments", "Filter bank common spatial pattern algorithm on BCI competition iv datasets 2a and 2b", "Adaptation of motor imagery EEG classification model based on tensor decomposition", "Introduction to NeuroComm: A platform for developing real-time EEG-based brain-computer interface applications", "A Feasibility Study of Detecting Brain Signal in EEG During Emotional Self-Regulation", "Information processing of optical sensor data in ambient applications", "Method and system for classifying brain signals in a BCI using a subject-specific model", "Asymmetric spatial pattern for EEG-based emotion detection", "A feasibility study of non-invasive motor-imagery BCI-based robotic rehabilitation for stroke patients", "An EEG-based BCI system for 2-D cursor control by combining Mu/Beta rhythm and P300 potential", "System and method for motor learning", "Learning from feedback training data at a self-paced brain\u2013computer interface", "Detection of variations in cognitive workload using multi-modality physiological sensors and a large margin unbiased regression machine", "Hybrid P300 and Mu-Beta brain computer interface to operate a brain controlled wheelchair", "Signal processing system for brain machine interface and method performed by the system", "A Brain-Computer Interface Based Attention Training Program for Treating Attention Deficit Hyperactivity Disorder", "Scalp EEG-based Pain Detection using Convolutional Neural Network", "A BCI speller based on SSVEP using high frequency stimuli design", "Brain-computer interface based attention and social cognition training programme for children with ASD and co-occurring ADHD: A feasibility trial", "A Randomized Controlled Trial of a Brain-Computer Interface based Attention Training Program for ADHD", "Spatial filter adaptation based on geodesic-distance for motor EEG classification", "Temporal classification of multichannel near-infrared spectroscopy signals of motor imagery for developing a brain\u2013computer interface", "Filter Bank Feature Combination (FBFC) approach for brain-computer interface", "Toward EEG-based Olfactory Sensing through Spatial Temporal Subspace Optimization", "Multi-class filter bank common spatial pattern for four-class motor imagery BCI", "Cluster impurity and forward-backward error maximization-based active learning for EEG signals classification", "Optimum spatio-spectral filtering network for brain\u2013computer interface", "A New Modality of Brain Computer Interfaces for 2D Robot Control", "Controlling a wheelchair indoors using thought", "A brain-controlled wheelchair based on P300 and path guidance", "Media communication center using brain computer interface", "Method and system for concentration detection", "Selective subband entropy for motor imagery detection in asynchronous brain computer interface", "Mutual information-based selection of optimal spatial\u2013temporal patterns for single-trial EEG-based BCIs", "Subject-independent brain computer interface through boosting", "TESANet: Self-attention network for olfactory EEG classification", "Proceedings of the 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence).", "Automatic sleep onset detection using single EEG sensor", "Signal processing for brain-computer interface: Enhance feature extraction and classification", "Iterative clustering and support vectors-based high-confidence query selection for motor imagery eeg signals classification", "Dynamically weighted classification with clustering to tackle non-stationarity in brain computer interfacing", "Efficacy and Usability of a Brain-Computer Interface System in Improving Cognition in Elderly", "A maximum mutual information approach for constructing a 1D continuous control signal at a self-paced brain\u2013computer interface", "Spatial filter adaptation based on the divergence framework for motor imagery EEG classification", "JOINT SPATIAL-TEMPORAL FILTER DESIGN FOR ANALYSIS OF MOTOR IMAGERY EEG", "A clinical evaluation on the spatial patterns of non-invasive motor imagery-based brain-computer interface in stroke", "EEG Source Imaging of Movement Decoding: The State of the Art and Future Directions", "Shrinkage estimator based regularization for EEG motor imagery classification", "Hand movement trajectory reconstruction from EEG for brain-computer interface systems", "A new discriminative common spatial pattern method for motor imagery brain\u2013computer interfaces", "Discriminative filterbank selection and EEG information fusion for brain computer interface", "Quantitative EEG as Biomarkers for the Monitoring of Post-Stroke Motor Recovery in BCI and tDCS Rehabilitation", "Multi-direction hand movement classification using EEG-based source space analysis", "EEG source space analysis of the supervised factor analytic approach for the classification of multi-directional arm movement", "Enhancement of attention and cognitive skills using EEG based neurofeedback game", "A novel supervised locality sensitive Factor analysis to classify voluntary hand movement in multi direction using EEG source space", "Spatio-temporal variations in hand movement trajectory based brain activation patterns", "A Multi-view CNN with Novel Variance Layer for Motor Imagery Brain Computer Interface", "Design of an online EEG based neurofeedback game for enhancing attention and memory", "Effects of Transcranial Direct Current Stimulation on the Motor-Imagery Brain-Computer Interface for Stroke Recovery: An EEG Source-Space study", "A Study on the impact of spectral variability in brain-computer interface", "Adaptive tracking of discriminative frequency components in electroencephalograms for a robust brain\u2013computer interface", "A Wavelet-CSP method to classify hand movement directions in EEG based BCI system", "Evaluation of EEG features during overt visual attention during neurofeedback game", "Wavlet phase-locking based binary classification of hand movement directions from EEG", "EEG-based Classification of Fast and Slow Hand Movements Using Wavelet-CSP Algorithm", "Multi-class EEG classification of voluntary hand movement directions", "FBCNet: A multi-view convolutional neural network for brain-computer interface", "Prognostic and Monitory EEG-Biomarkers for BCI Upper-limb Stroke Rehabilitation", "Adaptive estimation of hand movement trajectory in an EEG based brain\u2013computer interface system", "Cortical source localization for analysing single-trial motor imagery EEG", "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "Exposure Therapy With Personalized Real-Time Arousal Detection and Feedback to Alleviate Social Anxiety Symptoms in an Analogue Adult Sample: Pilot Proof-of-Concept Randomized\u00a0\u2026", "A pilot randomized controlled trial using eeg-based brain\u2013computer interface training for a Chinese-speaking group of healthy elderly", "Brain-computer-interface-based intervention re-normalizes brain functional network topology in children with attention deficit/hyperactivity disorder", "A brain-computer interface based cognitive training system for healthy elderly: a randomized control pilot study for usability and preliminary efficacy", "BCI facilitates the improvement of cognitive functions in children and elderly", "Effectiveness of a Personalized Brain-Computer Interface System for Cognitive Training in Healthy Elderly: A Randomized Controlled Trial", "Autodidactic cognitive training device and method thereof", "Device and method for generating a representation of a subject's attention level", "Effectiveness of a brain-computer interface based programme for the treatment of ADHD: a pilot study", "Brain-computer interface and its applications in cognitive training", "Neural Indexes of Attention Extracted from EEG Correlate with Elderly Reaction Time in response to an Attentional Task", "Deep Convolutional Neural Network for the Detection of Attentive Mental State in Elderly", "EEG predicts the attention level of elderly measured by RBANS", "Method for assessing the treatment of attention-deficit/hyperactivity disorder", "Personalized features for attention detection in children with Attention Deficit Hyperactivity Disorder", "Efficacy and Usability of a Brain-Computer Interface System in Improving Cognition in Elderly", "Can we play with ADHD? An alternative game-based treatment for inattentive symptoms in attention-deficit/hyperactivity disorder", "A Brain-Computer Interface Based Attention Training Program for Treating Attention Deficit Hyperactivity Disorder", "Actigraphy studies and clinical and biobehavioural correlates in schizophrenia: a systematic review", "Large-scale brain functional network topology disruptions underlie symptom heterogeneity in children with attention-deficit/hyperactivity disorder", "Brain-computer interface based attention and social cognition training programme for children with ASD and co-occurring ADHD: A feasibility trial", "A Randomized Controlled Trial of a Brain-Computer Interface based Attention Training Program for ADHD", "An ocular artefacts correction method for discriminative EEG analysis based on logistic regression", "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "Hand movement trajectory reconstruction from EEG for brain-computer interface systems", "Detecting and tracking multiple directional movements in EEG based BCI", "Emerging Trends in BCI-Robotics for Motor Control and Rehabilitation", "Spatio-temporal variations in hand movement trajectory based brain activation patterns", "A Multi-view CNN with Novel Variance Layer for Motor Imagery Brain Computer Interface", "Real-time subject-independent pattern classification of overt and covert movements from fNIRS signals", "Investigation on robustness of EEG-based brain-computer interfaces", "Performance evaluation of compressed deep CNN for motor imagery classification using EEG", "A Comparative Study of Mental States in 2D and 3D Virtual Environments Using EEG", "TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition", "A Wavelet-CSP method to classify hand movement directions in EEG based BCI system", "EEG representation in deep convolutional neural networks for classification of motor imagery", "Wavlet phase-locking based binary classification of hand movement directions from EEG", "EEG-based Classification of Fast and Slow Hand Movements Using Wavelet-CSP Algorithm", "Multi-class EEG classification of voluntary hand movement directions", "Design considerations for long term non-invasive Brain Computer Interface training with tetraplegic CYBATHLON pilot", "FBCNet: A multi-view convolutional neural network for brain-computer interface", "Prognostic and Monitory EEG-Biomarkers for BCI Upper-limb Stroke Rehabilitation", "Adaptive transfer learning for EEG motor imagery classification with deep Convolutional Neural Network", "Adaptive estimation of hand movement trajectory in an EEG based brain\u2013computer interface system", "Correction: Real-Time Subject-Independent Pattern Classification of Overt and Covert Movements from fNIRS Signals", "Robust EEG channel selection across sessions in brain-computer interface involving stroke patients", "Sohyfis-yager: A self-organizing Yager based hybrid neural fuzzy inference system", "EEG Data Space Adaptation to Reduce Intersession Nonstationarity in Brain-Computer Interface", "SaFIN: A self-adaptive fuzzy inference network", "Fapop: Feature analysis enhanced pseudo outer-product fuzzy rule identification system", "T2-hyfis-yager: Type 2 hybrid neural fuzzy inference system realizing yager inference", "Optimizing the channel selection and classification accuracy in EEG-based BCI", "Assessment of the Efficacy of EEG-based MI-BCI with Visual Feedback and EEG Correlates of Mental Fatigue for Upper-Limb Stroke Rehabilitation", "Omitting the intra-session calibration in EEG-based brain computer interface used for stroke rehabilitation", "An analysis on driver drowsiness based on reaction time and EEG band power", "Mutual information-based optimization of sparse spatio-spectral filters in brain\u2013computer interface", "Optimizing EEG channel selection by regularized spatial filtering and multi band signal decomposition", "eT2FIS: An evolving type-2 neural fuzzy inference system", "HyFIS-Yager-gDIC: A self-organizing hybrid neural fuzzy inference system realizing yager inference", "Multi-frequency band common spatial pattern with sparse optimization in Brain-Computer Interface", "kaBEDONN: posthoc eXplainable Artificial Intelligence with Data Ordered Neural Network", "Two Instances of Interpretable Neural Network for Universal Approximations", "Evaluating Weakly Supervised Object Localization Methods Right? A Study on Heatmap-based XAI and Neural Backed Decision Tree", "Convolutional neural network interpretability with general pattern theory", "Endorsed Attributions: eXplainable AI (XAI) with Voting Mechanism with Application in Healthcare", "Enhancing the Confidence of Deep Learning Classifiers via Interpretable Saliency Maps", "Enhancing the Extraction of Interpretable Information for Ischemic Stroke Imaging from Deep Neural Networks", "Quantifying Explainability of Saliency Methods in Deep Neural Networks with a Synthetic Dataset", "Generalization on the Enhancement of Layerwise Relevance Interpretability of Deep Neural Network", "Self Reward Design with Fine-grained Interpretability", "EEG Data Space Adaptation to Reduce Intersession Nonstationarity in Brain-Computer Interface", "Spatially sparsed common spatial pattern to improve BCI performance", "Multi-frequency band common spatial pattern with sparse optimization in Brain-Computer Interface", "EEG Channel Selection Using Decision Tree in Brain-Computer Interface", "Optimizing the channel selection and classification accuracy in EEG-based BCI", "Omitting the intra-session calibration in EEG-based brain computer interface used for stroke rehabilitation", "Facilitating motor imagery-based brain\u2013computer interface for stroke patients using passive movement", "Mutual information-based optimization of sparse spatio-spectral filters in brain\u2013computer interface", "Optimizing EEG channel selection by regularized spatial filtering and multi band signal decomposition", "Optimizing Spatial Filters by Minimizing-Within-Class Dissimilarities in Electroencephalogram-Based Brain-Computer Interface", "Robust EEG channel selection across sessions in brain-computer interface involving stroke patients", "An efficient P300-based brain-computer interface with minimal calibration time", "Learning from other subjects helps reducing brain-computer interface calibration time", "Comparison of designs towards a subject-independent brain-computer interface based on motor imagery", "Spatially regularized common spatial patterns for EEG classification", "Electrocorticographic Representations of Segmental Features in Continuous Speech", "Towards a fully interpretable eeg-based bci system", "Regularizing common spatial patterns to improve BCI designs: unified theory and new algorithms", "An adaptive filter bank for motor imagery based brain computer interface", "Design of an online EEG based neurofeedback game for enhancing attention and memory", "A new discriminative common spatial pattern method for motor imagery brain\u2013computer interfaces", "Discriminative filterbank selection and EEG information fusion for brain computer interface", "Adaptive tracking of discriminative frequency components in electroencephalograms for a robust brain\u2013computer interface", "A Study on the impact of spectral variability in brain-computer interface", "2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)", "Evaluation of EEG features during overt visual attention during neurofeedback game", "Enhancement of attention and cognitive skills using EEG based neurofeedback game", "Effectiveness of a Personalized Brain-Computer Interface System for Cognitive Training in Healthy Elderly: A Randomized Controlled Trial", "Corrigendum: Using Transcranial Direct Current Stimulation to Augment the Effect of Motor Imagery-Assisted Brain-Computer Interface Training in Chronic Stroke Patients\u00a0\u2026", "Brain functional changes in stroke following rehabilitation using brain-computer interface-assisted motor imagery with and without tDCS: a pilot study", "Brain-computer-interface-based intervention re-normalizes brain functional network topology in children with attention deficit/hyperactivity disorder", "Task-related brain functional network reconfigurations relate to motor recovery in chronic subcortical stroke", "Minimizing Hybrid Dice Loss for Highly Imbalanced 3D Neuroimage Segmentation", "Brain MRI-based 3D Convolutional Neural Networks for Classification of Schizophrenia and Controls", "Large-scale brain functional network topology disruptions underlie symptom heterogeneity in children with attention-deficit/hyperactivity disorder", "Structural and diffusion MRI based schizophrenia classification using 2D pretrained and 3D naive Convolutional Neural Networks", "Controlling a wheelchair using a BCI with low information transfer rate", "Hybrid P300 and Mu-Beta brain computer interface to operate a brain controlled wheelchair", "A brain controlled wheelchair to navigate in familiar environments", "Controlling a wheelchair indoors using thought", "A brain-controlled wheelchair based on P300 and path guidance", "Temporal classification of multichannel near-infrared spectroscopy signals of motor imagery for developing a brain\u2013computer interface", "Real-time subject-independent pattern classification of overt and covert movements from fNIRS signals", "Resting state changes in functional connectivity correlate with movement recovery for BCI and robot-assisted upper-extremity training after stroke", "A subject-independent pattern-based brain-computer interface", "Correction: Real-Time Subject-Independent Pattern Classification of Overt and Covert Movements from fNIRS Signals", "Temporal classification of multichannel near-infrared spectroscopy signals of motor imagery for developing a brain\u2013computer interface", "Real-time subject-independent pattern classification of overt and covert movements from fNIRS signals", "Resting state changes in functional connectivity correlate with movement recovery for BCI and robot-assisted upper-extremity training after stroke", "A subject-independent pattern-based brain-computer interface", "Correction: Real-Time Subject-Independent Pattern Classification of Overt and Covert Movements from fNIRS Signals", "MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels", "SemiGNN-PPI: Self-Ensembling Multi-Graph Neural Network for Efficient and Generalizable Protein-Protein Interaction Prediction", "Self-supervised Assisted Active Learning for Skin Lesion Segmentation", "Meta-hallucinator: Towards Few-Shot Cross-Modality Cardiac Image Segmentation", "DSAL: Deeply Supervised Active Learning from Strong and Weak Labelers for Biomedical Image Segmentation", "ACT-Net: Asymmetric Co-Teacher Network for Semi-supervised Memory-efficient Medical Image Segmentation", "Hierarchical consistency regularized mean teacher for semi-supervised 3d left atrium segmentation", "LE-UDA: Label-efficient unsupervised domain adaptation for medical image segmentation", "Multimodal continuous emotion recognition: A technical report for abaw5", "MS-MT: Multi-Scale Mean Teacher with Contrastive Unpaired Translation for Cross-Modality Vestibular Schwannoma and Cochlea Segmentation", "MMGL: Multi-Scale Multi-View Global-Local Contrastive learning for Semi-supervised Cardiac Image Segmentation", "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "Continuous Emotion Recognition With Audio-Visual Leader-Follower Attentive Fusion", "Continuous Emotion Recognition using Visual-audio-linguistic information: A Technical Report for ABAW3", "GIGN: Learning Graph-in-graph Representations of EEG Signals for Continuous Emotion Recognition", "MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural Networks for Continuous and Discrete EEG Emotion Recognition", "Motor-Controlled Spindle (MCS) Detection for Primate in BCI System", "LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface", "TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition", "Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning", "Learning generalized representations of eeg between multiple cognitive attention tasks", "TESANet: Self-attention network for olfactory EEG classification", "MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels", "SemiGNN-PPI: Self-Ensembling Multi-Graph Neural Network for Efficient and Generalizable Protein-Protein Interaction Prediction", "Self-supervised Assisted Active Learning for Skin Lesion Segmentation", "Meta-hallucinator: Towards Few-Shot Cross-Modality Cardiac Image Segmentation", "DSAL: Deeply Supervised Active Learning from Strong and Weak Labelers for Biomedical Image Segmentation", "ACT-Net: Asymmetric Co-Teacher Network for Semi-supervised Memory-efficient Medical Image Segmentation", "Hierarchical consistency regularized mean teacher for semi-supervised 3d left atrium segmentation", "LE-UDA: Label-efficient unsupervised domain adaptation for medical image segmentation", "MMGL: Multi-Scale Multi-View Global-Local Contrastive learning for Semi-supervised Cardiac Image Segmentation", "Decoding Single-Hand and Both-Hand Movement Directions from Noninvasive Neural Signals", "A novel method of emergency situation detection for a brain-controlled vehicle by combining EEG signals with surrounding information", "Effects of Cognitive Distraction on Upper Limb Movement Decoding from EEG Signals", "A review on EMG-based motor intention prediction of continuous human upper limb motion for human-robot collaboration", "A single-trial event-related potential estimation based on independent component analysis and Kalman smoother", "Brain-Controlled Multi-Robot at Servo-Control Level Based on Nonlinear Model Predictive Control", "EEG Source Imaging of Movement Decoding: The State of the Art and Future Directions", "Shrinkage estimator based regularization for EEG motor imagery classification", "Effects of Transcranial Direct Current Stimulation on the Motor-Imagery Brain-Computer Interface for Stroke Recovery: An EEG Source-Space study", "Detecting and tracking multiple directional movements in EEG based BCI", "Multi-direction hand movement classification using EEG-based source space analysis", "EEG source space analysis of the supervised factor analytic approach for the classification of multi-directional arm movement", "Cortical source localization for analysing single-trial motor imagery EEG", "A novel supervised locality sensitive Factor analysis to classify voluntary hand movement in multi direction using EEG source space", "ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with Iterative Self-Training", "Time-Series Representation Learning via Temporal and Contextual Contrasting", "Self-supervised contrastive representation learning for semi-supervised time-series classification", "An Attention-based Deep Learning Approach for Sleep Stage Classification with Single-Channel EEG", "ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with Iterative Self-Training", "Time-Series Representation Learning via Temporal and Contextual Contrasting", "Self-supervised contrastive representation learning for semi-supervised time-series classification", "An Attention-based Deep Learning Approach for Sleep Stage Classification with Single-Channel EEG", "An Attention-based Deep Learning Approach for Sleep Stage Classification with Single-Channel EEG", "Time-Series Representation Learning via Temporal and Contextual Contrasting", "Self-supervised contrastive representation learning for semi-supervised time-series classification", "ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with Iterative Self-Training", "Artificial neural network based intracranial pressure mean forecast algorithm for medical decision support", "Go green! Reusing brain monitoring data containing missing values: a feasibility study with traumatic brain injury patients", "Artifact removal for intracranial pressure monitoring signals: a robust solution with signal decomposition", "SHORT-TERM TREND FORECAST OF NEUROPHYSIOLOGICAL SIGNALS FOR MEDICAL DECISION SUPPORT", "Utilization of temporal information for intracranial pressure development trend forecasting in traumatic brain injury", "Artifact correction with robust statistics for non-stationary intracranial pressure signal monitoring", "iSyNCC: An intelligent system for patient monitoring & clinical decision support in neuro-critical-care", "Online ICP forecast for patients with traumatic brain injury", "ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with Iterative Self-Training", "Time-Series Representation Learning via Temporal and Contextual Contrasting", "An Attention-based Deep Learning Approach for Sleep Stage Classification with Single-Channel EEG", "Method and system for classifying brain signals in a BCI using a subject-specific model", "Unsupervised brain computer interface based on inter-subject information", "Unsupervised brain computer interface based on intersubject information and online adaptation", "Learning adaptive subject-independent P300 models for EEG-based brain-computer interfaces", "Subject-independent brain computer interface through boosting", "Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor Imagery Classification", "Score-based Data Generation for EEG Spatial Covariance Matrices: Towards Boosting BCI Performance", "Federated Transfer Learning for EEG Signal Classification", "Deep Optimal Transport for Domain Adaptation on SPD Manifolds", "Self-paced BCI with NIRS based on speech activity", "Cross-subject classification of speaking modes using fNIRS", "Hybrid fNIRS-EEG based classification of auditory and visual perception processes", "Speaking mode recognition from functional near infrared spectroscopy", "Self-paced BCI with NIRS based on speech activity", "Cross-subject classification of speaking modes using fNIRS", "Hybrid fNIRS-EEG based classification of auditory and visual perception processes", "Speaking mode recognition from functional near infrared spectroscopy", "Machine learning-guided synthesis of advanced inorganic materials", "Machine Learning Driven Synthesis of Few-Layered WTe2 with Geometrical Control", "Machine learning-guided synthesis of advanced inorganic materials", "Machine Learning Driven Synthesis of Few-Layered WTe2 with Geometrical Control", "Effectiveness of a Personalized Brain-Computer Interface System for Cognitive Training in Healthy Elderly: A Randomized Controlled Trial", "A pilot randomized controlled trial using eeg-based brain\u2013computer interface training for a Chinese-speaking group of healthy elderly", "A brain-computer interface based cognitive training system for healthy elderly: a randomized control pilot study for usability and preliminary efficacy", "Sub-band common spatial pattern (SBCSP) for brain-computer interface", "A closed-loop, music-based brain-computer interface for emotion mediation", "A Comparative Study of Mental States in 2D and 3D Virtual Environments Using EEG", "A closed-loop, music-based brain-computer interface for emotion mediation", "A closed-loop Brain-Computer Music Interface for continuous affective interaction", "A closed-loop, music-based brain-computer interface for emotion mediation", "A closed-loop Brain-Computer Music Interface for continuous affective interaction", "E-Key: an EEG-Based Biometric Authentication and Driving Fatigue Detection System", "Machine learning technique reveals intrinsic EEG connectivity characteristics of patients with mild stroke during cognitive task performing", "Design a novel BCI for neurorehabilitation using concurrent LFP and EEG features: a case study", "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification", "OCTAve: 2D en face Optical Coherence Tomography Angiography Vessel Segmentation in Weakly-Supervised Learning with Locality Augmentation", "Generative Adversarial Networks-Based Data Augmentation for Brain\u2013Computer Interface", "Electrocorticographic Representations of Segmental Features in Continuous Speech", "Neurorehabilitation from a distance: can intelligent technology support decentralized access to quality therapy?", "Design considerations for long term non-invasive Brain Computer Interface training with tetraplegic CYBATHLON pilot", "Neurorehabilitation from a distance: can intelligent technology support decentralized access to quality therapy?", "Design considerations for long term non-invasive Brain Computer Interface training with tetraplegic CYBATHLON pilot", "An end-to-end 3D convolutional neural network for decoding attentive mental state", "A Transformer-based deep neural network model for SSVEP classification", "Task-related brain functional network reconfigurations relate to motor recovery in chronic subcortical stroke", "Brain functional changes in stroke following rehabilitation using brain-computer interface-assisted motor imagery with and without tDCS: a pilot study", "WiFi-Sleep: Sleep Stage Monitoring Using Commodity Wi-Fi Devices", "Neurorehabilitation from a distance: can intelligent technology support decentralized access to quality therapy?", "A linear discriminant analysis method based on mutual information maximization", "An effective BCI speller based on semi-supervised learning", "Analysis of source sparsity and recoverability for SCA based blind source separation", "A self-training semi-supervised support vector machine algorithm and its applications in brain computer interface", "A hybrid BCI system for 2-d asynchronous cursor control", "Equivalence probability and sparsity of two sparse solutions in sparse representation", "Voxel selection in fMRI data analysis: A sparse representation method", "Signal processing for brain-computer interface: Enhance feature extraction and classification", "A self-training semi-supervised SVM algorithm and its application in an EEG-based brain computer interface speller system", "An EEG-based BCI system for 2-D cursor control by combining Mu/Beta rhythm and P300 potential", "An extended EM algorithm for joint feature extraction and classification in brain-computer interfaces", "A semi-supervised SVM learning algorithm for joint feature extraction and classification in brain computer interfaces", "Voxel selection in fMRI data analysis based on sparse representation", "An EEG-based BCI system for 2D cursor control", "Digital signal processing and machine learning", "Joint feature re-extraction and classification using an iterative semi-supervised support vector machine algorithm", "Enhancing feature extraction with sparse component analysis for brain-computer interface", "Sparse factorization preprocessing-based offline analysis for a cursor control experiment", "Probability estimation for recoverability analysis of blind source separation based on sparse representation"], "link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dpaHy1TF288C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:SPgoriM2DtkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:35r97b3x0nAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:WMsFzbFqK_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:G-26V_K0F8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QIV2ME_5wuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KUbvn5osdkgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2VmNxfDIOWgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9N3KX2BFTccC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bKwnt0rjkrwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2BeMVx_SZpEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:mZB2-lCpWbQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K3LRdlH-MEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:CHSYGLWDkRkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:f4T9rk490XkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K_uVUG1YJAoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:5Ul4iDaHHb8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:KaRcLhEUy5UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:PR6Y55bgFSsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:zA6iFVUQeVQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:prvsfHNhuEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FKzTm0Bp8ZYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:maZDTaKrznsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EUQCXRtRnyEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eTOb990cMygC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Fr8DH2VBP9sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:H6myOybQgeYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PRLG7g5oK-wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:uWiczbcajpAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:cCmJLe1CRJUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FnaCo-ypupUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_V0JUKP8578C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HHUT0vUrEqMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:pgiGeGwzGf8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:0D9gKr9vLLUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:70eg2SAEIzsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VL0QpB8kHFEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Dip1O2bNi0gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:oR5SthnA400C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1yQoGdGgb4wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:M3zsPnPgUlUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eMMeJKvmdy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2Iopv88g0QUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:t6usbXjVLHcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-f6ydRqryjwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:twffdjNOitAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:x-Ysmmx-H-kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:IWHjjKOFINEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QLZAdv6BrvsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8QO3eJiZnkEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:xoH8P16vUNYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GzlcqhCAosUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:xtoqd-5pKcoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:PBZ9sWDp-nEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZuybSZzF8UAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:P5F9QuxV20EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Y5dfb0dijaUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NhqRSupF_l8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:X-Dm1JipzzIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:vCSeWdjOjw8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:D03iK_w7-QYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:gmhHX4scLhsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Y6EZgx1ah38C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:nlmsuG0oqtYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:u_35RYKgDlwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:XD-gHx7UXLsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QaLwMs-zPFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:WY6AygvC5sMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:URolC5Kub84C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fEOibwPWpKIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:JO0bfRJr_gQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:mvPsJ3kp5DgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:C4Vd9JCM9EcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:eflP2zaiRacC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Q3_nmhWTCy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BrmTIyaxlBUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7T_dCfhhGW4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1QLOHW2CHAAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:J4wmHkHhN-kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:p2g8aNsByqUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:XiVPGOgt02cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GZelqfngyKEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:TlqgXrSKREMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:E9iozgzfyhkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bnK-pcrLprsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ML0RJ9NH7IQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:TA1nTKmGtTgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:MXK_kJrjxJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RsqFu5Siv-AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:coeFWI40FR8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:jkTRWqoJ8oAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:i2xiXl-TujoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tkaPQYYpVKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:uQrt9rju91QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RGFaLdJalmkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-FonjvnnhkoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ZbiiB1Sm8G8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:5Y7y0xowK3MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:3oYmN_DgFiMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:l07DEcJES74C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4OULZ7Gr8RgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:uJ-U7cs_P_0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:H3xT48m3F74C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:TQgYirikUcIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_B80troHkn4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BN2gBF5gczIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:hMod-77fHWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GnPB-g6toBAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:jgpk9vOjLEcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:blknAaTinKkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:SpbeaW3--B0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:KxtntwgDAa4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:OU6Ihb5iCvQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LPZeul_q3PIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZfRJV9d4-WMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7T2F9Uy0os0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eq2jaN3J8jMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:M7yex6snE4oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:WA5NYHcadZ8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:S16KYo8Pm5AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:R6aXIXmdpM0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ULOm3_A8WrAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:olpn-zPbct0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Sipo1f_CKiIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:e_rmSamDkqQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:z_wVstp3MssC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HE397vMXCloC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:IT5EXw6i2GUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qzuIxkxWBNsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:I8ubwoE7ciMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Qqt8gOYqc0UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:AvfA0Oy_GE0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4DMP91E08xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dpaHy1TF288C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_kc_bZDykSQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QIV2ME_5wuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KUbvn5osdkgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qNJvDq80yDAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:x78xNeCKx3UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vs4DU1qUSb8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:CHSYGLWDkRkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K3LRdlH-MEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:cNepPnSnVCgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:zA6iFVUQeVQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EUQCXRtRnyEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:R3hNpaxXUhUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tzM49s52ZIMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KQ7zX_ltr48C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:70eg2SAEIzsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eMMeJKvmdy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-f6ydRqryjwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KVD38NuK74kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:pqnbT2bcN3wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bEWYMUwI8FkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:IWHjjKOFINEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:xtRiw3GOFMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9QTmwX2E1jEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:AXPGKjj_ei8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:h-fwNd0rmTkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:P5F9QuxV20EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2SmvwDDsShQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:e5wmG9Sq2KIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:a0OBvERweLwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NaGl4SEjCO4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Xc-mKOjpdrwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:aXI_bbQgCfgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:AdUz3-SiDfgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6uOcHTua4cQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:afsF9h1fxg0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lLPirIASiZEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:u_35RYKgDlwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:OWf_fnsf0g4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:aryKp6_dckwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:q3CdL3IzO_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:WY6AygvC5sMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_xSYboBqXhAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:W7OEmFMy1HYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:UxriW0iASnsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:LkGwnXOMwfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:eflP2zaiRacC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:J4wmHkHhN-kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dhFuZR0502QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:r7mTg6vxT4gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:r4zddjZt6C4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vV6vV6tmYwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bnK-pcrLprsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ML0RJ9NH7IQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:SP6oXDckpogC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:rO6llkc54NcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_8F20clBW_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ns9cj8rnVeAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:uQrt9rju91QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:WqliGbK-hY8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zDMysJqCCKgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hTqO-V9ugBQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:IbYibzvn7iEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fZtrMt_Z7PsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:3oYmN_DgFiMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4OULZ7Gr8RgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:nIr65G9GQVgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:TQgYirikUcIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_B80troHkn4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:hMod-77fHWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Z5m8FVwuT1cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RHpTSmoSYBkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:O3NaXMp0MMsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_Re3VWB3Y0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:KxtntwgDAa4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RYcK_YlVTxYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zQyJfvL_HJsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:cnT3a81PI4sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vlMkzkLhH4wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:iH-uZ7U-co4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7T2F9Uy0os0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:olpn-zPbct0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HbR8gkJAVGIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lSLTfruPkqcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qzuIxkxWBNsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:AvfA0Oy_GE0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4DMP91E08xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:JtjtGO9FvpUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qjuL_XCUnM8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bcT4vkklUMwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:k_IJM867U9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:nlmsuG0oqtYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:0KZCP5UExFUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LAaCg2gyLagC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EXDW3tg14iEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-mAZECE-jN4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:mq6pegT_rlEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FXgMSCUEOHUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PoWvk5oyLR8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K_uVUG1YJAoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dshw04ExmUIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GnPB-g6toBAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BrmTIyaxlBUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:gUOu-QWEMMQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:E9iozgzfyhkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZfRJV9d4-WMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:M7yex6snE4oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Sipo1f_CKiIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:vCSeWdjOjw8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8NHCvSvNRCIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:22I2CSi1iVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:zVd9Rc0DoukC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6uOcHTua4cQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lLPirIASiZEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:_5pobawY6TYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:q3CdL3IzO_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LWUVeqegjeYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KVD38NuK74kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:x78xNeCKx3UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K3LRdlH-MEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:bEWYMUwI8FkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:uH1VZYVfkoQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:aXQ7jtEqGowC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K5ggCqHMkpcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9i1gB6tY3MIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2SmvwDDsShQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:eTOb990cMygC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HbR8gkJAVGIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vlECJaBXBlQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:WqliGbK-hY8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:J6qkoyn5ZssC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:E8M3ZPqbjf0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:IbYibzvn7iEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fZtrMt_Z7PsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:aXI_bbQgCfgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:zVd9Rc0DoukC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bcT4vkklUMwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:MIZpzCdxGj0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:2hfDYGh-f1UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:mq6pegT_rlEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:FXgMSCUEOHUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:auQHJw8QJBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:CaJTFBI5vqAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_wawhP5Vwy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:r_W8SUTUyowC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:yKZlB_2wKysC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BrmTIyaxlBUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6IwoDg2IE1oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:E9iozgzfyhkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZfRJV9d4-WMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:M7yex6snE4oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:czIYXmO0riYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Sipo1f_CKiIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:vCSeWdjOjw8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Lmuc1furtc4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8NHCvSvNRCIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tDdgxD0hSQMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:t6usbXjVLHcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VLnqNzywnoUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fEOibwPWpKIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fQNAKQ3IYiAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ZHo1McVdvXMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dfsIfKJdRG4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:maZDTaKrznsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:xoH8P16vUNYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1yQoGdGgb4wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GzlcqhCAosUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RsqFu5Siv-AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:blknAaTinKkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:eJXPG6dFmWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BqipwSGYUEgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tkaPQYYpVKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:SDNreWq1RjYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Sx7WuSFExYwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:OTBXYDkIvNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:sAujV351FBYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zGnLiCkldm4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ZxXHo_Hcam8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:YpRCXavlr0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:10ZmGoIvuzkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8igAKu_hPxwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Yj1HztTP_LkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:fEOibwPWpKIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NhqRSupF_l8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tkaPQYYpVKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:prvsfHNhuEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:maZDTaKrznsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1yQoGdGgb4wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Q3_nmhWTCy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RsqFu5Siv-AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:blknAaTinKkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:W5xh706n7nkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:t6usbXjVLHcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:mB3voiENLucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:5nxA0vEk-isC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:MXK_kJrjxJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:L8Ckcad2t8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:8o7LCxyMrhgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:b0M2c_1WBrUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:MKvDIwB-zewC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:BUYA1_V_uYcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PoWvk5oyLR8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:k_IJM867U9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GnPB-g6toBAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:dshw04ExmUIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8v7czoltWYsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:gUOu-QWEMMQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EXDW3tg14iEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KVD38NuK74kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:BN2gBF5gczIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1QLOHW2CHAAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:_5pobawY6TYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:PBZ9sWDp-nEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qVBRRHSSJ04C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:sk-5v2XeZBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:E8M3ZPqbjf0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:7_FrD3gH8REC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ns9cj8rnVeAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:LkGwnXOMwfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:auQHJw8QJBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:mvPsJ3kp5DgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PRLG7g5oK-wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tDdgxD0hSQMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:auQHJw8QJBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:mvPsJ3kp5DgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:PRLG7g5oK-wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tDdgxD0hSQMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:UBnQDr5gPskC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Q5bjhRmoBfUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VdWZULf8Gq0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Ln2xPWQ6zl8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GsgvGxwuA5UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:DPkBdyRpVwQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QUYzkoTeugQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qkvbYSGtNvkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-Iwc2SO-hmoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8Z0Dsp3hPRYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:sArNgO4T4MoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:zVd9Rc0DoukC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:8Fucociq1QoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Efx6ZPdPmuEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Lyl8M50Wyb0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:co-xmOEWlm8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EwQYaEtUpKwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:JjPkQosUWiAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:yKZlB_2wKysC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VaBbNeojGYwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:DtORCzn_ASQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zQyJfvL_HJsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:UBnQDr5gPskC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Q5bjhRmoBfUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VdWZULf8Gq0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Ln2xPWQ6zl8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:GsgvGxwuA5UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:DPkBdyRpVwQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:QUYzkoTeugQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qkvbYSGtNvkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:sArNgO4T4MoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:VfMbra648c4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zPkyA21Y468C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9qGwjJavaBUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:5qu0sgD3nvwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:xwIxJehhd2UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4p5LGG1h9z0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:JtjtGO9FvpUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:qjuL_XCUnM8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:K_uVUG1YJAoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:MIZpzCdxGj0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:0KZCP5UExFUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LAaCg2gyLagC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:22I2CSi1iVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:-mAZECE-jN4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RVsengBWOnMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:JkxM1axsR-IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6syOTa9L3GQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:QBJtjoHflPwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RVsengBWOnMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:JkxM1axsR-IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6syOTa9L3GQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:QBJtjoHflPwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:QBJtjoHflPwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:JkxM1axsR-IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6syOTa9L3GQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RVsengBWOnMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:XiSMed-E-HIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:SeFeTyx0c_EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:tS2w5q8j5-wC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:j8SEvjWlNXcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:wbdj-CoPYUoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NJ774b8OgUMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:pyW8ca7W8N0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Fu2w8maKXqMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RVsengBWOnMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:JkxM1axsR-IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:QBJtjoHflPwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:vV6vV6tmYwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_kc_bZDykSQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:W7OEmFMy1HYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:NaGl4SEjCO4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RYcK_YlVTxYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:3YIFwf-X_CwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:u76CbRzuV8AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:LoiWQfKZB3kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ypg3kOuG8gIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EkHepimYqZsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ye4kPcJQO24C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:d4paSpBSrDQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LjlpjdlvIbIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:EkHepimYqZsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:ye4kPcJQO24C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:d4paSpBSrDQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:LjlpjdlvIbIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:nvAonm6-wpUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1GSnt3Xtl_sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:nvAonm6-wpUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1GSnt3Xtl_sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KVD38NuK74kC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:lLPirIASiZEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:q3CdL3IzO_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZLdq17c_vQkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:r_W8SUTUyowC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZLdq17c_vQkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bzhzIcV5SW4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ZLdq17c_vQkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:bzhzIcV5SW4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:Yv3O0rUKnT0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:4JjQL45tqTYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:T_m5ky3rny8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:ktX0m338QuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:flnLHN-H2asC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:KaRcLhEUy5UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:8o7LCxyMrhgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hMwNgRnlwaMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:czIYXmO0riYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hMwNgRnlwaMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:czIYXmO0riYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:KFIQUvoPKFAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:6nNZn6i0kyMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:PBZ9sWDp-nEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:1QLOHW2CHAAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:L8oS6_awjPoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:hMwNgRnlwaMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:mVmsd5A6BfQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=400&pagesize=100&citation_for_view=sg4vxPoAAAAJ:u9iWguZQMMsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:kNdYIx-mwKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:UxriW0iASnsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:HDshCWvjkbEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=300&pagesize=100&citation_for_view=sg4vxPoAAAAJ:3s1wT3WcHBgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:iH-uZ7U-co4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&citation_for_view=sg4vxPoAAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:YOwf2qJgpHMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:_FxGoFyzp5QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:e5wmG9Sq2KIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:RGFaLdJalmkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=20&pagesize=80&citation_for_view=sg4vxPoAAAAJ:0EnyYjriUFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:_Qo2XoVZTnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=200&pagesize=100&citation_for_view=sg4vxPoAAAAJ:9ZlFYXVOiuMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sg4vxPoAAAAJ&cstart=100&pagesize=100&citation_for_view=sg4vxPoAAAAJ:zYLM7Y9cAGgC"]}, "published_by_year": {"Year": ["1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023"], "# of Publications": [1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 1, 13, 7, 14, 12, 18, 13, 19, 24, 14, 16, 6, 11, 10, 15, 18, 18, 11, 3]}, "citations_by_year": {"Year": ["1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Citations": [0, 0, 1, 3, 2, 2, 0, 0, 0, 1, 0, 5, 5, 33, 94, 154, 202, 307, 475, 666, 878, 940, 1192, 1308, 1548, 1550, 1764, 2164, 2867, 3654, 3209, 128]}, "all_time_h_index": 72, "all_time_i10_index": 249, "all_time_i20_index": 184, "h_index_by_year": {"Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 7, 9, 13, 15, 18, 23, 28, 30, 33, 38, 41, 46, 51, 57, 61, 66, 72]}, "h_index_by_publication_year": {"Publication Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 1, 13, 7, 14, 12, 16, 13, 17, 18, 14, 13, 6, 11, 10, 13, 16, 16, 11, 3]}, "avg_citations_by_publication_year": {"Publication Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "Avg Citations per Publication": [13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 103.33333333333333, 36.0, 64.61538461538461, 225.71428571428572, 158.57142857142858, 103.41666666666667, 175.83333333333334, 87.0, 105.42105263157895, 72.875, 64.71428571428571, 95.4375, 25.833333333333332, 51.54545454545455, 73.3, 61.333333333333336, 73.94444444444444, 121.77777777777777, 27.636363636363637, 13.666666666666666]}, "h_index_by_years_from_publication_year": {"Publication Year": [1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2021, 2021, 2021, 2022, 2022, 2023], "Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2018, 2019, 2020, 2021, 2022, 2023, 2019, 2020, 2021, 2022, 2023, 2020, 2021, 2022, 2023, 2021, 2022, 2023, 2022, 2023, 2023], "h-index": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 5, 7, 7, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, 12, 12, 13, 13, 2, 4, 5, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 4, 7, 8, 9, 11, 12, 12, 12, 12, 13, 13, 14, 14, 14, 14, 1, 4, 7, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 3, 6, 8, 10, 11, 13, 13, 13, 13, 14, 15, 15, 16, 16, 2, 5, 7, 8, 9, 10, 10, 11, 11, 13, 13, 13, 13, 3, 5, 8, 9, 11, 13, 14, 15, 16, 16, 17, 17, 4, 7, 10, 12, 15, 16, 16, 17, 17, 17, 18, 1, 4, 7, 8, 10, 12, 13, 13, 14, 14, 3, 5, 8, 10, 11, 12, 13, 13, 13, 1, 3, 5, 6, 6, 6, 6, 6, 2, 6, 7, 8, 11, 11, 11, 2, 4, 8, 9, 10, 10, 3, 8, 10, 12, 13, 5, 10, 13, 16, 5, 13, 16, 6, 11, 3]}}