{"full_name": "Alexei Sourin", "email": "assourin@ntu.edu.sg", "google_scholar": "https://scholar.google.com/citations?user=8A7kHCYAAAAJ&hl=en&oi=ao", "dr_ntu": "https://dr.ntu.edu.sg/cris/rp/rp00274", "designation": "Associate Professor, School of Computer Science and Engineering", "image_path": "./profile_img/alexei_sourin.jpg", "biography": "Dr. Alexei Sourin was born in Moscow and received his M.Eng. and Ph.D. degrees in computer graphics from the Moscow Engineering Physics Institute, Russia (MEPhI) in 1983 and 1988, respectively. From 1983 to 1993 he was a researcher at MEPhI where he worked on different scientific visualization and computer animation projects. Since 1993 he held faculty positions at Nanyang Technological University (NTU) in Singapore, except a period from 1999 to 2000 when he was Associate Professor at Moscow Institute of Physics and Technology (MIPT). Currently he is a tenured Associate Professor with the School of Computer Science and Engineering at NTU. His research interests are in shape modeling, multi-modal interaction, music visualization, and automated visual inspection in manufacturing. Dr. Sourin published over 230 referred research papers and was invited to give talks to many scientific events. Dr. Sourin is also one of the pioneers of electronic education in Singapore. From 2012 to 2018, he was a Chair of the IFIP WG5.10 Computer Graphics and Virtual Worlds. Dr. Sourin is a Senior Member of IEEE and a member of ACM SIGGRAPH. He is an associate editor of several international journals including The Visual Computer (Springer) and Transactions on Computational Science (Springer). He was on the program committees of over 120 international conferences. He is a coordinator of the International Conferences on Cyberworlds for which he was also General and Program Chair in many years.", "orcid": "https://orcid.org/0000-0003-4051-2927", "other_websites": ["http://www3.ntu.edu.sg/home/assourin/"], "bachelor_degree": null, "masters": "Moscow Engineering Physics Institute, Russia (MEPhI)", "phd": "Moscow Engineering Physics Institute, Russia (MEPhI)", "name": "Alexei Sourin", "id": "rp00274", "publications": {"Publication Year": ["1995", "2006", "1995", "2020", "2006", "2019", "2000", "2004", "2019", "2006", "2001", "2001", "2007", "2000", "2006", "2001", "2006", "2009", "2006", "1993", "2009", "2018", "2006", "1996", "2019", "2008", "2009", "2013", "2017", "2016", "2016", "1998", "2007", "2011", "2004", "2014", "2011", "2020", "2018", "2007", "2017", "2010", "2005", "2005", "2016", "2009", "2016", "2011", "2009", "2008", "2002", "2002", "2018", "2010", "2010", "2007", "2006", "2002", "2014", "2008", "2007", "2009", "1995", "2017", "2016", "2011", "2009", "2021", "2012", "2022", "2016", "2016", "2013", "2013", "2013", "2009", "2006", "2016", "2015", "2013", "2013", "2012", "2005", "2002", "2021", "2020", "2019", "2016", "2014", "2012", "2004", "2003", "2021", "2021", "2016", "2014", "2010", "2010", "2009", "2005", "2005", "2023", "2019", "2019", "2017", "2013", "2006", "2005", "2002", "1998", "2021", "2020", "2019", "2018", "2018", "2018", "2016", "2015", "2015", "2014", "2005", "1999", "1998", "Unknown", "Unknown", "2019", "2019", "2017", "2017", "2016", "2014", "2013", "2012", "2012", "2012", "2006", "2004", "2003", "1994", "Unknown", "Unknown", "Unknown", "2022", "2022", "2021", "2021", "2021", "2021", "2021", "2021", "2021", "2021", "2021", "2018", "2018", "2018", "2017", "2017", "2016", "2016", "2015", "2013", "2013", "2012", "2011", "2011", "2011", "2010", "2010", "2010", "2010", "2010", "2010", "2009", "2008", "2007", "2006", "2006", "2006", "2006", "2005", "2005", "2004", "2004", "2004", "2004", "2003", "2003", "2002", "2002", "2002", "2002", "2000", "1996", "1996", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"], "Title": ["Function representation in geometric modeling: concepts, implementation and applications", "Human electroencephalograms seen as fractal time series: Mathematical analysis and visualization", "Function representation for sweeping by a moving solid", "Soldering defect detection in automatic optical inspection", "Cybercampuses: design issues and future directions", "One class based feature learning approach for defect detection using deep autoencoders", "Virtual orthopedic surgery training", "Nanyang Technological University virtual campus [virtual reality project]", "Interactive labelling of a multivariate dataset for supervised machine learning using linked visualisations, clustering, and active learning", "Grid-based computer animation rendering", "Synthetic carving using implicit surface primitives", "Functionally based virtual computer art", "Physically based hydraulic erosion simulation on graphics processing unit", "Orthopedic surgery training on personal computer", "Cyber-learning in cyberworlds", "Functionally based virtual embossing", "Function-defined shape metamorphoses in visual cyberworlds", "Novel tools for quantification of brain responses to music stimuli", "Analysis and visualization of human electroencephalograms seen as fractal time series", "Multidimensional geometric modeling and visualization based on the function representation of objects", "EEG data driven animation and its application", "Unsupervised surface defect detection using deep autoencoders and data augmentation", "Function-based shape modelling extension of the Virtual Reality Modelling Language", "Using real functions with application to hair modelling", "Detection defect in printed circuit boards using unsupervised feature extraction upon transfer learning", "Function-based visualization and haptic rendering in shared virtual spaces", "Interactive surface-guided segmentation of brain MRI data", "Image-driven virtual simulation of arthroscopy", "Procedural modeling of architecture with round geometry", "Exploration of natural free-hand interaction for shape modeling using leap motion controller", "Understanding people's mental models of mid-air interaction for virtual assembly and shape modeling", "Volume Modelling: Representations and advanced operations", "Orthopedic surgery training simulation", "Tangible images", "Interactive function-based shape modeling for cyberworlds", "Feasibility study on free hand geometric modelling using leap motion in VRML/X3D", "Haptic interaction with 2D images", "Interactive visual labelling versus active learning: an experimental comparison", "Mid-air interaction with optical tracking for 3D modeling", "Interactive function-based shape modelling", "Case study: shared virtual and augmented environments for creative applications", "A PDE method for patchwise approximation of large polygon meshes", "Place metaphors in educational cyberworlds: A virtual campus case study", "Function-based representation of complex geometry and appearance", "Real-time haptic interaction with RGBD video streams", "Visual immersive haptic mathematics", "Mid-air gestures for virtual modeling with leap motion", "Function-based approach to mixed haptic effects rendering", "3D visualization and segmentation of brain MRI data", "Visual immersive haptic rendering on the web", "Interactive function-based artistic shape modeling", "Function-defined shape node for VRML", "Towards automatic optical inspection of soldering defects", "Towards tangible images and video in cyberworlds--function-based approach", "Emotion modeling and interaction of NPCS in virtual simulation and games", "Function-based haptic interaction in cyberworlds", "Function-based shape modeling and visualization in X3D", "Interactive polygonisation for function-based shape modelling", "Image-driven haptic rendering", "Partial differential equations for function based geometry modelling within visual cyberworlds", "Fractal spectra and visualization of the brain activity evoked by olfactory stimuli", "Function-based haptic collaboration in X3D", "Function representation in geometric modeling: concepts, implementation and applications, The Visual Computer, vol. 11, No. 8", "Interactive shape modeling using leap motion controller", "Transactions on Computational Science XXVI: Special Issue on Cyberworlds and Cybersecurity", "Visual immersive mathematics in 3D web", "Collaboration in 3D Shared Spaces using X3D and VRML", "Detection and segmentation of image anomalies based on unsupervised defect reparation", "Function-based single and dual point haptic interaction in cyberworlds", "Self-supervised pairing image clustering for automated quality control", "Procedural modeling of round building geometry", "Problems of human-computer interaction in cyberworlds", "Towards making panoramic images in virtual arthroscopy", "Towards hand-eye coordination training in virtual knee arthroscopy", "Image-driven haptic simulation of arthroscopic surgery", "Visual immersive haptic mathematics in shared virtual spaces", "Computer Graphics: From a Small Formula to Cyberworlds", "Haptic interaction with a polygon mesh reconstructed from images", "Image\u2010inspired haptic interaction", "Image-driven haptic rendering in virtual environments", "Modern information technology: Information visualization, virtual environment, neo-geography, tangible images", "Design and implementation of a haptics-based virtual venepuncture simulation and training system", "Computer Graphics: From a Small Formula to Virtual Worlds", "Simulation and visualization of thermal wave propagation in picoscales", "Generation of music with dynamics using deep convolutional generative adversarial network", "Generation of irregular music patterns with deep learning", "Multiple linked-view exploration on large displays facilitated by a secondary handheld device", "Constructive roofs from solid building primitives", "Virtual knee arthroscopy using haptic devices and real surgical images", "Virtual palpation for medical training in cyberworlds", "Analytically-defined collaborative shape modeling in VRML", "Simulation and Visualization of Thermal Wave Propagation in Sub-nano-Scales: Ultra-fast laser heating of solid materials", "The Impact of a Number of Samples on Unsupervised Feature Extraction, Based on Deep Learning for Detection Defects in Printed Circuit Boards", "Virtual assembling using hand tracking with leap motion controller", "Assessing haptic video interaction with neurocognitive tools", "Constructive roof geometry", "Segmentation of MRI brain data using a haptic device", "Automatic reconstruction and web visualization of complex PDE shapes", "Towards a Definition of Virtual Objects using Partial Differential Equations", "Function-defined shape metamorphoses in VRML", "From a small formula to cyberworlds", "Automated Anomaly Detection for Surface Defects by Dual Generative Networks With Limited Training Data", "mVis in the wild: Pre-study of an interactive visual machine learning system for labelling", "Music in the Air with Leap Motion Controller", "Interactive screenspace fragment rendering for direct illumination from area lights using gradient aware subdivision and radial basis function interpolation", "Image-based virtual palpation", "Interactive grid-based free-form shape modeling", "Virtual Campus\u2013It is Fun and Educational", "Function-based 3d web visualization", "Virtual simulation of orthopaedic surgery training", "Making images with mathematics", "Self-supervised pairing image clustering and its application in cyber manufacturing", "Eye-tracking based adaptive parallel coordinates", "Towards asynchronous video-haptic interaction in cyberspace", "Tangible Video Communication over the Internet", "Interactive rendering of translucent materials under area lights using voxels and Poisson disk samples", "Interactive screenspace stream-compaction fragment rendering of direct illumination from area lights", "Towards meniscus elasticity simulation in virtual knee arthroscopy", "Haptic Interaction with Video Streams Containing Depth Data", "Modeling arthroscopic camera with haptic devices in image-based virtual environments", "From a small formula to virtual worlds", "Orthopaedic Surgery Simulation", "Advanced techniques of functionally based shape modeling with applications in computer art", "A cpu-gpu collaborative architecture for parallel desktop computing", "Computer Graphics\u2013From a Small Formula to Virtual Worlds; published in 2005 by Prentice Hall", "Playing digital music by waving hands in the air", "Visual Informatics", "Voxel-based interactive rendering of translucent materials under area lights using sparse samples", "Tangible images of real life scenes", "Neurocognitive tools for assessing haptic interaction", "Multisensory experience with images", "Interactive free-form shape modeling in cyberworlds", "A new approach to virtual palpation", "Interactive visualization of mathematics in 3D web", "Haptic editing of MRI brain data", "Function-based Extension of VRML and X3D", "VIRTUAL CAMPUS", "Web visualization of function-defined shapes", "Time dependent set-theoretic operations for functionally represented solid objects", "Tangible arthroscopic images", "Towards Virtual Haptic Palpation", "Virtual Orthopedic Surgery on Personal Computer", "Feasibility Study on Interactive Geometry Sonification", "Making Shapes with Mathematics", "Anomaly Detection and Segmentation Based on Defect Repaired Image Resynthesis", "Application of Generative Adversarial Networks and Latent Space Exploration in Music Visualisation", "Adding Visual Appearance to Geometry", "From Ancient Greeks to Pixels", "Putting Everything Together", "Motions", "Let\u2019s Draw", "Geometric Shapes", "Transformations", "2018 International Conference on Cyberworlds,{CW} 2018", "Transactions on Computational Science XXXII: Special Issue on Cybersecurity and Biometrics", "Interactive cutting of thin deformable objects", "Adding a sense of touch to online shopping: does it really help?", "Foreword to the Special Issue on 2016 International Conference on Cyberworlds (CYBERWORLDS 2016)", "Preface to the special section on Cyberworlds 2015", "Constructive Roofs from Solid Building Primitives", "PROCEEDINGS-2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS, CW 2015", "Haptic Simulation of Venipuncture", "Preface to special issue on Cyberworlds 2011", "Design and implementation of a haptics-based virtual venepuncture simulation and training system", "Special issue on Cyberworlds 2010", "Transactions on Computational Science XII", "Reconstructing multiresolution mesh for web visualization based on PDE resampling", "A framework for visual and haptic collaboration in shared virtual spaces", "Setting Cyber-Instructors in Cyberspace", "Haptic rendering of mixed haptic effects", "2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS 20-22 October 2010, Singapore", "Towards immersive visualization of mathematics", "Constructing Subdivision Connectivity Mesh via PDE Parameterization", "3D INTERACTIVE SEGMENTATION OF BRAIN MRI", "Partial differential equations for function based geometry modelling within", "RENDERING-ON-DEMAND SERVICE ACROSS HETEROGENEOUS GRID ENVIRONMENT", "Hybrid Function-Based Shape Modeling and Web Visualization", "Los Alamitos, California", "Fundamentals of alveolar gas diffusion: mathematical modeling and visualization", "Virtual Campus of Nanyan Technological University", "Function-based time-dependent shape modeling on the Web", "Modelling and investigation of the pneumo-olfactory function of humans", "Editorial Preface: Cyberworlds and Education", "Cyberworlds-Guest editor's introduction", "Interactive function based shape modelling", "Interactive function-based shape modeling", "Organized by", "Theme: Scientific Visualization and Image Processing-Navigation, Compression, Meshes, Data Management-Web Visualization of Function-Defined Shapes", "CALL FOR PAPERS Cyberworlds 2003 International Conference on Cyberworlds, CW 2003", "Interactive Polygonisation for Function-based Modelling", "PROCEEDINGS-1ST INTERNATIONAL SYMPOSIUM ON CYBER WORLDS, CW 2002", "Message from the CW 2016 Program Chair", "Real-time dynamic simulation virtual campus", "Shape Modeling with using Real Functions [in Russian]", "Shape modelling and computer graphics with real functions", "Modeling Arthroscopic Camera with Haptic Devices in Image-based Environments", "\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6807\u6ce8\u4e0e\u4e3b\u52a8\u5b66\u4e60: \u5b9e\u9a8c\u6bd4\u8f83 (\u82f1\u6587)", "Message from the Program and Track Co-Chairs", "International Program Committee CW 2021", "Greetings from the Program and Track Co-Chairs", "Program Co-chairs", "Visualization and Haptic Rendering of Virtual Objects Defined by Mathematical Functions", "Combinatorial 3-Manifolds from Sets of Tetrahedra", "Poster Track Chair Message", "General Track Chair Message", "General Track Chair", "The 2018 International Conference on Cyberworlds was hosted by Fraunhofer Singapore and organized in partnership with Nanyang Technological University and in cooperation with\u00a0\u2026", "Function representation for sweeping by a moving solid", "Llyr Ap Cenydd, Bangor University Elif Ayiter, Sabanci University Selim Balcisoy, Sabanci University Guido Brunnett, Chemnitz University of Technology", "We take this opportunity to thank the members of the International Program Committee for their support, reviews, fruitful discussions, and ideas. Last but not least, we thank\u00a0\u2026", "Conference Founder", "Yoshihiro Kanamori, Hiroki Yamada, Masaki Hirose, Jun Mitani, and Yukio Fukui", "Cyberworlds and Education", "Computational Science XXVI", "DMDCM 2011 Program Committee", "ICVRV 2011", "on Cyberworlds", "CGA 2010 Program Committee", "CGVR 2010 Program Committee", "Daniel Thalmann, EPFL, VRlab", "Cyberworlds Conferences Steering Committee", "Conference Steering Committee", "CGA 2010 Reviewers", "Conference organisation", "It is our pleasure to welcome you to the International Conference on Cyberworlds 2007 in Hannover, Germany. We are happy that the Gottfried Wilhelm Leibniz Universit\u00e4t was\u00a0\u2026", "CGVR 2010 Reviewers", "U-Media 2011 Technical Program Committee", "General Conference Chairs Daniel Thalmann", "Khaled El-Maleh, Qualcomm, USA Stefano Ferretti, Universit\u00e0 di Bologna, Italy Michael Hartle, Darmstadt University of Technology, Germany Jianhua He, Swansea University, United\u00a0\u2026", "CW 2012 Organization", "CW 2016 International Program Committee", "Vandewalle N., 921 Viergever MA, 775 Viv6 R., 713 Vladimirov A., 95", "Virtual Meniscus Examination in Knee Arthroscopy Training", "International Workshop on Biometric Security Program Committee", "Darmstadt, Germany, 25\u201327 September 2012", "Web Visualization of the Function-defined Virtual Worlds", "Virtual Function-based Artistic Shape Modeling"], "Link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:EUQCXRtRnyEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:0izLItjtcgwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:8d8msizDQcsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:kh2fBNsKQNwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:W7OEmFMy1HYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:MXK_kJrjxJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:_FxGoFyzp5QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:ZfRJV9d4-WMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:q3CdL3IzO_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:b0M2c_1WBrUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:a9-T7VOCCH8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:ULOm3_A8WrAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:P5F9QuxV20EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:-_dYPAW6P2MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:kzcrU_BdoSEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:VL0QpB8kHFEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:abG-DnoFyZgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:0EnyYjriUFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:O3NaXMp0MMsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:olpn-zPbct0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:xtRiw3GOFMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:2VqYfGB8ITEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:SpbeaW3--B0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:Zph67rFs4hoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:uJ-U7cs_P_0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:3fE2CSJIrl8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:LkGwnXOMwfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:ye4kPcJQO24C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:kNdYIx-mwKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hkOj_22Ku90C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:R3hNpaxXUhUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:mVmsd5A6BfQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:M3ejUd6NZC8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:KlAtU1dfN6UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:foquWX3nUaYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:_Qo2XoVZTnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:4JMBOYKVnBMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:5nxA0vEk-isC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:PVjk1bu6vJQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:YOwf2qJgpHMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:5ugPr518TE4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:_kc_bZDykSQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:aqlVkmm33-oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:Aul-kAQHnToC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:M7yex6snE4oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:GFxP56DSvIMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:NhqRSupF_l8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hC7cP41nSMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:yMeIxYmEMEAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:nb7KW1ujOQ8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:HtS1dXgVpQUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:Fu2w8maKXqMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:dQ2og3OwTAUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:VOx2b1Wkg3QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:LPZeul_q3PIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:vRqMK49ujn8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:7PzlFSSx8tAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:JQOojiI6XY0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:eMMeJKvmdy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:fQNAKQ3IYiAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:fbc8zXXH2BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:08ZZubdj9fEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:QIV2ME_5wuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:qxL8FJ1GzNcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:LhH-TYMQEocC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:IUKN3-7HHlwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:bz8QjSJIRt4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:JoZmwDi-zQgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:J-pR_7NvFogC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:l7t_Zn2s7bgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:4DMP91E08xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:evX43VCCuoAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:OP4eGU-M3BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:yqoGN6RLRZoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:7T2F9Uy0os0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:tkaPQYYpVKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:35N4QoGY0k4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hFOr9nPyWt4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:dhFuZR0502QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:Wp0gIr-vW9MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:HoB7MX3m0LUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:buQ7SEKw-1sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:anf4URPfarAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:HtEfBTGE9r8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:35r97b3x0nAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:sSrBHYA8nusC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:9ZlFYXVOiuMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:IWHjjKOFINEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:qUcmZB5y_30C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:-f6ydRqryjwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:KbBQZpvPDL4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:9c2xU6iGI7YC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:NXb4pA-qfm4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:0N-VGjzr574C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:PoWvk5oyLR8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:VaXvl8Fpj5cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:NJ774b8OgUMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:LjlpjdlvIbIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:WqliGbK-hY8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:1qzjygNMrQYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:_axFR9aDTf0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:KxtntwgDAa4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ZeXyd9-uunAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:YohjEiUPhakC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:rmuvC79q63oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4fGpz3EwCPoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:lvd772isFD0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:b1wdh0AR-JQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:fEOibwPWpKIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:UHK10RUVsp4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:XiVPGOgt02cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4fKUyHm3Qg0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:tOudhMTPpwUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:738O_yMBCRsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:CHSYGLWDkRkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:M3NEmzRMIkIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:2P1L_qKh6hAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:HDshCWvjkbEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:mB3voiENLucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:AXPGKjj_ei8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:WA5NYHcadZ8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:eJXPG6dFmWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:NyGDZy8z5eUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:0CzhzZyukY4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:a3BOlSfXSfwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:HeT0ZceujKMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:fFSKOagxvKUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:3htObqc8RwsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:OR75R8vi5nAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:OcBU2YAGkTUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ODE9OILHJdcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:yFnVuubrUp4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:bKqednn6t2AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:GtLg2Ama23sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:jL-93Qbq4QoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:k8Z6L05lTy4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ILKRHgRFtOwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:j8SEvjWlNXcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:uLbwQdceFCQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ZuybSZzF8UAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:IRz6iEL74y4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:DJbcl8HfkQkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:WbkHhVStYXYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:PVgj2kMGcgYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:JV2RwH3_ST0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ClCfbGk0d_YC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:RYcK_YlVTxYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:rO6llkc54NcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:blknAaTinKkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:BrmTIyaxlBUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:D_sINldO8mEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:iH-uZ7U-co4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:Mojj43d5GZwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:mNrWkgRL2YcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:9vf0nzSNQJEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:TFP_iSt0sucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:kuK5TVdYjLIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ZHo1McVdvXMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ns9cj8rnVeAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:Dip1O2bNi0gC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:uDGL6kOW6j0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:i2xiXl-TujoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:nVrZBo8bIpAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:QD3KBmkZPeQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:hMsQuOkrut0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:vDijr-p_gm4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:k_IJM867U9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:otzGkya1bYkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:HIFyuExEbWQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:mlAyqtXpCwEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:W5xh706n7nkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4xDN1ZYqzskC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:NaGl4SEjCO4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:L8Ckcad2t8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:wMgC3FpKEyYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:8xutWZnSdmoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:F9fV5C73w3QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:r_AWSJRzSzQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:QYdC8u9Cj1oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4hFrxpcac9AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:LO7wyVUgiFcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:5qfkUJPXOUwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:edDO8Oi4QzsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:Ug5p-4gJ2f0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:XoXfffV-tXoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ruyezt5ZtCIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:e_rmSamDkqQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:lmc2jWPfTJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:MLfJN-KU85MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:tuHXwOkdijsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:gsN89kCJA0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:TIZ-Mc8IlK0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:tYavs44e6CUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:L7CI7m0gUJcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:vbGhcppDl1QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:BwyfMAYsbu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4MWp96NkSFoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ML0RJ9NH7IQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:Z5m8FVwuT1cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:BUYA1_V_uYcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:AvfA0Oy_GE0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:uWiczbcajpAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:epqYDVWIO7EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:zLWjf1WUPmwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:EkHepimYqZsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ipzZ9siozwsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:0KyAp5RtaNEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:t7zJ5fGR-2UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:tzM49s52ZIMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:_Ybze24A_UAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:5awf1xo2G04C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:Y5dfb0dijaUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:bnK-pcrLprsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:K3LRdlH-MEoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:a0OBvERweLwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4OULZ7Gr8RgC"], "Topic": ["Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Federated Learning", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Federated Learning", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Computer Scienc", "Computer Scienc", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others"], "# of Citations": [735, 114, 111, 82, 74, 70, 61, 55, 51, 52, 45, 45, 43, 44, 40, 41, 37, 34, 35, 32, 34, 32, 31, 31, 31, 28, 28, 25, 22, 23, 21, 23, 22, 19, 20, 18, 18, 17, 18, 18, 16, 17, 16, 16, 16, 15, 14, 14, 15, 15, 15, 15, 13, 11, 13, 13, 13, 13, 10, 11, 11, 8, 9, 9, 9, 9, 9, 8, 8, 7, 7, 7, 7, 7, 7, 6, 7, 6, 5, 6, 6, 6, 5, 6, 5, 5, 5, 5, 4, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "Description": ["Concepts of functionally based geometric modeling including sets of objects, operations, and relations are discussed. Transformations of a defining real function are described for set-theoretic operations, blending, offsetting, bijective mapping, projection, cartesian products, and metamorphosis. Inclusion, point membership, and intersection relations are also described. We use a high-level geometric language that can extend the interactive modeling system by input symbolic descriptions of primitives, operations, and predicates. This approach supports combinations of representational styles, including constructive geometry, sweeping, soft objects, voxel-based objects, deformable and other animated objects. Application examples of aesthetic design, collisions simulation, NC machining, range data processing, and 3D texture generation are given.", "The paper presents a novel technique of nonlinear spectral analysis, which has been used for processing encephalograms of humans. This technique is based on the concept of generalized entropy of a given probability distribution, known as the R\u00e9nyi entropy that allows defining the set of generalized fractal dimensions of encephalogram (EEG) and determining fractal spectra of encephalographic signals. Unlike the Fourier spectra, the spectra of fractal dimensions contain information of both frequency and amplitude characteristics of EEG and can be used together with well-accepted techniques of EEG analysis as an enhancement of the latter. Powered by volume visualization of the brain activity, the method provides new clues for understanding the mental processes in humans.", "Sweeping is one of the constructive techniques of solid modeling that creates new rigid solids which are not simple Boolean constructions and combinations of solid components. The full integration of this operation in solid modelers has not yet been achieved [1]. This paper is an attempt to treat solids modeled with set-theoretic operations and with sweeping on the general base of representation by a real function of three variables. It provides a way for solving such long standing problems as sweeping by a CSG-solid, self-intersections and set operations on sweeps.", "This paper proposes an integrated detection framework of solder joint defects in the context of Automatic Optical Inspection (AOI) of Printed Circuit Boards (PCBs). Both localization and classifications tasks were considered. For the localization part, in contrast to the existing methods that are highly specified for particular PCBs, we used a generic deep learning method which can be easily ported to different configurations of PCBs and soldering technologies and also gives real-time speed and high accuracy. For the classification part, an active learning method was proposed to reduce the labeling workload when a large labeled training database is not easily available because it requires domain-specified knowledge. The experiments show that the localization method is fast and accurate. In addition, high accuracy with only minimal user input was achieved in the classification framework on two different datasets. The\u00a0\u2026", "In recent years, the usage of 3D cyberworlds for educational purposes has increased. The metaphors behind the visual design of such cyberworlds are quite diverse, from replication of real universities, art museums and scientific labs to non-existing fictitious places. In this paper, we focus specifically on \u201ccybercampuses\u201d, i.e. virtual worlds representing real educational institutions such as universities and schools. Based on the results of a case study that we have performed, this paper provides an initial set of requirements for a cybercampus representing an existing university. In this connection, we analyze place metaphors and associated design features of the Virtual Campus of Nanyang Technological University in Singapore, discuss the correspondence between the identified metaphors and associated educational goals, and provide directions for further development. Finally, we outline the major\u00a0\u2026", "Detecting defects is an integral part of any manufacturing process. Most works still utilize traditional image processing algorithms to detect defects owing to the complexity and variety of products and manufacturing environments. In this paper, we propose an approach based on deep learning which uses autoencoders for extraction of discriminative features. It can detect different defects without using any defect samples during training. This method, where samples of only one class (i.e. defect-free samples) are available for training, is called One Class Classification (OCC). This OCC method can also be used for training a neural network when only one golden sample is available by generating many copies of the reference image by data augmentation. The trained model is then able to generate a descriptor\u2014a unique feature vector of an input image. A test image captured by an Automatic Optical Inspection (AOI\u00a0\u2026", "Medicine is one of the most promising areas for emerging computer graphics and virtual reality techniques. VR training simulators let surgeons practice on virtual body tissue and get the same feedback they would experience in performing a real operation. Hybrid VR systems permit medical practitioners to view the patient overlaid with 3D data sets derived from 3D scanners, thus providing doctors and surgeons with pseudo X-ray vision. While currently available immersive VR surgery systems usually require expensive hardware and software, we developed a desktop VR orthopedic surgery training system that can run on commonly available personal computers.", "The idea for building a VR model of the NTU campus came about six years ago when the School of Computer Engineering purchased a powerful graphics workstation with advanced modeling software systems, MultiGen-Paradigm's MultiGen and Vega. Three-dimensional Web visualization developed rapidly. Personal computers became capable of making VR walkthroughs even in shared virtual worlds. Cybertown created by Tony Rockliff and Pascal Baudar with Virtual Reality Modeling Language (VRML) on the Blaxxun Platform, inspired us to put our virtual campus on the Web.", "Supervised machine learning techniques require labelled multivariate training datasets. Many approaches address the issue of unlabelled datasets by tightly coupling machine learning algorithms with interactive visualisations. Using appropriate techniques, analysts can play an active role in a highly interactive and iterative machine learning process to label the dataset and create meaningful partitions. While this principle has been implemented either for unsupervised, semi-supervised, or supervised machine learning tasks, the combination of all three methodologies remains challenging.In this paper, a visual analytics approach is presented, combining a variety of machine learning capabilities with four linked visualisation views, all integrated within the mVis (multivariate Visualiser) system. The available palette of techniques allows an analyst to perform exploratory data analysis on a multivariate dataset and\u00a0\u2026", "Rendering computer animation frames is a very time consuming job. Using parallel computing on clusters and so-called render farms is a common solution to this problem. In this paper we describe how Grid computing can be used for computer animation rendering. We propose a framework for Grid rendering services, describe its implementation, and present the results and statistics. A loseless 3D compression algorithm was also devised to solve the existing problem of transferring gigabytes of scene representation files (Renderman (.rib) and mental images (.mi)). This compression algorithm has been filed for patent in Singapore.", "Several techniques of computer-aided synthetic carving are presented. We describe both procedural methods for relief carvings and patterned lattices, as well as interactive carving. Different techniques of depth data generation for relief carving are described: polygon-to-function conversion, pattern-dependent interpolation, and ray-casting. All proposed methods are based on using implicit surfaces or, more generally, the function representation of geometric objects.", "This article describes how virtual embossing and wood cutting can be done using the function representation of a shape and tools. The software is implemented as an interactive shape modeler where a functional model of the shape is subsequently modified with offset and set-theoretic operations. For visualization, interactive ray tracing is used. Bounding boxes together with the spatial organization of the functional model provide the required fast function evaluation that is usually a bottleneck for functionally based shape modeling systems. The software runs on a personal computer.", "Visual simulation of natural erosion on terrains has always been a fascinating research topic in the field of computer graphics. While there are many algorithms already developed to improve the visual quality of terrain, the recent simulation methods revolve around physically-based hydraulic erosion because it can generate realistic natural-looking terrains. However, many of such algorithms were tested only on low resolution terrains. When simulated on a higher resolution terrain, most of the current algorithms become computationally expensive. This is why in many applications today, terrains are generated off-line and loaded during the application runtime. This method restricts the number of terrains which can be stored if there is a limitation on storage capacity. Recently, graphics hardware has evolved into an indispensable tool in improving the speed of computation. This has motivated us to develop an erosion\u00a0\u2026", "Surgical training is one of the most promising areas in medicine where 3-D computer graphics and virtual reality techniques are emerging. This paper provides an advanced report on our project that aims to create virtual reality tools for training medical students and for improving skills and efficiency of orthopedic surgeons in internal fixation of bone fractures. The paper describes the whole pipeline from the CT scanner through the Unix-workstation to the personal computer where eventually the program works. We also describe the methods and mathematical models that allowed us to implement the ultimate goal of the project\u2014to allow the surgeons to perform training surgical operations even at their home computers without any special expensive hardware devices. This project was initiated in Singapore and currently continues as an international project.", "This article discusses the problems of teaching computer graphics and shape modeling in large and distributed classes using visual cyberworlds\u2014shared information worlds on the Web. Cyberworlds allow for providing personal mentoring to the students with different cultural and educational backgrounds. The Virtual Campus of Nanyang Technological University is such a cyberworld, which is being used for teaching computer graphics and shape modeling. A part of this cyberworld is the Virtual Shape Modeling Laboratory. It is used by the computer graphics students for designing geometric shapes defined with analytical formulas. Augmenting the existing ways of electronic education with cyberworlds appears to be useful which was proved by the final exam results and overall attitude of the students.", "Embossing is the art of decorating metals in relief from the reverse side. This article describes how virtual embossing can be done using  a functionally based representation of the metal plate and the tools. The program is implemented as an interactive shape modeler where a functional model of the metal plate is subsequently modified with offset and set-theoretic operations. For visualization, interactive ray tracing is used. Bounding boxes together with the spatial organization of the functional model provide the required fast function evaluation that is usually a bottleneck for functionally based shape modeling systems. The program runs on a personal computer.", "Animated shape transformations should be an intrinsic part of visual cyberworlds. However, quite often only limited animation of the polygon-based shapes can be found there, specifically when using the virtual reality modeling language (VRML) and its successor extensible 3D (X3D). This greatly limits the expressive power of visual cyberworlds and has motivated our research in this direction. In this paper, we present function-based extensions of VRML and X3D, which allow for time-dependent shape modeling on the web. Our shape modeling approach is based on the concurrent use of implicit, explicit and parametric functions defining geometry, appearance and their transformations through time. The functions are typed straight in VRML/X3D code as individual formulas and as function scripts. We have also developed a web enabled interactive software tool for modeling function-based VRML/X3D objects.", "Therapeutic effect of music is known for long time. Music therapy can be used to improve the current patient\u2019s state or even prevent some deceases of psychosomatic origin. For decades, the basic research methods of music psychology mainly relied on survey with questionnaire or on observations of subjects. Investigating the effect of music through electroencephalograms (EEG) could be more precise and objective. In this paper, we describe fractal dimension model for quantification of brain responses to external stimuli. Human EEG evoked by music stimuli are analysed with the developed software. The proposed technique of processing EEG is based on the R\u00e9nyi entropy \u2014 the concept of generalized entropy of a given probability distribution. It allows defining generalized fractal dimension of EEG. The experiments involved ten subjects, both male and female twenty years old university students. The\u00a0\u2026", "The paper presents a novel technique of nonlinear spectral analysis. This technique is based on the concept of generalized entropy of a given probability distribution, known as the R\u00e9nyi entropy. This concept allows defining generalized fractal dimension of encephalogram (EEG) and determining fractal spectra of encephalographic signals. These spectra contain information of both frequency and amplitude characteristics of EEG and can be used together with well-accepted techniques of EEG analysis as an enhancement of the latter. Powered by volume visualization of the brain activity, the method provides new clues for understanding the mental processes in humans.", "We represent multidimensional geometric modeling with using of a continuous function of several variables which has positive value inside, negative value outside and zero value on the object boundary. We use the theory of R.-functions to implement set-theoretic operations. Function transformations are described for bijective mapping, projection, cartesian product, offsetting, blending, hypertexturing and morphing operations. This representation uni\ufb01es CSG, sweeping, implicit models, voxel-based objects, deformable and other animated objects. Visualization of descriptive functions on the base of the inductive approach is discussed. Application for parallel simulation of collisions of irregularly shaped particles is presented.", "Human electroencephalograph (EEG) data driven animation is often used in neurofeedback systems for concentration training in children and adults. Visualization of the time-series data could be used in neurofeedback and for the data analysis. The paper proposes a novel method of 3D mapping of EEG data and describes visualization system VisBrain that was developed for EEG data analysis. We employed a concept of a dynamic 3D volumetric shape for showing how the electrical signal changes through time. For the shape, a time-dependent solid blobby object was used. This object is defined using implicit functions. Besides just a visual comparison, we propose to apply set-theoretic (\u201cBoolean\u201d) operations to the moving shapes to isolate activities common for both of them per time point, as well as those that are unique for either one. The advantages of the method are demonstrated with real EEG\u00a0\u2026", "Surface level defect detection, such as detecting missing components, misalignments and physical damages, is an important step in any manufacturing process. In this paper, similarity matching techniques for manufacturing defect detection are discussed. We are proposing an algorithm which detects surface level defects without relying on the availability of defect samples for training. Furthermore, we are also proposing a method which works when only one or a few reference images are available. It implements a deep autoencoder network and trains input reference image(s) along with various copies automatically generated by data augmentation. The trained network is then able to generate a descriptor-a unique signature of the reference image. After training, a test image of the same product is sent to the trained network to generate a test image descriptor. By matching the reference and test descriptors, a\u00a0\u2026", "In this paper we propose a new approach to web visualisation with VRML based on a function-based shape modelling, which unifies different types of mathematical functions in order to enrich the existing web visualisation techniques for modelling. In our method, parametric, implicit and explicit functions can be used concurrently for defining geometry, colour, texture, and other properties of shapes. Geometric shapes and their properties are defined by functions in their respective domains and then merged into function-defined objects. The proposed framework allows for its extending with any function-based model. To illustrate our method and to prove its feasibility, we implemented it for web visualisation as the Function-based Extension of Virtual Reality Modelling Language. In this implementation, parametric implicit and explicit analytical formulae are used for defining geometry and appearance of three\u00a0\u2026", "In this paper, we define complex solids by real functions. Just from relatively small formulae we produce highly detailed complex objects and are able to manipulate and transform them producing more complex ones. We show how complex static and time-dependent objects can be created with the use of socalled R-functions. Then, we consider just one long-standing problem, hair modelling, and show how our functionally based model can be applied there. In modelling hair, we represent it with solid noise and subsequently unify it with the solid being made hairy. The hair and the solid are defined by real functions and the resultant hairy solid is in turn functionally defined and can be an argument for other operations. We are able to control length, thickness and curliness of hair and to obtain different hairstyles varying defining functions and applying set-theoretic operations to solid hair.", "Automatic optical inspection for manufacturing traditionally was based on computer vision. However, there are emerging attempts to do it using deep learning approach. Deep convolutional neural network allows to learn semantic image features which could be used for defect detection in products. In contrast to the existing approaches where supervised or semi-supervised training is done on thousands of images of defects, we investigate whether unsupervised deep learning model for defect detection could be trained with orders of magnitude smaller amount of representative defect-free samples (tenths rather than thousands). This research is motivated by the fact that collection of large amounts of defective samples is difficult and expensive. Our model undergoes only one-class training and aims to extract distinctive semantic features from the normal samples in an unsupervised manner. We propose a variant of\u00a0\u2026", "We seek to further expand the collaborative potential of shared virtual spaces by using haptic force-feedback. We propose how to define tangible physical properties of the objects, together with their geometry and appearance, by using mathematical functions. We illustrate this concept by developing software which allows us to touch and feel surfaces of VRML and X3D objects, convert them to solid objects, as well as create any other solid objects using the function-based extension of VRML and\u00a0X3D. We define geometry, appearance and tangible physical properties of the solid objects by implicit, explicit and parametric functions straight in the VRML/X3D code or in loadable libraries. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail. We\u00a0\u2026", "MRI segmentation is a process of deriving semantic information from volume data. For brain MRI data, segmentation is initially performed at a voxel level and then continued at a brain surface level by generating its approximation. While successful most of the time, automated brain segmentation may leave errors which have to be removed interactively by editing individual 2D slices. We propose an approach for correcting these segmentation errors in 3D modeling space. We actively use the brain surface, which is estimated (potentially wrongly) in the automated FreeSurfer segmentation pipeline. It allows us to work with the whole data set at once, utilizing the context information and correcting several slices simultaneously. Proposed heuristic editing support and automatic visual highlighting of potential error locations allow us to substantially reduce the segmentation time. The paper describes the implementation\u00a0\u2026", "In recent years, minimally invasive arthroscopic surgery has replaced a number of conventional open orthopedic surgery procedures on joints. While this achieves a number of advantages for the patient, the surgeons have to learn very different skills, since the surgery is performed with special miniature pencil-like tools and cameras inserted through little incisions while observing the surgical field on video monitor. Therefore, virtual reality simulation becomes an alternative to traditional surgical training based on hundreds years old apprentice\u2013master model that involves either real patients or increasingly difficult to procure cadavers. Normally, 3D simulation of the virtual surgical field requires significant efforts from the software developers but yet remains not always photorealistic. In contrast to this, for photorealistic visualization and haptic interaction with the surgical field we propose to use real arthroscopic\u00a0\u2026", "Creation of procedural 3D building models can significantly reduce the costs of modeling, since it allows for generating a variety of similar shapes from one procedural description. The common field of application for procedural modeling is modeling of straight building facades, which are very well suited for shape grammars\u2014a special kind of procedural modeling system.In order to generate round building geometry, we present a way to set up different coordinate systems in shape grammars. Besides Cartesian, these are primarily cylindrical and spherical coordinate systems for generation of structures such as towers or domes, that can procedurally adapt to different dimensions and parameters. The users can apply common splitting idioms from shape grammars in their familiar way for creating round instead of straight geometry.The second enhancement we propose is to provide a way for users to give high level\u00a0\u2026", "In this paper, we propose a web-enabled shape modeling system with natural free-hand interaction, which can be easily learned by users while imposing least mental load on them. The deformation interface allows for performing various deformations, including stretching, compressing, squeezing, enlarging, twisting and tapering, on shapes interactively mimicking how they are done in real life. The manipulation interface allows an object to be directly grabbed and manipulated with either one or two hands, while also smoothly switching between them. Constrained methods are also provided for precise manipulation. An intuitive metaphor is designed to help the users to discover the interaction techniques by themselves without any manuals or instructions. A rendering pipeline, based on function-based extension of VRML/X3D, is designed with hidden complexity to support the proposed functionalities of the system\u00a0\u2026", "Naturalness of the mid-air interaction interface for virtual assembly and shape modeling is important. In order to design an interface perceived as \"natural\" by most people, common behaviors and mental patterns for mid-air interaction of people have to be recognized, which is an area merely explored yet. This paper serves this purpose of understanding the users' mental interaction models, in order to provide standards and recommendation for devising a natural virtual interaction interface. We tested three kinds of tasks --- manipulating tasks, deforming tasks and tool-based operating tasks on 16 participants. We have found that: 1) different features of mental models were observed for different types of tasks. Interaction techniques should be designed to match these features; 2) virtual hand self-avatar helps estimate size of virtual objects, as well as helps plan and visualize the complex process and procedures of a\u00a0\u2026", "We present our approach to volume modelling which combines volume representations by voxel data and by continuous real functions. We discuss the main differences between direct volume visualization and modelling with voxel data, questions of conversion between two representations including volume reconstruction from contour data. We illustrate the approach by several advanced operations on a volumetric object: set-theoretic operations, sweeping, hypertexturing, feature-based sculpting, splitting, spatial and temporal transformations.", "Surgical training is one of the most promising areas in medicine where 3-D computer graphics and virtual reality techniques are emerging. Orthopedic surgery is a discipline requiring appreciation and understanding of complex 3-dimensional bony structures and their relationships to nerves, blood vessels and other vital structures. Learning these spatial skills requires a lengthy period and much practice. In this paper, we present a software simulator which was developed to aid in the understanding of the complex 3-dimensional relationships between bones and implants. The developed software cuts down the learning curve and allows for better and more precise surgery by letting the surgeon practice the surgery in a virtual environment before undertaking the actual procedure.", "Visual and haptic rendering pipelines exist concurrently and compete for computing resources while the refresh rate of haptic rendering is two orders of magnitude higher than that of visual rendering (1000 Hz vs. 30-50Hz). However, in certain cases, 3D visual rendering can be replaced by merely displaying 2D images, thus releasing the resources to image-driven haptic rendering algorithms. A number of approaches have been proposed to provide haptic interaction with 2D images but they suffer from various problems and do not provide a fully believable impression of haptic sensation of the 3D scene displayed in the image. Based on the method of haptic effect generation, the existing approaches can be classified into techniques that use information derived from the image, and techniques that use additional information along with the image to enable haptic interaction. Previously, we proposed our own method\u00a0\u2026", "Shared virtual worlds require exchanging shape models over the Internet. Since complex shapes such as VRML objects are often defined with polygonal meshes, the size of models may become very large. It slows down their visualization and limits the model's precision. Using function-based models incorporated into VRML or other visualization frameworks allows for reducing the overall size of models as well as provides any required level of detail. In this paper, we propose a fast function-based shape modeling framework. The developed software is used for collaborative shape modeling in VRML shared virtual worlds. It allows for passive visualization of the complex function-based models in cyberworlds as well as for their interactive modeling.", "Common shape modelling is usually done with virtual tools controlled by interactive or hap tic devices, which have one interface point for simulating collision between the object and the modelling tool. Shape modeling with some kind of virtual hand where several fingers deform the object was not very common since the respective devices are either too expensive or not very precise. Introduction of affordable Leap Motion device opens new prospects for free hand shape modeling. This paper is a feasibility study on using Leap Motion for shape modeling in VRML/X3D environments where virtual objects are defined by mathematical functions and hence can easily be exchanged across the internet due to their small size.", "Visual and haptic rendering pipelines exist concurrently and compete for computing resources while the refresh rate of haptic rendering is two orders of magnitude higher than that of visual rendering (1000 Hz vs. 30-50Hz). However, in many cases, 3D visual rendering can be replaced by merely displaying 2D images, thus releasing the resources to image-driven haptic rendering algorithms. These algorithms provide for haptic texture rendering in vicinity of a touch point, but usually require additional information augmented with the image to provide for haptic perception of geometry of the shapes displayed in images. We propose a framework for making tangible images which allows haptic perception of three features: scene geometry, texture and physical properties. Haptic geometry rendering technique uses depth information, that could be acquired by a multitude of ways for providing haptic interaction with\u00a0\u2026", "Methods from supervised machine learning allow the classification of new data automatically and are tremendously helpful for data analysis. The quality of supervised maching learning depends not only on the type of algorithm used, but also on the quality of the labelled dataset used to train the classifier. Labelling instances in a training dataset is often done manually relying on selections and annotations by expert analysts, and is often a tedious and time-consuming process. Active learning algorithms can automatically determine a subset of data instances for which labels would provide useful input to the learning process. Interactive visual labelling techniques are a promising alternative, providing effective visual overviews from which an analyst can simultaneously explore data records and select items to a label. By putting the analyst in the loop, higher accuracy can be achieved in the resulting classifier\u00a0\u2026", "Compared to common 2D interaction done with mouse and other 2D tracking devices, 3D hand tracking with low-cost optical cameras can provide more degrees of freedom, as well as natural gestures, when shape modeling is done in virtual spaces. However, though quite precise, the optical tracking devices cannot avoid problems intrinsic to hand interaction, such as hand tremor and jump release, and they also introduce an additional problem of hand occlusion. We investigate how to minimize the negative impact of these problems, and eventually propose to use hands in a way similar to how it is done when playing the Theremin \u2013 an electronic musical instrument controlled without physical contact by hands of the performer. We suggest that the dominant hand controls manipulation and deformation of objects while the non-dominant hand controls grasping, releasing and precision of interaction. Based on this\u00a0\u2026", "In this paper we address interactive shape modelling of geometric shapes defined by mathematical functions. We introduce mathematical operators that implement modifications of geometry and appearance of the shapes. Any of the operators involved in creating the shape can be edited, modified or removed at any time, thus allowing for a great flexibility of the modelling pipeline and opening prospects for efficient reusing and improving of the previously created models. Interactive modification of the function model with concurrent visualisation of the respective polygonal mesh lets us provide both the interactivity and any required level of detail resulting in photo-realistic appearance of the shapes.", "The origin of shared virtual worlds is summarized. They were predicted by many novelists as well as envisaged in blockbuster movies at the start of the computer era. Constructing the first shared virtual worlds began in the last decade of the twentieth century when the Internet became ubiquitous. Extensions of the hypertext mark-up language (HTML) to immersive 3D graphics were proposed by several vendors and research groups that eventually materialized into what we know now as Extensible 3D (X3D) and its predecessor Virtual Reality Modeling Language (VRML). Academia has capitalized on these new horizons for education by setting up virtual campuses in Active Worlds\u2014online shared virtual worlds based on the Renderware rendering engine. Thousands of virtual citizens populated CyberTown\u2014a 3D online community developed in VRML language and the Blaxxun collaborative platform. The\u00a0\u2026", "Three-dimensional (3D) representations of complex geometric shapes, especially when they are reconstructed from magnetic resonance imaging (MRI) and computed tomography (CT) data, often result in large polygon meshes which require substantial storage for their handling, and normally have only one fixed level of detail (LOD). This can often be an obstacle for efficient data exchange and interactive work with such objects. We propose to replace such large polygon meshes with a relatively small set of coefficients of the patchwise partial differential equation (PDE) function representation. With this model, the approximations of the original shapes can be rendered with any desired resolution at interactive rates. Our approach can directly work with any common 3D reconstruction pipeline, which we demonstrate by applying it to a large reconstructed medical data set with irregular geometry.", "In the recent years, the usage of 3D cyberworlds for educational purposes has increased. The metaphors behind the design of virtual places are quite diverse, from replication of real universities to art museums and scientific labs. Based on the results of a case study we have performed, this paper provides an initial set of requirements for a cyberworld representing an existing university. In this connection, we analyze place metaphors and associated design features of the virtual campus of Nanyang Technological University in Singapore in the context of related work. Finally, we discuss the correspondence between the identified metaphors and associated educational goals, providing directions for further development of the virtual campus", "In this paper, we introduce a function-based extension of Virtual Reality Modeling Language. In this extension, analytical functions are used for defining geometry and appearance of 3D shapes, as well as transformations of them. By analytical functions we understand definitions with parametric, implicit and explicit formulas. In our hybrid function-based web visualization model, these very different analytical representations can be used concurrently for defining geometry and appearance of the shapes. We also illustrate how the proposed extension can be further enriched with any proprietary function-based models. The presented VRML plug-in is very useful for building both static and interactive virtual environments on the Web. This is illustrated with the implementation of the Virtual Collaborative Shape Modeling Laboratory.", "Video interaction is a common way of communication in cyberspace. It can become more immersive by incorporating haptic modality. Using commonly available depth sensing controllers like Microsoft Kinect, information about the depth of a scene can be captured in real-time together with the video. In this paper, we present a method for real-time haptic interaction with videos containing depth data. Forces are computed based on the depth information. Spatial and temporal filtering of the depth stream is used to provide stability of force feedback delivered to the haptic device. Fast collision detection ensures the proposed approach to be used in real-time. We present an analysis of various factors that affect algorithm performance. The usefulness of the approach is illustrated by highlighting possible application scenarios.", "In the modern urban society, human brain is not being sufficiently trained to deal with problems which require 3D perception. As a result, when teaching subjects richly infused with mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that would allow for defining complex geometry, visual appearance and tangible physical properties of the virtual objects using language of mathematical functions. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept using our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted to tangible ones as well as augmented\u00a0\u2026", "We study to which extent Leap Motion can be used for mid-air interaction while working on various virtual assembling and shape modeling tasks. First, we outline the conceptual design phase, which is done by studying and classification of how human hands are used for various creative tasks in real life. Then, during the phase of the functional design, we propose our hypothesis how to efficiently implement and use natural gestures with Leap Motion and introduce the ideas of the algorithms. Next we describe the implementation phase of the gestures in virtual environment. It is followed by the user study proving our concept.", "Commonly, surface and solid haptic effects are defined in such a way that they hardly can be rendered together. We propose a method for defining mixed haptic effects including surface, solid, and force fields. These haptic effects can be applied to virtual scenes containing various objects, including polygon meshes, point clouds, impostors, and layered textures, voxel models as well as function-based shapes. Accordingly, we propose a way how to identify location of the haptic tool in such virtual scenes as well as consistently and seamlessly determine haptic effects when the haptic tool moves in the scenes with objects having different sizes, locations, and mutual penetrations. To provide for an efficient and flexible rendering of haptic effects, we propose to concurrently use explicit, implicit and parametric functions, and algorithmic procedures.", "Automatic segmentation of brain MRI data usually leaves some segmentation errors behind that are to be subsequently removed interactively using computer graphics tools. This interactive removal is normally performed by operating on individual 2D slices. It is very tedious and still leaves some segmentation errors which are not visible on the slices. We have proposed to perform a novel 3D interactive correction of brain segmentation errors introduced by the fully automatic segmentation algorithms. We have developed the tool which is based on a 3D semi-automatic propagation algorithm. The paper describes the implementation principles of the proposed tool and illustrates its application.", "We propose how to define complex geometry, appearance and tangible physical properties of the X3D and VRML objects using mathematical functions straight in the scene definition code or in loadable libraries. We can also touch and feel surfaces of X3D and VRML objects as well as convert them to solid tangible objects. We can define tangible density and force fields associated with standard and function-defined geometries. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail. We illustrate this concept with several application examples based on our plug-in to X3D and VRML browser.", "This paper addresses interactive function-based shape modeling where relatively small formulas are used rather than thousands of polygons. Interactive modification of the function model with concurrent visualization of the respective polygonal mesh provides both interactivity and any required level of detail leading to a photorealistic appearance of the resulting shapes. We have proposed a rendering method capable of handling local shape modifications with any desired precision. We have also proposed methods which let us accelerate the final function evaluation - a common bottleneck for function-based shape modeling. Finally, we describe applications of interactive function-based shape modeling to photorealistic virtual embossing and carving.", "This paper describes how the web-based visualisation can be greatly improved using the function-based shape modelling technique. We propose the function-defined VRML shape node, which allows the content creators to describe any complex models with relatively small functions compared to the large-size polygonal mesh based VRML nodes. The design, the implementation details, and the application examples of the proposed node are discussed. The software is available for downloading from the project website.", "This paper proposes a method for automatic image-based classification of solder joint defects in the context of Automatic Optical Inspection (AOI) of Printed Circuit Boards (PCBs). Machine learning-based approaches are frequently used for image-based inspection. However, a main challenge is to manually create sufficiently large labeled training databases to allow for high accuracy of defect detection. Creating such large training databases is time-consuming, expensive, and often unfeasible in industrial production settings. In order to address this problem, an active learning framework is proposed which starts with only a small labeled subset of training data. The labeled dataset is then enlarged step-by-step by combining K-means clustering with active user input to provide representative samples for the training of an SVM classifier. Evaluations on two databases with insufficient and shifting solder joints samples\u00a0\u2026", "Haptic interaction is commonly used with 3D objects defined by their geometric and solid models. Extension of the haptic interaction to 3D Cyber worlds is a challenging task due to the Internet bandwidth constraints and often prohibitive sizes of the models. We study how to replace visual and haptic rendering of shared 3D objects with 2D image visualization and 3D haptic rendering of the forces reconstructed from the images or augmenting them, which will eventually simulate realistic haptic interaction with 3D objects. This approach allows us to redistribute the computing power so that it can concentrate mainly on the tasks of haptic interaction and rendering. We propose how to implement such interaction with small function descriptions of the haptic information augmenting images and video. We illustrate the proposed ideas with the function-based extension of VRML and X3D.", "Virtual simulations and games utilizing NPCs, or computer controlled agents, are more predominant now than ever. Many of these simulations suffer from a lack of effective, stimulating, and natural emotion-based behaviours in the interaction among the NPCs, as well as with the human players. This paper presents an easy-to-use, portable, diverging, and adaptive emotion model based on psychological and sociological research, for simulation and game designers to utilize easily in their virtual world. The proposed emotion model allows the player to better relate, understand and believe in characters in the virtual environment", "We seek to further expand the shared collaborative potential of cyberworlds by using haptic forcefeedback in shared virtual scenes. We propose how to define density of the objects, together with their geometry and appearance, by using mathematical functions. We illustrate this concept by developing software which allows us to touch and feel surfaces of VRML and X3D objects, convert them to solid objects as well as create any other solid objects using the function-based extension of VRML and X3D. We define geometry, appearance and density of the solid objects by implicit, explicit and parametric functions straight in the VRML/X3D code or in dynamic-link libraries. Since the function-based models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail. We illustrate the proposed with\u00a0\u2026", "In this paper, a function-based extension of Extensible 3D (X3D) is proposed. The extension allows authors to use analytical functions to define geometry, color, 3D texture as well as operations on 3D shapes or time-dependent metamorphoses. The functions can be implicit, parametric or explicit functions, defined as analytical formulas or scripts with similar syntax as ECMAScripts. The extension allows authors to benefit from both the compactness of function-based models and the new features in Extensible 3D. The Scene Access Interface (SAI) of X3D is used in the general implementation of the function-based extension. Xj3D browser is chosen as the development platform. Besides the SAI implementation, a special plugin for BS Contact VRML/X3D is also developed using non-standard interface.", "This paper addresses interactive function-based shape modelling. Interactive modification of the function model with concurrent visualization of the respective polygonal mesh lets us provide both the interactivity and any required level of detail leading to photo-realistic appearance of the resulting shapes. We have proposed an interactive visualisation method capable of handling local shape modifications with any desired precision. We illustrate the implementation of the proposed visualisation method on the example of the interactive function-based artistic shape modelling.", "Haptic interaction requires the content creators to make haptic models of the virtual objects while it is not always possible or feasible, especially when it comes to using real images or videos as elements of interaction. We, therefore, propose tangible images and image-driven haptic rendering where a displayed image is used as a source of the force-feedback calculations at any pixel touched by the haptic device. We introduce the main idea and describe how it is implemented as a core algorithm for image-driven haptic rendering, as well as for a few particular cases of haptic rendering emphasizing colors, contours and textures of the objects displayed in the images. Implementations of the proposed method to desktop tangible image application and haptic video communication on the web are presented as a proof of concept.", "We propose the use of partial differential equations (PDEs) for shape modelling within visual cyberworlds. PDEs, especially those that are elliptic in nature, enable surface modelling to be defined as boundary-value problems. Here we show how the PDE based on the Biharmonic equation subject to suitable boundary conditions can be used for shape modelling within visual cyberworlds. We discuss an analytic solution formulation for the Biharmonic equation which allows us to define a function based geometry whereby the resulting geometry can be visualised efficiently at arbitrary levels of shape resolutions. In particular, we discuss how function based PDE surfaces can be readily integrated within VRML and X3D environments.", "In this paper we analyze human electroencephalograms (EEG) evoked by olfactory stimuli. The study is performed by nonlinear spectral analysis and 3D visualization of EEG. Our technique of processing EEG spectra is based on R\u00e9nyi entropy\u2014the concept of generalized entropy of a given probability distribution. It allows for defining generalized fractal dimension of electroencephalogram (EEG) and determining fractal spectra of electroencephalographic signals. Powered by 3D visualization of the brain activity, the method provides new clues for understanding the mental processes in humans. Our study proved that male and female brains react differently to olfactory stimuli.", "We seek to further expand X3D by augmenting it with function-based definitions of geometry, appearance and tangible physical properties. Besides using alone, the introduced nodes can augment and enrich the standard X3D shapes by function-defined geometry, appearance and tangible physical properties. These new virtual objects can be explored haptically with various desktop force-feedback devices. We also propose a general visual and haptic collaborative framework for using it with X3D. We implement it as new pilot versions of BS Collaborate server and BS Contact VRML/X3D viewer. In our collaborative framework, two pipelines---visual and haptic---complement each other to provide a simple and efficient solution to problems requiring collaboration in shared virtual spaces on the web.", null, "Compared to commonly used 2D tracking devices, 3D hand tracking by low-cost optical cameras can provide more degrees of freedom, as well as natural gestures for interaction done in virtual spaces. However, it is not considered to be precise enough for 3D modeling due to the problems of hand jitter, jump release, and occlusion. To avoid these problems, we propose to use bimanual interaction and separate the functions of a hand --- the dominant hand controls 3D position and rotation, while the other hand controls grasping and releasing. This interaction is similar to playing the theremin --- an electronic musical instrument controlled without physical contact by hands of the performer. Based on this method, we describe a generic set of reliable and precise interaction techniques for 3D shape modeling. A pilot user study shows that the proposed technique supports 3D modeling faster than that with Maya using\u00a0\u2026", "This, the 26th issue of the Transactions on Computational Science journal, is comprised of ten extended versions of selected papers from the International Conference on Cyberworlds 2014, held in Santander, Spain, in June 2014. The topics covered include areas of virtual reality, games, social networks, haptic modeling, cybersecurity, and applications in education and arts.", "Existing methods for cyber learning mathematics and geometry are restricted to a limited class of geometric objects, most of which are predefined in the system. Besides, no existing methods emphasize the geometric meaning of mathematic functions. Our research aims at improving learners' three-dimensional spatial abilities by providing an intuitive and efficient environment for learning mathematics and geometry, specifically, the geometric meaning of mathematic functions. We propose a new 3D web learning environment that does not restrict to a list of predefined primitive geometric objects, allows the learner to interactively create objects by defining their properties using analytical functions, and immerses the learner into the environment. The object properties, including geometry, visual appearance and physical properties, are created in their own coordinate domains and then assembled together to define a\u00a0\u2026", "We propose a framework for visual and haptic collaboration in 3D shared virtual spaces. Virtual objects can de declared as shared objects which visual and physical properties are rendered synchronously on each client computer. We introduce virtual tools which are shared objects associated with interactive and haptic devices. We implement the proposed ideas as new pilot versions of BS Collaborate server and BS Contact VRML/X3D viewer. In our collaborative framework, two pipelines-visual and haptic-complement each other to provide a simple and efficient solution to problem requiring collaboration in shared virtual spaces on the Web. We discuss two implementation frameworks based on the strong and thin server concepts.", "Anomaly detection is a challenging task in the field of data analysis, especially when it comes to unsupervised pixel-level segmentation of anomalies in images. In this paper, we present a novel multi-stage image resynthesis framework for detecting and segmenting image anomalies. In contrast to existing reconstruction-based approaches, our method is based on repairing suspicious regions of defective images so that the defects can be localized in the residual map between inputs and the repaired outputs. To avoid the reconstruction artifacts caused by defects, we propose to generate each pixel of the image by its context in the first coarse reconstruction stage. Then, while excluding all safe pixels, our method repairs suspicious regions that have large deviations to the original input image in subsequent stages. After several iterations, the defects will be detected in the final residual map. The experimental\u00a0\u2026", "Polygon and point based models dominate virtual reality. These models also affect haptic rendering algorithms, which are often based on collision with polygons. With application to dual point haptic devices for operations like grasping, complex polygon and point based models will make the collision detection procedure slow. This results in the system not able to achieve interactivity for force rendering. To solve this issue, we use mathematical functions to define and implement geometry (curves, surfaces and solid objects), visual appearance (3D colours and geometric textures) and various tangible physical properties (elasticity, friction, viscosity, and force fields). The function definitions are given as analytical formulas (explicit, implicit and parametric), function scripts and procedures. We proposed an algorithm for haptic rendering of virtual scenes including mutually penetrating objects with different sizes and\u00a0\u2026", "In manufacturing, artificial intelligence is attracting widespread attention to maximize industrial productivity. Image clustering, as a fundamental research direction in unsupervised learning, has been applied in various fields. Since no label information is demanded in clustering, a preliminary analysis of the unlabeled data can be done while saving lots of manpower. In this paper, we propose a novel Self-supervised Pairing Image Clustering network. It predicts clustering results in an end-to-end pair classification network, which is trained excluding any label information. Specifically, we devised a self-supervised pairing module that is able to accurately and efficiently create both types of pairs as training data after exploiting the pair distribution. Cooperating with the pair classification loss function, we added two regularization terms to ensure the clustering results to be unambiguous and close to the real data distribution\u00a0\u2026", "Creation of procedural 3D building models can significantly lessen the costs of modeling, since it allows generating a variety of similar shapes from one procedural description. The common field of application for procedural modeling is modeling of straight building facades, which are very well suited for shape grammars \u2013 a special kind of procedural modeling system. In order to generate round building geometry, we present a way to setup different coordinate systems in shape grammars. Besides Cartesian, these are primarily cylindrical and spherical coordinate systems for generation of structures like towers or domes, that can procedurally adapt to different dimensions and parameters. The users can apply common splitting idioms from shape grammars in their familiar way, for creating round instead of straight geometry.", "Created intentionally or spontaneously, cyberworlds are information spaces and communities that immensely augment the way we interact, participate in business and receive information throughout the world. This paper reports position statements presented at the plenary panel of the 2015th International Conference on Cyberworlds. First, the problems of enhancing creativity in cyberworlds using new interfaces are considered. It follows by the discussions on using biometric interfaces in on-line services. Finally, the challenges of using brain-computer interfaces and emotion recognition using electroencephalograms are considered.", "Minimally invasive arthroscopic surgery has become the gold standard for orthopedic surgery procedures on joints done by making small incisions on the skin through which special miniature pencil-like cameras and tools are inserted. Simulation of the arthroscopic procedures in virtual environments is based on the specifics of the arthroscopic camera which is normally not a common forward-looking but a short-focus side-looking camera. In this paper we write about two problems which arise when modeling views seen through the virtual arthroscopic camera controlled by a desktop hap tic device in a hybrid image-based virtual environment. These are automatic creation of panoramic images of the surgical field from the actual arthroscopic videos and removing fish-eye distortions from the individual video frames.", "Minimally invasive arthroscopic surgery has replaced the common orthopaedic surgery procedures on joints. However it demands from surgeons to acquire very different motor-skills for using special miniature pencil-like instruments and cameras inserted through little incisions on the body while observing the surgical field on a video monitor. Training in virtual reality is becoming an alternative to traditional surgical training based on either real patients or increasingly difficult to procure cadavers. In this paper we propose solutions for simulation in virtual environments a few basic arthroscopic procedures including incision of the arthroscopic camera, positioning of the instrument in front of it, as well as using scissors and graspers. Our approach is based on both full 3D simulation and haptic interaction as well as image-based visualization and haptic interaction.", "Virtual haptic simulation of minimally invasive arthroscopic surgery becomes an extremely important training tool that allows the medical students to acquire necessary motor skills before they can approach actual patients. Normally, 3D simulation of the interior of a joint requires significant efforts from the software developers but yet remains not always photo realistic. In this paper, we propose a pioneering approach of using augmented real arthroscopic images for realistic and immersive image-driven visualization and haptic interaction within the surgical field as if it were actual three-dimensional scene where body parts displayed in the image act and feel as real 3D objects rather than their images.", "When teaching subjects richly infused with mathematics, in particular geometry, topology and shape modeling, there is a frequent problem that the learners are not able to \u201cvisualize\u201d the attendant theoretical concepts. It is important, therefore, to constantly illustrate the associated theories with practical visual exercises, which are preferably to be done in collaboration with other learners to allow them to discuss possible approaches to the problem and to consult with the instructor, virtually or face-to-face. We have proposed an approach that would allow for solving mathematical problems while being immersed within shared virtual 3D collaborative environments. Only mathematical formulas are used by the learners for immediate interactive definition of geometry, appearance and physical property of the shapes being created in the virtual environment. We target learners and educators who are studying\u00a0\u2026", "Computer Graphics | Guide books ACM Digital Library home ACM home Google, Inc. (search) \nAdvanced Search Browse About Sign in Register Advanced Search Journals Magazines \nProceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch \nAdvanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksComputer \nGraphics: From a Small Formula to Cyberworlds (Second Edition) book Free Access Share \non Computer Graphics: From a Small Formula to Cyberworlds (Second Edition) Author: \nAlexei Sourin View Profile Authors Info & Claims 01 June 2006 Online:01 June 2006Publication \nHistory 1citation 0 Downloads Metrics Total Citations1 Total Downloads0 Last 12 Months0 \nLast 6 weeks0 Get Citation Alerts New Citation Alert added! This alert has been successfully \nadded and will be sent to: You will be notified whenever a record that you have \u2026", "Multi-view reconstruction methods are able to produce polygon meshes of a complex scene with millions of triangles which are well suited for visualization purposes. However, these large-scale, dense meshes normally cannot be haptically rendered directly with readily available APIs. In this paper, we present a method to extend meshes reconstructed from images to visual-haptic applications by using images for visual display while an improved hybrid collision detection method is used to meet the real-time requirements for haptic rendering. Moreover, three main imperfections (holes, outliers and degenerated facets) inherent in reconstructed models are also handled to help provide a smooth and consistent force feedback. Given a reconstructed model and the corresponding image, the proposed method provides a way to virtually explore the scene in the image, making it possible to appreciate art works and\u00a0\u2026", "We add new modality to image\u2010based visualization by converting ordinary photos into tangible images, which can be then haptically rendered. This is performed by interactive sketching haptic models on the photos so that the models match the image parts, which will become tangible. In contrast to common geometric modelling, we define the haptic models in a three\u2010dimensional haptic modelling space distorted by the central projection. Analytic FRep functions (variants of implicit functions) are mostly used for defining the haptic models. The tangible images thus created can realistically simulate some actual three\u2010dimensional scenes by implementing the principle \u201cWhat You See Is What You Touch\u201d while in fact still be 2D images. Copyright \u00a9 2015 John Wiley & Sons, Ltd.", "Haptic interaction significantly augments our experience with a computer and in cyber worlds in particular. However, haptic interaction requires the content creators to make physical or haptic models of the virtual objects while it is not always possible or feasible, especially when it comes to using real images or videos as elements of interaction. We, therefore, propose to use image-driven haptic rendering where a displayed image, real or simulated, is used as a source of the force-feedback calculations at any pixel touched by the haptic device. We introduce the main idea and describe how it is implemented as a core algorithm for image-driven haptic rendering, as well as for a few particular cases of haptic rendering of different dominant colors, textures and contours of the objects displayed in the images. Implementations of the proposed method to desktop tangible image application and haptic video communication\u00a0\u2026", "The ever increasing complexity of the physical phenomena studied in scientific and engineering disciplines, requires the development of new approaches and powerful technique for processing and analysis of complex data. Scientific Visualization developing methods and tools for understanding the problems to be solved by bringing in a person's ability to see and perceive the image. The article deals with the preconditions of occurrence of this scientific field, the stages of its formation as a scientific discipline and major achievements. Shows the transition from technology to render virtual environment. Currently, scientific visualization is quite complete scientific discipline. Purpose of virtual environments is to provide users with a virtual workspace, in which they can observe and investigate create the virtual real-time data, models and the scenes. Presents selected results of the development of scientific visualization\u00a0\u2026", "Venepuncture or venipuncture is drawing blood from vein for testing or blood transfusion purposes. It is one of the most routinely performed invasive procedures that medical students must learn. Haptic interaction in virtual reality environments may provide an advance tool for training these skills. We present a novel and low-cost approach for image-based virtual haptic venepuncture simulation. We use actual photos of patient arms to provide a quick implementation of different virtual arms with better visual immersion. The function-based model of virtual veins helps us to achieve fast collision detection, while the haptic model for the multi-layer soft tissue provides stable and realistic force feedback. The implemented system was validated by medical staff.", null, null, "Following the rapid advancement of Artificial Intelligence and transition into the era of Big Data, researchers have started to explore the possibility of using machine learning in creative domains such as music generation. However, most research were focused on musical composition and removed expressive attributes during data pre-processing, which resulted in mechanical-sounding generated music. To address this issue, music elements, such as pitch, time and velocity, were extracted from MIDI tracks and encoded with piano-roll data representation. With the piano-roll data representation, Deep Convolutional Generative Adversarial Network (DCGAN) learned the data distribution from the given dataset and generated new data derived from the same distribution. The generated music was evaluated based on its incorporation of music dynamics and a user study. The evaluation results verified that DCGAN could\u00a0\u2026", "Recent interest and development in artificial intelligence spurred researchers to explore the role that deep learning could play in creative music. There exists a variety of deep learning music generation systems and methods that fulfil different objectives such as generation of a specific musical texture or accompaniment for a melody. However, current implementations lack content variability as they are only able to generate music with a fixed length or varied length with fixed temporal granularity. We propose a new hybrid temporal scope representation that generates music with both varied length and temporal granularity, enabling the generation of progressive meters such as irregular and mixed meters. We introduce a model made up of a Bidirectional Long Short-Term Memory (Bi-LSTM) network that uses our hybrid temporal scope representation to generate coherent music with irregular and mixed meters\u00a0\u2026", "Large displays are capable of visualising a large amount of data on multiple views including scatterplots and parallel coordinates and are often present in meeting rooms. They can be used to interact with a dataset and foster discussion among team members. Although some of these large screens have multi-touch capabilities, in many cases it is cumbersome to have to stand close to the display in order to interact with it. One of the solutions is to use a small handheld display to interact with the large display. This paper discusses how traditional interactions such as selection, brushing, and linking can be performed using a secondary handheld device. As a proof of concept, a system including scatterplots and parallel coordinates views is implemented. The interactions are straightforward and are useful for any interactive visual analysis application on a large display with wireless connectivity.", "The creation of building models has high importance, due to the demand for detailed buildings in virtual worlds, games, movies and geo information systems. Due to the high complexity of such models, especially in the urban context, their creation is often very demanding in resources. Procedural methods have been introduced to lessen these costs, and allow to specify a building (or a class of buildings) by a higher level approach, and leave the geometry generation to the system. While these systems allow to specify buildings in immense detail, roofs still pose a problem. Fully automatic roof generation algorithms might not yield desired results (especially for reconstruction purposes), and complete manual specification can get very tedious due to complex geometric configurations. We present a new method for an abstract building specification, that allows to specify complex buildings from simpler parts with\u00a0\u2026", "Knee arthroscopic surgery is performed on the knee joint by making small incisions on the skin through which an endoscopic camera (arthroscope) is inserted along with miniature surgical instruments. It demands from the surgeons to acquire special motor-skills. A few commercial simulators are available for arthroscopic surgery training however the area is still very open for research and development. In contrast to the common fully-3D way of simulation of knee arthroscopy, we propose a hybrid image-based approach where real arthroscopic videos are converted to panoramic images which are augmented with 3D deformable models of the tissues as well as 3D models of surgical instruments. The motions of the virtual arthroscope and the instruments are controlled by two desktop haptic devices. The hybrid virtual scene is visualized through a moving circular window, which follows the motion of the virtual\u00a0\u2026", "In this paper, we introduce a new approach to virtual palpation for medical training in cyber worlds. We analyze palpation as a medical procedure. Then, we survey the existing virtual palpation projects, which use haptic devices, and propose a new image-driven approach to haptic palpation that can be easily ported to any web-enabled and collaborative environments. We also introduce variable haptic interaction point that allows us to implement multiple-point haptic interaction while using a single-point desktop haptic device. Lastly, we prove our hypothesis by implementing the proposed approach for abdominal palpation and validating it with medical practitioners. We also discuss the advantages of our method over other existing works in terms of flexibility, simplicity and scalability.", "In this paper we introduce a function-defined extension of Virtual Reality Modeling Language where analytical formulas are used for defining geometry and appearance of 3D shapes. By \"functions\" we understand analytical definitions with parametric, implicit and FRep formulas. In our model, different analytical representations can be used concurrently for defining geometry and appearance of the shapes. The proposed structure of the software allows for its extending with any proprietary function-based models. The extension is designed for collaborative shape modeling as well as for building shared virtual worlds. This is illustrated with the implementation of the collaborative shape modeling hands-on experience, which is a part of the Virtual Campus - a shared cyberworld of Nanyang Technological University.", null, "Deep learning provides new ways for defect detection in automatic optical inspections (AOI). However, the existing deep learning methods require thousands of images of defects to be used for training the algorithms. It limits the usability of these approaches in manufacturing, due to lack of images of defects before the actual manufacturing starts. In contrast, we propose to train a defect detection unsupervised deep learning model, using a much smaller number of images without defects. We propose an unsupervised deep learning model, based on transfer learning, that extracts typical semantic patterns from defect-free samples (one-class training). The model is built upon a pre-trained VGG16 model. It is further trained on custom datasets with different sizes of possible defects (printed circuit boards and soldered joints) using only small number of normal samples. We have found that the defect detection can be performed very well on a smooth background; however, in cases where the defect manifests as a change of texture, the detection can be less accurate. The proposed study uses deep learning self-supervised approach to identify if the sample under analysis contains any deviations (with types not defined in advance) from normal design. The method would improve the robustness of the AOI process to detect defects.", "The hand tracking device Leap Motion Controller has been applied in many areas since it was released. Two innovative interaction mechanisms were designed by the author for virtual object manipulation, in which collision detection between the virtual hands and the objects is not required. Instead, it controls the grasping and releasing with the gestures of one hand; and controls the direction and amount of the object's displacement with the other hand. After several tests, the mechanisms are proven to have reasonably high precision. They allow the users to adjust the parameters to create customized systems, leading to an optimal outcome.", "Haptic interaction is a form of a user-computer interaction where physical forces are delivered to the user via vibrations, displacements and rotations of special haptic devices. When quality of the experience of the haptic interaction is assessed, mostly subjective tests using various questionnaires are performed. We proposed novel neurocognitive tools for assessing both overall experience of the haptic interaction, as well as particular time-stamped activities. Our assessment tools are based on recognition of emotions and stress obtained from Electroencephalograms (EEG). We used them in a feasibility study on adding haptic interaction to Skype video conversation.", "While the growing demand for new building models contained in virtual worlds, games, and movies, makes the easy and fast creation of modifiable models more and more important, 3D modeling of buildings can be a tedious task due to their sometimes complex geometry. For historic buildings, especially the roofs can be challenging. We present a new method of combining simple building solids to form more complex buildings, and give an emphasis on the blending of roof faces. This can be integrated in common pipelines for procedural modeling of buildings and will bring more expressiveness than existing methods.", "MRI segmentation is a process of deriving semantic information from volume data. For brain MRI data, segmentation is initially performed at a voxel level and then continued at a brain surface level by generating its approximation. While successful most of the time, automated brain segmentation may leave errors which have to be removed interactively by editing individual 2D slices. We propose an approach for correcting these segmentation errors in 3D modeling space using a desktop haptic device. We actively use the brain surface, which is reconstructed in the automated FreeSurfer segmentation pipeline. It allows us to work with the whole data set at once, utilizing the context information and correcting several slices simultaneously. Proposed heuristic editing support and automatic visual highlighting of potential error locations allow us to substantially reduce the segmentation time. The paper describes the\u00a0\u2026", "Various Partial Differential Equations (PDE) have been used in computer graphics for approximating surfaces of geometric shapes by finding solutions to PDEs subject to suitable boundary conditions. The PDE boundary conditions are defined as 3D curves on the surface of the shapes. We propose how to automatically derive these curves as boundaries of curved patches on the surface of the original polygon mesh. The analytic solution to the PDE used throughout this work is fully determined by finding a set of coefficients associated with parametric functions according to the particular set of boundary conditions. The PDE coefficients require an order of magnitude smaller space compared to the original polygon data and can be interactively rendered with different level of detail. It allows for an efficient exchange of the PDE shapes in 3D Cyber worlds and their web visualization. In this paper we analyze and\u00a0\u2026", "We propose an efficient alternative to commonly used parametric surfaces such as NURBS surfaces for definition of complex geometry in shared virtual spaces. Our mathematical model allows to define objects by only providing coordinates of the section curves in 3-space. The resulting parametric functions allow fast calculation of the coordinates of the points on the surface of the objects. We devise an algorithm which evaluates the coefficients of these functions in real time. Given the small size of the resulting formulas and interactive rates for their calculation, we are able to efficiently use such PDE-based models for making virtual objects in shared virtual spaces. We describe the modeling framework and illustrate the proposed theoretical concepts with our function-based extension of VRML and X3D.", "In this paper we propose FVRML---a function-based extension of Virtual Reality Modeling Language which allows for time-dependent shape modeling on the web. Shape's geometry, 3D texture, color and transformations changing through time can be defined with analytical functions typed straight in VRML code. FVRML allows us to greatly extend the abilities of VRML with a very intuitive approach to shape modeling based on using analytical functions. Several functions can be combined into one using java scripts emulated in FVRML, which allows for even greater flexibility and convenience of shape modeling.", "Cyberworlds created on the web allow for providing personal mentoring of the students with different cultural and educational backgrounds. Virtual Campus of Nanyang Technological University is designed to be such a cyberworld. This is a place for research and education, fun and immersion in campus life. Besides standard VRML, its hybrid function-based extension is used in the design of Virtual Campus. In place of thousands of polygons, small formulas are used for constituting complex geometric shapes and appearances. Collaborative Shape Modeling Laboratory, which is a part of the Virtual Campus, is based on this extension. It is developed to help students with their computer graphics assignments.", "The manufacturing process in the pharmaceutical industry requires for using vessels or tanks which inner surfaces can undergo fouling and/or may develop visible defects that have to be cleaned away. Surface contamination can present itself in different forms, and there is no available image database of stains. In this paper, we propose to use an unsupervised anomaly detection approach which trains models on one or just a few images of clean surfaces. First, we propose an inpainting GAN with global and local generators to make full use of every single image and to reduce the overfitting caused by a limited number of images in the training dataset. Furthermore, we propose a periodic noise injection technique to increase the number of images for training and to improve the detection performance of the network. The experimental results demonstrate that the proposed network and noise injection technique\u00a0\u2026", "Many machine learning algorithms require a labelled training dataset. The task of labelling a multivariate dataset can be tedious, but can be supported by systems combining interactive visualisation and machine learning techniques into a single interface. mVis is such a system, providing a unified ecosystem to explore multivariate datasets and execute machine learning algorithms to build labelled datasets.This paper describes a pre-study evaluation of the mVis system, comprising case studies in two different domains: collaborative intelligence and daily activities. In each case study, a volunteer researcher was asked to use mVis to explore, analyse, and label their own dataset in their own environment, while thinking out loud. The case studies provided valuable leanings in terms of the usability of the system, understanding how different analysts work, and identifying important missing features.", "Not many people know about the first electronic musical instrument - the theremin - and can play it. The idea of this instrument is very groundbreaking: it is played without physical contact with it and in the same way as we sing but by using hands in place of our vocal cords. In this paper we consider how to implement the theremin with a computer using very different physical principles of optical hand tracking and by adding advantages of visual interfaces. The goal of this research is to eventually fulfill the dream of the inventor to make the theremin a musical instrument for everyone and to prove that everyone can play music.", "Interactive rendering of direct illumination from area lights in virtual worlds has always proven to be challenging. In this paper, we propose a deferred multi-resolution approach for rendering direct illumination from area lights. Our approach subdivides the screenspace into multi-resolution 2D-fragments in which higher resolution fragments are generated and placed in regions with geometric, depth and visibility-to-light discontinuities. Compared to former techniques that use inter-fragment binary visibility test, our intra-fragment technique is able to detect shadow more efficiently while using fewer fragments. We also make use of gradient information across our binary visibility tests to further allocate higher resolution fragments to regions with larger visibility discontinuities. Our technique utilizes the stream-compaction feature of the transform feedback shader (TFS) in the graphics shading pipeline to filter out fragments\u00a0\u2026", "In this paper, we propose a new approach to virtual abdominal palpation. Firstly, we describe palpation as a medical procedure. Then, we analyze the necessity of virtual palpation. Next, we present our survey on the existing work on virtual palpation. Then, we propose a new image-driven function-based approach to virtual palpation to address the weakness of the previous works. Lastly, we discuss the advantages of our method over other existing works.", "Geometric shape modeling becomes increasingly complex and resource-demanding task. In this paper we propose a method to leverage the power of grid to provide users with high-precision free-form shape modeling environment. Function-based representation allows for defining shapes with an unlimited level of detail while keeping a small size of the model. The model compactness allows us to create optimal infrastructure for distributing work between processing nodes. A novel parallel surface extraction algorithm was proposed to avoid a uniform sampling of the defining function. Only points located close to the surface of the shape are sampled. A protocol for interactive communication between the user of the modeling system and the processing modules in grid has been developed to support shape modification, visualization with arbitrary precision and dynamic load-dependent allocation of computing\u00a0\u2026", "Virtual Campus is a shared virtual model of Nanyang Technological University. It is a great multimedia place for electronic education and fun, research and games, meeting new friends, and immersion in campus life. It can be accessed from any Internet connected computer running MS Windows. In this place you can be anything: choose a fancy look, or turn yourself into a sports car, spooky creature, insect, or sparkling cloud. Visitors may wander around or fly, go to offices or student hostels, attend electronic lectures, or just chat with other visitors or robots. One of the places of the Virtual Campus is Collaborative Shape Modelling Hands-On Experience. Being a part of the computer graphics course, it teaches students how 3D shapes and their colours can be easily defined with parametric and implicit functions.", "This paper describes how the web-based visualization can be greatly improved using the function-based shape modeling technique. The improvement is possible because the proposed function-defined VRML shape node allows the content creators to describe any complex models with relatively small functions compared to the large-size polygonal mesh based VRML nodes. These function-defined shapes can be used together with the common VRML shapes. The proposed node has a few implementations capable of visualizing geometric shapes defined with HyperFun language as well as in any proprietary function-defined data formal. For fast visualization of the function-defined shapes, we have developed an improved continuation polygonization algorithm specifically designed for VRML visualization. The design, the implementation details, and the application examples of the proposed node are discussed.", "ConclusionThe implemented tools allow the surgeon to fix not only fractures but also allow the simulating of internal operations for some bone diseases. For example, the surgical technique of fixing with cancellous screws can also be used for slipped capital femoral epiphyses, ankle arthrodeses, sacroiliac joint disruptions, subtalar arthrodeses and others.The following advantages of the Virtual Bone-setter can be listed:\u2022 Simulation of different common bone fractures and fixation techniques.\u2022 Simulation of untypical bone fractures and fixation techniques.\u2022 Viewing the objects through \u201cthe image intensifier\u201d.\u2022 Rotating the scene and objects in the scene.\u2022 Walk through the bone canal.\u2022 Reverse process.", "Information visualization creates images from abstract data by interpreting them geometrically. It may require skills of making images with raw mathematics while the graphics content is now mostly created by using sophisticated licensed software. As a result, fewer and fewer developers are capable of using procedurally based visualization in which mathematical formulas are used for defining complex geometric shapes, transformations, and motions as well as for coloring the geometry. The book explains how to see geometry and colors beyond simple mathematical formulas and teaches how to represent geometric shapes and motions from first principles by digital sampling mathematical functions. The book may serve as a self-contained text for a one-semester computer graphics and visualization course for computer science and engineering students, as well as a reference manual for researchers and developers.", "Artificial intelligence is being increasingly applied in manufacturing to maximize industrial productivity. Image clustering, as a fundamental research direction in unsupervised learning, has been used in various fields. Since no label information is required in clustering, it can perform a preliminary analysis of the data while saving lots of manpower. In this paper, we propose a novel end-to-end clustering network called Self-supervised Pairing Image Clustering (SPIC) for industrial application, which produces clustering prediction for input images in an advanced pair classification network. For training this network, a self-supervised pairing module is built to form balanced pairs accurately and efficiently without label information. Since the existence of trivial solutions cannot be avoided in most of unsupervised learning methods, two additional information theoretic-constraints regularize the training that ensures the\u00a0\u2026", "Parallel coordinates is a well-known technique for visual analysis of high-dimensional data. Although it is effective for interactive discovery of patterns in subsets of dimensions and data records, it also has scalability issues for large datasets. In particular, the amount of visual information potentially being shown in a parallel coordinates plot grows combinatorially with the number of dimensions. Choosing the right ordering of axes is crucial, and poor design can lead to visual noise and a cluttered plot. In this case, the user may overlook a significant pattern, or leave some dimensions unexplored. In this work, we demonstrate how eye-tracking can help an analyst efficiently and effectively reorder the axes in a parallel coordinates plot. Implicit input from an inexpensive eye-tracker assists the system in finding unexplored dimensions. Using this information, the system guides the user either visually or automatically to find\u00a0\u2026", "Video-conferencing and video calls are common nowadays. However, without being able to physically touch or feel each other, we cannot have full immersive communication achieved. Unlike earlier attempts of joining video and haptic communication into one integrated system, we propose to setup an asynchronous method of exchanging haptic interaction data while using traditional ways of video communication. The data packets are exchanged over the Internet cloud server where only participating haptic interface point coordinates, orientation angles of the device handles are transmitted. We also explore more options like using depth-sensing cameras and handtracking devices to capture motion of hand, arm or the whole body of one user so that he becomes both visible and tangible to the other party. The proposed way of communication is validated by technical measurements and a user study. A test of\u00a0\u2026", "Video-conferencing and video phone calls are common nowadays. However more immersion can be achieved if we not only see and hear but also physically feel each other. In contrast to previous attempts which were mostly setting up integral video-haptic communication systems, we propose a different way where we use any existing video communication tools while asynchronously exchanging over the Internet cloud server very little data packets containing only haptic interaction data. In case of desktop haptic devices, we only exchange between the participating computers haptic interface point coordinates, orientation angles of the device handles and computed force vectors. More options for haptic communication appear when we replace common video cameras with depth-sensing cameras and hand-tracking devices. Then, motion of the hand, arm or even the whole body of one party can be both seen and\u00a0\u2026", "Interactive rendering of translucent materials in virtual worlds has always proved to be challenging. Rendering their indirect illumination produces further challenges. In our work, we develop a voxel illumination framework for translucent materials illuminated by area lights. Our voxel illumination uses two existing voxel structures, the Enhanced Subsurface Light Propagation Volumes (ESLPV), which handles the local translucent material appearance and the Light Propagation Volumes (LPV), which handles indirect illumination for the surrounding diffuse surfaces. By using a set of sparse translucent Poisson disk samples (TPDS) and diffuse Poisson disk samples (DPDS) for the ESLPV and LPV, illumination can be gathered from area lights effectively. This allows the direct illumination of the translucent material to be rendered in the ESLPV, and the diffuse indirect illumination of the surrounding scene can be rendered\u00a0\u2026", "Interactive rendering of illumination from area lights in virtual worlds has always proved to be challenging. In this paper, we extend the work of multi resolution rendering for direct illumination from area lights. We propose a deferred shading method for direct illumination which subdivides screenspace into multi resolution 2D-fragments in which higher resolution fragments are created to represent geometric and depth discontinuities as well as shadow boundaries. To detect shadow boundaries, our subdivision scheme, sub-fragment visibility test (SFVT), performs a visibility discontinuity check within each fragment and subdivides the fragment to a higher resolution level if discontinuity is found. In addition, our proposed gradient aware screenspace subdivision (GASS) algorithm accelerates the refinement by increasing the number of subdivisions based on gradient differences. Our technique utilizes the\u00a0\u2026", "Tears are typical injuries of the meniscus-a thin tissue located within the knee between the two leg bones. They are treated by minimally invasive arthroscopic surgery. We propose how to achieve real-time visually realistic deformation of the meniscus by using linear co-rotational finite element method applied to the coarse mesh enriched with monitor points responsible for fine wrinkles simulation.", "Video interaction is a common way of communication in cyberspace. It can become more immersive by incorporating hap tic modality. Using commonly available depth sensing controllers like Microsoft Kinect, information about the depth of a scene can be captured in real-time together with the video. In this paper, we present a method for real-time hap tic interaction with videos containing depth data. Forces are computed based on the depth information. Spatial and temporal filtering of the depth stream is used to provide stability of force feedback delivered to the hap tic device. Fast collision detection ensures the proposed approach to be used in real-time. The usefulness of the approach is illustrated by a tangible video application example.", "Minimally invasive arthroscopic surgery has become the gold standard for orthopaedic surgery procedures on joints. It is done by making small incisions on the skin through which special miniature pencil-like cameras and tools are inserted. However, it demands from surgeons to acquire very different motor-skills while observing the surgical field on a video monitor. Simulation of the arthroscopic procedures in virtual environments is based on the specifics of the arthroscopic camera which is normally not a common forward-looking but a wide-angle oblique-viewing camera. In this paper we write about modeling views seen through the virtual arthroscopic camera controlled by a desktop haptic device in hybrid image-based virtual environment.", null, null, "We describe several advanced shape modeling techniques such as polygon-to-function conversion, pattern dependent interpolation of scattered data, and reconstruction from medial axis. These techniques are applied to model complex shapes for computer art works. Procedural and interactive approaches to synthetic carving are described. All introduced techniques are united under the shapes representation by real-valued functions.", null, null, "We study how music can be played with a computer by tracking hands in the air. We begin our considerations by analyzing how the theremin can be played\u2014an electronic musical instrument which is played without physical contact by the hands of the performer. We then look at the present hand-tracking technologies available for common personal computers and mobile devices and hypothesize that optical tracking devices, like Leap Motion controller, may be used for simulating the theremin functions with a common personal computer. We then describe our own implementation of the digital theremin and analyze why the theremin is considered as the most difficult to play musical instrument and how its deficiencies can be overcome with the help of computer graphics.", "Supervised machine learning techniques require labelled multivariate training datasets. Many approaches address the issue of unlabelled datasets by tightly coupling machine learning algorithms with interactive visualisations. Using appropriate techniques, analysts can play an active role in a highly interactive and iterative machine learning process to label the dataset and create meaningful partitions. While this principle has been implemented either for unsupervised, semi-supervised, or supervised machine learning tasks, the combination of all three methodologies remains challenging. In this paper, a visual analytics approach is presented, combining a variety of machine learning capabilities with four linked visualisation views, all integrated within the mVis (multivariate Visualiser) system. The available palette of techniques allows an analyst to perform exploratory data analysis on a multivariate dataset and divide it into meaningful labelled partitions, from which a classifier can be built. In the workflow, the analyst can label interesting patterns or outliers in a semi-supervised process supported by active learning. Once a dataset has been interactively labelled, the analyst can continue the workflow with supervised machine learning to assess to what degree the subsequent classifier has effectively learned the concepts expressed in the labelled training dataset. Using a novel technique called automatic dimension selection, interactions the analyst had with dimensions of the multivariate dataset are used to steer the machine learning algorithms. A real-world football dataset is used to show the utility of mVis for a series of analysis and labelling\u00a0\u2026", "Interactive rendering of translucent materials in virtual worlds has always proved to be challenging. In our work, we develop a voxel illumination framework for translucent materials illuminated by area lights. Our voxel illumination framework consists of two voxel structures. They are the Enhanced Subsurface Light Propagation Volumes (ESLPV), which handles the local translucent material appearance and the Light Propagation Volumes (LPV), which handles indirect illumination for the entire scene. Using a set of sparsely distributed Poisson disk samples in the ESLPV and LPV, illumination can be gathered from area lights. A uniform set of Poisson disk samples on the translucent objects is resampled and chosen as Translucent Planar Lights (TPLs) and is used to distribute lighting from translucent objects into the LPV by an additional gathering process. Our technique allows for direct and indirect illuminations from\u00a0\u2026", "Haptic technologies allow for adding a new \u201ctouching\u201d modality into virtual scenes. 3D reconstruction of a real life scene results, however, often in millions of polygons which cannot be simultaneously visualized and haptically rendered. In this paper, we propose a way of haptic interaction with real life scenes where multiple original images of the real scenes are augmented with reconstructed polygon meshes. We present our solution to the problems of haptic model alignment with the images and interactive haptic rendering of large polygon meshes with reconstruction artifacts. In particular, the presented collision detection algorithm is not restricted by any hypothesis and robust enough to support smooth interaction with millions of polygons. The feasibility and usability of the proposed solution is evaluated in a user study.", "Haptic interaction is based on applying forces, vibrations, and/or motions to the computer user with special haptic devices. To understand how believable the haptic interaction is, questionnaires evaluating sensory immersion, comfort, realism, and satisfaction are used. However, this method only allows for overall evaluation of the quality of experience. Based on the existing ways of using EEG for identification of the brain states, we hypothesized that we should be able to capture changes of the users' feelings during haptic interaction while traditional user questionnaires can be used as a reference. Moreover, using time-stamped EEG data at any time interval starting from 1/32 sec, we should also be able to actively engage the potential users into the design and development phases of various haptic interactions. To prove the hypothesis, we proposed, implemented and applied neurocognitive methods, based on\u00a0\u2026", "We augment images with additional data allowing us to visualize them with elements of animation as well as interact with the images using haptic devices as if they were actual 3D scenes. First, we apply procedural simulation to simulate image distortions, which are characteristic for various phenomena like blowing wind, fluid flow, etc. Next, we consider how haptic rendering of images can be performed. This in turn includes haptic rendering of forces augmented to the images as well as haptic interaction with haptic objects augmented to the images. The immersive images thus obtained can be exchanged across the internet to realistically simulate 3D virtual scenes while in fact still be 2D images augmented with rather little additional data files in a way how movie subtitles files are added to the video files. The proposed approach is illustrated with a few representative examples.", "When procedural models based on implicit functions are used for defining complex shapes, the final model may become slow for rendering. We propose an algorithm for accelerating such rendering for free-form shape modeling where some initial shape is gradually modified by other implicitly-defined shapes with relatively smaller sizes compared to the final shape. The algorithm then adds additional functions to the final function script, which makes the rendering of the whole shape faster. The resulting accelerated function scripts can be then rendered on any suitable rendering platform that we illustrate by using function-based extension of VRML/X3D and POV-Ray.", "In this paper, a new approach to virtual medical abdominal palpation has been introduced. Firstly, we describe palpation as a medical procedure. Then, we analyze the necessity of virtual palpation. Next, we present our survey on the existing work on virtual palpation. Then, we propose a new image-driven function-based approach to virtual palpation to address the weakness of the previous works. Lastly, we discuss the advantages of our method over other existing works.", "We propose a new educational web-enabled 3D shape modeling framework that does not restrict to a list of predefined primitive geometric objects and allows the user to interactively create objects by incremental modifications of the basic shape with the tool shapes that are defined by analytical functions. The shape definition is eventually a function script which can be rendered on any suitable graphics system. The function script includes accelerating structures that significantly improve the shape rendering performance allowing us to sustain interactivity with large number of interactive operations applied.", "Automated brain segmentation may leave errors which can be identified by comparing the location of the actual MRI voxels with reference to the reconstructed pial polygonal surface of the brain. Location of the segmentation errors can be marked by displaying color spots on the brain surface followed by its interactive editing, as we previously proposed. In this paper, a new haptic friction-based approach of identifying and correcting errors has been discussed. The user can feel as different friction the discrepancy along the reconstructed surface by moving a haptic proxy along it followed by rubbing the surface as if it is being polished. The proposed approach does not only limit its application in editing of medical data, but can also be successfully used for visually impaired group as this dynamic friction-based editing helps any novice user identify error prone area just by touching the surface.", "We have proposed and implemented function-based extensions of Extensible 3D (X3D) and its predecessor Virtual Reality Modeling Language (VRML) which allow for defining time-dependent geometric shapes, their appearances and transformations with analytically defined parametric, implicit and explicit functions. The function-defined shapes can be used together with the standard X3D and VRML shapes. In this paper we present the most recent significantly revised and amended definition of the FVRML/FX3D nodes. Besides defining shapes by analytical functions, we have developed interactive function-based shape modeling tools. We have also extended these interactive shape modeling tools to work on the Grid.", "Virtual Campus is a shared virtual model of Nanyang Technological University. It is a great place for electronic education and fun, research and games, meeting new friends, and immersion in campus life. It can be accessed from any Internet connected computer running MS Windows. In this place you can be anything: choose a fancy look, or turn yourself into a sports car, spooky creature, insect, or sparkling cloud. Everything is possible in this cyberworld. You may wander around or fly, go to offices or student hostels, attend electronic lectures, or just chat with other visitors or robots. One of the places of the Virtual Campus is Collaborative Shape Modeling Hands-On Experience. Being a part of the computer graphics course, it teaches students how 3D shapes and their colors can be easily defined with parametric and implicit functions.", "This paper describes how function-based shape modeling can be expanded to web visualization, as well as how web-based visualization can be greatly improved by using the function-based shape modeling technique. We have proposed a function-defined VRML shape node, which allows the content creators to describe any complex models with relatively small functions compared to the large-size polygonal mesh models. These function-defined shapes can be used together with the common VRML shapes. The design, the implementation details, and the application examples of the proposed node are discussed.", "The uniform function representation of multidimensional geometric objects and the theory of R-functions are used to implement set-theoretic operations over time dependent solids. Traditional set-theoretic operations and introduced recursively defined swept-operations are discussed. The swept-operations are defined on the base of the concept of the moving solid envelope with the function representation closure property provided. Examples for NC machining are given.< >", "Current orthopedic surgery training is based on hundreds years old apprentice-master training model which involves surgery on real patients and expensive infrequent workshops conducted in unrealistic situations on artificial \u2018sawbone\u2019and on increasingly difficult to procure cadavers. However, the emphasis today is on minimally invasive orthopedic surgery, such as arthroscopy, in which an examination and treatment of damage of almost any joint in the human body is performed using an arthroscope, a type of miniature endoscopic camera that is inserted into the body through a small \u201ckey-hole\u201d incision. Virtual simulation of arthroscopy becomes an extremely important training tool that allows the medical students to acquire necessary motor skills before they can approach real patients. Normally, 3D simulation of the interior of a joint requires significant efforts from the software developers but yet remains not always photo realistic. In this paper, we propose a pioneering approach to use real arthroscopic images for realistic and immersive image-driven visualization and haptic interaction within the surgical field as if it were real three-dimensional scene where body parts displayed in the image act and feel as real 3D objects rather than their images..", "In this paper, we consider virtual medical training where abdominal palpation is implemented with desktop haptic devices. Firstly, we have defined palpation as used in medical practice. Then, we surveyed the existing virtual palpation projects which use haptic devices. Lastly, we propose a new image-driven and function-based approach to haptic palpation and discuss its advantages in terms of flexibility, simplicity and extendibility.", "Surgical training is one of the most promising areas in medicine where 3-D computer graphics and virtual reality techniques are emerging. This paper provides an advanced report on our project that aims to create virtual reality tools for training medical students and for improving skills and efficiency of orthopedic surgeons in internal fixation of bone fractures. The paper describes the whole pipeline from the CT scanner through the Unix-workstation to the personal computer where eventually the program works. We also describe the methods and mathematical models that allowed us to implement the ultimate goal of the project\u2014to allow the surgeons to perform training surgical operations even at their home computers without any special expensive hardware devices. This project was initiated in Singapore and currently continues as an international project.", "We performed a feasibility study on new ways of using sound in interactive computer graphics to improve visual interaction as well as to replace or augment haptic interaction. We considered using sound during surface interaction tasks performed with a desktop haptic device and an optical hand tracking device and evaluated the efficiency of such interactive geometry sonification in terms of its precision and speed. We also considered scenarios of using sound for easing navigation while moving along a path or surface.", "This paper presents an approach to procedural modeling and the interactive software tool ShapeExplorer designed to make geometric shapes and visual appearances defined by mathematical functions (explicit, implicit and parametric). It can run on Windows, MacOS and Linux. It is just one interactive window where the user can type the definitions scripts and other parameters. The purpose of ShapeExplorer is to work as a quick all-in-one multi-platform design and visualization tool providing mathematical models for virtual environments.", "Anomaly detection is a challenging task in data analysis, especially when it comes to unsupervised pixel-level segmentation of anomalies in images. In this paper, we present a novel multi-stage defect repaired image resynthesis framework for the detection and segmentation of anomalies in images. In contrast to the existing reconstruction-based approaches, our reconstruction is free from artifacts caused by defective regions so that the defects can be identified from the residual map between input samples and their resynthesized defect-eliminated outputs. Our method outperforms the state-of-art benchmarks in most categories using the publicly available MVTec dataset. Besides, the method also demonstrates an excellent capability of repairing defects in abnormal samples.", "Generative Adversarial Networks (GANs) are a very recent chapter in generative models and music visualisation. This paper explores the application of GANs in music visualisation via latent space exploration using latent directions. The output music visualisation tool is then evaluated via a user study to verify its effectiveness.", "In this chapter, we consider how visual appearance including colors, shadows, material properties and textures can be added to geometry and how its photorealistic appearance can be achieved. The formulas, previously used for defining geometry, now will define variable colors as a new modality of immersion into the world of geometric definitions.", "The chapter explains how we see the world and how computer makes images. Beginning with Ancient Greek Geometry, it travels to modern geometry, introduces the subject of computer graphics and visualization, explains how the graphics pipeline works, and how a geometric point turns into a color spot on a computer screen.", "In this chapter, the ways of making interactive, real-time and immersive visualization environments are considered including technical and physiological design and implementation issues. Still the same transformations, and actually the same basic mathematical principles, will be used in the fast visualization methods.", "This chapter explains how the previously introduced mathematical formulas, defining shapes and transformation matrices, can be extended to time-dependent models of moving shapes. Motions of rigid shapes and shape morphing transformations are considered. Besides pseudo-physical motions, definitions based on Newtonian physics are also introduced.", "This chapter introduces to the reader a few commonly used freeware software tools\u2014OpenGL, POV-Ray, VRML, and X3D\u2014which will let the readers apply theoretical principles into practice without requesting expensive hardware and software solutions. Also, the readers will learn how immersive visual mathematics can be implemented using the function-based extensions of VRML and X3D, which allow for defining geometric shapes and their appearances with mathematical functions. Finally, the Shape Explorer tool will be presented to the reader as a multi-platform companion viewer for all the examples used in the book.", "This chapter presents the mathematical foundations of shape modeling. Curves, surfaces, and solid objects are considered as set of points, which are obtained by sampling various types of mathematical functions. Using the concept of sweeping, many varieties of shapes are defined based on only a few simple foundation principles.", "This chapter considers how the same formulas, used for making shapes, can define their transformations. The rationale for using matrix transformations is explained and affine and projection matrix transformations are presented. Generalization of geometric sweeping implemented with matrices is further discussed.", "2018 International Conference on Cyberworlds, {CW} 2018 - Archive ouverte HAL Acc\u00e9der \ndirectement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation HAL HAL - \nArchives Ouvertes La connaissance libre et partag\u00e9e Accueil D\u00e9p\u00f4t Consultation Les derniers \nd\u00e9p\u00f4ts Par type de publication Par discipline Par ann\u00e9e de publication Par structure de \nrecherche Les portails de l'archive Recherche Documentation hal-02091432, version 1 \nDirection d'ouvrage, Proceedings, Dossier 2018 International Conference on Cyberworlds, {CW} \n2018 Alexei Sourin 1 Olga Sourina Christophe Rosenberger Marius Erdt D\u00e9tails 1 NTU - School \nof Computer Engineering [Singapore] Type de document : Direction d'ouvrage, Proceedings, \nDossier Domaine : Informatique [cs] / Cryptographie et s\u00e9curit\u00e9 [cs.CR] Liste compl\u00e8te des \nm\u00e9tadonn\u00e9es Voir https://hal.archives-ouvertes.fr/hal-02091432 Contributeur : Morgan Barbier \u2026", "This, the 32nd issue of the Transactions on Computational Science, focusses on cybersecurity and biometrics. The eight detailed papers cover the following topics: Multimodal Warnings for Distracted Smartphone Users on the Move; EEG-Based Mental Workload and Stress Monitoring of Crew Members in a Maritime Virtual Simulator; Detecting Web Defacement and Enabling Web-Content Regeneration; Software as a Weapon in the Context of (Inter) national Security; Multi-user Architecture and Multi-player Games; An Adaptive Discrete Wavelet Transform Based Face Recognition Approach; Synthesizing Images of Imagined Faces Based on Relevance Feedback; and Neurofeedback Training to Enhance the Focused Attention of Elite Rifle Shooters.", "Simulation of cutting is essential for many applications such as virtual surgical training. Most existing methods use the same triangle mesh for both visualization and collision handling, although the requirements for them in the interactive simulation are different. We introduce visual-collision binding between high-resolution visual meshes and low-resolution collision meshes, and thus extend the spatially reduced framework to support cutting. There are two phases in our framework: pre-processing and simulation. In the pre-processing phase, the fvisual-collision binding is built based on the computation of geodesic paths. In the simulation phase, the cutting paths are detected on the collision triangles and then mapped to local 2D coordinates systems in which the intersections between visual mesh and the cutting paths are calculated. Both collision and visual meshes are then re-meshed locally. The visual-collision binding is updated after cutting, based on which the collision-simulation and visual-simulation embedding are updated locally. Experimental results show that our cutting method is an efficient and flexible tool for interactive cutting simulation.", "Haptic feedback has always been a missing link in online shopping. In this project, we study whether a commonly-used haptic device with only one Haptic Interface Point (HIP) can be used in online shopping for compensating lack of physical touch. A user study was conducted in which data-driven haptic weight, shape and texture information was simulated and provided to the users. Despite the limitations of the device, the results have shown positive effects of providing haptic feedback in enhancing users' understanding of physical properties of a product.1", "Foreword to the Special Issue on 2016 International Conference on Cyberworlds (CYBERWORLDS \n2016) \u2014 Keio University Skip to main navigation Skip to search Skip to main content Keio \nUniversity Home Keio University Logo Help & FAQ English \u65e5\u672c\u8a9e Home Profiles Research \nunits Research output Search by expertise, name or affiliation Foreword to the Special Issue \non 2016 International Conference on Cyberworlds (CYBERWORLDS 2016) Issei Fujishiro, \nAlexei Sourin Department of Information and Computer Science Research output: Contribution \nto journal \u203a Article \u203a peer-review Overview Fingerprint Original language English Pages \n(from-to) 1-2 Number of pages 2 Journal Computers and Graphics (Pergamon) Volume 64 \nDOIs https://doi.org/10.1016/j.cag.2017.02.006 Publication status Published - 2017 May 1 \nASJC Scopus subject areas Engineering(all) Human-Computer Interaction Computer Graphics \u2026", "Cyberworlds are information worlds or communities created in cyberspace by collaborating participants either intentionally or spontaneously. As information worlds, they accumulate information regardless whether or not anyone is in. Cyberworlds can be based on sharing text, image and video information, as well as they can be immersive multi-user networked shared virtual worlds. Cyberworlds have been created and applied in such areas as e-business, e-commerce, e-manufacturing, e-learning and cultural heritage. They augment and sometimes replace the real life and become a significant component of real economy. The examples of such cyberworlds with millions of participants are communities created in different social networking services, virtual shared worlds and multiplayer online games. Problems of cyberworlds were discussed at the 2015th International Conference on Cyberworlds which was held in\u00a0\u2026", "The creation of building models has high importance, due to the demand for detailed buildings in virtual worlds, games, movies and geo information systems. Due to the high complexity of such models, especially in the urban context, their creation is often very demanding in resources. Procedural methods have been introduced to lessen these costs, and allow to specify a building (or a class of buildings) by a higher level approach, and leave the geometry generation to the system. While these systems allow to specify buildings in immense detail, roofs still pose a problem. Fully automatic roof generation algorithms might not yield desired results (especially for reconstruction purposes), and complete manual specification can get very tedious due to complex geometric configurations. We present a new method for an abstract building specification, that allows to specify complex buildings from simpler parts with an emphasis on assisting the blending of roofs.", null, "Extraction or drawing blood from veins is known as venipuncture. It is a dedicated and specialized skill that one can only become proficient after doing much observation and more important practice. This paper proposes a different image-based haptic simulation for venipuncture training. The actual photographs are used for a fast implementation of different arms with better visual immersion, and the function-based modeling method is provided for fast collision detection and computation.", "The present special issue is devoted to the state-of-the-art research on virtual worlds. It has extended versions of five articles presented at the International Conference on Cyberworlds 2011, Banff, Alberta, Canada. As stated in the Cyberworlds conference mission statement, cyberworlds are information worlds or communities created on cyberspace by participants collaborating, either intentionally or spontaneously. As information worlds, they accumulate information regardless whether or not anyone is in, and they can be with or without 2D or 3D visual graphics appearance. The examples of such cyberworlds are communities created in different social networking services, 3D shared virtual environments, and multiplayer online games. Cyberworlds are closely related to the real world and have a serious impact on it. Applications exist in such areas as e-business, e-commerce, e-manufacturing, e-learning, e-security\u00a0\u2026", "Venepuncture or venipuncture is drawing blood from vein for testing or blood transfusion purposes. It is one of the most routinely performed invasive procedures that medical students must learn. Haptic interaction in virtual reality environments may provide an advance tool for training these skills. We present a novel and low-cost approach for image-based virtual haptic venepuncture simulation. We use actual photos of patient arms to provide a quick implementation of different virtual arms with better visual immersion. The function-based model of virtual veins helps us to achieve fast collision detection, while the haptic model for the multi-layer soft tissue provides stable and realistic force feedback. The implemented system was validated by medical staff.", "Cyberworlds are information worlds or communities created on cyberspace by collaborating participants either intentionally or spontaneously. As information worlds, they accumulate information regardless whether or not anyone is in, and they can be with or without 2D or 3D visual graphics appearance. The topic of the cyberworlds is very essential in our time of globalization of economy and competition for resources. Cyberspace opens new waste virtual lands and unlimited opportunities for the entrepreneurs, researchers, engineers, students, and in fact to any network users. It is very common nowadays to be connected online to people and various businesses and projects around the world. We even do not think where exactly, on which server, this or that event happens or a person resides. We just say\u2014it is in cyberspace, in Facebook, in Twitter, in Second Life, or, for computer gamers, in the World of Warcraft\u00a0\u2026", null, "Various Partial Differential Equations (PDEs) have been used in computer graphics for approximating surfaces of geometric shapes by finding solutions to PDEs, subject to suitable boundary conditions. The PDE boundary conditions are defined as 3D curves on surfaces of the shapes. We propose how to automatically derive these curves from the surface of the original polygon mesh. Analytic solutions to the PDEs used throughout this work are fully determined by finding a set of coefficients associated with parametric functions according to the particular set of boundary conditions. When large polygon meshes are used, the PDE coefficients require an order of magnitude smaller space compared to the original polygon data and can be interactively rendered with different levels of detail. It allows for an efficient exchange of the PDE shapes in 3D Cyberworlds and their web visualization. In this paper we\u00a0\u2026", "We propose a framework for visual and haptic collaboration in X3D/VRML shared virtual spaces. In this collaborative framework, two pipelines\u2014visual and haptic\u2014complement each other to provide a simple and efficient solution to problem requiring collaboration in shared virtual spaces on the web. We consider shared objects defined as virtual object with their visual and physical properties rendered synchronously on each client computer. We introduce virtual tools which are shared objects associated with interactive and haptic devices. We implemented the proposed ideas as a server-client framework with a dedicated viewer. We discuss two implementation frameworks based on the strong and thin server concepts.", "Creating cyber-instructors or virtual humans in cyberspace capable of maintaining conversation with learners as well as offering different educational services may become an excellent teaching tool implementing personal mentoring in Cyber worlds. In this paper, a framework of the cyber-instructor based on the commonly available software tools is proposed. The components of the framework are replaceable and can be easily tuned to particular educational needs and technical implementations. Several implementations of the cyber-instructor with various looks and feels of the HCI have been studied and implemented such as 3D talking avatar, web chat with multimedia components and chat engine communication.", "Commonly, surface and solid haptic effects are separated for haptic rendering. We propose a method for defining surface and solid haptic effects as well as various force fields in 3D cyber worlds containing mixed geometric models, including polygon meshes, point clouds, image-based billboards and layered textures, voxel models and functions-based models of surfaces and solids. We also propose a way how to identify location of the haptic tool in such haptic scenes as well as consistently and seamlessly determine haptic effects when the haptic tool moves in the scenes with objects having different sizes, locations, and mutual penetrations.", "Cyberworlds are information worlds or communities created on cyberspace by collaborating participants either intentionally or spontaneously. As information worlds, they accumulate information regardless whether or not anyone is in, and they can be with or without 2D or 3D visual graphics appearance. The examples of such cyberworlds are communities created in different social networking services, 3D shared virtual environments, and multiplayer online games. Cyberworlds are closely related to the real world and have a serious impact on it. Cyberworlds have been created and applied in such areas as e-business, e-commerce, e-manufacturing, e-learning, e-medicine, and cultural heritage, etc. Cyberworlds augment and sometimes replace the real life and become a significant component of real economy. The international conferences on Cyberworlds have being organized annually since 2002 with the\u00a0\u2026", "In the modern urban society, human brain is not being sufficiently trained to deal with problems which require strong 3D spatial visualization. As a result, when teaching subjects richly infused with geometry and mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that allows for defining geometry, visual appearance and tangible physical properties of virtual objects by using mathematical formulas. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept with our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted into tangible ones as well as augmented with function-defined visual appearances. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail which we illustrate with an interactive modeling tool used in education in our university.", "In this paper we present a novel algorithm for constructing subdivision connectivity mesh from dense original mesh. Our algorithm begins from a coarse base mesh generated from the original mesh and then the original mesh is divided into a set of patches guided by the base mesh. The patches are subsequently parameterized onto a planar domain by the mean value coordinates method. For each mesh patch, four boundary condition curves are calculated via the parameterization for local PDE patch construction. Considering the boundary curves as shape control boundary curve conditions, a PDE patch can be built and its coefficients are evaluated from the boundary curves. The PDE patch gives an explicit parametric representation of the mesh patch. Finally, all the PDE patches are remeshed via the planar parametric domains and a new resampled mesh with subdivision connectivity can be obtained with an arbitrary resolution", "Automatic segmentation of brain MRI data usually leaves some segmentation errors behind that are to be subsequently removed interactively, using computer graphics tools. This interactive removal is normally performed by operating on individual 2D slices. It is very tedious and still leaves some segmentation errors which are not visible on the slices. We have proposed to perform a novel 3D interactive correction of brain segmentation errors introduced by the fully automatic segmentation algorithms. We have developed the tool which is based on 3D semi-automatic propagation algorithm. The paper describes the implementation principles of the proposed tool and illustrates its application.", "We propose the use of Partial Differential Equations (PDEs) for shape modelling within visual cyberworlds. PDEs, especially those that are elliptic in nature, enable surface modelling to be defined as boundary-value problems. Here we show how the PDE based on the Biharmonic equation subject to suitable boundary conditions can be used for shape modelling within visual cyberworlds. We discuss an analytic solution formulation for the Biharmonic equation which allows us to define a function based geometry whereby the resulting geometry can be visualised efficiently at arbitrary levels of shape resolutions. In particular, we discuss how function based PDE surfaces can be readily integrated within VRML and X3D environments.", "Rendering of images is a very compute intensive task. Thus, it was chosen as one of the prospective commercial market that could leverage on grid/cluster technology. This paper reports on the development and deployment of grid rendering service across a heterogeneous grid environment. It covers the entire process from the submission of the jobs to management and rendering of the model. The prototype was successfully deployed and the results show the feasibility as well as the advantage of using the Grid in rendering animation.", "We have proposed and implemented function-based extensions of X3D and its predecessor VRML which allow for defining time-dependent geometric shapes, their appearance and transformations with analytically defined parametric, implicit and explicit functions. The function-defined shapes can be used together with the standard X3D and VRML shapes. Besides defining shapes by analytical functions, we have developed interactive function-based shape modeling tools. We have also extended these interactive shape modeling tools to work on the grid. Function-defined models can be efficiently rendered at the media grid portal", "2006 International Conference on Cyberworlds (CW 2006) (Table of Contents) Page 1 \nProceedings 2006 International Conference on Cyberworlds CW 2006 28-29 November \n2006 Lausanne, Switzerland Edited by Daniel Thalmann and Alexei Sourin Organized by \nEPFL, VRlab, Lausanne, Switzerland Los Alamitos, California Washington \u2022 Tokyo Page 2 \nCopyright \u00a9 2006 by The Institute of Electrical and Electronics Engineers, Inc. All rights \nreserved. Copyright and Reprint Permissions: Abstracting is permitted with credit to the \nsource. Libraries may photocopy beyond the limits of US copyright law, for private use of \npatrons, those articles in this volume that carry a code at the bottom of the first page, \nprovided that the per-copy fee indicated in the code is paid through the Copyright \nClearance Center, 222 Rosewood Drive, Danvers, MA 01923. Other copying, reprint, or \nrepublication requests should be addressed to: \u2026", "A novel mathematical model, based on transport through porous media, for simulating numerically the spatial and temporal gas-diffusion process within the alveolar region of the lung is discussed. The model depends on a representative physical property of the alveolar region termed the effective diffusivity, a function of the diffusivity, solubility, morphology and interface topography of each alveolar constituent. Unfortunately, the direct determination of the effective diffusivity of the alveolar region is impractical because of the difficulty in describing the internal geometry of each alveolar constituent. However, the transient solution of the macroscopic model can be used in conjunction with the lung-diffusing capacity (measured in a clinical setting) to determine the effective diffusivity of the alveolar region. With the effective diffusivity known, the three-dimensional effects of red blood-cell distribution on the lung-diffusing capacity can be predicted via numerical simulations. The results, obtained for normal (random), uniform, center-cluster, cornercluster, and several chain-like distributions, reveal a strong relationship between the type of red-cell distribution and the lung-diffusing capacity. The model developed has been used in order to study the impact of microscopic particles whose presence in the alveolar region may affect the lung-diffusing capacity. Clusters of particles were distributed according to the Poisson distribution with a different distribution parameter (the average number of particles per cluster).", "Nanyang in Chinese means \u201csouth seas\u201d \u00bea reference to the Southeast Asian region. Back in the 1940s and 1950s, many Chinese from mainland China ventured south to seek their fortunes in new lands. Malaya\u00benow Singapore and Malaysia\u00bewas then known as Nanyang to the Chinese. After World War II, a university was founded in Singapore that would provide tertiary, comprehensive education in Chinese. On March 23, 1953, 523 acres of donated land helped expand the new Nanyang University (known as Nan Tah in Chinese). The modern Nanyang Technological University (NTU, www. ntu. edu. sg) originated from Nan Tah. NTU occupies a large, beautiful campus with hilly terrain in Jurong, located in the western part of Singapore. Many of the campus buildings have sophisticated, futuristic architecture, some designed by Kenzo Tange, the famous Japanese architect.", "In this paper we propose FVRML - a function-based extension of Virtual Reality Modeling Language which allows for time-dependent shape modeling on the Web. Shape's geometry, 3D texture, color and transformations can be defined with analytical functions typed straight in VRML code. These analytical functions can be functions of time. FVRML allows us to greatly extend the abilities of VRML with a very intuitive approach to shape modeling based on using analytical functions. Several functions can be combined into one using Java scripts emulated in FVRML, which allows for even greater flexibility and convenience of shape modeling", "Our previous studies show that the lung diffusing capacity - the parameter characterizing alveolar (gas exchange) performance - depends on the effective diffusivity of the alveolar region, morphology of the domain (boundaries between the domain constituents, red blood cell distribution, etc.), and the initial conditions imposed on the alveolar region.  These initial conditions can significantly vary depending on the flow conditions in the conductive zone of the respiratory duct and the physical properties of the duct itself.  Thus, for instance, the presence of solid micro-particles or other volatile components in the breathing air can affect the alveolar performance.  Therefore, a numerical simulation of the \"two-phase\" air flow is necessary in order to determine the entrance conditions in the alveolar region. In order to perform a numerical simulation of the \"two-phase\" air flow, one has to know the outside breathing conditions  -  for instance, chemical components entering the respiratory duct.  1. Diagnostics of diffusion limited respiratory diseases.  2. To study the impact of the second phase present in the air on the respiratory function. 3. Pneumo-olfactory studies (modeling).  4. To develop a mathematical model and algorithm of the human olfactory function, including smell perception and recognition.  5. Side-products of the project.", "This special issue \u201cCyberworlds and Education\u201d is based on papers presented at the 2003 International Conference onCyberworlds (heldin Singapore, December 3-5, 2004). This conference was organized by the School of Computer Engineering of the Nanyang Technological University. Cyberworlds are information worlds formed on the web either intentionally or spontaneously, with or without visual design. As information worlds, they can be", null, "In this project we have addressed interactive shape modelling problem using the function-based approach, where geometric shapes and their properties are defined with mathematical functions. Interactive modification of the function model with concurrent visualisation of the respective polygonal mesh provided us both the interactivity and any required level of detail resulting in photo-realistic appearance of the shapes. We introduced geometric operators to represent interactive modifications of geometry and appearance of the shapes. Mathematically the same functions are used for defining the shape?s geometry as well as colours, which can be interactively applied to it. Any of the operators involved in creating the shape can be edited, modified or removed at any time thus allowing for a great flexibility of the modelling pipeline and opening prospects for efficient reusing and improving of the models previously created.", "This paper addresses interactive function-based free-form shape modeling where relatively small formulas are used rather than thousands of polygons. Interactive modification of the function model with concurrent double-resolution visualization of the respective polygonal mesh lets us provide both the interactivity and any required level of detail leading to photo-realistic appearance of the resulting shapes. We have proposed a rendering algorithm capable of handling local shape modifications with any desired precision. Also, we proposed a few methods, which let us accelerate the final function evaluation-a common bottleneck for the function-based shape modeling. Finally, we have described applications of the interactive function-based shape modeling to photo-realistic virtual crafting.", "The following topics on cyberworld are discussed: philosophy, ethics, law and security of cyberworlds; distributed simulation and distributed virtual environment; shared and virtual worlds; geometric modeling and visualization for cyberworlds; intelligent agents; datamining and warehousing; cyberbusiness; cyberlearning; cybermuseums; and cyberinformation.", null, null, "This paper addresses interactive function-based shape modelling. Interactive modification of the function model with concurrent visualization of the respective polygonal mesh lets us provide both the interactivity and any required level of detail leading to photo-realistic appearance of the resulting shapes. We have proposed an interactive visualisation method capable of handling local shape modifications with any desired precision. We illustrate the implementation of the proposed visualisation method on the example of the interactive function-based artistic shape modelling.", null, "The term cyberworlds, as we use it, is mostly known to the research community in connection with the International Conferences on Cyberworlds, which have being running annually since the year 2002 (cyberworlds-conferences. org). Cyberworlds are information worlds or communities created in cyberspace by collaborating participants either intentionally or spontaneously. As information worlds, they accumulate information regardless of whether or not anyone is in. Cyberworlds can be based on sharing text, image and video information. They can also be immersive multi-user networked shared virtual worlds. Cyberworlds have been created and applied in such areas as E-business, E-commerce, E-manufacturing, E-learning, and cultural heritage. They augment and sometimes replace real life and become a significant component of a real economy.The 2016 International Conference on Cyberworlds considered\u00a0\u2026", "This project develops a virtual reality database of NTU campus including naturally looking terrain and roads and textured models of buildings.  User is able to walk/fly through the virtual campus.  Different visualisation conditions are able to apply such as different time of the day and fog.", null, null, "Minimally invasive arthroscopic surgery has become the gold standard for orthopaedic surgery procedures on joints. It is done by making small incisions on the skin through which special miniature pencil-like cameras and tools are inserted. However, it demands from surgeons to acquire very different motor-skills while observing the surgical field on a video monitor. Simulation of the arthroscopic procedures in virtual environments is based on the specifics of the arthroscopic camera which is normally not a common forward-looking but a wide-angle oblique-viewing camera. In this paper we write about modeling views seen through the virtual arthroscopic camera controlled by a desktop haptic device in hybrid image-based virtual environment.", "\u76d1\u7763\u5f0f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u81ea\u52a8\u5206\u7c7b\u65b0\u6570\u636e, \u4e14\u5bf9\u6570\u636e\u5206\u6790\u975e\u5e38\u6709\u5e2e\u52a9. \u76d1\u7763\u5f0f\u673a\u5668\u5b66\u4e60\u7684\u8d28\u91cf\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u4f7f\u7528\u7684\u7b97\u6cd5\u7c7b\u578b, \u4e5f\u4f9d\u8d56\u4e8e\u7528\u4e8e\u8bad\u7ec3\u5206\u7c7b\u5668\u7684\u6807\u6ce8\u6570\u636e\u96c6\u7684\u8d28\u91cf. \u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u7684\u6807\u6ce8\u5b9e\u4f8b\u901a\u5e38\u4f9d\u8d56\u4e8e\u4e13\u4e1a\u5206\u6790\u4eba\u5458\u7684\u624b\u5de5\u9009\u62e9\u4e0e\u6ce8\u91ca, \u4e14\u901a\u5e38\u662f\u4e00\u4e2a\u5355\u8c03\u4e0e\u8017\u65f6\u7684\u8fc7\u7a0b. \u6807\u7b7e\u53ef\u4ee5\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e3a\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u6709\u7528\u7684\u8f93\u5165, \u4ee5\u81ea\u52a8\u786e\u5b9a\u6570\u636e\u5b9e\u4f8b\u7684\u5b50\u96c6. \u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6807\u6ce8\u6280\u672f\u662f\u6709\u524d\u666f\u7684\u9009\u62e9, \u5b83\u63d0\u4f9b\u6709\u6548\u7684\u89c6\u89c9\u6982\u89c8, \u5206\u6790\u4eba\u5458\u53ef\u4ece\u4e2d\u540c\u65f6\u67e5\u770b\u6570\u636e\u8bb0\u5f55\u4e0e\u9009\u62e9\u9879\u76ee\u6807\u7b7e. \u5c06\u5206\u6790\u4eba\u5458\u7f6e\u4e8e\u5faa\u73af\u4e2d, \u751f\u6210\u7684\u5206\u7c7b\u5668\u53ef\u5f97\u5230\u66f4\u9ad8\u51c6\u786e\u7387. \u867d\u7136\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6807\u6ce8\u6280\u672f\u7684\u521d\u6b65\u7ed3\u679c\u5728\u67d0\u79cd\u610f\u4e49\u4e0a\u6709\u524d\u666f\u7684, \u8003\u8651\u5230\u7528\u6237\u6807\u6ce8\u53ef\u6539\u5584\u76d1\u7763\u5f0f\u5b66\u4e60, \u4f46\u662f\u8be5\u6280\u672f\u7684\u8bb8\u591a\u65b9\u9762\u4ecd\u6709\u5f85\u63a2\u7d22. \u672c\u6587\u4f7f\u7528 m Vis \u5de5\u5177\u6807\u6ce8\u4e00\u4e2a\u591a\u5143\u6570\u636e\u96c6\u4ee5\u6bd4\u8f83 3 \u79cd\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6280\u672f (\u76f8\u4f3c\u56fe, \u6563\u70b9\u77e9\u9635\u4e0e\u5e73\u884c\u5750\u6807\u56fe) \u4ee5\u53ca\u4e3b\u52a8\u5b66\u4e60. \u7ed3\u679c\u8868\u660e 3 \u79cd\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6807\u6ce8\u6280\u672f\u7684\u5206\u7c7b\u51c6\u786e\u7387\u5747\u9ad8\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5, \u76f8\u5bf9\u4e8e\u6563\u70b9\u77e9\u9635\u4e0e\u5e73\u884c\u5750\u6807\u56fe, \u7528\u6237\u4e3b\u89c2\u4e0a\u66f4\u504f\u7231\u4f7f\u7528\u76f8\u4f3c\u56fe\u6807\u6ce8. \u7528\u6237\u4e5f\u53ef\u4ee5\u6839\u636e\u4f7f\u7528\u7684\u53ef\u89c6\u5316\u6280\u672f\u91c7\u7528\u4e0d\u540c\u6807\u6ce8\u7b56\u7565.", "Created intentionally or spontaneously, cyberworlds are information spaces and communities that use computer technologies to augment the way we interact, participate in business and receive information throughout the world. Cyberworlds have ever-growing impact on our lives and the evolution of the world economy. CW2021 is the 20th conference organized annually since 2002 (http://cyberworldsconferences. org).Out of the 104 submissions which the conference received this year, we eventually selected for publication 29 full, 12 short and 9 poster papers. Full papers were accepted with the average ranking of 4.0\u20135.0 while short and poster papers were considered in the range of 3.0\u20135.0. The reviewing of papers was doubleblind. All the papers were assigned at least 3 reviewers, and discussions among the reviewers were initiated by the program chair in case of conflicting reviews. The selection criteria for\u00a0\u2026", "International Program Committee Toggle navigation IEEE Computer Society Digital Library Jobs \nTech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society \nIEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference \nProceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News \nResource Center Press Room Advertising About Us Cart All Advanced Search Conference \nCover Image Download 1.Home 2.Proceedings 3.cw 2021 International Program Committee \n2021, pp. xv-xvii, DOI Bookmark: 10.1109/CW52790.2021.00007 Keywords Authors Abstract \nProvides a listing of current committee members and society officers. International Program \nCommittee CW 2021 Visual and Interactive Computing Selim Balcisoy, Sabanci University, \nTurkey Amal Dev Parakkat, Indian Institute of Technology Madras, India Rae Earnshaw, \u2026", "Created intentionally or spontaneously, cyberworlds are information spaces and communities that use computer technologies to augment the way we interact, participate in business and receive information throughout the world. Cyberworlds have ever-growing impact on our lives and the evolution of the world economy. CW2020 is the 19th conference organized annually since 2002 (http://cyberworlds-conferences. org).This year we had to organise a conference in very unusual circumstances of COVID-19 pandemia. It affected every country and every potential authors. However, instead of postponing the conference, we decided to hold it online with a hope to organise it in Caen next year.", "Message from the Chairs Toggle navigation IEEE Computer Society Digital Library Jobs \nTech News Resource Center Press Room Advertising About Us IEEE IEEE Computer \nSociety IEEE Computer Society Digital Library My Subscriptions Magazines Journals \nConference Proceedings Institutional Subscriptions IEEE IEEE Computer Society More \nJobs Tech News Resource Center Press Room Advertising About Us Cart All Advanced \nSearch Conference Cover Image Download 1.Home 2.Proceedings 3.cw 2019 Message \nfrom the Chairs 2019, pp. 14-14, DOI Bookmark: 10.1109/CW.2019.00005 Keywords \nAuthors Abstract Presents the introductory welcome message from the conference \nproceedings. May include the conference officers' congratulations to all involved with the \nconference event and publication of the proceedings record. Message from the Chairs \nCyberworlds 2019, in cooperation with the Society for Art \u2026", "In the modern urban society, human brain is not being sufficiently trained to deal with problems which require strong 3D spatial visualization. As a result, when teaching subjects richly infused with geometry and mathematics it is usually a challenge for the learners to follow the instructor and visualize how mathematical concepts reflect in 3D geometry and colors. We have proposed an approach that allows for defining geometry, visual appearance and tangible physical properties of virtual objects by using mathematical formulas. It allows the learners to get immersed within the 3D scene and explore the shapes which are being modeled visually and haptically. We illustrate this concept with our function-based extension of X3D and VRML. Besides definition of objects with mathematical functions straight in the scene file, standard X3D and VRML objects can be converted into tangible ones as well as augmented with\u00a0\u2026", "We seek to further expand the shared collaborative potential of cyberworlds by using haptic force- feedback in shared virtual scenes. We propose how to define density of the objects, together with their geometry and appearance, by using mathematical functions. We illustrate this concept by developing software which allows us to touch and feel surfaces of VRML and X3D objects, convert them to solid objects as well as create any other solid objects using the function-based extension of VRML and X3D. We define geometry, appearance and density of the solid objects by implicit, explicit and parametric functions straight in the VRML/X3D code or in dynamic-link libraries. Since the function-based models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail. We illustrate the proposed with several application examples.", "The following topics are dealt with: feature extraction; electroencephalography; learning (artificial intelligence); medical signal processing; virtual reality; data visualisation; solid modelling; computational geometry; neurophysiology; computer games.", "Created intentionally or spontaneously, cyberworlds are information spaces and communities that use computer technologies to augment the way we interact, participate in business and receive information throughout the world. As information worlds, they accumulate information regardless whether or not anyone is in, and they can be with or without 2D or 3D visual graphics appearance. The examples of such cyberworlds are communities created in different social networking services, 3D shared virtual environments, and multiplayer online games. Cyberworlds are closely related to the real world and have a serious impact on it. Cyberworlds have been created and applied in such areas as e-business, e-commerce, e-manufacturing, e-learning, e-medicine, and cultural heritage, etc. Cyberworlds augment and sometimes replace the real life and become a significant component of real economy. We invited papers\u00a0\u2026", "Conference Organization Toggle navigation IEEE Computer Society Digital Library Jobs \nTech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society \nIEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference \nProceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News \nResource Center Press Room Advertising About Us Cart All Advanced Search Conference \nCover Image Download 1.Home 2.Proceedings 3.cw 2018 Conference Organization 2018, \npp. 15-15, DOI Bookmark: 10.1109/CW.2018.00006 Keywords Authors Abstract Provides a \nlisting of current committee members and society officers. Conference Organization CW 2018 \nGeneral Chair Wolfgang Mueller-Wittig, Fraunhofer Singapore Program Chair Alexei Sourin, \nNanyang Technological University, Singapore General Track Chair Alexei Sourin, Nanyang \u2026", "The conference received papers from 25 countries. After reviewing, we accepted 29 full papers with 43% acceptance rate, 14 short papers also with 43% acceptance rate, and 11 poster papers with 64% acceptance rate. Full papers were accepted with the average ranking of [4.0\u20135.0] while short and poster papers were considered in the range of [3.0\u20135.0]. All papers had at least 3 reviewers, and discussions among the reviewers were initiated by the program chair in case of conflicting reviews. The selection criteria for the papers were based on their technical content, language, quality of presentation, use of the allocated page limit (8 pages for full and 4 pages for short papers), and zero tolerance of plagiarism\u2014the papers shortlisted for acceptance were checked with iThenticate system. For the full papers, an additional requirement was a possibility of extending them with at least 30% of new content for publication\u00a0\u2026", null, "Provides a listing of current committee members and society officers.", "Message from Program Chairs Toggle navigation IEEE Computer Society Digital Library Jobs \nTech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society \nIEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference \nProceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News \nResource Center Press Room Advertising About Us Cart All Advanced Search Conference \nCover Image Download 1.Home 2.Proceedings 3.cw 2017 Message from Program Chairs 2017, \npp. xx, DOI Bookmark: 10.1109/CW.2017.5 Keywords Authors Abstract Presents the introductory \nwelcome message from the conference proceedings. May include the conference officers' \ncongratulations to all involved with the conference event and publication of the proceedings \nrecord. Message from the Program Chairs CW 2017 The term cyberworlds, as we use it, \u2026", "Provides a listing of current committee members and society officers.", null, "This special issue \u201cCyberworlds and Education\u201d is based on papers presented at the 2003 International Conference on Cyberworlds (held in Singapore, December 3-5, 2004). This conference was organized by the School of Computer Engineering of the Nanyang Technological University. Cyberworlds are information worlds formed on the web either intentionally or spontaneously, with or without visual design. As information worlds, they can be virtual or real, or both. In terms of information modeling, the theoretical ground for cyberworlds is far above the level of integrating spatial database models and temporal database models. In conjunction with web-based activities, cyberworlds have been leading the real world in finance, business, commerce, manufacturing and politics. Although a GDP equivalent has been traded on the web in a day for years already, yet little research has been carried out on cyberworlds.", "Computational science, an emerging and increasingly vital field, is now widely recognized as an integral part of scientific and technical investigations, affecting researchers and practitioners in areas ranging from aerospace and automotive research to biochemistry, electronics, geosciences, mathematics, and physics. Computer systems research and the exploitation of applied research naturally complement each other. The increased complexity of many challenges in computational science demands the use of supercomputing, parallel processing, sophisticated algorithms, and advanced system software and architecture. It is therefore invaluable to have input by systems research experts in applied computational science research. Transactions on Computational Science focuses on original high-quality research in the realm of computational science in parallel and distributed environments, also encompassing the\u00a0\u2026", "Provides a listing of current committee members and society officers.", "The conference offers a note of thanks and lists its reviewers.", "Conference proceedings title page.", "Provides a listing of current committee members.", "Provides a listing of current committee members.", "Presents the welcome message from the conference proceedings.", "Provides a listing of current committee members.", "Provides a listing of current committee members.", "CGA 2010 Reviewers Page 1 CGA 2010 Reviewers Sergei Bereg, University of Texas at \nDallas, USA Karoly Bezdek, University of Calgary, Canada JA Rod Blais, University of Calgary, \nCanada Ovidio Daescu, University of Texas at Dallas, USA Tamal Dey, Ohio State University, \nUSA Christopher Gold, Hong Kong Polytechnic University, Hong Kong Osvaldo Gervasi, \nUniversity of Perugia, Italy Marina L. Gavrilova, University of Calgary, Canada Hisamoto \nHiyoshi, Gunma University, Japan Andres Iglesias, University de Cantabria, Spain DT Lee, \nInstitute of Information Science, Academia Sinica Deok-Soo Kim, Hanyang University, Korea \nIvana Kolingerova, University of West Bohemia, Czech Republic Nikolai Medvedev, Novosibirsk \nRussian Academy of Science, Russia Dimitri Plemenos, Universite de Limoges, France Val \nPinciu, Southern Connecticut State University, USA Jon Rokne, University of Calgary, Canada \u2026", "Provides a listing of current committee members and society officers.", "Professor Tosiyasu L. Kunii, who established the CYBERWORLDS conference in 1993, describes Cyberworlds as \u201cinformation worlds formed on the Internet either intentionally or spontaneously, with or without design. As information worlds, they are either virtual or real, and can be both.\u201d The broad variety of Cyberworlds is reflected in the number of represented topics, which range from the ethics of cyberworlds, to virtual reality, security, medicine, up to E-business and games. The subjects of the workshops are more specialized. The HAPTEX workshop\u2019s topic is the modeling of Virtual Reality systems incorporating haptic and tactile feedback, while the NASAGEM workshop focuses on advanced mathematical methods for geometric modeling and shape analysis.", "The conference offers a note of thanks and lists its reviewers.", "U-Media 2011 Technical Program Committee Toggle navigation IEEE Computer Society Digital \nLibrary Jobs Tech News Resource Center Press Room Advertising About Us IEEE IEEE \nComputer Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals \nConference Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs \nTech News Resource Center Press Room Advertising About Us Cart All Advanced Search \nConference Cover Image Download 1.Home 2.Proceedings 3.u-media 2011 U-Media 2011 \nTechnical Program Committee 2011, pp. xvi, DOI Bookmark: 10.1109/U-MEDIA.2011.7 Keywords \nAuthors U-Media 2011 Technical Program Committee Alex Kot Nanyang, Technological \nUniversity, Singapore Alexei Sourin, Nanyang Technological University, Singapore \nCharalampos Z. Patrikakis, National Technical University of Athens, Greece Che-Lun Hung, \u2026", "Provides a listing of current committee members and society officers.", "Program Committee Toggle navigation IEEE Computer Society Digital Library Jobs Tech News \nResource Center Press Room Advertising About Us IEEE IEEE Computer Society IEEE \nComputer Society Digital Library My Subscriptions Magazines Journals Conference Proceedings \nInstitutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource \nCenter Press Room Advertising About Us Cart All Advanced Search Conference Cover Image \nDownload 1.Home 2.Proceedings 3.ism 2010 Program Committee 2010, pp. xvi-xvi, DOI \nBookmark: 10.1109/ISM.2010.9 Keywords Authors Abstract Provides a listing of current \ncommittee members. Program Committee Marios Angelides, Brunel University, United Kingdom \nDorin Bocu, University Transilvania of Brasov, Romania Hao-Teng Chang, China Medical \nUniversity, Taiwan Yao-Chung Chang, National Taitung University, Taiwan Ling-Jyh Chen, \u2026", "Provides a listing of current committee members and society officers.", "International Program Committee Toggle navigation IEEE Computer Society Digital Library Jobs \nTech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society \nIEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference \nProceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News \nResource Center Press Room Advertising About Us Cart All Advanced Search Conference \nCover Image Download 1.Home 2.Proceedings 3.cw 2016 International Program Committee \n2016, pp. xi-xii, DOI Bookmark: 10.1109/CW.2016.7 Keywords Authors Abstract Provides a \nlisting of current committee members and society officers. CW 2016 International Program \nCommittee (alphabetically by last name) Full/Short Papers Track Balcisoy, Selim (Sabanci \nUniversity, Turkey) Brunnett, Guido (Chemnitz University of Technology, Germany) Chen, Yung-\u2026", null, "Knee arthroscopy is a minimally invasive surgery performed on the knee joint. Virtual simulation of arthroscopy is an extremely important training tool that allows the medical students to acquire necessary motor skills before they can approach real patients. We propose how to achieve visually realistic deformation of the virtual meniscus by using linear co-rotational finite element method applied to the coarse mesh enriched with monitor points responsible for fine wrinkles simulation. The simulation is performed in real time and it closely follows the actual meniscus deformation. The generated wrinkles are easily adjustable and do not require large memory.", "Provides a listing of current committee members and society officers.", "Presents the title page of the proceedings.", "This paper describes how the web visualization can be greatly improved using the function-based shape modeling technique. The improvement is possible because the proposed function-defined VRML shape node allows the content creators to describe any complex models with relatively small functions compared to the large-size polygonal mesh based VRML nodes. These functiondefined shapes can be used together with the common VRML shapes. The proposed node has a few implementations capable of visualizing geometric shapes defined with HyperFun language as well as in any proprietary function-defined data format. For fast visualization of the function-defined shapes, we have developed an improved continuation polygonization algorithm specifically designed for VRML visualization. The design, the implementation details, and the application examples of the proposed node are discussed.", "This paper addresses virtual function-based shape modeling where relatively small formulas are used rather than thousands of polygons. Interactive modification of the function model with concurrent visualization of the respective polygonal mesh lets us provide both the interactivity and any required level of detail leading to photo-realistic appearance of the resulting shapes. We have proposed a rendering method capable of handling local shape modifications with any desired precision on a personal computer. Also, we have proposed a few methods, which let us accelerate the final function evaluation\u2014a common bottleneck for the function-based shape modeling. Finally, we describe applications of the interactive function-based shape modeling to photorealistic virtual embossing and carving."]}, "collaboration_network": {"target": ["Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Olga Sourina", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Shahzad Rasool", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Wenting Dai", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Lei Wei", "Dr Valery Adzhiev", "Dr Valery Adzhiev", "Dr Valery Adzhiev", "Dr Valery Adzhiev", "DR. VLADIMIR KULISH", "DR. VLADIMIR KULISH", "DR. VLADIMIR KULISH", "DR. VLADIMIR KULISH", "DR. VLADIMIR KULISH", "DR. VLADIMIR KULISH", "Jian Cui", "Jian Cui", "Jian Cui", "Jian Cui", "Jian Cui", "Jian Cui", "Jian Cui", "Jian Cui", "Tet Sen Howe", "Tet Sen Howe", "Tet Sen Howe", "Xingzi Zhang", "Xingzi Zhang", "Xingzi Zhang", "Xingzi Zhang", "Xingzi Zhang"], "target_id": ["Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "Xetgr0kAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "ERuoo-UAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "y4z7GYUAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "MempzJMAAAAJ", "7gsH4MUAAAAJ", "7gsH4MUAAAAJ", "7gsH4MUAAAAJ", "7gsH4MUAAAAJ", "11sik5YAAAAJ", "11sik5YAAAAJ", "11sik5YAAAAJ", "11sik5YAAAAJ", "11sik5YAAAAJ", "11sik5YAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "YbznojwAAAAJ", "vbJiXO4AAAAJ", "vbJiXO4AAAAJ", "vbJiXO4AAAAJ", "yJACRtIAAAAJ", "yJACRtIAAAAJ", "yJACRtIAAAAJ", "yJACRtIAAAAJ", "yJACRtIAAAAJ"], "type": ["Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside SCSE"], "location": ["Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "National University of Sciences and Technology, Islamabad", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Deakin University", "Bournemouth University", "Bournemouth University", "Bournemouth University", "Bournemouth University", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University"], "year": ["Unknown", "Unknown", 2016, 2015, 1998, 2011, 2006, 2006, 2009, "Unknown", 2010, "Unknown", 2006, "Unknown", 2008, 2016, "Unknown", 2007, 1999, 2000, 2013, 2006, 2005, "Unknown", 2011, "Unknown", 2007, "Unknown", 2016, 2009, 2007, 2018, "Unknown", "Unknown", 2009, 2009, 2000, "Unknown", 2014, "Unknown", 2013, 2016, 2011, 2016, 2015, 2010, 2014, 2013, 2013, 2015, 2014, 2014, 2016, 2011, "Unknown", 2021, 2019, 2020, 2022, 2018, 2020, 2021, 2018, 2021, 2023, 2019, 2011, 2012, 2009, 2009, 2008, 2009, 2010, 2008, 2009, 2010, "Unknown", 2007, 1996, 1996, 1995, 1993, 2006, 2009, 2006, 2006, 2009, 2007, 2016, 2016, 2018, "Unknown", 2016, 2014, 2017, 2020, 2000, 2000, 2007, 2014, 2017, 2016, 2015, 2017], "title": ["U-Media 2011 Technical Program Committee", "Message from the Program and Track Co-Chairs", "Assessing haptic video interaction with neurocognitive tools", "PROCEEDINGS-2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS, CW 2015", "Virtual simulation of orthopaedic surgery training", "Transactions on Computational Science XII", "Human electroencephalograms seen as fractal time series: Mathematical analysis and visualization", "Cyber-learning in cyberworlds", "Novel tools for quantification of brain responses to music stimuli", "International Workshop on Biometric Security Program Committee", "Towards immersive visualization of mathematics", "CW 2016 International Program Committee", "Analysis and visualization of human electroencephalograms seen as fractal time series", "Virtual Orthopedic Surgery on Personal Computer", "Function-based visualization and haptic rendering in shared virtual spaces", "Problems of human-computer interaction in cyberworlds", "Program Co-chairs", "Function-based haptic interaction in cyberworlds", "Orthopaedic Surgery Simulation", "Orthopedic surgery training on personal computer", "Modern information technology: Information visualization, virtual environment, neo-geography, tangible images", "Cybercampuses: design issues and future directions", "Place metaphors in educational cyberworlds: A virtual campus case study", "Visualization and Haptic Rendering of Virtual Objects Defined by Mathematical Functions", "Special issue on Cyberworlds 2010", "Yoshihiro Kanamori, Hiroki Yamada, Masaki Hirose, Jun Mitani, and Yukio Fukui", "Orthopedic surgery training simulation", "Combinatorial 3-Manifolds from Sets of Tetrahedra", "Neurocognitive tools for assessing haptic interaction", "Towards a Definition of Virtual Objects using Partial Differential Equations", "Fractal spectra and visualization of the brain activity evoked by olfactory stimuli", "2018 International Conference on Cyberworlds,{CW} 2018", "Llyr Ap Cenydd, Bangor University Elif Ayiter, Sabanci University Selim Balcisoy, Sabanci University Guido Brunnett, Chemnitz University of Technology", "Greetings from the Program and Track Co-Chairs", "Visual immersive haptic mathematics in shared virtual spaces", "EEG data driven animation and its application", "Virtual orthopedic surgery training", "on Cyberworlds", "Image-driven haptic rendering", "Tangible arthroscopic images", "Image-driven virtual simulation of arthroscopy", "Real-time haptic interaction with RGBD video streams", "Haptic interaction with 2D images", "Assessing haptic video interaction with neurocognitive tools", "PROCEEDINGS-2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS, CW 2015", "Towards tangible images and video in cyberworlds--function-based approach", "Multisensory experience with images", "Image-driven haptic rendering in virtual environments", "Towards hand-eye coordination training in virtual knee arthroscopy", "Haptic Interaction with Video Streams Containing Depth Data", "Modeling arthroscopic camera with haptic devices in image-based virtual environments", "Virtual knee arthroscopy using haptic devices and real surgical images", "Neurocognitive tools for assessing haptic interaction", "Tangible images", "Modeling Arthroscopic Camera with Haptic Devices in Image-based Environments", "Detection and segmentation of image anomalies based on unsupervised defect reparation", "One class based feature learning approach for defect detection using deep autoencoders", "Soldering defect detection in automatic optical inspection", "Self-supervised pairing image clustering for automated quality control", "Unsupervised surface defect detection using deep autoencoders and data augmentation", "Self-supervised pairing image clustering and its application in cyber manufacturing", "Anomaly Detection and Segmentation Based on Defect Repaired Image Resynthesis", "Towards automatic optical inspection of soldering defects", "The Impact of a Number of Samples on Unsupervised Feature Extraction, Based on Deep Learning for Detection Defects in Printed Circuit Boards", "Automated Anomaly Detection for Surface Defects by Dual Generative Networks With Limited Training Data", "Detection defect in printed circuit boards using unsupervised feature extraction upon transfer learning", "Function-based approach to mixed haptic effects rendering", "Function-based single and dual point haptic interaction in cyberworlds", "Function-based haptic collaboration in X3D", "Visual immersive haptic mathematics", "Visual immersive haptic rendering on the web", "Collaboration in 3D Shared Spaces using X3D and VRML", "A framework for visual and haptic collaboration in shared virtual spaces", "Function-based visualization and haptic rendering in shared virtual spaces", "Visual immersive haptic mathematics in shared virtual spaces", "Haptic rendering of mixed haptic effects", "Combinatorial 3-Manifolds from Sets of Tetrahedra", "Function-based haptic interaction in cyberworlds", "Shape Modeling with using Real Functions [in Russian]", "Shape modelling and computer graphics with real functions", "Function representation in geometric modeling: concepts, implementation and applications", "Multidimensional geometric modeling and visualization based on the function representation of objects", "Analysis and visualization of human electroencephalograms seen as fractal time series", "EEG data driven animation and its application", "Human electroencephalograms seen as fractal time series: Mathematical analysis and visualization", "Fundamentals of alveolar gas diffusion: mathematical modeling and visualization", "Novel tools for quantification of brain responses to music stimuli", "Fractal spectra and visualization of the brain activity evoked by olfactory stimuli", "Understanding people's mental models of mid-air interaction for virtual assembly and shape modeling", "Exploration of natural free-hand interaction for shape modeling using leap motion controller", "Mid-air interaction with optical tracking for 3D modeling", "\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6807\u6ce8\u4e0e\u4e3b\u52a8\u5b66\u4e60: \u5b9e\u9a8c\u6bd4\u8f83 (\u82f1\u6587)", "Mid-air gestures for virtual modeling with leap motion", "Feasibility study on free hand geometric modelling using leap motion in VRML/X3D", "Interactive shape modeling using leap motion controller", "Interactive visual labelling versus active learning: an experimental comparison", "Virtual orthopedic surgery training", "Orthopedic surgery training on personal computer", "Orthopedic surgery training simulation", "Multisensory experience with images", "Adding a sense of touch to online shopping: does it really help?", "Haptic interaction with a polygon mesh reconstructed from images", "Image\u2010inspired haptic interaction", "Tangible images of real life scenes"], "link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ipzZ9siozwsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:F9fV5C73w3QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:7T2F9Uy0os0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:IRz6iEL74y4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:-f6ydRqryjwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ClCfbGk0d_YC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:MXK_kJrjxJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:bnK-pcrLprsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:D_sINldO8mEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:_Ybze24A_UAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:_FxGoFyzp5QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:eJXPG6dFmWUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:dQ2og3OwTAUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:4hFrxpcac9AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:5nxA0vEk-isC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:KxtntwgDAa4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:fbc8zXXH2BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:LkGwnXOMwfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:LO7wyVUgiFcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:JV2RwH3_ST0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:gsN89kCJA0AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:0EnyYjriUFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:5qfkUJPXOUwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:UHK10RUVsp4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:dhFuZR0502QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:aqlVkmm33-oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:GtLg2Ama23sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:lmc2jWPfTJgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:QYdC8u9Cj1oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:BwyfMAYsbu0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:5ugPr518TE4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:AXPGKjj_ei8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:P5F9QuxV20EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:ye4kPcJQO24C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:xtRiw3GOFMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:7T2F9Uy0os0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:IRz6iEL74y4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:_Qo2XoVZTnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:XiVPGOgt02cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:fQNAKQ3IYiAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:LPZeul_q3PIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:WqliGbK-hY8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:1qzjygNMrQYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:J-pR_7NvFogC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:UHK10RUVsp4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:O3NaXMp0MMsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:wMgC3FpKEyYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:yMeIxYmEMEAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:8d8msizDQcsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:0izLItjtcgwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:HtS1dXgVpQUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:q3CdL3IzO_QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:9c2xU6iGI7YC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:a3BOlSfXSfwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:foquWX3nUaYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:OP4eGU-M3BUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:buQ7SEKw-1sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:a9-T7VOCCH8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:R3hNpaxXUhUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:nb7KW1ujOQ8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:kNdYIx-mwKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:M3ejUd6NZC8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hC7cP41nSMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:rO6llkc54NcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=200&pagesize=100&citation_for_view=8A7kHCYAAAAJ:5qfkUJPXOUwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:5nxA0vEk-isC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:NaGl4SEjCO4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:L8Ckcad2t8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:ZfRJV9d4-WMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:_FxGoFyzp5QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ZHo1McVdvXMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:aqlVkmm33-oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:VL0QpB8kHFEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:kzcrU_BdoSEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:SpbeaW3--B0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:8xutWZnSdmoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:hkOj_22Ku90C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:olpn-zPbct0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:M7yex6snE4oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:2VqYfGB8ITEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&citation_for_view=8A7kHCYAAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:0EnyYjriUFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:XiVPGOgt02cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:ILKRHgRFtOwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:JQOojiI6XY0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=20&pagesize=80&citation_for_view=8A7kHCYAAAAJ:eMMeJKvmdy0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A7kHCYAAAAJ&cstart=100&pagesize=100&citation_for_view=8A7kHCYAAAAJ:fEOibwPWpKIC"]}, "published_by_year": {"Year": ["1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Publications": [1, 1, 3, 3, 0, 3, 1, 3, 3, 9, 4, 8, 9, 15, 6, 4, 10, 11, 7, 7, 10, 6, 4, 14, 8, 9, 9, 4, 14, 3, 1, 47]}, "citations_by_year": {"Year": ["1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Citations": [0, 1, 9, 16, 23, 28, 37, 38, 60, 84, 54, 84, 93, 98, 108, 130, 151, 145, 144, 105, 139, 142, 100, 94, 120, 124, 122, 115, 169, 192, 145, 11]}, "all_time_h_index": 27, "all_time_i10_index": 61, "all_time_i20_index": 34, "h_index_by_year": {"Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [0, 1, 2, 3, 3, 3, 4, 4, 6, 7, 7, 8, 8, 9, 10, 13, 14, 16, 18, 18, 19, 21, 22, 22, 22, 23, 23, 23, 24, 26, 27]}, "h_index_by_publication_year": {"Publication Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [1, 1, 3, 1, 0, 2, 1, 2, 3, 4, 1, 3, 4, 8, 5, 3, 7, 4, 4, 3, 6, 4, 2, 7, 3, 3, 4, 3, 4, 1, 1]}, "avg_citations_by_publication_year": {"Publication Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "Avg Citations per Publication": [32.0, 1.0, 285.0, 10.333333333333334, 0.0, 9.333333333333334, 2.0, 35.0, 43.666666666666664, 5.777777777777778, 1.5, 10.125, 5.444444444444445, 27.133333333333333, 17.833333333333332, 12.75, 15.3, 4.454545454545454, 8.571428571428571, 3.142857142857143, 6.1, 6.5, 2.25, 8.214285714285714, 6.5, 7.555555555555555, 18.444444444444443, 26.5, 1.6428571428571428, 2.3333333333333335, 2.0]}, "h_index_by_years_from_publication_year": {"Publication Year": [1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2021, 2021, 2021, 2022, 2022, 2023], "Year": [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2018, 2019, 2020, 2021, 2022, 2023, 2019, 2020, 2021, 2022, 2023, 2020, 2021, 2022, 2023, 2021, 2022, 2023, 2022, 2023, 2023], "h-index": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 3, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 1, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 4, 4, 4, 4, 4, 5, 6, 6, 1, 1, 2, 2, 3, 3, 3, 3, 4, 4, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 4, 5, 5, 6, 6, 6, 7, 2, 2, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 2, 3, 4, 4, 1, 2, 3, 3, 0, 2, 4, 1, 1, 1]}}