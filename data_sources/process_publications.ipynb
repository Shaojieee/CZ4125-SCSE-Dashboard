{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "google_scholar_pub_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_pubs_keys = set()\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    for v in pubs.values():\n",
    "        google_scholar_pubs_keys = google_scholar_pubs_keys | v.keys()\n",
    "len(google_scholar_pubs_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application_number',\n",
       " 'authors',\n",
       " 'book',\n",
       " 'conference',\n",
       " 'description',\n",
       " 'external_link',\n",
       " 'institution',\n",
       " 'inventors',\n",
       " 'issue',\n",
       " 'journal',\n",
       " 'pages',\n",
       " 'patent_number',\n",
       " 'patent_office',\n",
       " 'publication_date',\n",
       " 'publisher',\n",
       " 'report_number',\n",
       " 'source',\n",
       " 'total_citations',\n",
       " 'volume'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_pubs_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of published by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknowns = 0\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    years = {}\n",
    "    min_year, max_year = float('inf'), datetime.datetime.now().year\n",
    "    for v in pubs.values():\n",
    "        if 'publication_date' in v:\n",
    "            publication_year = int(v['publication_date'].split('/')[0])\n",
    "            min_year = min(publication_year, min_year)\n",
    "            if publication_year>max_year:\n",
    "                publication_year = 'unknown'\n",
    "                unknowns+=1\n",
    "        else:\n",
    "            publication_year = 'unknown'\n",
    "            unknowns+=1\n",
    "        years[publication_year] = years.get(publication_year, 0) + 1\n",
    "    \n",
    "    # For years in between with no citations\n",
    "    for year in range(min_year, max_year+1):\n",
    "        years[year] = years.get(year, 0)\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['published_by_year'] = years\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'w') as f:\n",
    "        json.dump(profile, f)\n",
    "unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\# of Citations by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_index(citations):\n",
    "    return sum(x >= i + 1 for i, x in enumerate(sorted(list(citations), reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "google_scholar_pub_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' in f]\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    years = {}\n",
    "    min_year, max_year = float('inf'), datetime.datetime.now().year\n",
    "    for v in pubs.values():\n",
    "        if 'publication_date' in v and 'total_citations' in v:\n",
    "            publication_year = int(v['publication_date'].split('/')[0])\n",
    "            min_year = min(publication_year, min_year)\n",
    "            if publication_year>max_year:\n",
    "                years['unknown'] = years.get('unknown', 0) + sum(v['total_citations'].values())\n",
    "\n",
    "            pub_citations = v['total_citations']\n",
    "            for year, cites in pub_citations.items():\n",
    "                if int(year)<=max_year:\n",
    "                    years[int(year)] = years.get(int(year), 0) + pub_citations[year]\n",
    "                else:\n",
    "                    years['unknown'] = years.get('unknown', 0) + pub_citations[year]\n",
    "\n",
    "\n",
    "    # For years in between with no citations\n",
    "    final = {'Year': [], '# of Citations': []}\n",
    "    for year in range(min_year, max_year+1):\n",
    "        final['Year'].append(year)\n",
    "        final['# of Citations'].append(years.get(year, 0))\n",
    "    \n",
    "    \n",
    "    if 'unknown' in years:\n",
    "        final['Year'].append('unkown')\n",
    "        final['# of Citations'].append(years['unknown'])\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['citations_by_year'] = final\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All time h-index & i10-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "google_scholar_pub_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' in f]\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    citations = []\n",
    "    min_year, max_year = float('inf'), datetime.datetime.now().year\n",
    "    for v in pubs.values():\n",
    "        if 'publication_date' in v and 'total_citations' in v:\n",
    "            publication_year = int(v['publication_date'].split('/')[0])\n",
    "            # Appending total citations by year for each publication year\n",
    "            if publication_year>max_year:\n",
    "                continue\n",
    "            pub_citations = v['total_citations']\n",
    "            total_citations = 0\n",
    "            for year in range(publication_year, max_year+1):\n",
    "                total_citations += pub_citations.get(str(year), 0)\n",
    "                \n",
    "            citations.append(total_citations)\n",
    "    \n",
    "    all_time_h_index = h_index(citations)\n",
    "    all_time_i10_index = len([i for i in citations if i>=10])\n",
    "    \n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['all_time_h_index'] = all_time_h_index\n",
    "        profile['all_time_i10_index'] = all_time_i10_index\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h-index by publication year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "google_scholar_pub_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' in f]\n",
    "\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    years = {}\n",
    "    min_year, max_year = float('inf'), datetime.datetime.now().year\n",
    "    for v in pubs.values():\n",
    "        if 'publication_date' in v and 'total_citations' in v:\n",
    "            publication_year = int(v['publication_date'].split('/')[0])\n",
    "            min_year = min(publication_year, min_year)\n",
    "            \n",
    "            if publication_year>max_year:\n",
    "                continue\n",
    "            # Appending total citations by year for each publication year\n",
    "            pub_citations = v['total_citations']\n",
    "            total_citations = 0\n",
    "            for year in range(publication_year, max_year+1):\n",
    "                total_citations += pub_citations.get(str(year), 0)\n",
    "            years[publication_year] = years.get(publication_year, []) + [total_citations]\n",
    "\n",
    "    # Getting h-index for each year\n",
    "    for year in years:\n",
    "        years[year] = h_index(years[year])\n",
    "\n",
    "\n",
    "    # For years in between with no citations,\n",
    "    for year in range(int(min_year), max_year+1):\n",
    "        years[year] = years.get(year, 0)\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['h_index_by_publication_year'] = years\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h-index by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "google_scholar_pub_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' in f]\n",
    "\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    years = {}\n",
    "    min_year, max_year = float('inf'), datetime.datetime.now().year\n",
    "    for v in pubs.values():\n",
    "        if 'publication_date' in v and 'total_citations' in v:\n",
    "            publication_year = int(v['publication_date'].split('/')[0])\n",
    "            min_year = min(publication_year, min_year)\n",
    "            if publication_year>max_year:\n",
    "                continue\n",
    "            pub_citations = v['total_citations']\n",
    "            total_citations = 0\n",
    "            for year in range(publication_year, max_year+1):\n",
    "                total_citations += pub_citations.get(str(year), 0)\n",
    "                years[year] = years.get(year, []) + [total_citations]\n",
    "\n",
    "    # Getting h-index for each year\n",
    "    for year in years:\n",
    "        years[year] = h_index(years[year])\n",
    "\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['h_index_by_year'] = years\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h-index by year since publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "google_scholar_pub_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' in f]\n",
    "\n",
    "\n",
    "for file in google_scholar_pub_files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    years = {}\n",
    "    min_year, max_year = float('inf'), datetime.datetime.now().year\n",
    "    for v in pubs.values():\n",
    "        if 'publication_date' in v and 'total_citations' in v:\n",
    "            publication_year = int(v['publication_date'].split('/')[0])\n",
    "            min_year = min(min_year, publication_year)\n",
    "\n",
    "            if publication_year>max_year:\n",
    "                continue\n",
    "\n",
    "            cur_year = years.get(publication_year, {})\n",
    "            pub_citations = v['total_citations']\n",
    "            total_citations = 0\n",
    "            for year in range(publication_year, max_year+1):\n",
    "                total_citations += pub_citations.get(str(year), 0)\n",
    "                cur_year[year] = cur_year.get(year, []) + [total_citations]\n",
    "            \n",
    "            years[publication_year] = cur_year\n",
    "    \n",
    "    # Getting h-index for each year\n",
    "    final = {'Publication Year': [], 'Year': [], 'h-index': []}\n",
    "    for publication_year in years:\n",
    "        final['Publication Year'].append(publication_year)\n",
    "        final['h-index'].append([None]*(publication_year-min_year)+[h_index(years[publication_year][year]) for year in years[publication_year]])\n",
    "    \n",
    "    final['Year'] = [x for x in range(min_year, max_year+1)]\n",
    "\n",
    "\n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['h_index_by_years_from_publication_year'] = final\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-18]}.json', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scse_dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
