[{"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:Zph67rFs4hoC", "title": "Self-supervised graph transformer on large-scale molecular data", "authors": ["Yu Rong", "Yatao Bian", "Tingyang Xu", "Weiyang Xie", "Ying Wei", "Wenbing Huang", "Junzhou Huang"], "description": "How to obtain informative representations of molecules is a crucial prerequisite in AI-driven drug design and discovery. Recent researches abstract molecules as graphs and employ Graph Neural Networks (GNNs) for molecular representation learning. Nevertheless, two issues impede the usage of GNNs in real scenarios:(1) insufficient labeled molecules for supervised training;(2) poor generalization capability to new-synthesized molecules. To address them both, we propose a novel framework, GROVER, which stands for Graph Representation frOm self-superVised mEssage passing tRansformer. With carefully designed self-supervised tasks in node-, edge-and graph-level, GROVER can learn rich structural and semantic information of molecules from enormous unlabelled molecular data. Rather, to encode such complex information, GROVER integrates Message Passing Networks into the Transformer-style architecture to deliver a class of more expressive encoders of molecules. The flexibility of GROVER allows it to be trained efficiently on large-scale molecular dataset without requiring any supervision, thus being immunized to the two issues mentioned above. We pre-train GROVER with 100 million parameters on 10 million unlabelled molecules---the biggest GNN and the largest training dataset in molecular representation learning. We then leverage the pre-trained GROVER for molecular property prediction followed by task-specific fine-tuning, where we observe a huge improvement (more than 6% on average) from current state-of-the-art methods on 11 challenging benchmarks. The insights we gained are that well-designed self\u00a0\u2026", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [4, 68, 167, 181, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:IjCSPb-OGe4C", "title": "End-to-End Adversarial Memory Network for Cross-domain Sentiment Classification.", "authors": ["Zheng Li", "Yun Zhang", "Ying Wei", "Yuxiang Wu", "Qiang Yang"], "description": "Domain adaptation tasks such as cross-domain sentiment classification have raised much attention in recent years. Due to the domain discrepancy, a sentiment classifier trained in a source domain may not work well when directly applied to a target domain. Traditional methods need to manually select pivots, which behave in the same way for discriminative learning in both domains. Recently, deep learning methods have been proposed to learn a representation shared by domains. However, they lack the interpretability to directly identify the pivots. To address the problem, we introduce an endto-end Adversarial Memory Network (AMN) for cross-domain sentiment classification. Unlike existing methods, the proposed AMN can automatically capture the pivots using an attention mechanism. Our framework consists of two parametershared memory networks with one for sentiment classification and the other for domain classification. The two networks are jointly trained so that the selected features minimize the sentiment classification error and at the same time make the domain classifier indiscriminative between the representations from the source or target domains. Moreover, unlike deep learning methods that cannot tell which words are the pivots, AMN can offer a direct visualization of them. Experiments on the Amazon review dataset demonstrate that AMN can significantly outperform state-of-the-art methods.", "publication_year": 2017, "citations_by_year": {"year": [2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [1, 23, 41, 51, 43, 38, 25, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:hqOjcs7Dif8C", "title": "Hierarchically Structured Meta-learning", "authors": ["Huaxiu Yao", "Ying Wei", "Junzhou Huang", "Zhenhui Li"], "description": "In order to learn quickly with few samples, meta-learning utilizes prior knowledge learned from previous tasks. However, a critical challenge in meta-learning is task uncertainty and heterogeneity, which can not be handled via globally sharing knowledge among tasks. In this paper, based on gradient-based meta-learning, we propose a hierarchically structured meta-learning (HSML) algorithm that explicitly tailors the transferable knowledge to different clusters of tasks. Inspired by the way human beings organize knowledge, we resort to a hierarchical task clustering structure to cluster tasks. As a result, the proposed approach not only addresses the challenge via the knowledge customization to different clusters of tasks, but also preserves knowledge generalization among a cluster of similar tasks. To tackle the changing of task relationship, in addition, we extend the hierarchical structure to a continual learning environment. The experimental results show that our approach can achieve state-of-the-art performance in both toy-regression and few-shot image classification problems.", "publication_year": 2019, "citations_by_year": {"year": [2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [3, 49, 58, 60, 47, 1]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:_FxGoFyzp5QC", "title": "Learning from multiple cities: A meta-learning approach for spatial-temporal prediction", "authors": ["Huaxiu Yao", "Yiding Liu", "Ying Wei", "Xianfeng Tang", "Zhenhui Li"], "description": "Spatial-temporal prediction is a fundamental problem for constructing smart city, which is useful for tasks such as traffic control, taxi dispatching, and environment policy making. Due to data collection mechanism, it is common to see data collection with unbalanced spatial distributions. For example, some cities may release taxi data for multiple years while others only release a few days of data; some regions may have constant water quality data monitored by sensors whereas some regions only have a small collection of water samples. In this paper, we tackle the problem of spatial-temporal prediction for the cities with only a short period of data collection. We aim to utilize the long-period data from other cities via transfer learning. Different from previous studies that transfer knowledge from one single source city to a target city, we are the first to leverage information from multiple cities to increase the stability of\u00a0\u2026", "publication_year": 2019, "citations_by_year": {"year": [2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [4, 37, 42, 61, 48, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:KxtntwgDAa4C", "title": "Hierarchical attention transfer network for cross-domain sentiment classification", "authors": ["Zheng Li", "Ying Wei", "Yu Zhang", "Qiang Yang"], "description": "Cross-domain sentiment classification aims to leverage useful information in a source domain to help do sentiment classification in a target domain that has no or little supervised information. Existing cross-domain sentiment classification methods cannot automatically capture non-pivots, ie, the domain-specific sentiment words, and pivots, ie, the domain-shared sentiment words, simultaneously. In order to solve this problem, we propose a Hierarchical Attention Transfer Network (HATN) for cross-domain sentiment classification. The proposed HATN provides a hierarchical attention transfer mechanism which can transfer attentions for emotions across domains by automatically capturing pivots and non-pivots. Besides, the hierarchy of the attention mechanism mirrors the hierarchical structure of documents, which can help locate the pivots and non-pivots better. The proposed HATN consists of two hierarchical attention networks, with one named P-net aiming to find the pivots and the other named NP-net aligning the non-pivots by using the pivots as a bridge. Specifically, P-net firstly conducts individual attention learning to provide positive and negative pivots for NP-net. Then, P-net and NP-net conduct joint attention learning such that the HATN can simultaneously capture pivots and non-pivots and realize transferring attentions for emotions across domains. Experiments on the Amazon review dataset demonstrate the effectiveness of HATN.", "publication_year": 2018, "citations_by_year": {"year": [2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [4, 29, 43, 47, 34, 30, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:UeHWp8X0CEIC", "title": "Deep Neural Networks for High Dimension, Low Sample Size Data.", "authors": ["Bo Liu", "Ying Wei", "Yu Zhang", "Qiang Yang"], "description": "Deep neural networks (DNN) have achieved breakthroughs in applications with large sample size. However, when facing high dimension, low sample size (HDLSS) data, such as the phenotype prediction problem using genetic data in bioinformatics, DNN suffers from overfitting and high-variance gradients. In this paper, we propose a DNN model tailored for the HDLSS data, named Deep Neural Pursuit (DNP). DNP selects a subset of high dimensional features for the alleviation of overfitting and takes the average over multiple dropouts to calculate gradients with low variance. As the first DNN method applied on the HDLSS data, DNP enjoys the advantages of the high nonlinearity, the robustness to high dimensionality, the capability of learning from a small number of samples, the stability in feature selection, and the end-to-end training. We demonstrate these advantages of DNP via empirical results on both synthetic and real-world biological datasets.", "publication_year": 2017, "citations_by_year": {"year": [2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [1, 12, 31, 28, 37, 31, 34, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:zYLM7Y9cAGgC", "title": "Transfer learning via learning to transfer", "authors": ["Yingi Wei", "Yu Zhang", "Junzhou Huang", "Qiang Yang"], "description": "In transfer learning, what and how to transfer are two primary issues to be addressed, as different transfer learning algorithms applied between a source and a target domain result in different knowledge transferred and thereby the performance improvement in the target domain. Determining the optimal one that maximizes the performance improvement requires either exhaustive exploration or considerable expertise. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer are the best for a future pair of domains by optimizing the reflection function. We also theoretically analyse the algorithmic stability and generalization bound of L2T, and empirically demonstrate its superiority over several state-of-the-art transfer learning algorithms.", "publication_year": 2018, "citations_by_year": {"year": [2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [5, 22, 26, 36, 35, 36, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:5nxA0vEk-isC", "title": "Graph few-shot learning via knowledge transfer", "authors": ["Huaxiu Yao", "Chuxu Zhang", "Ying Wei", "Meng Jiang", "Suhang Wang", "Junzhou Huang", "Nitesh Chawla", "Zhenhui Li"], "description": "Towards the challenging problem of semi-supervised node classification, there have been extensive studies. As a frontier, Graph Neural Networks (GNNs) have aroused great interest recently, which update the representation of each node by aggregating information of its neighbors. However, most GNNs have shallow layers with a limited receptive field and may not achieve satisfactory performance especially when the number of labeled nodes is quite small. To address this challenge, we innovatively propose a graph few-shot learning (GFL) algorithm that incorporates prior knowledge learned from auxiliary graphs to improve classification accuracy on the target graph. Specifically, a transferable metric space characterized by a node embedding and a graph-specific prototype embedding function is shared between auxiliary graphs and the target, facilitating the transfer of structural knowledge. Extensive experiments and ablation studies on four real-world graph datasets demonstrate the effectiveness of our proposed model and the contribution of each component.", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [16, 28, 48, 45, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:mVmsd5A6BfQC", "title": "Adversarial sparse transformer for time series forecasting", "authors": ["Sifan Wu", "Xi Xiao", "Qianggang Ding", "Peilin Zhao", "Ying Wei", "Junzhou Huang"], "description": "Many approaches have been proposed for time series forecasting, in light of its significance in wide applications including business demand prediction. However, the existing methods suffer from two key limitations. Firstly, most point prediction models only predict an exact value of each time step without flexibility, which can hardly capture the stochasticity of data. Even probabilistic prediction using the likelihood estimation suffers these problems in the same way. Besides, most of them use the auto-regressive generative mode, where ground-truth is provided during training and replaced by the network\u2019s own one-step ahead output during inference, causing the error accumulation in inference. Thus they may fail to forecast time series for long time horizon due to the error accumulation. To solve these issues, in this paper, we propose a new time series forecasting model--Adversarial Sparse Transformer (AST), based on Generated Adversarial Networks (GANs). Specifically, AST adopts a Sparse Transformer as the generator to learn a sparse attention map for time series forecasting, and uses a discriminator to improve the prediction performance from sequence level. Extensive experiments on several real-world datasets show the effectiveness and efficiency of our method.", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 16, 40, 68, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:9yKSN-GCB0IC", "title": "Transfer knowledge between cities", "authors": ["Ying Wei", "Yu Zheng", "Qiang Yang"], "description": "The rapid urbanization has motivated extensive research on urban computing. It is critical for urban computing tasks to unlock the power of the diversity of data modalities generated by different sources in urban spaces, such as vehicles and humans. However, we are more likely to encounter the label scarcity problem and the data insufficiency problem when solving an urban computing task in a city where services and infrastructures are not ready or just built. In this paper, we propose a FLexible multimOdal tRAnsfer Learning (FLORAL) method to transfer knowledge from a city where there exist sufficient multimodal data and labels, to this kind of cities to fully alleviate the two problems. FLORAL learns semantically related dictionaries for multiple modalities from a source domain, and simultaneously transfers the dictionaries and labelled instances from the source into a target domain. We evaluate the proposed\u00a0\u2026", "publication_year": 2016, "citations_by_year": {"year": [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [2, 7, 21, 12, 14, 21, 24, 12, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:YsMSGLbcyi4C", "title": "Exploiting coarse-to-fine task transfer for aspect-level sentiment classification", "authors": ["Zheng Li", "Ying Wei", "Yu Zhang", "Xiang Zhang", "Xin Li"], "description": "Aspect-level sentiment classification (ASC) aims at identifying sentiment polarities towards aspects in a sentence, where the aspect can behave as a general Aspect Category (AC) or a specific Aspect Term (AT). However, due to the especially expensive and labor-intensive labeling, existing public corpora in AT-level are all relatively small. Meanwhile, most of the previous methods rely on complicated structures with given scarce data, which largely limits the efficacy of the neural models. In this paper, we exploit a new direction named coarse-to-fine task transfer, which aims to leverage knowledge learned from a rich-resource source domain of the coarse-grained AC task, which is more easily accessible, to improve the learning in a low-resource target domain of the fine-grained AT task. To resolve both the aspect granularity inconsistency and feature mismatch between domains, we propose a Multi-Granularity Alignment Network (MGAN). In MGAN, a novel Coarse2Fine attention guided by an auxiliary task can help the AC task modeling at the same finegrained level with the AT task. To alleviate the feature false alignment, a contrastive feature alignment method is adopted to align aspect-specific feature representations semantically. In addition, a large-scale multi-domain dataset for the AC task is provided. Empirically, extensive experiments demonstrate the effectiveness of the MGAN.", "publication_year": 2019, "citations_by_year": {"year": [2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [14, 28, 32, 25, 18, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:KlAtU1dfN6UC", "title": "Collaborative unsupervised domain adaptation for medical image diagnosis", "authors": ["Yifan Zhang", "Ying Wei", "Qingyao Wu", "Peilin Zhao", "Shuaicheng Niu", "Junzhou Huang", "Mingkui Tan"], "description": "Deep learning based medical image diagnosis has shown great potential in clinical medicine. However, it often suffers two major difficulties in real-world applications: 1) only limited labels are available for model training, due to expensive annotation costs over medical images; 2) labeled images may contain considerable label noise ( e.g.,  mislabeling labels) due to diagnostic difficulties of diseases. To address these, we seek to exploit rich labeled data from relevant domains to help the learning in the target task via Unsupervised Domain Adaptation (UDA). Unlike most UDA methods that rely on clean labeled data or assume samples are equally transferable, we innovatively propose a Collaborative Unsupervised Domain Adaptation algorithm, which conducts transferability-aware adaptation and conquers label noise in a collaborative way. We theoretically analyze the generalization performance of the proposed\u00a0\u2026", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [13, 28, 45, 27, 2]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:MXK_kJrjxJIC", "title": "Transferable end-to-end aspect-based sentiment analysis with selective adversarial learning", "authors": ["Zheng Li", "Xin Li", "Ying Wei", "Lidong Bing", "Yu Zhang", "Qiang Yang"], "description": "Joint extraction of aspects and sentiments can be effectively formulated as a sequence labeling problem. However, such formulation hinders the effectiveness of supervised methods due to the lack of annotated sequence data in many domains. To address this issue, we firstly explore an unsupervised domain adaptation setting for this task. Prior work can only use common syntactic relations between aspect and opinion words to bridge the domain gaps, which highly relies on external linguistic resources. To resolve it, we propose a novel Selective Adversarial Learning (SAL) method to align the inferred correlation vectors that automatically capture their latent relations. The SAL method can dynamically learn an alignment weight for each word such that more important words can possess higher alignment weights to achieve fine-grained (word-level) adaptation. Empirically, extensive experiments demonstrate the effectiveness of the proposed SAL method.", "publication_year": 2019, "citations_by_year": {"year": [2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 20, 24, 25, 24, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:cFHS6HbyZ2cC", "title": "Improving generalization in meta-learning via task augmentation", "authors": ["Huaxiu Yao", "Long-Kai Huang", "Linjun Zhang", "Ying Wei", "Li Tian", "James Zou", "Junzhou Huang"], "description": "Meta-learning has proven to be a powerful paradigm for transferring the knowledge from previous tasks to facilitate the learning of a novel task. Current dominant algorithms train a well-generalized model initialization which is adapted to each task via the support set. The crux lies in optimizing the generalization capability of the initialization, which is measured by the performance of the adapted model on the query set of each task. Unfortunately, this generalization measure, evidenced by empirical results, pushes the initialization to overfit the meta-training tasks, which significantly impairs the generalization and adaptation to novel tasks. To address this issue, we actively augment a meta-training task with \u201cmore data\u201d when evaluating the generalization. Concretely, we propose two task augmentation methods, including MetaMix and Channel Shuffle. MetaMix linearly combines features and labels of samples from both the support and query sets. For each class of samples, Channel Shuffle randomly replaces a subset of their channels with the corresponding ones from a different class. Theoretical studies show how task augmentation improves the generalization of meta-learning. Moreover, both MetaMix and Channel Shuffle outperform state-of-the-art results by a large margin across many datasets and are compatible with existing meta-learning algorithms.", "publication_year": 2021, "citations_by_year": {"year": [2021, 2022, 2023, "unknown"], "num_citations": [9, 30, 24, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:kNdYIx-mwKoC", "title": "From whole slide imaging to microscopy: Deep microscopy adaptation network for histopathology cancer image classification", "authors": ["Yifan Zhang", "Hanbo Chen", "Ying Wei", "Peilin Zhao", "Jiezhang Cao", "Xinjuan Fan", "Xiaoying Lou", "Hailing Liu", "Jinlong Hou", "Xiao Han", "Jianhua Yao", "Qingyao Wu", "Mingkui Tan", "Junzhou Huang"], "description": "Deep learning (DL) has achieved remarkable performance on digital pathology image classification with whole slide images (WSIs). Unfortunately, high acquisition costs of WSIs hinder the applications in practical scenarios, and most pathologists still use microscopy images (MSIs) in their workflows. However, it is especially challenging to train DL models on MSIs, given limited image qualities and high annotation costs. Alternatively, directly applying a WSI-trained DL model on MSIs usually performs poorly due to huge gaps between WSIs and MSIs. To address these issues, we propose to exploit deep unsupervised domain adaptation to adapt DL models trained on the labeled WSI domain to the unlabeled MSI domain. Specifically, we propose a novel Deep Microscopy Adaptation Network (DMAN). By reducing domain discrepancies via adversarial learning and entropy minimization, and alleviating class\u00a0\u2026", "publication_year": 2019, "citations_by_year": {"year": [2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [4, 11, 22, 14, 13, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:4TOpqqG69KYC", "title": "COVID-DA: Deep domain adaptation from typical pneumonia to COVID-19", "authors": ["Yifan Zhang", "Shuaicheng Niu", "Zhen Qiu", "Ying Wei", "Peilin Zhao", "Jianhua Yao", "Junzhou Huang", "Qingyao Wu", "Mingkui Tan"], "description": "The outbreak of novel coronavirus disease 2019 (COVID-19) has already infected millions of people and is still rapidly spreading all over the globe. Most COVID-19 patients suffer from lung infection, so one important diagnostic method is to screen chest radiography images, e.g., X-Ray or CT images. However, such examinations are time-consuming and labor-intensive, leading to limited diagnostic efficiency. To solve this issue, AI-based technologies, such as deep learning, have been used recently as effective computer-aided means to improve diagnostic efficiency. However, one practical and critical difficulty is the limited availability of annotated COVID-19 data, due to the prohibitive annotation costs and urgent work of doctors to fight against the pandemic. This makes the learning of deep diagnosis models very challenging. To address this, motivated by that typical pneumonia has similar characteristics with COVID-19 and many pneumonia datasets are publicly available, we propose to conduct domain knowledge adaptation from typical pneumonia to COVID-19. There are two main challenges: 1) the discrepancy of data distributions between domains; 2) the task difference between the diagnosis of typical pneumonia and COVID-19. To address them, we propose a new deep domain adaptation method for COVID-19 diagnosis, namely COVID-DA. Specifically, we alleviate the domain discrepancy via feature adversarial adaptation and handle the task difference issue via a novel classifier separation scheme. In this way, COVID-DA is able to diagnose COVID-19 effectively with only a small number of COVID-19 annotations. Extensive\u00a0\u2026", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [8, 23, 21, 10, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:yD5IFk8b50cC", "title": "Learning to multitask", "authors": ["Yu Zhang", "Ying Wei", "Qiang Yang"], "description": "Multitask learning has shown promising performance in many applications and many multitask models have been proposed. In order to identify an effective multitask model for a given multitask problem, we propose a learning framework called Learning to MultiTask (L2MT). To achieve the goal, L2MT exploits historical multitask experience which is organized as a training set consisting of several tuples, each of which contains a multitask problem with multiple tasks, a multitask model, and the relative test error. Based on such training set, L2MT first uses a proposed layerwise graph neural network to learn task embeddings for all the tasks in a multitask problem and then learns an estimation function to estimate the relative test error based on task embeddings and the representation of the multitask model based on a unified formulation. Given a new multitask problem, the estimation function is used to identify a suitable multitask model. Experiments on benchmark datasets show the effectiveness of the proposed L2MT framework.", "publication_year": 2018, "citations_by_year": {"year": [2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 11, 18, 17, 8, 8, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:2osOgNQ5qMEC", "title": "Transferable Contextual Bandit for Cross-Domain Recommendation", "authors": ["Bo Liu", "Ying Wei", "Yu Zhang", "Zhixian Yan", "Qiang Yang"], "description": "Traditional recommendation systems (RecSys) suffer from two problems: the exploitation-exploration dilemma and the cold-start problem. One solution to solving the exploitation-exploration dilemma is the contextual bandit policy, which adaptively exploits and explores user interests. As a result, the contextual bandit policy achieves increased rewards in the long run. The contextual bandit policy, however, may cause the system to explore more than needed in the cold-start situations, which can lead to worse short-term rewards. Cross-domain RecSys methods adopt transfer learning to leverage prior knowledge in a source RecSys domain to jump start the cold-start target RecSys. To solve the two problems together, in this paper, we propose the first applicable transferable contextual bandit (TCB) policy for the cross-domain recommendation. TCB not only benefits the exploitation but also accelerates the exploration in the target RecSys. TCB's exploration, in turn, helps to learn how to transfer between different domains. TCB is a general algorithm for both homogeneous and heterogeneous domains. We perform both theoretical regret analysis and empirical experiments. The empirical results show that TCB outperforms the state-of-the-art algorithms over time.", "publication_year": 2018, "citations_by_year": {"year": [2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [1, 5, 12, 13, 7, 6, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:qjMakFHDy7sC", "title": "Scalable heterogeneous translated hashing", "authors": ["Ying Wei", "Yangqiu Song", "Yi Zhen", "Bo Liu", "Qiang Yang"], "description": "Hashing has enjoyed a great success in large-scale similarity search. Recently, researchers have studied the multi-modal hashing to meet the need of similarity search across different types of media. However, most of the existing methods are applied to search across multi-views among which explicit bridge information is provided. Given a heterogeneous media search task, we observe that abundant multi-view data can be found on the Web which can serve as an auxiliary bridge. In this paper, we propose a Heterogeneous Translated Hashing (HTH) method with such auxiliary bridge incorporated not only to improve current multi-view search but also to enable similarity search across heterogeneous media which have no direct correspondence. HTH simultaneously learns hash functions embedding heterogeneous media into different Hamming spaces, and translators aligning these spaces. Unlike almost all\u00a0\u2026", "publication_year": 2014, "citations_by_year": {"year": [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 2, 6, 7, 9, 5, 0, 1, 5, 1, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&citation_for_view=5UpFdKsAAAAJ:9ZlFYXVOiuMC", "title": "Learn to cross-lingual transfer with meta graph learning across heterogeneous languages", "authors": ["Zheng Li", "Mukul Kumar", "William Headden", "Bing Yin", "Ying Wei", "Yu Zhang", "Qiang Yang"], "description": "Recent emergence of multilingual pre-training language model (mPLM) has enabled breakthroughs on various downstream cross-lingual transfer (CLT) tasks. However, mPLM-based methods usually involve two problems:(1) simply fine-tuning may not adapt general-purpose multilingual representations to be task-aware on low-resource languages;(2) ignore how cross-lingual adaptation happens for downstream tasks. To address the issues, we propose a meta graph learning (MGL) method. Unlike prior works that transfer from scratch, MGL can learn to cross-lingual transfer by extracting meta-knowledge from historical CLT experiences (tasks), making mPLM insensitive to low-resource languages. Besides, for each CLT task, MGL formulates its transfer process as information propagation over a dynamic graph, where the geometric structure can automatically capture intrinsic language relationships to explicitly guide cross-lingual transfer. Empirically, extensive experiments on both public and real-world datasets demonstrate the effectiveness of the MGL method.", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 11, 7, 12, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:4OULZ7Gr8RgC", "title": "Frustratingly easy transferability estimation", "authors": ["Long-Kai Huang", "Junzhou Huang", "Yu Rong", "Qiang Yang", "Ying Wei"], "description": "Transferability estimation has been an essential tool in selecting a pre-trained model and the layers in it for transfer learning, to transfer, so as to maximize the performance on a target task and prevent negative transfer. Existing estimation algorithms either require intensive training on target tasks or have difficulties in evaluating the transferability between layers. To this end, we propose a simple, efficient, and effective transferability measure named TransRate. Through a single pass over examples of a target task, TransRate measures the transferability as the mutual information between features of target examples extracted by a pre-trained model and their labels. We overcome the challenge of efficient mutual information estimation by resorting to coding rate that serves as an effective alternative to entropy. From the perspective of feature representation, the resulting TransRate evaluates both completeness (whether features contain sufficient information of a target task) and compactness (whether features of each class are compact enough for good generalization) of pre-trained features. Theoretically, we have analyzed the close connection of TransRate to the performance after transfer learning. Despite its extraordinary simplicity in 10 lines of codes, TransRate performs remarkably well in extensive evaluations on 35 pre-trained models and 16 downstream tasks.", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [11, 13, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:D03iK_w7-QYC", "title": "Meta-learning with an adaptive task scheduler", "authors": ["Huaxiu Yao", "Yu Wang", "Ying Wei", "Peilin Zhao", "Mehrdad Mahdavi", "Defu Lian", "Chelsea Finn"], "description": "To benefit the learning of a new task, meta-learning has been proposed to transfer a well-generalized meta-model learned from various meta-training tasks. Existing meta-learning algorithms randomly sample meta-training tasks with a uniform probability, under the assumption that tasks are of equal importance. However, it is likely that tasks are detrimental with noise or imbalanced given a limited number of meta-training tasks. To prevent the meta-model from being corrupted by such detrimental tasks or dominated by tasks in the majority, in this paper, we propose an adaptive task scheduler (ATS) for the meta-training process. In ATS, for the first time, we design a neural scheduler to decide which meta-training tasks to use next by predicting the probability being sampled for each candidate task, and train the scheduler to optimize the generalization capacity of the meta-model to unseen tasks. We identify two meta-model-related factors as the input of the neural scheduler, which characterize the difficulty of a candidate task to the meta-model. Theoretically, we show that a scheduler taking the two factors into account improves the meta-training loss and also the optimization landscape. Under the setting of meta-learning with noise and limited budgets, ATS improves the performance on both miniImageNet and a real-world drug discovery benchmark by up to 13% and 18%, respectively, compared to state-of-the-art task schedulers.", "publication_year": 2021, "citations_by_year": {"year": [2021, 2022, 2023, "unknown"], "num_citations": [0, 13, 12, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:ufrVoPGSRksC", "title": "Learning to Transfer", "authors": ["Ying Wei", "Yu Zhang", "Qiang Yang"], "description": "Transfer learning borrows knowledge from a source domain to facilitate learning in a target domain. Two primary issues to be addressed in transfer learning are what and how to transfer. For a pair of domains, adopting different transfer learning algorithms results in different knowledge transferred between them. To discover the optimal transfer learning algorithm that maximally improves the learning performance in the target domain, researchers have to exhaustively explore all existing transfer learning algorithms, which is computationally intractable. As a trade-off, a sub-optimal algorithm is selected, which requires considerable expertise in an ad-hoc way. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we first learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer for a newly arrived pair of domains by optimizing the reflection function. Extensive experiments demonstrate the L2T's superiority over several state-of-the-art transfer learning algorithms and its effectiveness on discovering more transferable knowledge.", "publication_year": 2017, "citations_by_year": {"year": [2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 2, 6, 8, 4, 1, 0, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:u-x6o8ySG0sC", "title": "Instilling social to physical: Co-regularized heterogeneous transfer learning", "authors": ["Ying Wei", "Yin Zhu", "Cane Leung", "Yangqiu Song", "Qiang Yang"], "description": "Ubiquitous computing tasks, such as human activity recognition (HAR), are enabling a wide spectrum of applications, ranging from healthcare to environment monitoring. The success of a ubiquitous computing task relies on sufficient physical sensor data with groundtruth labels, which are always scarce due to the expensive annotating process. Meanwhile, social media platforms provide a lot of social or semantic context information. People share what they are doing and where they are frequently in the messages they post. This rich set of socially shared activities motivates us to transfer knowledge from social media to address the sparsity issue of labelled physical sensor data. In order to transfer the knowledge of social and semantic context, we propose a Co-Regularized Heterogeneous Transfer Learning (CoHTL) model, which builds a common semantic space derived from two heterogeneous domains. Our proposed method outperforms state-of-the-art methods on two ubiquitous computing tasks, namely human activity recognition and region function discovery.", "publication_year": 2016, "citations_by_year": {"year": [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [1, 1, 5, 5, 5, 1, 2, 1, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:dfsIfKJdRG4C", "title": "Meta-learning hyperparameter performance prediction with neural processes", "authors": ["Ying Wei", "Peilin Zhao", "Junzhou Huang"], "description": "The surrogate that predicts the performance of hyperparameters has been a key component for sequential model-based hyperparameter optimization. In practical applications, a trial of a hyper-parameter configuration may be so costly that a surrogate is expected to return an optimal configuration with as few trials as possible. Observing that human experts draw on their expertise in a machine learning model by trying configurations that once performed well on other datasets, we are inspired to build a trial-efficient surrogate by transferring the meta-knowledge learned from historical trials on other datasets. We propose an end-to-end surrogate named as Transfer NeuralProcesses (TNP) that learns a comprehensive set of meta-knowledge, including the parameters of historical surrogates, historical trials, and initial configurations for other datasets. Experiments on extensive OpenML datasets and three computer vision datasets demonstrate that the proposed algorithm achieves state-of-the-art performance in at least one order of magnitude less trials.", "publication_year": 2021, "citations_by_year": {"year": [2021, 2022, 2023, "unknown"], "num_citations": [2, 7, 6, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:aqlVkmm33-oC", "title": "Translider: Transfer ensemble learning from exploitation to exploration", "authors": ["Kuo Zhong", "Ying Wei", "Chun Yuan", "Haoli Bai", "Junzhou Huang"], "description": "In transfer learning, what and where to transfer has been widely studied. Nevertheless, the learned transfer strategies are at high risk of over-fitting, especially when only a few annotated instances are available in the target domain. In this paper, we introduce the concept of transfer ensemble learning, a new direction to tackle the over-fitting of transfer strategies. Intuitively, models with different transfer strategies offer various perspectives on what and where to transfer. Therefore a core problem is to search these diversely transferred models for ensemble so as to achieve better generalization. Towards this end, we propose the Transferability Slider (TranSlider) for transfer ensemble learning. By decreasing the transferability, we obtain a spectrum of base models ranging from pure exploitation of the source model to unconstrained exploration for the target domain. Furthermore, the manner of decreasing transferability\u00a0\u2026", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 5, 6, 2, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:UxriW0iASnsC", "title": "Blind image quality assessment via vision-language correspondence: A multitask learning perspective", "authors": ["Weixia Zhang", "Guangtao Zhai", "Ying Wei", "Xiaokang Yang", "Kede Ma"], "description": "We aim at advancing blind image quality assessment (BIQA), which predicts the human perception of image quality without any reference information. We develop a general and automated multitask learning scheme for BIQA to exploit auxiliary knowledge from other tasks, in a way that the model parameter sharing and the loss weighting are determined automatically. Specifically, we first describe all candidate label combinations (from multiple tasks) using a textual template, and compute the joint probability from the cosine similarities of the visual-textual embeddings. Predictions of each task can be inferred from the joint distribution, and optimized by carefully designed loss functions. Through comprehensive experiments on learning three tasks-BIQA, scene classification, and distortion type identification, we verify that the proposed BIQA method 1) benefits from the scene classification and distortion type identification tasks and outperforms the state-of-the-art on multiple IQA datasets, 2) is more robust in the group maximum differentiation competition, and 3) realigns the quality annotations from different IQA datasets more effectively. The source code is available at https://github. com/zwx8981/LIQE.", "publication_year": 2023, "citations_by_year": {"year": [2023, "unknown"], "num_citations": [11, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:pyW8ca7W8N0C", "title": "Functionally regionalized knowledge transfer for low-resource drug discovery", "authors": ["Huaxiu Yao", "Ying Wei", "Long-Kai Huang", "Ding Xue", "Junzhou Huang", "Zhenhui Jessie Li"], "description": "More recently, there has been a surge of interest in employing machine learning approaches to expedite the drug discovery process where virtual screening for hit discovery and ADMET prediction for lead optimization play essential roles. One of the main obstacles to the wide success of machine learning approaches in these two tasks is that the number of compounds labeled with activities or ADMET properties is too small to build an effective predictive model. This paper seeks to remedy the problem by transferring the knowledge from previous assays, namely in-vivo experiments, by different laboratories and against various target proteins. To accommodate these wildly different assays and capture the similarity between assays, we propose a functional rationalized meta-learning algorithm FRML for such knowledge transfer. FRML constructs the predictive model with layers of neural sub-networks or so-called functional regions. Building on this, FRML shares an initialization for the weights of the predictive model across all assays, while customizes it to each assay with a region localization network choosing the pertinent regions. The compositionality of the model improves the capacity of generalization to various and even out-of-distribution tasks. Empirical results on both virtual screening and ADMET prediction validate the superiority of FRML over state-of-the-art baselines powered with interpretability in assay relationship.", "publication_year": 2021, "citations_by_year": {"year": [2021, 2022, 2023, "unknown"], "num_citations": [0, 5, 5, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:a0OBvERweLwC", "title": "Metats: Meta teacher-student network for multilingual sequence labeling with minimal supervision", "authors": ["Zheng Li", "Danqing Zhang", "Tianyu Cao", "Ying Wei", "Yiwei Song", "Bing Yin"], "description": "Sequence labeling aims to predict a fine-grained sequence of labels for the text. However, such formulation hinders the effectiveness of supervised methods due to the lack of token-level annotated data. This is exacerbated when we meet a diverse range of languages. In this work, we explore multilingual sequence labeling with minimal supervision using a single unified model for multiple languages. Specifically, we propose a Meta Teacher-Student (MetaTS) Network, a novel meta learning method to alleviate data scarcity by leveraging large multilingual unlabeled data. Prior teacher-student frameworks of self-training rely on rigid teaching strategies, which may hardly produce high-quality pseudo-labels for consecutive and interdependent tokens. On the contrary, MetaTS allows the teacher to dynamically adapt its pseudo-annotation strategies by the student\u2019s feedback on the generated pseudo-labeled data of each language and thus mitigate error propagation from noisy pseudo-labels. Extensive experiments on both public and real-world multilingual sequence labeling datasets empirically demonstrate the effectiveness of MetaTS.", "publication_year": 2021, "citations_by_year": {"year": [2021, 2022, 2023, "unknown"], "num_citations": [1, 3, 5, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:3fE2CSJIrl8C", "title": "Fisher deep domain adaptation", "authors": ["Yinghua Zhang", "Yu Zhang", "Ying Wei", "Kun Bai", "Yangqiu Song", "Qiang Yang"], "description": "Deep domain adaptation models learn a neural network in an unlabeled target domain by leveraging the knowledge from a labeled source domain. This can be achieved by learning a domain-invariant feature space. Though the learned representations are separable in the source domain, they usually have a large variance and samples with different class labels tend to overlap in the target domain, which yields suboptimal adaptation performance. To fill the gap, a Fisher loss is proposed to learn discriminative representations which are within-class compact and between-class separable. Experimental results on two benchmark datasets show that the Fisher loss is a general and effective loss for deep domain adaptation. Noticeable improvements are brought when it is used together with widely adopted transfer criteria, including MMD, CORAL and domain adversarial loss. For example, an absolute improvement of\u00a0\u2026", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [1, 3, 4, 2, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:u5HHmVD_uO8C", "title": "Heterogeneous translated hashing: A scalable solution towards multi-modal similarity search", "authors": ["Ying Wei", "Yangqiu Song", "Yi Zhen", "Bo Liu", "Qiang Yang"], "description": "Multi-modal similarity search has attracted considerable attention to meet the need of information retrieval across different types of media. To enable efficient multi-modal similarity search in large-scale databases recently, researchers start to study multi-modal hashing. Most of the existing methods are applied to search across multi-views among which explicit correspondence is provided. Given a multi-modal similarity search task, we observe that abundant multi-view data can be found on the Web which can serve as an auxiliary bridge. In this paper, we propose a Heterogeneous Translated Hashing (HTH) method with such auxiliary bridge incorporated not only to improve current multi-view search but also to enable similarity search across heterogeneous media which have no direct correspondence. HTH provides more flexible and discriminative ability by embedding heterogeneous media into different Hamming\u00a0\u2026", "publication_year": 2016, "citations_by_year": {"year": [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 3, 0, 0, 1, 3, 1, 1, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:abG-DnoFyZgC", "title": "Artificial intelligence for retrosynthesis prediction", "authors": ["Yinjie Jiang", "Yemin Yu", "Ming Kong", "Yu Mei", "Luotian Yuan", "Zhengxing Huang", "Kun Kuang", "Zhihua Wang", "Huaxiu Yao", "James Zou", "Connor W Coley", "Ying Wei"], "description": "In recent years, there has been a dramatic rise in interest in retrosynthesis prediction with artificial intelligence (AI) techniques. Unlike conventional retrosynthesis prediction performed by chemists and by rule-based expert systems, AI-driven retrosynthesis prediction automatically learns chemistry knowledge from off-the-shelf experimental datasets to predict reactions and retrosynthesis routes. This provides an opportunity to address many conventional challenges, including heavy reliance on extensive expertise, the sub-optimality of routes, and prohibitive computational cost. This review describes the current landscape of AI-driven retrosynthesis prediction. We first discuss formal definitions of the retrosynthesis problem and review the outstanding research challenges therein. We then review the related AI techniques and recent progress that enable retrosynthesis prediction. Moreover, we propose a novel\u00a0\u2026", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [0, 7, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:_xSYboBqXhAC", "title": "Self-supervised text erasing with controllable image synthesis", "authors": ["Gangwei Jiang", "Shiyao Wang", "Tiezheng Ge", "Yuning Jiang", "Ying Wei", "Defu Lian"], "description": "Recent efforts on text erasing have shown promising results. However, existing methods require rich yet costly label annotations to obtain robust models, which limits their use for practical applications. To this end, we study an unsupervised scenario by proposing a novel Self-supervised Text Erasing (STE) framework that jointly learns to synthesize training images with erasure ground-truth and accurately erase texts in the real world. We first design a style-aware image synthesis function to generate synthetic images with diverse styled texts based on two synthetic mechanisms. To bridge the text style gap between the synthetic and real-world data, a policy network is constructed to control the synthetic mechanisms by picking style parameters with the guidance of two specifically designed rewards. The synthetic training images with ground-truth are then fed to train a coarse-to-fine erasing network. To produce better\u00a0\u2026", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [0, 6, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:b0M2c_1WBrUC", "title": "The Role of Deconfounding in Meta-learning", "authors": ["Yinjie Jiang", "Zhengyu Chen", "Kun Kuang", "Luotian Yuan", "Xinhai Ye", "Zhihua Wang", "Fei Wu", "Ying Wei"], "description": "Meta-learning has emerged as a potent paradigm for quick learning of few-shot tasks, by leveraging the meta-knowledge learned from meta-training tasks. Well-generalized meta-knowledge that facilitates fast adaptation in each task is preferred; however, recent evidence suggests the undesirable memorization effect where the meta-knowledge simply memorizing all meta-training tasks discourages task-specific adaptation and poorly generalizes. There have been several solutions to mitigating the effect, including both regularizer-based and augmentation-based methods, while a systematic understanding of these methods in a single framework is still lacking. In this paper, we offer a novel causal perspective of meta-learning. Through the lens of causality, we conclude the universal label space as a confounder to be the causing factor of memorization and frame the two lines of prevailing methods as different deconfounder approaches. Remarkably, derived from the causal inference principle of front-door adjustment, we propose two frustratingly easy but effective deconfounder algorithms, ie, sampling multiple versions of the meta-knowledge via Dropout and grouping the meta-knowledge into multiple bins. The proposed causal perspective not only brings in the two deconfounder algorithms that surpass previous works in four benchmark datasets towards combating memorization, but also opens a promising direction for meta-learning.", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [1, 4, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:P5F9QuxV20EC", "title": "Adversarial task up-sampling for meta-learning", "authors": ["Yichen Wu", "Long-Kai Huang", "Ying Wei"], "description": "The success of meta-learning on existing benchmarks is predicated on the assumption that the distribution of meta-training tasks covers meta-testing tasks. Frequent violation of the assumption in applications with either insufficient tasks or a very narrow meta-training task distribution leads to memorization or learner overfitting. Recent solutions have pursued augmentation of meta-training tasks, while it is still an open question to generate both correct and sufficiently imaginary tasks. In this paper, we seek an approach that up-samples meta-training tasks from the task representation via a task up-sampling network. Besides, the resulting approach named Adversarial Task Up-sampling (ATU) suffices to generate tasks that can maximally contribute to the latest meta-learner by maximizing an adversarial loss. On few-shot sine regression and image classification datasets, we empirically validate the marked improvement of ATU over state-of-the-art task augmentation strategies in the meta-testing performance and also the quality of up-sampled tasks.", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [1, 3, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:CHSYGLWDkRkC", "title": "Grasp: Navigating retrosynthetic planning with goal-driven policy", "authors": ["Yemin Yu", "Ying Wei", "Kun Kuang", "Zhengxing Huang", "Huaxiu Yao", "Fei Wu"], "description": "Retrosynthetic planning occupies a crucial position in synthetic chemistry and, accordingly, drug discovery, which aims to find synthetic pathways of a target molecule through a sequential decision-making process on a set of feasible reactions. While the majority of recent works focus on the prediction of feasible reactions at each step, there have been limited attempts toward improving the sequential decision-making policy. Existing strategies rely on either the expensive and high-variance value estimation by online rollout, or a settled value estimation neural network pre-trained with simulated pathways of limited diversity and no negative feedback. Besides, how to return multiple candidate pathways that are not only diverse but also desirable for chemists (eg, affordable building block materials) remains an open challenge. To this end, we propose a Goal-dRiven Actor-critic retroSynthetic Planning (GRASP) framework, where we identify the policy that performs goal-driven retrosynthesis navigation toward a user-demand objective. Our experiments on the benchmark Pistachio dataset and a chemists-designed dataset demonstrate that the framework outperforms state-of-the-art approaches by up to 32.2% on search efficiency and 5.6% on quality. Remarkably, our user studies show that GRASP successfully plans pathways that accomplish the goal prescribed with a designated goal (building block materials).", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [1, 3, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:NhqRSupF_l8C", "title": "Disentangling task relations for few-shot text classification via self-supervised hierarchical task clustering", "authors": ["Juan Zha", "Zheng Li", "Ying Wei", "Yu Zhang"], "description": "Few-Shot Text Classification (FSTC) imitates humans to learn a new text classifier efficiently with only few examples, by leveraging prior knowledge from historical tasks. However, most prior works assume that all the tasks are sampled from a single data source, which cannot adapt to real-world scenarios where tasks are heterogeneous and lie in different distributions. As such, existing methods may suffer from their globally knowledge-shared mechanisms to handle the task heterogeneity. On the other hand, inherent task relation are not explicitly captured, making task knowledge unorganized and hard to transfer to new tasks. Thus, we explore a new FSTC setting where tasks can come from a diverse range of data sources. To address the task heterogeneity, we propose a self-supervised hierarchical task clustering (SS-HTC) method. SS-HTC not only customizes cluster-specific knowledge by dynamically organizing heterogeneous tasks into different clusters in hierarchical levels but also disentangles underlying relations between tasks to improve the interpretability. Extensive experiments on five public FSTC benchmark datasets demonstrate the effectiveness of SS-HTC.", "publication_year": 2022, "citations_by_year": {"year": [2022, 2023, "unknown"], "num_citations": [1, 3, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:0EnyYjriUFMC", "title": "Transferable Neural Processes for Hyperparameter Optimization", "authors": ["Ying Wei", "Peilin Zhao", "Huaxiu Yao", "Junzhou Huang"], "description": "Automated machine learning aims to automate the whole process of machine learning, including model configuration. In this paper, we focus on automated hyperparameter optimization (HPO) based on sequential model-based optimization (SMBO). Though conventional SMBO algorithms work well when abundant HPO trials are available, they are far from satisfactory in practical applications where a trial on a huge dataset may be so costly that an optimal hyperparameter configuration is expected to return in as few trials as possible. Observing that human experts draw on their expertise in a machine learning model by trying configurations that once performed well on other datasets, we are inspired to speed up HPO by transferring knowledge from historical HPO trials on other datasets. We propose an end-to-end and efficient HPO algorithm named as Transfer Neural Processes (TNP), which achieves transfer learning by incorporating trials on other datasets, initializing the model with well-generalized parameters, and learning an initial set of hyperparameters to evaluate. Experiments on extensive OpenML datasets and three computer vision datasets show that the proposed model can achieve state-of-the-art performance in at least one order of magnitude less trials.", "publication_year": 2019, "citations_by_year": {"year": [2019, 2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 1, 3, 0, 0, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:qxL8FJ1GzNcC", "title": "Don\u2019t Overlook the Support Set: Towards Improving Generalization in Meta-learning", "authors": ["Huaxiu Yao", "Longkai Huang", "Ying Wei", "Li Tian", "Junzhou Huang", "Zhenhui Li"], "description": "Meta-learning has proven to be a powerful paradigm for transferring the knowledge from previously tasks to facilitate the learning of a novel task. Current dominant algorithms train a well-generalized model initialization which is adapted to each task via the support set. The crux, obviously, lies in optimizing the generalization capability of the initialization, which is measured by the performance of the adapted model on the query set of each task. Unfortunately, this generalization measure, evidenced by empirical results, pushes the initialization to overfit the query but fail the support set, which significantly impairs the generalization and adaptation to novel tasks. To address this issue, we include the support set when evaluating the generalization to produce a new meta-training strategy, MetaMix, that linearly combines the input and hidden representations of samples from both the support and query sets. Theoretical studies on classification and regression tasks show how MetaMix can improve the generalization of meta-learning. More remarkably, MetaMix obtains state-of-the-art results by a large margin across many datasets and remains compatible with existing meta-learning algorithms.", "publication_year": 2020, "citations_by_year": {"year": [2020, 2021, 2022, 2023, "unknown"], "num_citations": [0, 2, 1, 0, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:dshw04ExmUIC", "title": "Learning chemical rules of retrosynthesis with pre-training", "authors": ["Yinjie Jiang", "WEI Ying", "Fei Wu", "Zhengxing Huang", "Kun Kuang", "Zhihua Wang"], "description": "Retrosynthesis aided by artificial intelligence has been a very active and bourgeoning area of research, for its critical role in drug discovery as well as material science. Three categories of solutions, ie, template-based, template-free, and semi-template methods, constitute mainstream solutions to this problem. In this paper, we focus on template-free methods which are known to be less bothered by the template generalization issue and the atom mapping challenge. Among several remaining problems regarding template-free methods, failing to conform to chemical rules is pronounced. To address the issue, we seek for a pre-training solution to empower the pre-trained model with chemical rules encoded. Concretely, we enforce the atom conservation rule via a molecule reconstruction pre-training task, and the reaction rule that dictates reaction centers via a reaction type guided contrastive pre-training task. In our empirical evaluation, the proposed pre-training solution substantially improves the single-step retrosynthesis accuracies in three downstream datasets.", "publication_year": 2023, "citations_by_year": {"year": [2023, "unknown"], "num_citations": [2, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:uWQEDVKXjbEC", "title": "Learning to Substitute Spans towards Improving Compositional Generalization", "authors": ["Zhaoyi Li", "Ying Wei", "Defu Lian"], "description": "Despite the rising prevalence of neural sequence models, recent empirical evidences suggest their deficiency in compositional generalization. One of the current de-facto solutions to this problem is compositional data augmentation, aiming to incur additional compositional inductive bias. Nonetheless, the improvement offered by existing handcrafted augmentation strategies is limited when successful systematic generalization of neural sequence models requires multi-grained compositional bias (i.e., not limited to either lexical or structural biases only) or differentiation of training sequences in an imbalanced difficulty distribution. To address the two challenges, we first propose a novel compositional augmentation strategy dubbed \\textbf{Span} \\textbf{Sub}stitution (SpanSub) that enables multi-grained composition of substantial substructures in the whole training set. Over and above that, we introduce the \\textbf{L}earning \\textbf{to} \\textbf{S}ubstitute \\textbf{S}pan (L2S2) framework which empowers the learning of span substitution probabilities in SpanSub in an end-to-end manner by maximizing the loss of neural sequence models, so as to outweigh those challenging compositions with elusive concepts and novel surroundings. Our empirical results on three standard compositional generalization benchmarks, including SCAN, COGS and GeoQuery (with an improvement of at most 66.5\\%, 10.3\\%, 1.2\\%, respectively), demonstrate the superiority of SpanSub, %the learning framework L2S2 and their combination.", "publication_year": 2023, "citations_by_year": {"year": [2023, "unknown"], "num_citations": [1, 0]}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:OU6Ihb5iCvQC", "title": "DeepAlgPro: an interpretable deep neural network model for predicting allergenic proteins", "authors": ["Chun He", "Xinhai Ye", "Yi Yang", "Liya Hu", "Yuxuan Si", "Xianxin Zhao", "Longfei Chen", "Qi Fang", "Ying Wei", "Fei Wu", "Gongyin Ye"], "description": "Allergies have become an emerging public health problem worldwide. The most effective way to prevent allergies is to find the causative allergen at the source and avoid re-exposure. However, most of the current computational methods used to identify allergens were based on homology or conventional machine learning methods, which were inefficient and still had room to be improved for the detection of allergens with low homology. In addition, few methods based on deep learning were reported, although deep learning has been successfully applied to several tasks in protein sequence analysis. In the present work, a deep neural network-based model, called DeepAlgPro, was proposed to identify allergens. We showed its great accuracy and applicability to large-scale forecasts by comparing it to other available tools. Additionally, we used ablation experiments to demonstrate the critical importance of the\u00a0\u2026", "publication_year": 2023, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:p2g8aNsByqUC", "title": "Concept-wise Fine-tuning Matters in Preventing Negative Transfer", "authors": ["Yunqiao Yang", "Long-Kai Huang", "Ying Wei"], "description": "A multitude of prevalent pre-trained models mark a major milestone in the development of artificial intelligence, while fine-tuning has been a common practice that enables pre-trained models to figure prominently in a wide array of target datasets. Our empirical results reveal that off-the-shelf fine-tuning techniques are far from adequate to mitigate negative transfer caused by two types of underperforming features in a pre-trained model, including rare features and spuriously correlated features. Rooted in structural causal models of predictions after fine-tuning, we propose a Concept-wise fine-tuning (Concept-Tuning) approach which refines feature representations in the level of patches with each patch encoding a concept. Concept-Tuning minimizes the negative impacts of rare features and spuriously correlated features by (1) maximizing the mutual information between examples in the same category with regard to a slice of rare features (a patch) and (2) applying front-door adjustment via attention neural networks in channels and feature slices (patches). The proposed Concept-Tuning consistently and significantly (by up to 4.76%) improves prior state-of-the-art fine-tuning methods on eleven datasets, diverse pre-training strategies (supervised and self-supervised ones), various network architectures, and sample sizes in a target dataset.", "publication_year": 2023, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:nb7KW1ujOQ8C", "title": "A Multi-objective Perspective towards Improving Meta-Generalization", "authors": ["Weiduo Liao", "Ying Wei", "Qirui Sun", "Qingfu Zhang", "Hisao Ishibuchi"], "description": "To improve meta-generalization, i.e., accommodating out-of-domain meta-testing tasks beyond meta-training ones, is of significance to extending the success of meta-learning beyond standard benchmarks. Previous heterogeneous meta-learning algorithms have shown that tailoring the global meta-knowledge by the learned clusters during meta-training promotes better meta-generalization to novel meta-testing tasks. Inspired by this, we propose a novel multi-objective perspective to sharpen the compositionality of the meta-trained clusters, through which we have empirically validated that the meta-generalization further improves. Grounded on the hierarchically structured meta-learning framework, we formulate a hypervolume loss to evaluate the degree of conflict between multiple cluster-conditioned parameters in the two-dimensional loss space over two randomly chosen tasks belonging to two clusters and two mixed tasks imitating out-of-domain tasks. Experimental results on more than 16 few-shot image classification datasets show not only improved performance on out-of-domain meta-testing datasets but also better clusters in visualization.", "publication_year": 2022, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:EUQCXRtRnyEC", "title": "Learning to generate imaginary tasks for improving generalization in meta-learning", "authors": ["Yichen Wu", "Long-Kai Huang", "Ying Wei"], "description": "The success of meta-learning on existing benchmarks is predicated on the assumption that the distribution of meta-training tasks covers meta-testing tasks. Frequent violation of the assumption in applications with either insufficient tasks or a very narrow meta-training task distribution leads to memorization or learner overfitting. Recent solutions have pursued augmentation of meta-training tasks, while it is still an open question to generate both correct and sufficiently imaginary tasks. In this paper, we seek an approach that up-samples meta-training tasks from the task representation via a task up-sampling network. Besides, the resulting approach named Adversarial Task Up-sampling (ATU) suffices to generate tasks that can maximally contribute to the latest meta-learner by maximizing an adversarial loss. On few-shot sine regression and image classification datasets, we empirically validate the marked improvement of ATU over state-of-the-art task augmentation strategies in the meta-testing performance and also the quality of up-sampled tasks.", "publication_year": 2022, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:1sJd4Hv_s6UC", "title": "Improving Task-Specific Generalization in Few-Shot Learning via Adaptive Vicinal Risk Minimization", "authors": ["Long-Kai Huang", "Ying Wei"], "description": "Recent years have witnessed the rapid development of meta-learning in improving the meta generalization over tasks in few-shot learning. However, the task-specific level generalization is overlooked in most algorithms. For a novel few-shot learning task where the empirical distribution likely deviates from the true distribution, the model obtained via minimizing the empirical loss can hardly generalize to unseen data. A viable solution to improving the generalization comes as a more accurate approximation of the true distribution; that is, admitting a Gaussian-like vicinal distribution for each of the limited training samples. Thereupon we derive the resulting vicinal loss function over vicinities of all training samples and minimize it instead of the conventional empirical loss over training samples only, favorably free from the exhaustive sampling of all vicinal samples. It remains challenging to obtain the statistical parameters of the vicinal distribution for each sample. To tackle this challenge, we further propose to estimate the statistical parameters as the weighted mean and variance of a set of unlabeled data it passed by a random walk starting from training samples. To verify the performance of the proposed method, we conduct experiments on four standard few-shot learning benchmarks and consolidate the superiority of the proposed method over state-of-the-art few-shot learning baselines.", "publication_year": 2022, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:bFI3QPDXJZMC", "title": "Minimizing Memorization in Meta-learning: A Causal Perspective", "authors": ["Yinjie Jiang", "Zhengyu Chen", "Luotian Yuan", "Ying Wei", "Kun Kuang", "Xinhai Ye", "Zhihua Wang", "Fei Wu"], "description": "Meta-learning has emerged as a potent paradigm for quick learning of few-shot tasks, by leveraging the meta-knowledge learned from meta-training tasks. Well-generalized meta-knowledge that facilitates fast adaptation in each task is preferred; however, recent evidence suggests the undesirable memorization effect where the meta-knowledge simply memorizing all meta-training tasks discourages task-specific adaptation and poorly generalizes. There have been several solutions to mitigating the effect, including both regularizer-based and augmentation-based methods, while a systematic understanding of these methods in a single framework is still lacking. In this paper, we offer a novel causal perspective of meta-learning. Through the lens of causality, we conclude the universal label space as a confounder to be the causing factor of memorization and frame the two lines of prevailing methods as different deconfounder approaches. Remarkably, derived from the causal inference principle of front-door adjustment, we propose two frustratingly easy but effective deconfounder algorithms, i.e., sampling multiple versions of the meta-knowledge via Dropout and grouping the meta-knowledge into multiple bins. The proposed causal perspective not only brings in the two deconfounder algorithms that surpass previous works in four benchmark datasets towards combating memorization, but also opens a promising direction for meta-learning.", "publication_year": 2021, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:Tyk-4Ss8FVUC", "title": "Learning to multitask", "authors": ["Yu Zhang", "Ying Wei", "Qiang Yang"], "description": null, "publication_year": 2018, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:WF5omc3nYNoC", "title": "Heterogeneous Transfer Learning", "authors": ["Ying Wei"], "description": "Artificial Intelligence has been enjoying an unprecedented boom recently. The huge success, however, still heavily depends on massive labeled data. Transfer learning, leveraging knowledge from a source domain to improve predictive models in a target domain which does not have sufficient labeled data, has been more and more popular. In transfer learning, a source and a target domain have a discrepancy in any of the feature space, distribution, label space, and predictive models, which traditional machine learning algorithms cannot handle. The majority of existing transfer learning algorithms focus on homogeneous transfer learning where the feature space, the label space as well as the predictive model are shared. However, homogeneous transfer learning algorithms lose their power if the shared feature space is insufficient to build satisfactory predictive models, or if a source domain in the same feature and label space cannot be found. In this case, heterogeneous transfer learning (HTL) is desired. Provided with a source domain in a completely different feature space or label space, heterogeneous transfer learning algorithms transfer knowledge in different perspectives, just as we human beings with a multi-sensory system are capable of transferring lip reading knowledge to improve speech understanding if one is whispering in a very low voice. The key to transfer learning is to building either instance-based or feature-based mappings between a source and a target domain. In this thesis, we focus on developing scalable and principled methodologies to build feature mappings under different heterogeneity: 1) how to build semantic\u00a0\u2026", "publication_year": 2017, "citations_by_year": {"year": [], "num_citations": []}}, {"link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5UpFdKsAAAAJ&cstart=20&pagesize=80&citation_for_view=5UpFdKsAAAAJ:8k81kl-MbHgC", "title": "Hierarchically Structured Meta-learning: Supplementary Material", "authors": ["Huaxiu Yao", "Ying Wei", "Junzhou Huang", "Zhenhui Li"], "description": "Proof of Theorem 1 Assuming a task Ti is sampled from E, its training and testing samples are iid drawn from distribution Si, ie, Dtr Ti\u223c Si and Dte Ti\u223c Si. According to Theorem 3 in (Kuzborskij & Lampert, 2017), if L is convex, the base learner f\u03b8Ti SGD is \u03f5 (Si, \u03b80)-on-average-stable with \u03f5 (Si, \u03b80)= O", "publication_year": null, "citations_by_year": {"year": [], "num_citations": []}}]