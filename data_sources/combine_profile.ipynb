{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "from utils import get_h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './raw_data'\n",
    "files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'dr_ntu' in f]\n",
    "names = []\n",
    "\n",
    "dr_ntu_keys = set()\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        profile = json.load(f)\n",
    "    \n",
    "    dr_ntu_keys = dr_ntu_keys | profile.keys()\n",
    "\n",
    "len(dr_ntu_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'articles',\n",
       " 'bibliometrics',\n",
       " 'biography',\n",
       " 'book_chapters',\n",
       " 'books',\n",
       " 'conferences',\n",
       " 'designation',\n",
       " 'dr_ntu',\n",
       " 'email',\n",
       " 'full_name',\n",
       " 'github',\n",
       " 'google_scholar',\n",
       " 'grants',\n",
       " 'image_path',\n",
       " 'interests',\n",
       " 'keywords',\n",
       " 'name_card',\n",
       " 'orcid',\n",
       " 'other_websites',\n",
       " 'scopus',\n",
       " 'web_of_science'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_ntu_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_ntu_information = [\n",
    "    'full_name', 'email', 'designation',\n",
    "    'biography',\n",
    "    'dr_ntu', 'google_scholar', 'orcid', 'other_websites', 'image_path'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './raw_data'\n",
    "files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' not in f]\n",
    "names = []\n",
    "\n",
    "google_scholar_keys = set()\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        profile = json.load(f)\n",
    "    \n",
    "    google_scholar_keys = google_scholar_keys | profile.keys()\n",
    "\n",
    "len(google_scholar_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation_statistics',\n",
       " 'co_authors',\n",
       " 'google_scholar',\n",
       " 'interests',\n",
       " 'publications'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "dr_ntu_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'dr_ntu' in f]\n",
    "\n",
    "output_dir = './processed_data'\n",
    "\n",
    "for dr_ntu in dr_ntu_files:\n",
    "    profile = {}\n",
    "    with open(dr_ntu, 'r') as f:\n",
    "        dr_ntu = json.load(f)\n",
    "    name = dr_ntu['full_name']\n",
    "\n",
    "    profile.update({k:v for k, v in dr_ntu.items() if k in dr_ntu_information})\n",
    "\n",
    "    # Updating google scholar url from google scholar profile search\n",
    "    google_scholar_profile_search_file = os.path.join(dir, f'google_scholar_profile_search_{name.lower().replace(\" \", \"_\")}.json')\n",
    "\n",
    "    if os.path.exists(google_scholar_profile_search_file):\n",
    "        with open(google_scholar_profile_search_file, 'r') as f:\n",
    "            google_scholar = json.load(f)\n",
    "        \n",
    "        profile.update(google_scholar)\n",
    "\n",
    "    with open(os.path.join(output_dir, f'{name.lower().replace(\" \", \"_\")}.json'), 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './processed_data'\n",
    "processed = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "gpt_dir = './education_gpt_output_data'\n",
    "gpt_prefix = 'education_v1'\n",
    "for file in processed:\n",
    "    with open(file, 'r') as f:\n",
    "        profile = json.load(f)\n",
    "    \n",
    "    name = file[17:-5]\n",
    "\n",
    "    with open(f'{gpt_dir}/{gpt_prefix}_{name}.json', 'r') as f:\n",
    "        education = json.load(f)\n",
    "\n",
    "    del education['name']\n",
    "    profile.update(education)\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './research_interest'\n",
    "files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "\n",
    "    file_name = file.split('/')[2]\n",
    "    \n",
    "    publications = {'Publication Year': [], 'Title': [], 'Link': [], 'Topic': [], '# of Citations': [], 'Description': []}\n",
    "    for pub in pubs:\n",
    "        publications['Publication Year'].append(str(pub['publication_year']) if pub['publication_year'] is not None else 'Unknown')\n",
    "        publications['Title'].append(pub['title'])\n",
    "        publications['Description'].append(pub['description'])\n",
    "        publications['Link'].append(pub['link'])\n",
    "        publications['Topic'].append(pub['final_topic'] if pub['final_topic'] is not None else 'Others')\n",
    "        publications['# of Citations'].append(sum(pub['citations_by_year']['num_citations']))\n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['publications'] = publications\n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'w') as f:\n",
    "        json.dump(profile, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './processed_data'\n",
    "files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "ntu_url = {}\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        profile = json.load(f)\n",
    "    name = profile['full_name']\n",
    "    if profile['google_scholar'] is not None:\n",
    "        id = profile['google_scholar'].split('user=')[1].split('&')[0]\n",
    "        ntu_url[id] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './raw_data'\n",
    "co_author_dir ='./co_authors_raw_data'\n",
    "google_scholar_files = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and 'google_scholar' in f and 'publication' not in f and 'profile' not in f]\n",
    "\n",
    "google_scholar_org_id = {'3012140508424117850': 'Nanyang Technological University'}\n",
    "for file in google_scholar_files:\n",
    "    with open(file, 'r') as f:\n",
    "        profile = json.load(f)\n",
    "\n",
    "    \n",
    "    titles = set([x['title'].lower() for x in profile['publications']])\n",
    "    co_authors = profile['co_authors']\n",
    "    \n",
    "    network = {'target':[], 'target_id':[], 'type':[], 'location':[], 'year': [], 'title': [], 'link': []}\n",
    "    for co_author in co_authors:\n",
    "\n",
    "        co_author_id = co_author['link'].split('user=')[1].split('&')[0]\n",
    "        # Checking if within ntu\n",
    "        co_author_name = ntu_url[co_author_id] if co_author_id in ntu_url else co_author['name']\n",
    "        co_author_file = f\"{co_author_dir}/google_scholar_{co_author['name'].lower().replace(' ', '_').replace('/','_')}.json\"\n",
    "\n",
    "        with open(co_author_file, 'r') as f:\n",
    "            co_author_profile = json.load(f)\n",
    "        if co_author_profile['publications'] is not None: \n",
    "            co_author_titles = set([x['title'].lower()for x in co_author_profile['publications']])\n",
    "        else:\n",
    "            co_author_titles = set()\n",
    "\n",
    "        same_titles = len(titles.intersection(co_author_titles))\n",
    "        if same_titles==0:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        # Get location and type\n",
    "        affiliates = co_author_profile['affiliates']\n",
    "        if affiliates is None or len(affiliates)==0:\n",
    "            type='Unknown'\n",
    "        else:\n",
    "            type = 'Outside NTU'\n",
    "        \n",
    "        if co_author_id in ntu_url:\n",
    "            type = 'NTU'\n",
    "            location = 'Nanyang Technological University'\n",
    "        elif len(affiliates)>0:\n",
    "            org = affiliates[0]['link'].split('org=')[1].split('&')[0]\n",
    "            google_scholar_org_id[org] = google_scholar_org_id.get(org, affiliates[0]['name'])\n",
    "            type = 'Outside NTU'\n",
    "            location = google_scholar_org_id[org]\n",
    "            for aff in affiliates:\n",
    "                if 'org=3012140508424117850' in aff['link'].lower():\n",
    "                    type = 'Outside SCSE'\n",
    "                    location = google_scholar_org_id['3012140508424117850']\n",
    "        else:\n",
    "            type = 'Unknown'\n",
    "            location = 'Unknown'\n",
    "\n",
    "\n",
    "        min_year = float('inf')\n",
    "        # Get year of publication\n",
    "        for title in titles.intersection(co_author_titles):\n",
    "            for pub in profile['publications']:\n",
    "                if pub['title'].lower()==title:\n",
    "                    if not math.isnan(pub['year']):\n",
    "                        publication_year = int(pub['year'])\n",
    "                        min_year = min(min_year, publication_year)\n",
    "                    else:\n",
    "                        publication_year = 'unknown'\n",
    "                        \n",
    "                    network['target'].append(co_author_name); network['target_id'].append(co_author_id)\n",
    "                    network['type'].append(type); network['location'].append(location)\n",
    "                    network['year'].append(publication_year)\n",
    "                    network['title'].append(pub['title']); network['link'].append(pub['title_link'])\n",
    "                    break\n",
    "        \n",
    "\n",
    "\n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-5]}.json', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['collaboration_network'] = network\n",
    "    \n",
    "    with open(f'./processed_data/{file.split(\"/\")[-1][15:-5]}.json', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of publications by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './processed_publications'\n",
    "pubs_file = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "cur_year = datetime.datetime.now().year\n",
    "for file in pubs_file:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    file_name = file.split('/')[2]\n",
    "\n",
    "    publication_by_year = {}\n",
    "    min_year = float('inf')\n",
    "    for details in pubs:\n",
    "        if details['publication_year'] is not None:\n",
    "            publication_year = details['publication_year']\n",
    "            min_year = min(publication_year, min_year)\n",
    "        else:\n",
    "            publication_year = 'unknown'\n",
    "        publication_by_year[publication_year] = publication_by_year.get(publication_year, 0) + 1\n",
    "    \n",
    "    # For years in between with no citations\n",
    "    final = {'Year': [], '# of Publications': []}\n",
    "    for year in range(min_year, cur_year+1):\n",
    "        final['Year'].append(str(year))\n",
    "        final['# of Publications'].append(publication_by_year.get(year, 0))\n",
    "    \n",
    "    if 'unknown' in publication_by_year:\n",
    "        final['Year'].append('unknown')\n",
    "        final['# of Publications'].append(publication_by_year['unknown'])\n",
    "        \n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['published_by_year'] = final\n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'w') as f:\n",
    "        json.dump(profile, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of citations by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './processed_publications'\n",
    "pubs_file = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "cur_year = datetime.datetime.now().year\n",
    "for file in pubs_file:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "\n",
    "    file_name = file.split('/')[2]\n",
    "    \n",
    "    total_citations_by_year = {}\n",
    "    min_year = float('inf')\n",
    "    for details in pubs:\n",
    "        \n",
    "        citations_by_year = details['citations_by_year']\n",
    "        for i in range(len(citations_by_year['year'])):\n",
    "            year = citations_by_year['year'][i]\n",
    "            citations = citations_by_year['num_citations'][i]\n",
    "            # Has unknown\n",
    "            total_citations_by_year[str(year)] = total_citations_by_year.get(str(year), 0) + citations\n",
    "            if year!='unknown':\n",
    "                min_year = min(min_year, year)\n",
    "\n",
    "    # For years in between with no citations\n",
    "    final = {'Year': [], '# of Citations': []}\n",
    "    for year in range(min_year, cur_year+1):\n",
    "        final['Year'].append(str(year))\n",
    "        final['# of Citations'].append(total_citations_by_year.get(str(year), 0))\n",
    "    \n",
    "    if 'unknown' in total_citations_by_year:\n",
    "        final['Year'].append('unknown')\n",
    "        final['# of Citations'].append(total_citations_by_year['unknown'])\n",
    "\n",
    "    with open(f'./processed_data/{file_name}', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['citations_by_year'] = final\n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h-index & i10-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './processed_publications'\n",
    "pubs_file = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "cur_year = datetime.datetime.now().year\n",
    "\n",
    "for file in pubs_file:\n",
    "    with open(file, 'r') as f:\n",
    "        pubs = json.load(f)\n",
    "    file_name = file.split('/')[2]\n",
    "    \n",
    "    citations_list = []\n",
    "    by_year = {}\n",
    "    by_publication_year = {}\n",
    "    by_year_since_published = {}\n",
    "\n",
    "\n",
    "    min_year = float('inf')\n",
    "    for details in pubs:\n",
    "        if details['publication_year'] is not None:\n",
    "            citations_by_year = details['citations_by_year']\n",
    "            publication_year = details['publication_year']\n",
    "            min_year = min(publication_year, min_year)\n",
    "\n",
    "            cur_year_since_published = by_year_since_published.get(publication_year, {})\n",
    "            total_citations = 0\n",
    "            sorted_year_index = sorted([x for x in range(len(citations_by_year['year']))], key=lambda x: str(citations_by_year['year'][x]))\n",
    "            \n",
    "            for i in sorted_year_index:\n",
    "                year = citations_by_year['year'][i]\n",
    "                citations = citations_by_year['num_citations'][i]\n",
    "                # No unknowns\n",
    "                if year!='unknown':\n",
    "                    total_citations += citations\n",
    "                    by_year[year] = by_year.get(year, []) + [total_citations]\n",
    "                    cur_year_since_published[year] = cur_year_since_published.get(year, []) + [total_citations]\n",
    "            \n",
    "            citations_list.append(total_citations)\n",
    "            by_publication_year[publication_year] = by_publication_year.get(publication_year, []) + [total_citations]\n",
    "            by_year_since_published[publication_year] = cur_year_since_published    \n",
    "\n",
    "\n",
    "    h_index_by_year_df = {'Year': [], 'h-index': []}\n",
    "    h_index_by_publication_year_df = {'Publication Year': [], 'h-index': []}\n",
    "    avg_citations_by_publication_year_df = {'Publication Year': [], 'Avg Citations per Publication': []}\n",
    "    h_index_by_year_since_published_df = {'Publication Year': [], 'Year': [], 'h-index': []}\n",
    "    for year in range(min_year, cur_year+1):\n",
    "        h_index_by_year_df['Year'].append(year)\n",
    "        h_index_by_year_df['h-index'].append(get_h_index(by_year.get(year,[])))\n",
    "\n",
    "        h_index_by_publication_year_df['Publication Year'].append(year)\n",
    "        h_index_by_publication_year_df['h-index'].append(get_h_index(by_publication_year.get(year, [])))\n",
    "\n",
    "        avg_citations_by_publication_year_df['Publication Year'].append(year)\n",
    "        avg_citations_by_publication_year_df['Avg Citations per Publication'].append(np.mean(by_publication_year.get(year, [0])))\n",
    "\n",
    "        for y in range(year, cur_year+1):\n",
    "            h_index_by_year_since_published_df['Publication Year'].append(year)\n",
    "            h_index_by_year_since_published_df['Year'].append(y)\n",
    "            h_index_by_year_since_published_df['h-index'].append(get_h_index(by_year_since_published.get(year,{}).get(y, [])))\n",
    "    \n",
    "    all_time_h_index = get_h_index(citations_list)\n",
    "    all_time_i10_index = len([i for i in citations_list if i>=10])\n",
    "    all_time_i20_index = len([i for i in citations_list if i>=20])\n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'r') as f:\n",
    "        profile = json.load(f)\n",
    "        profile['all_time_h_index'] = all_time_h_index\n",
    "        profile['all_time_i10_index'] = all_time_i10_index\n",
    "        profile['all_time_i20_index'] = all_time_i20_index\n",
    "        profile['h_index_by_year'] = h_index_by_year_df\n",
    "        profile['h_index_by_publication_year'] = h_index_by_publication_year_df\n",
    "        profile['avg_citations_by_publication_year'] = avg_citations_by_publication_year_df\n",
    "        profile['h_index_by_years_from_publication_year'] = h_index_by_year_since_published_df\n",
    "    \n",
    "    with open(f'./processed_data/{file_name}', 'w') as f:\n",
    "        json.dump(profile, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scse_dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
