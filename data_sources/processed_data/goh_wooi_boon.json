{"full_name": "Goh Wooi Boon", "designation": "Associate Professor, School of Computer Science and Engineering", "email": "aswbgoh@ntu.edu.sg", "image_path": "./profile_img/goh_wooi_boon.jpg", "biography": "Wooi-Boon Goh received a B.Sc (1st Class Hons) in Computer Science and Electronic Engineering from the University of Birmingham, UK (1984), a M.Phil from University of Warwick, UK (1992), and a Ph.D. from Nanyang Technological University, Singapore (2006). He is currently an Associate Professor and Associate Chair (Faculty) in the School of Computer Science and Engineering, Nanyang Technological University, and his research interests include human-computer interaction and computer vision. Before joining NTU, he was senior engineer and later engineering section manager at the Mechanization and Automation department of Hewlett Packard Singapore. His industrial engineering expertise is in the area of developing robot-assisted automation systems.", "grants": "Collaborative multi-touch learning environments for children with autism", "google_scholar": "https://scholar.google.com/citations?hl=en&user=w7C16A8AAAAJ", "orcid": null, "github": null, "scopus": null, "web_of_science": null, "dr_ntu": "https://dr.ntu.edu.sg/cris/rp/rp00693", "other_websites": [], "interests": ["Human Computer Interaction", "Computer Vision"], "bachelor_degree": null, "masters": null, "phd": null, "collaboration_network": {"target": ["Peng Song", "Peng Song", "Peng Song", "Peng Song", "Peng Song", "Anh (Paul) Nguyen", "Anh (Paul) Nguyen", "Anh (Paul) Nguyen", "Anh (Paul) Nguyen", "Janusz Starzyk", "Janusz Starzyk", "Janusz Starzyk", "Janusz Starzyk", "Xiaopei Liu", "Yanwu Xu", "Yanwu Xu", "Yanwu Xu", "Ying Shan", "Ying Shan", "Pheng Ann Heng", "Graham R Martin", "Graham R Martin", "Graham R Martin", "Daniel Jachyra", "Schubert Foo", "Schubert Foo", "Schubert Foo", "Dilip Krishnan", "Ravi S. Sharma", "Tung Lai Lai", "Ian McLoughlin", "Ian McLoughlin", "Ian McLoughlin", "Ian McLoughlin", "Shailendra Palvia", "Kwan-Liu Ma", "Chng Eng Siong", "Douglas L. Maskell", "Douglas L. Maskell", "Kenneth K Poon"], "target_id": ["DonXkFQAAAAJ", "DonXkFQAAAAJ", "DonXkFQAAAAJ", "DonXkFQAAAAJ", "DonXkFQAAAAJ", "dk7XvIsAAAAJ", "dk7XvIsAAAAJ", "dk7XvIsAAAAJ", "dk7XvIsAAAAJ", "JfcmdF8AAAAJ", "JfcmdF8AAAAJ", "JfcmdF8AAAAJ", "JfcmdF8AAAAJ", "dK02t3MAAAAJ", "0jP8f7sAAAAJ", "0jP8f7sAAAAJ", "0jP8f7sAAAAJ", "4oXBp9UAAAAJ", "4oXBp9UAAAAJ", "OFdytjoAAAAJ", "cU9BkBgAAAAJ", "cU9BkBgAAAAJ", "cU9BkBgAAAAJ", "zNvZBlcAAAAJ", "wdK1ehkAAAAJ", "wdK1ehkAAAAJ", "wdK1ehkAAAAJ", "_MEuWIMAAAAJ", "P_Q8uPYAAAAJ", "LY9jQvIAAAAJ", "mcnKgPoAAAAJ", "mcnKgPoAAAAJ", "mcnKgPoAAAAJ", "mcnKgPoAAAAJ", "pBKFRlgAAAAJ", "LgL2HpkAAAAJ", "FJodrCcAAAAJ", "o_roEHkAAAAJ", "o_roEHkAAAAJ", "OlsCIB8AAAAJ"], "type": ["Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Unknown", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Unknown", "Outside SCSE", "Outside SCSE", "Outside SCSE", "Outside NTU", "Unknown", "Outside SCSE", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "Outside NTU", "NTU", "Outside SCSE", "Outside SCSE", "Outside SCSE"], "location": ["SUTD", "SUTD", "SUTD", "SUTD", "SUTD", "Unknown", "Unknown", "Unknown", "Unknown", "Ohio University", "Ohio University", "Ohio University", "Ohio University", "ShanghaiTech University", "South China University of Technology", "South China University of Technology", "South China University of Technology", "Unknown", "Unknown", "Chinese University of HongKong", "University of Warwick", "University of Warwick", "University of Warwick", "Unknown", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Google", "Unknown", "Nanyang Technological University", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Singapore Institute of Technology", "Long Island University", "University of California at Davis", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University", "Nanyang Technological University"], "year": [2011, 2016, 2011, 2013, 2012, 2010, 2012, 2012, 2013, 2010, 2012, 2012, 2013, 2012, 2015, 2013, 2014, 1998, 2000, 2011, 1991, 1994, 1994, 2012, 1994, 1996, 1994, 1996, 1994, 1996, 2012, 2009, 2007, 2007, 1996, 2013, 2008, 2007, 2007, 2009], "title": ["Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation", "Hand-posture-augmented multitouch interactions for exploratory visualization", "WYSIWYF: exploring and annotating volume data with a tangible handheld device", "Exploring Volume Visualization with Whole-hand Multitouch Gestures", "A handle bar metaphor for virtual object manipulation with mid-air interaction", "Spatio-temporal sequence learning of visual place cells for robotic navigation", "Sequence recognition with spatio-temporal long-term memory organization", "Neural network structure for spatio-temporal long-term memory", "A spatio-temporal Long-term Memory approach for visual place recognition in mobile robotic navigation", "Spatio-temporal sequence learning of visual place cells for robotic navigation", "Sequence recognition with spatio-temporal long-term memory organization", "Neural network structure for spatio-temporal long-term memory", "A spatio-temporal Long-term Memory approach for visual place recognition in mobile robotic navigation", "A handle bar metaphor for virtual object manipulation with mid-air interaction", "Robust multi-scale superpixel classification for optic cup localization", "Domain prior based superpixel propagation for optic cup localization", "Multi-scale superpixel classification for optic cup localization", "Camera self-calibration from video sequences with changing focal length", "Sub-pixel location of edges with non-uniform blurring: a finite closed-form approach", "WYSIWYF: exploring and annotating volume data with a tangible handheld device", "Deriving optical flow in noisy image sequences", "Model-based multiresolution motion estimation in noisy images", "A multiresolution model-based segmentation algorithm for 3-D motion and structure estimation", "Neural network structure for spatio-temporal long-term memory", "A framework for the design and implementation of groupware: in search of a philosopher's stone?", "Design and implementation issues of groupware in the global organization", "Design and implementation issues for groupware", "Bi-directional 3D auto-regressive model approach to motion picture restoration", "A framework for the design and implementation of groupware: in search of a philosopher's stone?", "Design and implementation issues of groupware in the global organization", "Multi-touch Wall Displays for Informational and Interactive Collaborative Space", "Using embedded technology supports to foster development in children with autism", "An embedded systems graduate education for Singapore", "Message from the honorary chair.", "Design and implementation issues of groupware in the global organization", "Exploring Volume Visualization with Whole-hand Multitouch Gestures", "MICRO-EBLOCK: A modular platform for embedded system education", "An embedded systems graduate education for Singapore", "Message from the honorary chair.", "Using embedded technology supports to foster development in children with autism"], "link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:YFjsv_pBGBYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M3NEmzRMIkIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:hFOr9nPyWt4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:dhFuZR0502QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:hFOr9nPyWt4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:dhFuZR0502QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:mB3voiENLucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:TFP_iSt0sucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:KlAtU1dfN6UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:kNdYIx-mwKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:TQgYirikUcIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:YOwf2qJgpHMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M3ejUd6NZC8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:_Qo2XoVZTnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M3ejUd6NZC8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:9ZlFYXVOiuMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:7PzlFSSx8tAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Se3iqnhoufwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:bEWYMUwI8FkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M3NEmzRMIkIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:3fE2CSJIrl8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Se3iqnhoufwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:bEWYMUwI8FkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:7PzlFSSx8tAC"]}, "published_by_year": {"Year": ["1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Publications": [1, 1, 0, 0, 4, 1, 2, 3, 2, 0, 1, 1, 0, 3, 0, 1, 3, 6, 2, 4, 3, 8, 10, 6, 2, 4, 3, 1, 4, 4, 1, 1, 0, 0, 2]}, "citations_by_year": {"Year": ["1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "unknown"], "# of Citations": [0, 0, 0, 0, 1, 5, 2, 6, 7, 7, 0, 9, 6, 7, 14, 10, 9, 16, 19, 27, 31, 34, 49, 76, 92, 83, 78, 81, 84, 91, 140, 164, 173, 124, 4]}, "all_time_h_index": 18, "all_time_i10_index": 25, "h_index_by_publication_year": {"Publication Year": [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [1, 0, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0, 0, 2, 0, 1, 2, 4, 2, 2, 2, 4, 5, 3, 2, 3, 2, 1, 3, 4, 1, 1, 0, 0]}, "avg_citations_by_publication_year": {"Publication Year": [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "Avg Citations per Publication": [5.0, 0.0, 0.0, 0.0, 3.5, 1.0, 18.5, 6.333333333333333, 6.0, 0.0, 81.0, 0.0, 0.0, 3.0, 0.0, 5.0, 1.3333333333333333, 5.666666666666667, 48.0, 5.0, 28.333333333333332, 15.625, 37.4, 3.8333333333333335, 5.0, 18.5, 7.666666666666667, 18.0, 12.75, 62.75, 62.0, 12.0, 0.0, 0.0]}, "h_index_by_year": {"Year": [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023], "h-index": [0, 0, 0, 0, 1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6, 7, 7, 8, 9, 10, 12, 12, 12, 13, 14, 15, 17, 18, 18]}, "h_index_by_years_from_publication_year": {"Publication Year": [1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1992, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1993, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1997, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2021, 2021, 2021, 2022, 2022, 2023], "Year": [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2018, 2019, 2020, 2021, 2022, 2023, 2019, 2020, 2021, 2022, 2023, 2020, 2021, 2022, 2023, 2021, 2022, 2023, 2022, 2023, 2023], "h-index": [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 1, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 1, 2, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 2, 3, 4, 4, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}, "all_time_i20_index": 16, "publications": {"Publication Year": ["2012", "2019", "2008", "2011", "2010", "2000", "2020", "2015", "2019", "2012", "2012", "2018", "2012", "1996", "2012", "2011", "1997", "2017", "2007", "2016", "2015", "2009", "2021", "2013", "1994", "2018", "2011", "1996", "2018", "2015", "2014", "2016", "1998", "1998", "2019", "2019", "2013", "2011", "2010", "2009", "2008", "2007", "2007", "2005", "1990", "2015", "2011", "2007", "2003", "2003", "2014", "2013", "2007", "2018", "2016", "2009", "2006", "2006", "2013", "2013", "2013", "2012", "2011", "2011", "2003", "1995", "1994", "1994", "2012", "2012", "2012", "2012", "2011", "2010", "2009", "2007", "2006", "2001", "1997", "1997", "1994", "1991", "Unknown", "Unknown"], "Title": ["A handle bar metaphor for virtual object manipulation with mid-air interaction", "Inter-subject transfer learning with an end-to-end deep convolutional neural network for EEG-based BCI", "Strategies for shape matching using skeletons", "WYSIWYF: exploring and annotating volume data with a tangible handheld device", "Multi-touch techniques for exploring large-scale 3D astrophysical simulations", "Sub-pixel location of edges with non-uniform blurring: a finite closed-form approach", "Why do people watch others eat food? An Empirical Study on the Motivations and Practices of Mukbang Viewers", "Robust multi-scale superpixel classification for optic cup localization", "Towards EEG generation using GANs for BCI applications", "Neural network structure for spatio-temporal long-term memory", "Interaction design patterns for multi-touch tabletop collaborative games", "DualGaze: Addressing the midas touch problem in gaze mediated VR interaction", "The i-cube: design considerations for block-based digital manipulatives and their applications", "Bi-directional 3D auto-regressive model approach to motion picture restoration", "Multi-robot path planning with the spatio-temporal A* algorithm and its variants", "Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation", "A new spatio-temporal MRF model for the detection of missing data in image sequences", "Personalized features for attention detection in children with Attention Deficit Hyperactivity Disorder", "The multiresolution gradient vector field skeleton", "Cardboardsense: Interacting with DIY cardboard VR headset by tapping", "Tangible user interface and a system thereof", "Moir\u00e9 patterns from a CCD camera-are they annoying artifacts or can they be useful?", "Personalized task difficulty adaptation based on reinforcement learning", "A spatio-temporal Long-term Memory approach for visual place recognition in mobile robotic navigation", "Model-based multiresolution motion estimation in noisy images", "EEG predicts the attention level of elderly measured by RBANS", "Spatio-temporal A* algorithms for offline multiple mobile robot path planning", "Design and implementation issues of groupware in the global organization", "The influence of peer accountability on attention during gameplay", "A stochastic algorithm for makespan minimized multi-agent path planning in discrete space", "The MOY framework for collaborative play design in integrated shared and private interactive spaces", "Hand-posture-augmented multitouch interactions for exploratory visualization", "Camera self-calibration from video sequences with changing focal length", "Amplitude modulated sinusoidal modeling using least-square infinite series approximation with applications to timbre analysis", "Bootstrapped policy gradient for difficulty adaptation in intelligent tutoring systems", "Designing a multi-disciplinary group project for computer science and engineering students", "Time optimized multi-agent path planning using guided iterative prioritized planning", "Action role design and observations in a gestural interface-based collaborative game", "Spatio-temporal sequence learning of visual place cells for robotic navigation", "Using CCD moir\u00e9 pattern analysis to implement pressure-sensitive touch surfaces", "MICRO-EBLOCK: A modular platform for embedded system education", "Noise robust AM_FM demodulation using least-squares truncated power series approximation", "Issues and challenges of embedded processor education for working professionals.", "Structural and textural skeletons for noisy shapes", "Equivalence of some methods on fuzzy reasoning", "An iterative approach for makespan-minimized multi-agent path planning in discrete space", "Generic motion gesture detection scheme using only a triaxial accelerometer", "Interacting with projected media on deformable surfaces", "Part-based shape recognition using gradient vector field histograms", "Shape description using gradient vector field histograms", "Multi-scale superpixel classification for optic cup localization", "Domain prior based superpixel propagation for optic cup localization", "An embedded systems graduate education for Singapore", "Neural Indexes of Attention Extracted from EEG Correlate with Elderly Reaction Time in response to an Attentional Task", "MuSeeCol: A See-through Multi-Touch Surface for Face-to-Face Musical Collaboration", "Moire patterns from a CCD camera", "Shape analysis using multiresolution gradient vector field", "Shape analysis using multiresolution gradient vector field", "Exploring Volume Visualization with Whole-hand Multitouch Gestures", "Exploring Volume Visualization with Whole-hand Multitouch Gestures", "A Meta-Heuristic Approach for Energy-Efficient Multi-Agent Path Planning", "Sequence recognition with spatio-temporal long-term memory organization", "Design considerations for interactive audio streaming on wireless handheld controllers", "Accelerometer-based swinging gesture detection for an electronic handbell", "A Shape Descriptor for Shapes with Boundary Noise and Texture.", "Parallel algorithms for 3D multi-level median filtering with motion compensation", "A framework for the design and implementation of groupware: in search of a philosopher's stone?", "A multiresolution model-based segmentation algorithm for 3-D motion and structure estimation", "A fast voting-based technique for human action recognition in video sequences", "A fast voting-based technique for human action", "A Fast Voting-based Technique for Human Action Recognition in Video Sequences.", "Multi-touch Wall Displays for Informational and Interactive Collaborative Space", "WYSIWYF: Exploring and Annotating Volume Data with a Tangible Handheld Device", "A motion-based visual interface for 3D visualization and robotic control applications", "Using embedded technology supports to foster development in children with autism", "Message from the honorary chair.", "Strategies for part-based shape analysis using skeletons", "Software engineering, intelligent systems and visual technology", "Causality considerations for missing data reconstruction in image sequences", "CUED-05 parallel agorithms for motion picture restoration", "Design and implementation issues for groupware", "Deriving optical flow in noisy image sequences", "A Stochastic Method for Makespan Minimized Multi-Agent Path Planning in Discrete Space", "ROBUST SHAPE AXES EXTRACTION USING MULTIRESOLUTION GRADIENT VECTOR FIELDS"], "Link": ["https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:9yKSN-GCB0IC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:RYcK_YlVTxYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:u5HHmVD_uO8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:qjMakFHDy7sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:u-x6o8ySG0sC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:kNdYIx-mwKoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:SeFeTyx0c_EC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:isC4tDSrTZIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:ldfaerwXgEUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:Tyk-4Ss8FVUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:YsMSGLbcyi4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:35N4QoGY0k4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:MXK_kJrjxJIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:d1gkVwhDpl0C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:0EnyYjriUFMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:IjCSPb-OGe4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:2osOgNQ5qMEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:NaGl4SEjCO4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:zYLM7Y9cAGgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&citation_for_view=w7C16A8AAAAJ:NMxIlDl6LWMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:k_IJM867U9cC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:4TOpqqG69KYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:rO6llkc54NcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:dhFuZR0502QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:UeHWp8X0CEIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:lSLTfruPkqcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:hqOjcs7Dif8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Y0pCki6q_DkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:RGFaLdJalmkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:maZDTaKrznsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:aqlVkmm33-oC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:YFjsv_pBGBYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:KlAtU1dfN6UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:_FxGoFyzp5QC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:70eg2SAEIzsC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:2P1L_qKh6hAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:mVmsd5A6BfQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Zph67rFs4hoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:UebtZRa9Y70C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:roLk4NBRz8UC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:3fE2CSJIrl8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:8k81kl-MbHgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:LkGwnXOMwfcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:W7OEmFMy1HYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:RHpTSmoSYBkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:QIV2ME_5wuYC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:ULOm3_A8WrAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:_kc_bZDykSQC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:ufrVoPGSRksC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:eQOLeE2rZwMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:TFP_iSt0sucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:mB3voiENLucC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Se3iqnhoufwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:J_g5lzvAfSwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:GnPB-g6toBAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:R3hNpaxXUhUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:ZeXyd9-uunAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:5nxA0vEk-isC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M3NEmzRMIkIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:L8Ckcad2t8MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:Wp0gIr-vW9MC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:hFOr9nPyWt4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:HDshCWvjkbEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:IWHjjKOFINEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:WF5omc3nYNoC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:r0BpntZqJG4C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M3ejUd6NZC8C", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:YOwf2qJgpHMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:fPk4N6BV_jEC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:HoB7MX3m0LUC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:e5wmG9Sq2KIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:9ZlFYXVOiuMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:-f6ydRqryjwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:hC7cP41nSMkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:7PzlFSSx8tAC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:bEWYMUwI8FkC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:qxL8FJ1GzNcC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:4OULZ7Gr8RgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:4DMP91E08xMC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:M05iB0D1s5AC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:_Qo2XoVZTnwC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:TQgYirikUcIC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:BqipwSGYUEgC", "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=w7C16A8AAAAJ&cstart=20&pagesize=80&citation_for_view=w7C16A8AAAAJ:qUcmZB5y_30C"], "Topic": ["Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others", "Others"], "# of Citations": [245, 196, 92, 85, 80, 81, 62, 50, 45, 42, 38, 33, 30, 29, 20, 20, 19, 18, 18, 15, 14, 13, 12, 12, 12, 9, 9, 8, 7, 7, 7, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 4, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "Description": ["Commercial 3D scene acquisition systems such as the Microsoft Kinect sensor can reduce the cost barrier of realizing mid-air interaction. However, since it can only sense hand position but not hand orientation robustly, current mid-air interaction methods for 3D virtual object manipulation often require contextual and mode switching to perform translation, rotation, and scaling, thus preventing natural continuous gestural interactions. A novel handle bar metaphor is proposed as an effective visual control metaphor between the user's hand gestures and the corresponding virtual object manipulation operations. It mimics a familiar situation of handling objects that are skewered with a bimanual handle bar. The use of relative 3D motion of the two hands to design the mid-air interaction allows us to provide precise controllability despite the Kinect sensor's low image resolution. A comprehensive repertoire of 3D\u00a0\u2026", "Objective Despite the effective application of deep learning (DL) in brain\u2013computer interface (BCI) systems, the successful execution of this technique, especially for inter-subject classification, in cognitive BCI has not been accomplished yet. In this paper, we propose a framework based on the deep convolutional neural network (CNN) to detect the attentive mental state from single-channel raw electroencephalography (EEG) data. Approach We develop an end-to-end deep CNN to decode the attentional information from an EEG time series. We also explore the consequences of input representations on the performance of deep CNN by feeding three different EEG representations into the network. To ensure the practical application of the proposed framework and avoid time-consuming re-training, we perform inter-subject transfer learning techniques as a classification strategy. Eventually, to interpret the learned\u00a0\u2026", "Skeletons are often used as a framework for part-based shape description and matching. This paper describes some useful strategies that can be employed to improve the performance of such shape matching algorithms. Firstly, it is important that ligature-sensitive information be incorporated into the part decomposition and shape matching processes. Secondly, part decomposition should be treated as a dynamic process in which the selection of the final decomposition of a shape is deferred until the shape matching stage. Thirdly, both local and global measures must be employed when computing shape dissimilarity. Finally, skeletal segments must be weighted by appropriate visual saliency measures during the part matching process. These saliency measures include curvature and ligature-based measures. Experimental results show that the incorporation of these strategies significantly improves shape\u00a0\u2026", "Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat\u00a0\u2026", "Enabling efficient exploration of large-scale virtual environments such as those simulating astrophysical environments is highly challenging. Astrophysical virtual worlds span exceptionally large spatial scales occupied mostly by empty space, and this makes it difficult for the user to comprehend the spatial context during exploratory navigation. Public exhibits, where novice users have little experience using complicated virtual navigation interfaces, pose additional challenges. To address these issues, we propose multi-touch techniques to deliver an effective interface to navigate the unique features of large-scale 3D environments such as astrophysical simulations. In this work, we carefully study conventional multi-touch methods and adapt them to the practical requirements of this application. A novel technique called the powers-of-ten ladder is introduced to support efficient movement across huge spatial scales\u00a0\u2026", "Traditional sub-pixel edge detectors model edges as step changes in intensity. However, this assumption is unrealistic in natural images, where edges have varying degrees of blur. This paper generalizes the edge model to one containing a local blurring factor, and gives finite closed-form solutions for edge location with sub-pixel accuracy. Solutions are based on the spatial moments up to the second-order, and are theoretically precise within the finite size of a windowed area. Moreover, the integral nature of low order spatial moments provide the algorithm some resilience against additive white noise. Experiments on both synthetic and real images show that the accuracy of the proposed method is comparable to the more computationally demanding nonlinear optimization method. Absolute error of less than 0.02pixel is demonstrated on one image of a grid pattern.", "We present a mixed-methods study of viewers on their practices and motivations around watching mukbang \u2014 video streams of people eating large quantities of food. Viewers' experiences provide insight on future technologies for multisensorial video streams and technology-supported commensality (eating with others). We surveyed 104 viewers and interviewed 15 of them about their attitudes and reflections on their mukbang viewing habits, their physiological aspects of watching someone eat, and their perceived social relationship with mukbangers. Based on our findings, we propose design implications for remote commensality, and for synchronized multisensorial video streaming content.", "This paper presents an optimal model integration framework to robustly localize the optic cup in fundus images for glaucoma detection. This work is based on the existing superpixel classification approach and makes two major contributions. First, it addresses the issues of classification performance variations due to repeated random selection of training samples, and offers a better localization solution. Second, multiple superpixel resolutions are integrated and unified for better cup boundary adherence. Compared to the state-of-the-art intra-image learning approach, we demonstrate improvements in optic cup localization accuracy with full cup-to-disc ratio range, while incurring only minor increase in computing cost.", "Brain-computer interface has been always facing serious data-related problems such as lack of the sufficient data and data corruption. Artificial data generation is a potential solution to address these issues. Among generative techniques, the method of generative adversarial networks (GANs) with the successful applications in image processing has gained a lot of attention. The application of GANs for time-series data generation is a recent growing topic that first of all its feasibility needs to be assessed. In the present study, we investigate the performance of GANs in generating artificial electroencephalogram (EEG) signals. The results suggest that the generated EEG signals by GANs resemble the temporal, spectral, and spatial characteristics of real EEG. It thus opens new perspectives for further research in this area.", "This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.", "Characteristics of multi-touch tabletops, such as a large interactive surface and simultaneous multiple user inputs can be exploited in the design of interactions that facilitate positive social interaction among children during collaborative activities. Designs that facilitate behaviors like positive interdependence, group processing and social skills such as turn taking are discussed. We report qualitative observations regarding the effectiveness of the proposed interaction designs in trials involving two groups of children with contrasting psychological safety levels and formulated several generalizable design patterns that were observed to be effective in soliciting collaborative play on interactive tabletops.", "With the increasing acceptance of eye tracking as a viable interaction method for Virtual Reality (VR) headsets, thoughtful gaze interaction methods need to be carefully designed to meet common challenges such as the Midas Touch problem, where users unintentionally select onscreen objects by gazing upon them. This paper presents DualGaze, a novel interaction method in which users perform a distinctive two-step gaze gesture for object selection. Once users gaze upon an object that they wish to select, a confirmation flag pops up next to the object at a location where the users' gaze just passed through. This trajectory-adaptive flag placement strategy reduces the chance of unintentional confirmation by requiring a returning gaze back to the flag. We conducted a user study to compare the accuracy and selection speed of DualGaze and the popular gaze fixation method on a simple gaze-typing task. Our results\u00a0\u2026", "Manipulatives are tangible objects designed to support learning through exploratory arrangement and manipulation. The i-Cube is a cube-shaped digital manipulative that provides unique 3-D spatial awareness of the facets and orientation of neighboring i-Cubes. This paper discusses the considerations adopted in its design and the advantages of the proposed design to that of other cube-based tangible user interfaces. The i-Cubes are then employed in the design of two applications. MusiCube Arranger is a tangible music composition and layering system and Spelling Cube is an interactive system for learning spelling. These applications are used to illustrate how the unique features of the i-Cube can be exploited to implement novel tangible interactions such as free-form 3D stacking, interactive control through block orientation change and context-aware feedback.", "Most image restoration algorithms will blur edges of moving objects in the vicinity of occluded and uncovered image regions. These artifacts are visually annoying. This paper proposes a new bi-directional 3D auto-regressive model which is able to suppress mixed noise processes and recover lost signals in both the covered and uncovered regions in an image sequence. The performance of this algorithm is shown to be superior to the existing 3D AR model.", "This paper presents the design of an offline collision-free path planning algorithm for multiple mobile robots travelling simultaneously on a 2D gridded map. We first solved this problem by extending the traditional A* algorithm into 3D, namely two spatial and one time dimensions. This 3D approach is proved computationally costly and this led to the development of a novel and faster Spatio-Temporal (S-T) A* algorithm. This is a modified A* algorithm, which uses discrete time stamps and a temporal occupancy table to communicate previously planned routes and potential collision among robots. We further adapted the S-T A* algorithm to allow robots to stop and wait near nodes where potential collision is detected in order to increase their probability of finding a viable path to their destination. Using a time-based objective function that requires all robots in the environment to reach their respective destination\u00a0\u2026", "While very large collaborative surfaces are already being widely employed to facilitate concurrent interactions with multiple users, they involve no personalization in the touch interactions. Augmenting them to identify the touch interactions with multiple smart-phones can enable interesting co-located communal applications with context-based personalized interactions and information exchange amongst users' portable devices and the shared wall display. This paper proposes a novel matching technique, called tilt correlation, which employs the built-in tilt sensor to identify smart-phones that make concurrent two-point contacts on a common multi-touch wall display. Experimental investigations suggest that the resultant error rate is relatively low; in addition, we also propose a quantitative measure, called the Bourne Identity Index to allow application designers to determine the reliability of each device identification.", "This paper proposes a new spatial-temporal MRF model for the detection of missing data (also referred to as blotches) in image sequences. The blotches in noise-corrupted image sequences exhibit a temporal discontinuity characteristic which is commonly used for the detection of blotches. However, the badly motion compensated pixels will also appear as temporal discontinuities, thus making it difficult to distinguish the true blotches from the poorly motion compensated regions. The proposed MRF model addresses the problem of incorrect detection. It is found that the degree of false-alarm in the detection of the blotches in image sequences can be reduced by using a moving-edge detector in the MRF model to identify the blotch-edges from the moving edges.", "Measuring attention from electroencephalogram (EEG) has found applications in the treatment of Attention Deficit Hyperactivity Disorder (ADHD). It is of great interest to understand what features in EEG are most representative of attention. Intensive research has been done in the past and it has been proven that frequency band powers and their ratios are effective features in detecting attention. However, there are still unanswered questions, like, what features in EEG are most discriminative between attentive and non-attentive states? Are these features common among all subjects or are they subject-specific and must be optimized for each subject? Using Mutual Information (MI) to perform subject-specific feature selection on a large data set including 120 ADHD children, we found that besides theta beta ratio (TBR) which is commonly used in attention detection and neurofeedback, the relative beta power and theta\u00a0\u2026", "Many algorithms suppress skeleton associated with boundary perturbation by preventing their formation or by costly branch pruning. This work proposes a novel concept of structural and textural skeletons. The former is associated with the general shape structure and the latter with boundary perturbations. These skeletons remain disconnected to facilitate gross shape matching without the need for branch pruning. They are extracted from a multiresolution gradient vector field that is efficiently generated within a pyramidal framework. Experimental results show that these skeletons are scale and rotation invariant. They are less affected by boundary noise compared to skeletons extracted by popular iterative and non-iterative techniques.", "DIY cardboard-based VR headset that enfolds a commodity smartphone is a popular means of achieving low cost immersive stereoscopic viewing experiences. However, existing applications for these devices have limited user-input capability, allowing mainly look-at control by head tilting. CardboardSense is a set of novel tap-gesture-based inputs that take advantage of the motion sensing capabilities already available in most smartphones. The key premise is that finger contacts with the cardboard surface produce incidental but detectable vibrations that can be reliably differentiated from typical user head motion. Moreover, tapping on different surface locations produces differentiable temporal signatures in the sensor signals. We present methods to extract and analyze these temporal patterns, and experimentally determine a set of tapping gestures that can be accurately recognized. Experimental results show\u00a0\u2026", "The present invention relates to a TUI having a plurality of faces. A sensing system is provided to detect the presence of one or more adjacent TUIs within a predetermined sensing distance of one of the faces. Thus, the sensing system is arranged to detect whether any of the faces of the TUI opposes one or more adjacent TUIs. It may further be able to detect the relative orientation of opposing faces of the TUI and the one or more adjacent TUIs. The sensing system is further configured to enable the determination of the orientation of the TUI with respect to the vertical direction.", "When repetitive high frequency patterns appear in the view of a charge-coupled device (CCD) camera, annoying low frequency Moir\u00e9 patterns are often observed. This paper demonstrates that such Moir\u00e9 pattern can useful in measuring surface deformation and displacement. What is required, in our case, is that the surface in question is textured with appropriately aligned black and white line gratings and this surface is imaged using a grey scaled CCD camera. The characteristics of the observed Moir\u00e9 patterns are described along with a spatial domain model-fitting algorithm that is able to extract a dense camera-to-surface displacement measures. The experimental results discuss the reconstruction of planar incline and curved surfaces using only a coarse 33 lines per inch line grating patterns printed from a 600 dpi printer.", "Traditionally, the task difficulty level is often determined by domain experts based on some hand-crafted rules. However, with the adoption of Massive Open Online Courses (MOOCs), it has become harder to manually personalize task difficulty as the system designers are faced with a very large question bank and a user base of individuals with diverse backgrounds and ability levels. This research focuses on developing a data-driven method to adaptively adjust difficulty levels in order to maintain a target user performance level over a series of tasks whose difficulty level is highly variable among different individuals. Specifically, the issue of difficulty adaptation was formulated as a reinforcement learning problem. To ensure responsiveness of the interactive systems, a novel bootstrapped policy gradient (BPG) framework was developed, which can incorporate prior knowledge of difficulty ranking into policy\u00a0\u2026", "This paper proposes a solution to the problem of mobile robotic localization using visual indoor image sequences with a biologically inspired spatio-temporal neural network approach. The system contains three major subsystems: a feature extraction module, a scene quantization module and a spatio-temporal long-term memory (LTM) module. During learning, the scene quantization module clusters the visual images set into scene tokens. A K-Iteration Fast Learning Artificial Neural Network (KFLANN) is employed as the core unit of the quantization module. The KFLANN network is driven by intrinsic statistics of the data stream and therefore does not require the number of clusters to be predefined. In addition, the KFLANN performance is less sensitive to data presentation ordering compared to popular clustering methods such as k-means, and can therefore produce a consistent number of stable centroids. Using\u00a0\u2026", "It is argued that accurate optical flow can only be determined if problems such as local motion ambiguity, motion segmentation, and occlusion detection are simultaneously addressed. To meet this requirement, a new multiresolution region-growing algorithm is proposed. This algorithm consists of a region-growing process which is able to segment the flow field in an image into homogeneous regions which are consistent with a linear affine flow model. To ensure stability and robustness in the presence of noise, this region-growing process is implemented within the hierarchical framework of a spatial lowpass pyramid. The results of applying this algorithm to both natural and synthetic image sequences are presented.", "Purpose This study aims to investigate the correlation between neural indexes of attention and behavioral indexes of attention and detect the most informative period of brain activity in which the strongest correlation with attentive performance (behavioral index) exists. Finally, to further validate the findings, this paper aims at the prediction of different levels of attention function based on the attention score obtained from repeatable battery for the assessment of neurophysiological status (RBANS). Design/methodology/approach The present paper analyzes electroencephalogram (EEG) signals recorded by a single prefrontal channel from 105 elderly subjects while they were responding to Stroop color test which is an attention-demanded task. Beside Stroop test, subjects also performed RBANS which provides their level of functionality in different domains including attention. After data acquisition (EEG during Stroop test and\u00a0\u2026", "This paper presents an offline collision-free path planning algorithm for multiple mobile robots using a 2D spatial-time map. In this decoupled approach, a centralized planner uses a Spatio-Temporal A* algorithm to find the lowest time cost path for each robot in a sequentially order based on its assigned priority. Improvements in viable path solutions using wait time insertion and adaptive priority reassignment strategies are discussed.", "Groupware facilitates and supports collaboration within groups that may be physically and/or temporally separated. While much work has been done in establishing the concept of groupware and the impact of a variety of factors on the efficiency and effectiveness of its use; there is no seminal work that thoroughly investigates experimentally the design and implementation problems associated with such systems. In the area of design and implementation, some work has been done in regard to groupware for same time and place situations (eg meeting rooms) but there is a general vacuum in regard to groupware for groups that are geographically dispersed and cross time zones. In this chapter, we present a framework and an experimental methodology that addresses the problem of matching groupware design with its proposed use. Stated briefly, groupware is only effective when the system is considered in the context of group objectives, stakeholder roles and environmental constraints. Our research methodology is simple: prototyping and field testing beta versions of four main classes of groupware. We have gleaned a comprehensive list of parameters for the design and implementation of such systems. As a result, we have a provisional list of guidelines for the design and implementation of groupware which is particularly relevant to the global organization.", "The comparative advantages of competitive and cooperative multiplayer gameplay designs have been studied with mixed results. In this study, we have attempted to minimize other cooperative design attributes in order to focus on evaluating the effects of strong peer accountability on players' overall and sustained attention levels during competition and cooperation. A novel multiplayer game based on a cognitive task that uses the Stroop effect was developed and deployed in trials where quantitative in-game data measuring players' error rates and reaction times were collected for comparative analysis. The results show that players demonstrate higher levels of attention when they were made accountable to their partners as they make significantly less errors when cooperating than when competing. In addition, the individual response time data gathered reveals that peer accountability has a more positive influence\u00a0\u2026", "Makespan minimized multi-agent path planning (MAPP) requires the minimization of the time taken by the slowest agents to reach its destination. The resulting minimax objective function is non-smooth and the search for an optimal solution in MAPP can be intractable. In this work, a maximum entropy function is adopted to approximate the minimax objective function. An iterative algorithm named probabilistic iterative makespan minimization (PIMM) is then proposed to approximate a makespan minimized MAPP solution by solving a sequence of computationally hard MAPP minimization problems with a linear objective function. At each iteration, a novel local search algorithm called probabilistic iterative path coordination (PIPC) is used to find a sufficiently good solution for each MAPP minimization problem. Experimental results from comparative studies with existing MAPP algorithms show that the proposed\u00a0\u2026", "A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing collaborative play activities in environments that combine both private and shared interactive spaces. A collaborative game designed on a system that integrates multiple mobile devices with an interactive tabletop was presented to demonstrate the implementation of the proposed MOY framework. Observations from field trials involving two groups of children were used to summarize the collaborative behaviors that are likely to be observed under the different interaction design configurations.", "Conventional multitouch-based visualization systems mostly use just the touch information elicited from the touch surface to support the visualization applications, while rich contextual and dynamic information contained in user's hand postures above the surface remains untapped. This paper addresses this issue by proposing a family of finger-and-hand gestures that can be robustly recognized and employed over a multitouch tabletop surface. We describe how these gestures can be recognized in real-time with the use of depth sensing, and suggest several examples of how touch-based information augmented with information like hand differentiation, hand posture discrimination and finger tilt dynamics can improve conventional exploratory visualization. We present two case studies to show how the augmented gestures can be employed in different exploratory visualization scenarios more effectively.", "Camera self-calibration techniques make it possible to compute three-dimensional measurements of an observed scene from video sequences without prior knowledge of the camera intrinsic parameters. However, most previous techniques make the overly constraint assumption that camera intrinsic parameters remain constant throughout the image sequence. The self-calibration method described in this article generalises the camera model by adding into the intrinsic parameter set a variable focal length, whose change is approximated by a cubic B-spline. The modified intrinsic parameters are then calculated with adapted Kruppa equations, together with an initialization procedure that utilizes the genetic algorithm. Results obtained using synthetic image sequences are presented. It shows the algorithm's ability to trade the changing focal length (zooming) even under noisy conditions.", "A least-square infinite series approximation (L-SISA) technique is proposed for modeling amplitude modulated (AM) sinusoidal components of naturally occurring signals, such as those produced by traditional musical instruments. Each AM sinusoid is iteratively extracted using an analysis-by-synthesis technique and the problem of parameter estimation is linearised for least-square approximation through a systematic search in the frequency vector space. Some timbre analysis results obtained using the AM sinusoidal model are presented.", "With the increasing adoption of the Massive Open Online Courses (MOOC), there is an important need for online education systems to take into account individual differences so that contents and assessments can be personalized to match users who have diverse backgrounds and ability levels. The \u201cflow theory\u201d[6] suggests that the present challenge must be optimally set to a person\u2019s ability in order to avoid frustration when the task is too difficult and boredom when it is trivial. On the educational front, the theory of \u201cproximal development zone\u201d[1] suggests that learning gain is optimal when the difficulty level matches the student\u2019s ability.", "This paper describes the design of a group-based project that combines both the hardware and software disciplines of our Computer Science (CS) and Computer Engineering (CE) undergraduates. The goals for the multi-disciplinary design project (MDP) are to provide our 3 rd  year undergraduates with the opportunities to apply the theoretical knowledge acquired from their early years to solving a practical problem, foster a continuous improvement mindset, and experience the benefits and challenges of working collaboratively in a large team. This requires the formulation of a suitably complex problem that can integrate the skill sets from both the CE and CS programmes. It also requires suitable assessment strategies that can evaluate the students at the individual level, at the group level and at the inter-group level. This paper shares our pedagogical considerations in designing the project module, our experience\u00a0\u2026", "This paper proposes the guided iterative prioritized planning (GIPP) algorithm to address the problem of moving multiple mobile agents to their respective destinations in a shortest timerelated cost. Compared to other MAPP algorithms, the GIPP algorithm strikes a good balance between various performance criteria such as finding feasible solutions, completing the task promptly and low computational cost.", "This paper explores the design of action roles for children playing an animal character-based collaborative game with gestural-sensitive tangible user interfaces. Based on trial runs with two inclusive groups of participants with mixed age and learning abilities, we report preliminary case study observations of the collaborative play behaviors solicited by the different interaction design patterns associated with the manner in which the action roles were distributed and coupled.", "In this paper, we present a novel biologically-inspired spatio-temporal sequence learning architecture of visual place cells to leverage autonomous navigation. The construction of the place cells originates from the well-known architecture of Hubel and Wiesel to develop simple to complex features in ventral stream of the human brain. To characterize the contribution of each feature towards scene localization, we propose a novel significance analysis based on the activation profiles of features throughout the spatio-temporal domain. The K-iteration Fast Learning Neural Network (KFLANN) is then used as a Short-Term Memory (STM) mechanism to construct our sequence elements. Subsequently, each sequence is built and stored as a Long-Term Memory (LTM) cell via a one-shot learning mechanism. We also propose a novel algorithm for sequence recognition based on the LTM organization. The efficiency and\u00a0\u2026", "The Moir\u00e9 fringe patterns obtained when a CCD camera views a repetitive line grating can be exploited to measure small changes to surface displacements. We describe how curved surfaces with line grating patterns can be reconstructed by analysing the instantaneous frequency of the extracted 1D Moir\u00e9 waveform. Experimental results show that monotonically increasing displacements of a stretched canvas of less than 1mm can be clearly separated, suggesting the possibility of using the proposed Moir\u00e9-based vision technique to construct accurate pressure-sensitive touch surfaces.", "The advancement of technology in recent decades has brought computing beyond the desktop computer. With the focus on portable and interactive devices, it is necessary to equip the next generation of engineers with the necessary programming skills and a robust set of tools to create a wider range of applications. In the School of Computer Engineering at Nanyang Technological University (NTU), Singapore, we are developing a scalable microcontroller peripheral system called Micro-eBlocks to facilitate the studentpsilas learning of microcontroller based modules. The Micro-eBlocks are a suite of mix and match and plug-and-play input-output (I/O), sensor, communication and processor modules, which can be used to address a wide variety of embedded systems application needs. This paper describes the design philosophy and how it can be used to train embedded system engineers.", "This paper describes a parametric approach for demodulating multicomponent AM-FM sinusoidal signals. The parametric model consist of several truncated power series whose coefficients are estimated using linear least-square minimisation cast within an iterative parameter-substitution framework. It is shown that the proposed technique for AM-FM estimation is relatively robust to background noise compared to other techniques such as the smoothed energy operator separation algorithm and the Hilbert transform method.", "This paper describes how a course in embedded processors and peripherals can be effectively designed for a group of busy working professionals who come from diverse industrial backgrounds. With the increasing emphasis in life-long learning and adult education, we believe the experiences and pedagogical strategies shared here is increasingly relevant to many educators. The rationale behind these proposed strategies for both learning and assessment is described.", "The extraction of consistent skeletons in the presence of boundary noise is still a problem for most skeletonization algorithms. Many suppress skeletons associated with boundary perturbation, either by preventing their formation or removing them subsequently using additional operations. A more appropriate approach is to view a shape as comprising of structural and textural skeletons. The former describes the general structure of the shape and the latter its boundary characteristics. These two types of skeletons should be encouraged to remaining disconnected to facilitate gross shape matching without the need for branch pruning. Such skeletons can be formed by means of a multi-resolution gradient vector field (MGVF), which can be generated efficiently using a pyramidal framework. The robust scale-invariant extraction of the skeletons from the MGVF is described. Experimental results show that the MGVF\u00a0\u2026", "The author obtains several equivalent conditions of some methods on multidimensional and multi-conditional fuzzy reasoning. He proposes a method on general fuzzy reasoning which is a generalization of the Zadeh's interpolation method.< >", "Makespan-minimized multi-agent path planning (MAPP) seeks to minimize the time taken by the slowest of n agents to reach its destination and this is essentially a minimax-constrained optimization problem. In this work, an iterative max-min improvement (IMMI) algorithm is proposed to approximate the optimal solution of the makespan-minimized MAPP problem. At each iteration, a linear maximization problem is solved using a simplex method followed by a computationally hard MAPP minimization problem that is solved using a local search approach. To keep the local search from being trapped in an unfeasible solution, a Guided Local Search technique is proposed. Comparative results with other MAPP algorithms suggest that the proposed IMMI algorithm strikes a good tradeoff between the ability to find feasible solutions that can be traversed quickly and the computational time incurred in determining\u00a0\u2026", "A simple generic motion detection scheme suitable for use in gestural interfaces (GI) embedded with an accelerometer and is wirelessly connected to a PC is proposed. It consists of three processes, namely motion decomposition, wireless communication and motion pattern matching. Motion decomposition is performed within the GI on the human gestures to generate sequences of motion directions. Translational motion is identified based on the observations that any translation starts with a tangential acceleration and end with a tangential deceleration. On the other hand, rotational motions are identified by tracking the continuous changes in motion orientation. After the decomposition process, the decomposed motion directions are sent sequentially to a PC for sequence and combination matching to determine the type of gestural motions. The advantage of the proposed scheme is that it is simple, generic and has\u00a0\u2026", "This paper presents a novel human-computer interface for projector/camera-based applications that uses a deformable interaction surface. We discuss its design and implementation within the context of a radically different approach for controlling home appliances by pressing virtual buttons that are projected on soft deformable surfaces such as a sofa pillow. Effective real-time computer vision algorithms for implementing pointing and selection action detection for such an interface are discussed. Experimental results highlight the parameters and factors that have significant effect on the overall performance of such an interface.", "The gradient vector field generated from the boundary of a shape describes the regional interaction between the shape boundaries and can therefore be exploited to provide rich and robust shape description. We present a novel part-based shape representation that describes a shape using a set of gradient vector field histograms derived at salient points within the shape. Peaks and ridges derived from the local disparity in the vector field provides a means of locating these salient points called shape axes, from where polar sampling of the vector field is then used to build scale and rotational invariant histograms of the vectors\u2019 orientation. A multi-resolution pyramidal framework is proposed for generating the gradient vector field and extracting the shape axes. Results from shape recognition experiments show that the proposed shape descriptor is invariant to similarity transform, robust under boundary\u00a0\u2026", "We present a novel approach to shape representation that describes a shape using a set of histograms derived at salient points within the shape. A computationally efficient multiresolution pyramidal framework is used to generate a dense gradient vector field whose characteristics can be altered through the use of a scale parameter \u03b1. This parameter regulates the proportion of low and high spatial frequency components used in creating the vector field and can be set such that minor boundary distortions do not significantly change the representation of the shape. Local maximas of the directional disparity measure in the vector field are used for locating shape axes, from where polar sampling of the vector field is then used to build scale and rotational invariant histograms that describes subparts of the shape. A saliency measure based on the size of a part is introduced to provide appropriate weighting to\u00a0\u2026", "In this paper, we present a multi-scale approach based on superpixel classification for optic cup localization. Our approach provides 3 major contributions. First, a contrast enhancement scheme is proposed to reduce illumination influence and enhance feature discrimination. Second, features are extracted from multiple superpixels scales for richer description of the optic cup. Third, a unique cup is localized by integrating the multi-scales together using majority voting. Our approach was validated on a clinical online dataset, ORIGA-light, of 650 population-based images. Overall, our approach is able to achieve a 0.248 non-overlap ratio (m 1 ) and a 0.085 absolute CDR error (\u03b4). Experimental results also shows that our multi-scale approach has a complementary effect to increase performance stability, and is able to achieve a higher accuracy when compared with the previous state-of-the-art superpixel-based method.", "In this paper, we present an unsupervised framework using domain priors extracted from the primary structures of the optic nerve head for automated optic cup localization. Our approach provides 3 major contributions. First, we identify a new domain prior, optic cup origin. This prior is derived from the physiological understanding that the central retinal vessels traces its origin from the optic cup before extending to the rest of the retinal. Second, we propose extracting the features of the optic nerve head from superpixels, which are obtained from low-level grouping and have more natural and descriptive features than pixel based techniques. Third, the domain knowledge comprising of optic cup origin and cup pallor, and the extracted features from superpixels are then used to drive a similarity-based label propagation and refinement scheme for the optic cup localization. Our approach was validated on a clinical online\u00a0\u2026", "In early 2003, the Singapore Economic Development Board identified Embedded Systems as a major'new growth area'for the Singapore economy, building upon the existing infrastructure of technological companies, and proven ability for companies both local and overseas, to conduct advanced research and development, as well as specialist production, in Singapore. In response to this, Nanyang Technological University School of Computer Engineering proposed, and deployed, a part-time graduate masters' programme in embedded systems.", "In the present paper, we analyze electroencephalogram (EEG) signals recorded by a single frontal channel from 105 elderly subjects while they were responding to an attention-demanded task (Stroop color test). The first objective is to discover how post-cue frequency band oscillations of EEG, as neural index of attention, are correlated with elderly response time (RT), as behavioral index of attention. Furthermore, we aim to detect the most informative period of brain activity (EEG) in which the strongest correlations with reaction time exist. Our results show that 1) there is significant negative correlation between alpha gamma ratio (AGR) and response time (p<0.0001), 2) theta beta ratio (TBR) is positively correlated with subjects' response time (p<0.0001) and 3) these correlations are stronger in a 500ms period right after triggering the cue (question onset in Stroop test). Our study provides an insight into the research\u00a0\u2026", "MuSeeCol is a collaborative music creation system that allows two users to jointly and playfully compose melodic or percussive music. Collaborative music is rendered when two face-to-face users interact with their respective side of a see-through multi-touch sensitive acrylic panel. We present user study findings from nine pairs of individuals who have used the MuSeeCol system collaboratively and summarize some general observations of what types of interaction designs make for effective face-to-face collaboration.", "When repetitive high frequency patterns appear in the view of a charge-coupled device (CCD) camera, annoying low frequency Moir\u00e9 patterns are often observed. This paper demonstrates that such Moir\u00e9 pattern can useful in measuring surface deformation and displacement. What is required, in our case, is that the surface in question is textured with appropriately aligned black and white line gratings and this surface is imaged using a grey scaled CCD camera. The characteristics of the observed Moir\u00e9 patterns are described along with a spatial domain model-fitting algorithm that is able to extract a dense camera-to-surface displacement measures. The experimental results discuss the reconstruction of planar incline and curved surfaces using only a coarse 33 lines per inch line grating patterns printed from a 600 dpi printer.", "It is widely held that our perception of visual form is due to the excitation of cells sensitive to orientation and edge information at the boundary of the object. It is hypothesised in this work that the multiscale spatial integration along the hierarchical visual pathway do in some way migrate boundary-based orientation into the interior region of the shape and this dense multiresolution gradient vector field (MGVF) can be exploited for robust representation of shapes. Based on this premise, the thesis proposes a novel computationally efficient multiresolution framework for generating a dense gradient vector field for the interior region of a silhouette shape. Within this framework, the smoothness of the MGVF can be easily adjusted via a single smoothing parameter. The thesis subsequently explores the robustness and usefulness of the MGVF in two-dimensional shape analysis. Firstly, a multiresolution algorithm based on the detection of local directional disparity maximas in the gradient vector field is proposed for extracting the medial representation of a shape. It is shown that the MGVF skeleton can be extracted in a noise-robust manner and is invariant to both scaling and arbitrary rotation. Secondly, a global shape descriptor in the form of an orientation histogram is proposed to describe the gradient vector field characteristics within the shape. Comparative evaluation with other popular global descriptors suggests that this descriptor strikes a good compromise between boundary noise robustness, computational efficiency and the ability to classify shapes. Though compact and computationally efficient, the representation of an entire shape with a single\u00a0\u2026", "It is widely held that our perception of visual form is due to the excitation of cells sensitive to orientation and edge information at the boundary of the object. It is hypothesised in this work that the multiscale spatial integration along the hierarchical visual pathway do in some way migrate boundary-based orientation into the interior region of the shape and this dense multiresolution gradient vector field (MGVF) can be exploited for robust representation of shapes. Based on this premise, the thesis proposes a novel computationally efficient multiresolution framework for generating a dense gradient vector field for the interior region of a silhouette shape. Within this framework, the smoothness of the MGVF can be easily adjusted via a single smoothing parameter. The thesis subsequently explores the robustness and usefulness of the MGVF in two-dimensional shape analysis. Firstly, a multiresolution algorithm based on the detection of local directional disparity maximas in the gradient vector field is proposed for extracting the medial representation of a shape. It is shown that the MGVF skeleton can be extracted in a noise-robust manner and is invariant to both scaling and arbitrary rotation. Secondly, a global shape descriptor in the form of an orientation histogram is proposed to describe the gradient vector field characteristics within the shape. Comparative evaluation with other popular global descriptors suggests that this descriptor strikes a good compromise between boundary noise robustness, computational efficiency and the ability to classify shapes. Though compact and computationally efficient, the representation of an entire shape with a single\u00a0\u2026", "Exploded views and cutaway views have been demonstrated to be powerful visualization techniques to explore the complex internal structures in 3D volume data. Current approaches for creating them are mainly based on algorithms with very limited user controls. This paper proposes a novel set of whole-hand multitouch gestures for interactive creation and manipulation of these views on 3D volume data. Moreover, users can also interactively perform bimanual 'V'-shape cut and volume exploding, remove unwanted volume partitions to effectively create cutaway views, and create threshold-based volume segmentation and exploded views. Our proposed interaction design was also tried out by eight participants in a preliminary pilot study.", "Exploded views and cutaway views have been demonstrated to be powerful visualization techniques to explore the complex internal structures in 3D volume data. Current approaches for creating them are mainly based on algorithms with very limited user controls. This paper proposes a novel set of whole-hand multitouch gestures for interactive creation and manipulation of these views on 3D volume data. Moreover, users can also interactively perform bimanual \u2018V\u2019-shape cut and volume exploding, remove unwanted volume partitions to effectively create cutaway views, and create threshold-based volume segmentation and exploded views. Our proposed interaction design was also tried out by eight participants in a preliminary pilot study.", "We address the problem of multi-agent path planning (MAPP) by taking into account the total energy consumption of all agents, as measured by their cumulative distance travelled. A deterministic meta-heuristic technique called guided iterative prioritized planning (GIPP) is proposed to find good solutions with respect to this cumulative cost measure in a crowded environment. GIPP progressively explores a larger search space while incorporating a local optimum detection and resolution scheme to prevent the search process from being trapped in an unfeasible locally optimal solution. Comparative evaluations show that GIPP strikes a good tradeoff between the solution quality and computational time.", "In this work, we propose a connectionist memory structure for spatio-temporal sequence learning and recognition inspired by the Long-Term Memory structure of human cortex. Besides symbolic data, our framework is able to continuously process real-valued multi-dimensional data stream. This capability is made possible by addressing three critical problems in spatio-temporal learning, namely error tolerance, significance of sequence's elements and memory forgetting mechanism. We demonstrate the potential of the framework with a synthetic example and a real world example, namely the task of hand-sign language interpretation with the Australian Sign Language dataset.", "Interactive audio streaming over wireless network is usually carried out over high bandwidth wireless channels and is implemented using computationally well-resourced devices. This paper describes two basic design configurations for interactive audio streaming on a handheld controller that communicates with a host PC over a low data rate wireless network and operates under low power and processing capability conditions. The first design considers direct streaming of audio data over the wireless channel and the second considers audio data streaming from a local external memory within the remote device. We discuss issues related to audio playback quality and power consumption for each of this design configuration.", "This paper tackles the problem of detecting the swinging action of an electronic handbell. It describes a threshold-based algorithm that is able to detect an orientation-free swinging motion using only the X and Y axis signals of an accelerometer that is mounted at the end of a handle. Equations governing the accelerations of the accelerometer are defined. The equations are used to select the appropriate accelerometer axis for swing motion detection, which were X axis and Y axis. The characteristics of the swing motion are identified empirically and incorporated to the swing detection algorithm. The experimental results for swinging motion performed by 4 users on the electronic bell show that the accuracy of swing motion detection is 95.3%.", "We present a part-based shape descriptor that incorporates both the description of the general shape form of each subpart and its geometric relationship with other connected parts. Associated with each descriptor is a saliency measure that weighs each part\u2019s visual significance. By incorporating this saliency measure into the shape matching process, we able to discriminate between shape forms as well as take boundary texture into consideration when computing shape similarity. This paper also describes a multi-resolution pyramidal framework for generating the required gradient vector field and vector field disparity map from which the shape descriptors, in the form of gradient vector field histograms, are derived. Experimental results involving silhouettes images are presented to demonstrate the various characteristics of the proposed shape descriptor, which includes its invariance to similarity transform and its ability to match composite shapes containing boundary noise and texture, limb articulation and occlusion.", "This paper aims to develop effective parallel processing techniques for 3-dimensional (3D) multi-level median filtering (3DMMF) with motion compensation on video sequences. Due to the nature of unbalanced load of the filtering algorithm and the objective for the parallel approach, two methods of dynamic load balancing have been proposed and compared. They are sender-initiated-load-balancing (SILB) and receiver-initiated-load-balancing (RILB) algorithms. We propose a SILB algorithm which utilises the spatial-temporal characteristics of the processed sequences for load prediction to achieve dynamic load balancing. Both theoretical analysis and experimental results on the IBM SP2 computing surface have been presented in this paper.", "We present a framework and an experimental methodology that addresses the problem of matching design with usage issues when providing technological support for work groups. Stated tersely, groupware is only effective when the system is considered in the context of group objectives, stakeholder roles and environmental constraints. Our research methodology is simple: by prototyping and field-testing beta-versions of the four main classes of groupware, we hope to glean a comprehensive list of critical success factors for the design and implementation of such systems.< >", "It became apparent, even in the early works of Schunck (1988) that the task of optical flow estimation has to be carried out in conjunction with the task of motion segmentation (i.e. motion boundary detection). This fact has motivated the development of a novel model-based algorithm which is able to segment the optical flow field in an image into homogeneous regions which are consistent with a linear affine flow model. Furthermore, to ensure robustness in the presence of noise, this region-growing process is implemented within the hierarchical framework of a spatial low-pass pyramid. The results of applying this algorithm to the problem of estimating 3D motion and structure in monocular image sequences are presented.< >", "Human action recognition has been an active research area in recent years. However, building a robust human action recognition system still remains a challenging task due to the large variations in action classes, varying human appearances, illumination changes, camera motion, occlusions and background clutter. Most previous work focus on the goal of improving recognition rates. This paper describes a computationally fast votingbased approach for human action recognition, in which the action in the video sequence is recognized based on the support of the local spatio-temporal features. The proposed technique requires no parameter tuning and can produce recognition rates that are comparable to those in recent published literature. Moreover, the technique can localize the single human action in the video sequence without much additional computation. Recognition results on the KTH and Weizmann action dataset are presented.", "Human action recognition has been an active research area in recent years. However, building a robust human action recognition system still remains a challenging task due to the large variations in action classes, varying human appearances, illumination changes, camera motion, occlusions and background clutter. Most previous work focus on the goal of improving recognition rates. This paper describes a computationally fast votingbased approach for human action recognition, in which the action in the video sequence is recognized based on the support of the local spatio-temporal features. The proposed technique requires no parameter tuning and can produce recognition rates that are comparable to those in recent published literature. Moreover, the technique can localize the single human action in the video sequence without much additional computation. Recognition results on the KTH and Weizmann\u00a0\u2026", "Human action recognition has been an active research area in recent years. However, building a robust human action recognition system still remains a challenging task due to the large variations in action classes, varying human appearances, illumination changes, camera motion, occlusions and background clutter. Most previous work focus on the goal of improving recognition rates. This paper describes a computationally fast votingbased approach for human action recognition, in which the action in the video sequence is recognized based on the support of the local spatio-temporal features. The proposed technique requires no parameter tuning and can produce recognition rates that are comparable to those in recent published literature. Moreover, the technique can localize the single human action in the video sequence without much additional computation. Recognition results on the KTH and Weizmann action dataset are presented.", "GeoTouch was envisaged as a multi-touch display and information portal for GIS data within the Earth Observatory of Singapore: specifically as a focal point for collaborative discussion and exploration. The original GeoTouch, built in 2008 used proprietary hardware and software, and pioneered various multi-touch interface methodologies within the centre. Since then, GeoTouch-II has been unveiled, based upon commercial hardware rather than the bulky projection-based systems of the original, although the underlying GIS information handling and interfaces continue to be developed in-house. This chapter discusses both systems, drawing conclusions based upon observation and survey of more than three years of use, revealing patterns related to hardware and software limitations, and reveals important information concerning correlation between placement and usefulness.", "Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat finger annotation technique (F3AT) is proposed to perform accurate and speedy contour drawings. Our user studies support the efficacy of our proposed visual exploration and annotation interaction designs.", "The exploratory visualization of 3D data sets or multiple axis motion control of a monitoring camera mounted on a six-axis robot often require the user to control the viewing orientation and position of a camera view within a 3D space. This paper describes the design of an inertial motion sensing system, which uses only accelerometers to provide interactive 3D control of both orientation and position in such systems. We describe the interaction design strategies for exploratory visualization of 3D data using the proposed input device, which is mounted beneath a portable display. Experiments on the use of the proposed device suggest that with some training, the users are able to improve the speed with which they can navigate the orientation and position of a virtual camera to a desired target view in the 3D visual space.", null, "In early 2003, the Singapore Economic Development Board identified Embedded Systems as a major \u2018new growth area\u2019 for the Singapore economy, building upon the existing infrastructure of technological companies, and proven ability for companies both local and overseas, to conduct advanced research and development, as well as specialist production, in Singapore. In response to this, Nanyang Technological University School of Computer Engineering proposed, and deployed, a part-time graduate masters\u2019 programme in embedded systems. This paper discusses the need for such an embedded education in Singapore, the syllabus and course coverage which has been developed, and the response of students and industry to the initiative. Pitfalls and problems are identified at each stage.", "Skeletons are often used as a framework for part-based shape analysis. This paper describes some useful strategies that can be employed to improve the performance of such shape matching algorithms. Four key strategies are proposed. The first is to incorporate ligature-sensitive information into the part decomposition and shape matching processes. The second is to treat part decomposition as a dynamic process in which the selection of the final decomposition of a shape is deferred until the shape matching stage. The third is the need to combine both local and global measures when computing shape dissimilarity. Finally, curvature error between skeletal segments must be weighted by the limb-width profile along the skeleton. Experimental results show that the incorporation of these strategies significantly improves the retrieval accuracy when applied to LEMS\u2019s 99 and 216 silhouette database [10].", "The objectives of the RGM-5/95 was to provide funding for the training of graduate students  (M.A.Sc., M. Eng and Ph.D.) and research assistant in the area of software Engineering, intelligent systems and visual technology.", "The 3D autoregressive (AR) model with a non-causal support region has been successfully employed in the reconstruction of texture and missing regions in image sequences. This paper discusses the causality considerations when selecting the reconstruction model. When a distorted area to be reconstructed is large, a substantial computational load reduction can be obtained by implementing a predictor with a purely causal AR support. A novel reconstruction scheme which employs a selective causal/anti-causal (S-C/AC) AR model is presented. Experimental results suggest that the S-C/AC scheme produces a good trade-off between computational and reconstruction performance.", "CUED-05 parallel agorithms for motion picture restoration | NTU Singapore Skip navigation \nNanyang Technological University DR-NTU (Digital Repository of NTU) DR-NTU (Digital \nRepository of NTU) Communities & Collections Research Papers Organisations Theses FYPs \nProjects Academic Profile Explore by Research Papers Organisations Theses FYPs Projects \nAcademic Profile Guidelines The NTU Academic Profile (beta) has been redesigned to provide \nnew features to showcase research output of faculty. Read more. Login Show simple item \nrecord Show full item record Export item record Please use this identifier to cite or link to this \nitem: https://hdl.handle.net/10356/8128 Title: CUED-05 parallel agorithms for motion picture \nrestoration Authors: Chong, Man Nang Rayner, Peter Goh, Wooi Boon Seah, Hock Soon \nKokaram, Anil Keywords: DRNTU::Engineering::Computer science and engineering::Computing \u2026", "Groupware systems can be classified under four distinct classes, namely, messaging, conferencing, decision-making and co-authoring systems [Rodden, 1991]. In this project we have developed/configured four systems for the four classes of groupware for study.  They are: MEmail:-a heterogeneous multimedia electronic message system; MacGroupie;- a Macintosh-based desktop conferencing system; GroupSystem V :- a GUI-based GDSS; CommIT :- a PC-based shared whiteboard/group editor.  This project aims to explore the design and implementation issues related to these four different classes of groupware.", "A technique is presented extracting local image motion utilising the properties of spatiotemporal orientation i n the frequency domain. This technique is based on the eigenvalue analysis of the inertia tensor matrix of the frequency domain. An iterative velocity field smoothing algorithm was developed based on the properties of a variant of this inertia tensor matrix. This iterative algorithm is able to smooth noisy translational, rotational and other smoothly varying velocity flow fields, within the constraints of motion discontinuities. Some results from the application of this algorithm to noisy random dot sequences are presented.", "Makespan minimized Multi-Agent Path Planning (MAPP) requires the minimization of the time taken by the slowest agents to reach its destination. The resulting minimax objective function is non-smooth and the search for an optimal solution in MAPP can be intractable. In this work, a maximum entropy function is adopted to approximate the minimax objective function. A stochastic algorithm named Probabilistic Iterative Makespan Minimization (PIMM) is then proposed to find a makespan minimized MAPP solution by solving a sequence of computationally simpler MAPP minimization problems. At each iteration, a novel local search algorithm called Probabilistic Iterative Path Coordination (PIPC) is used to find a sufficiently good solution for each MAPP minimization problem. Experimental results from comparative studies with existing MAPP algorithms show that the proposed algorithm strikes a good tradeoff between the quality of the makespan minimized solution and the computational cost. c 2011 Published by Elsevier Ltd.", "ROBUST SHAPE AXES EXTRACTION USING MULTIRESOLUTION GRADIENT VECTOR \nFIELDS Wooi-Boon Goh Kai-Yun Chan School of Computer Engineering Centre for Advanced \nMedia Technology Nanyang Technological University School of Computer Engineering \nNanyang Avenue Nanyang Technological University, Singapore 639798 Nanyang Avenue, \nSingapore 639798 Abstract This paper describes a novel multiresolution technique for \nextracting the shape axes of 2D binary images. A gradient vector field representing the shape is \ngenerated using a multiresolution pyramidal technique and the shape axes are subsequently \nextracted by detecting the local directional disparity of the gradient vectors in the vector field. We \ndiscuss how the characteristics of the gradient vector field can be controlled such that the \nextracted shape axes in the interior of the shape are made robust to boundary noise and texture. \u2026"]}}