{"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:pyW8ca7W8N0C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5288526/", "authors": ["Sinno Jialin Pan", "Qiang Yang"], "publication_date": "2010/10/1", "journal": "IEEE Transactions on knowledge and data engineering", "volume": "22", "issue": "10", "pages": "1345-1359", "publisher": "Institute of Electrical and Electronics Engineers, Inc., 345 E. 47 th St. NY NY 10017-2394 USA", "description": "A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we\u00a0\u2026", "total_citations": {"2010": 87, "2011": 214, "2012": 281, "2013": 366, "2014": 464, "2015": 566, "2016": 720, "2017": 1027, "2018": 1829, "2019": 2614, "2020": 3292, "2021": 3919, "2022": 3801, "2023": 2740}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:pqnbT2bcN3wC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5640675/", "authors": ["Sinno Jialin Pan", "Ivor W Tsang", "James T Kwok", "Qiang Yang"], "publication_date": "2011/2", "journal": "IEEE Transactions on Neural Networks", "volume": "22", "issue": "2", "pages": "199-210", "publisher": "IEEE", "description": "Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the\u00a0\u2026", "total_citations": {"2010": 16, "2011": 34, "2012": 45, "2013": 79, "2014": 88, "2015": 128, "2016": 159, "2017": 192, "2018": 303, "2019": 467, "2020": 623, "2021": 708, "2022": 726, "2023": 538}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:-_dYPAW6P2MC": {"external_link": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Domain_Generalization_With_CVPR_2018_paper.html", "authors": ["Haoliang Li", "Sinno Jialin Pan", "Shiqi Wang", "Alex C Kot"], "publication_date": "2018", "conference": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "pages": "5400-5409", "description": "In this paper, we tackle the problem of domain generalization: how to learn a generalized feature representation for an \u201cunseen\u201d target domain by taking the advantage of multiple seen source-domain data. We present a novel framework based on adversarial autoencoders to learn a generalized latent feature representation across domains for domain generalization. To be specific, we extend adversarial autoencoders by imposing the Maximum Mean Discrepancy (MMD) measure to align the distributions among different domains, and matching the aligned distribution to an arbitrary prior distribution via adversarial feature learning. In this way, the learned feature representation is supposed to be universal to the seen source domains because of the MMD regularization, and is expected to generalize well on the target domain because of the introduction of the prior distribution. We proposed an algorithm to jointly train different components of our proposed framework. Extensive experiments on various vision tasks demonstrate that our proposed framework can learn better generalized features for the unseen target domain compared with state of-the-art domain generalization methods.", "total_citations": {"2018": 3, "2019": 44, "2020": 109, "2021": 211, "2022": 302, "2023": 318}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:2osOgNQ5qMEC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1772690.1772767", "authors": ["Sinno Jialin Pan", "Xiaochuan Ni", "Jian-Tao Sun", "Qiang Yang", "Zheng Chen"], "publication_date": "2010/4/26", "conference": "Proceedings of the 19th international conference on World wide web", "pages": "751-760", "publisher": "ACM", "description": "Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of users publishing sentiment data (e.g., reviews, blogs). Although traditional classification algorithms can be used to train sentiment classifiers from manually labeled text data, the labeling work can be time-consuming and expensive. Meanwhile, users often use some different words when they express sentiment in different domains. If we directly apply a classifier trained in one domain to other domains, the performance will be very low due to the differences between these domains. In this work, we develop a general solution to sentiment classification when we do not have any labels in a target domain but have some labeled data in a different domain, regarded as source domain. In this cross-domain sentiment classification setting, to bridge the gap between the domains, we propose a spectral feature alignment (SFA\u00a0\u2026", "total_citations": {"2010": 9, "2011": 28, "2012": 47, "2013": 49, "2014": 66, "2015": 71, "2016": 91, "2017": 93, "2018": 96, "2019": 116, "2020": 82, "2021": 79, "2022": 62, "2023": 50}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:u-x6o8ySG0sC": {"external_link": "https://cdn.aaai.org/AAAI/2008/AAAI08-108.pdf", "authors": ["Sinno Jialin Pan", "James T Kwok", "Qiang Yang"], "publication_date": "2008/7/13", "journal": "AAAI", "volume": "8", "pages": "677-682", "description": "Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new dimensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification.", "total_citations": {"2009": 16, "2010": 26, "2011": 34, "2012": 34, "2013": 35, "2014": 48, "2015": 46, "2016": 58, "2017": 63, "2018": 75, "2019": 93, "2020": 86, "2021": 67, "2022": 77, "2023": 50}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:M05iB0D1s5AC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6606584/", "authors": ["Jaechang Nam", "Sinno Jialin Pan", "Sunghun Kim"], "publication_date": "2013/5/18", "conference": "2013 35th International Conference on Software Engineering (ICSE)", "pages": "382-391", "publisher": "IEEE", "description": "Many software defect prediction approaches have been proposed and most are effective in within-project prediction settings. However, for new projects or projects with limited training data, it is desirable to learn a prediction model by using sufficient training data from existing source projects and then apply the model to some target projects (cross-project defect prediction). Unfortunately, the performance of cross-project defect prediction is generally poor, largely because of feature distribution differences between the source and target projects. In this paper, we apply a state-of-the-art transfer learning approach, TCA, to make feature distributions in source and target projects similar. In addition, we propose a novel transfer defect learning approach, TCA+, by extending TCA. Our experimental results for eight open-source projects show that TCA+ significantly improves cross-project prediction performance.", "total_citations": {"2013": 2, "2014": 24, "2015": 40, "2016": 46, "2017": 47, "2018": 63, "2019": 83, "2020": 77, "2021": 92, "2022": 105, "2023": 52}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:rO6llkc54NcC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6550016/", "authors": ["Mingsheng Long", "Jianmin Wang", "Guiguang Ding", "Sinno Jialin Pan", "S Yu Philip"], "publication_date": "2014/5", "journal": "IEEE Transactions on Knowledge and Data Engineering", "volume": "26", "issue": "5", "pages": "1076-1089", "publisher": "IEEE", "description": "Domain transfer learning, which learns a target classifier using labeled data from a different distribution, has shown promising value in knowledge discovery yet still been a challenging problem. Most previous works designed adaptive classifiers by exploring two learning strategies independently: distribution adaptation and label propagation. In this paper, we propose a novel transfer learning framework, referred to as Adaptation Regularization based Transfer Learning (ARTL), to model them in a unified way based on the structural risk minimization principle and the regularization theory. Specifically, ARTL learns the adaptive classifier by simultaneously optimizing the structural risk functional, the joint distribution matching between domains, and the manifold consistency underlying marginal distribution. Based on the framework, we propose two novel methods using Regularized Least Squares (RLS) and Support\u00a0\u2026", "total_citations": {"2015": 22, "2016": 40, "2017": 34, "2018": 60, "2019": 84, "2020": 109, "2021": 97, "2022": 103, "2023": 58}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:roLk4NBRz8UC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/8090", "authors": ["Yin Zhu", "Yuqiang Chen", "Zhongqi Lu", "Sinno Jialin Pan", "Gui-Rong Xue", "Yong Yu", "Qiang Yang"], "publication_date": "2011/8/4", "conference": "Twenty-Fifth AAAI Conference on Artificial Intelligence", "description": "Transfer learning as a new machine learning paradigm has gained increasing attention lately. In situations where the training data in a target domain are not sufficient to learn predictive models effectively, transfer learning leverages auxiliary source data from other related source domains for learning. While most of the existing works in this area only focused on using the source data with the same structure as the target data, in this paper, we push this boundary further by proposing a heterogeneous transfer learning framework for knowledge transfer between text and images. We observe that for a target-domain classification problem, some annotated images can be found on many social Web sites, which can serve as a bridge to transfer knowledge from the abundant text documents available over the Web. A key question is how to effectively transfer the knowledge in the source data even though the text can be arbitrarily found. Our solution is to enrich the representation of the target images with semantic concepts extracted from the auxiliary source data through a novel matrix factorization method. By using the latent semantic features generated by the auxiliary data, we are able to build a better integrated image classifier. We empirically demonstrate the effectiveness of our algorithm on the Caltech-256 image dataset.", "total_citations": {"2011": 4, "2012": 13, "2013": 16, "2014": 21, "2015": 32, "2016": 18, "2017": 32, "2018": 43, "2019": 70, "2020": 47, "2021": 57, "2022": 51, "2023": 33}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:hkOj_22Ku90C": {"external_link": "https://proceedings.neurips.cc/paper/2017/hash/c5dc3e08849bec07e33ca353de62ea04-Abstract.html", "authors": ["Xin Dong", "Shangyu Chen", "Sinno Jialin Pan"], "publication_date": "2017", "journal": "Advances in Neural Information Processing Systems", "volume": "30", "pages": "4857-4867", "description": "How to develop slim and accurate deep neural networks has become crucial for real-world applications, especially for those employed in embedded systems. Though previous work along this research line has shown some promising results, most existing methods either fail to significantly compress a well-trained deep network or require a heavy retraining process for the pruned deep network to re-boost its prediction performance. In this paper, we propose a new layer-wise pruning method for deep neural networks. In our proposed method, parameters of each individual layer are pruned independently based on second order derivatives of a layer-wise error function with respect to the corresponding parameters. We prove that the final prediction performance drop after pruning is bounded by a linear combination of the reconstructed errors caused at each layer. By controlling layer-wise errors properly, one only needs to perform a light retraining process on the pruned network to resume its original prediction performance. We conduct extensive experiments on benchmark datasets to demonstrate the effectiveness of our pruning method compared with several state-of-the-art baseline methods. Codes of our work are released at: https://github. com/csyhhu/L-OBS.", "total_citations": {"2018": 33, "2019": 55, "2020": 67, "2021": 105, "2022": 105, "2023": 72}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:5Ul4iDaHHb8C": {"external_link": "http://www.cse.cuhk.edu.hk/~sinnopan/publications/[IJCAI15]Supervised%20Representation%20Learning%20Transfer%20Learning%20with%20Deep%20Autoencoders.pdf", "authors": ["Fuzhen Zhuang", "Xiaohu Cheng", "Ping Luo", "Sinno Jialin Pan", "Qing He"], "publication_date": "2015/6/27", "conference": "Twenty-Fourth International Joint Conference on Artificial Intelligence", "description": "Transfer learning has attracted a lot of attention in the past decade. One crucial research issue in transfer learning is how to find a good representation for instances of different domains such that the divergence between domains can be reduced with the new representation. Recently, deep learning has been proposed to learn more robust or higherlevel features for transfer learning. However, to the best of our knowledge, most of the previous approaches neither minimize the difference between domains explicitly nor encode label information in learning the representation. In this paper, we propose a supervised representation learning method based on deep autoencoders for transfer learning. The proposed deep autoencoder consists of two encoding layers: an embedding layer and a label encoding layer. In the embedding layer, the distance in distributions of the embedded instances between the source and target domains is minimized in terms of KL-Divergence. In the label encoding layer, label information of the source domain is encoded using a softmax regression model. Extensive experiments conducted on three real-world image datasets demonstrate the effectiveness of our proposed method compared with several state-of-theart baseline methods.", "total_citations": {"2016": 9, "2017": 20, "2018": 38, "2019": 55, "2020": 71, "2021": 64, "2022": 85, "2023": 60}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:wbdj-CoPYUoC": {"external_link": "https://arxiv.org/abs/1603.06679", "authors": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao"], "publication_date": "2016", "conference": "EMNLP", "pages": "616-626", "description": "In aspect-based sentiment analysis, extracting aspect terms along with the opinions being expressed from user-generated content is one of the most important subtasks. Previous studies have shown that exploiting connections between aspect and opinion terms is promising for this task. In this paper, we propose a novel joint model that integrates recursive neural networks and conditional random fields into a unified framework for explicit aspect and opinion terms co-extraction. The proposed model learns high-level discriminative features and double propagate information between aspect and opinion terms, simultaneously. Moreover, it is flexible to incorporate hand-crafted features into the proposed model to further boost its information extraction performance. Experimental results on the SemEval Challenge 2014 dataset show the superiority of our proposed model over several baseline methods as well as the winning systems of the challenge.", "total_citations": {"2016": 1, "2017": 18, "2018": 31, "2019": 54, "2020": 87, "2021": 80, "2022": 81, "2023": 47}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:ZuybSZzF8UAC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/10974", "authors": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao"], "publication_date": "2017/2/12", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "31", "issue": "1", "description": "The task of aspect and opinion terms co-extraction aims to explicitly extract aspect terms describing features of an entity and opinion terms expressing emotions from user-generated texts. To achieve this task, one effective approach is to exploit relations between aspect terms and opinion terms by parsing syntactic structure for each sentence. However, this approach requires expensive effort for parsing and highly depends on the quality of the parsing results. In this paper, we offer a novel deep learning model, named coupled multi-layer attentions. The proposed model provides an end-to-end solution and does not require any parsers or other linguistic resources for preprocessing. Specifically, the proposed model is a multi-layer attention network, where each layer consists of a couple of attentions with tensor operators. One attention is for extracting aspect terms, while the other is for extracting opinion terms. They are learned interactively to dually propagate information between aspect terms and opinion terms. Through multiple layers, the model can further exploit indirect relations between terms for more precise information extraction. Experimental results on three benchmark datasets in SemEval Challenge 2014 and 2015 show that our model achieves state-of-the-art performances compared with several baselines.", "total_citations": {"2017": 6, "2018": 16, "2019": 52, "2020": 72, "2021": 89, "2022": 76, "2023": 61}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:KUbvn5osdkgC": {"external_link": "https://books.google.com/books?hl=en&lr=&id=dG_IDwAAQBAJ&oi=fnd&pg=PR9&dq=info:aLyFbbeWwsMJ:scholar.google.com&ots=Ud065hQPvU&sig=rlO_3O_mrjd9im24ehn0ATCVd-M", "authors": ["Qiang Yang", "Yu Zhang", "Wenyuan Dai", "Sinno Jialin Pan"], "publication_date": "2020/1/31", "publisher": "Cambridge University Press", "description": "Transfer learning deals with how systems can quickly adapt themselves to new situations, tasks and environments. It gives machine learning systems the ability to leverage auxiliary data and models to help solve target problems when there is only a small amount of data available. This makes such systems more reliable and robust, keeping the machine learning model faced with unforeseeable changes from deviating too much from expected performance. At an enterprise level, transfer learning allows knowledge to be reused so experience gained once can be repeatedly applied to the real world. For example, a pre-trained model that takes account of user privacy can be downloaded and adapted at the edge of a computer network. This self-contained, comprehensive reference text describes the standard algorithms and demonstrates how these are used in different transfer learning paradigms. It offers a solid grounding for newcomers as well as new insights for seasoned researchers and developers.", "total_citations": {"2019": 1, "2020": 30, "2021": 96, "2022": 106, "2023": 85}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:bnK-pcrLprsC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7435328/", "authors": ["Xin Xia", "David Lo", "Sinno Jialin Pan", "Nachiappan Nagappan", "Xinyu Wang"], "publication_date": "2016/10/1", "journal": "IEEE Transactions on software Engineering", "volume": "42", "issue": "10", "pages": "977-998", "publisher": "IEEE", "description": "Most software defect prediction approaches are trained and applied on data from the same project. However, often a new project does not have enough training data. Cross-project defect prediction, which uses data from other projects to predict defects in a particular project, provides a new perspective to defect prediction. In this work, we propose a HYbrid moDel Reconstruction Approach (HYDRA) for cross-project defect prediction, which includes two phases: genetic algorithm (GA) phase and ensemble learning (EL) phase. These two phases create a massive composition of classifiers. To examine the benefits of HYDRA, we perform experiments on 29 datasets from the PROMISE repository which contains a total of 11,196 instances (i.e., Java classes) labeled as defective or clean. We experiment with logistic regression as the underlying classification algorithm of HYDRA. We compare our approach with the most\u00a0\u2026", "total_citations": {"2015": 1, "2016": 5, "2017": 27, "2018": 37, "2019": 56, "2020": 39, "2021": 41, "2022": 56, "2023": 30}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:LPZeul_q3PIC": {"external_link": "https://scholars.cityu.edu.hk/en/publications/short-and-sparse-text-topic-modeling-via-selfaggregation(f7f973ab-812b-4fae-ad8f-dced13195b08).html", "authors": ["Xiaojun Quan", "Chunyu Kit", "Yong Ge", "Sinno Jialin Pan"], "publication_date": "2015/6/25", "conference": "Twenty-Fourth International Joint Conference on Artificial Intelligence", "description": "The overwhelming amount of short text data on social media and elsewhere has posed great challenges to topic modeling due to the sparsity problem. Most existing attempts to alleviate this problem resort to heuristic strategies to aggregate short texts into pseudo-documents before the application of standard topic modeling. Although such strategies cannot be well generalized to more general genres of short texts, the success has shed light on how to develop a generalized solution. In this paper, we present a novel model towards this goal by integrating topic modeling with short text aggregation during topic inference. The aggregation is founded on general topical affinity of texts rather than particular heuristics, making the model readily applicable to various short texts. Experimental results on real-world datasets validate the effectiveness of this new model, suggesting that it can distill more meaningful topics from short texts.", "total_citations": {"2016": 11, "2017": 18, "2018": 36, "2019": 36, "2020": 45, "2021": 37, "2022": 28, "2023": 20}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:PR6Y55bgFSsC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/10826", "authors": ["Ben Tan", "Yu Zhang", "Sinno Jialin Pan", "Qiang Yang"], "publication_date": "2017/2/13", "conference": "Thirty-First AAAI Conference on Artificial Intelligence", "description": "In this paper, we study a novel transfer learning problem termed Distant Domain Transfer Learning (DDTL). Different from existing transfer learning problems which assume that there is a close relation between the source domain and the target domain, in the DDTL problem, the target domain can be totally different from the source domain. For example, the source domain classifies face images but the target domain distinguishes plane images. Inspired by the cognitive processof human where two seemingly unrelated concepts can be connected by learning intermediate concepts gradually, we propose a Selective Learning Algorithm (SLA) to solve the DDTL problem with supervised autoencoder or supervised convolutional autoencoder as a base model for handling different types of inputs. Intuitively, the SLA algorithm selects usefully unlabeled data gradually from intermediate domains as a bridge to break the large distribution gap for transferring knowledge between two distant domains. Empirical studies on image classification problems demonstrate the effectiveness of the proposed algorithm, and on some tasks the improvement in terms of the classification accuracy is up to 17% over \u201cnon-transfer\u201d methods.", "total_citations": {"2017": 3, "2018": 14, "2019": 39, "2020": 41, "2021": 45, "2022": 42, "2023": 30}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:-f6ydRqryjwC": {"external_link": "https://aclanthology.org/P12-1043.pdf", "authors": ["Fangtao Li", "Sinno Jialin Pan", "Ou Jin", "Qiang Yang", "Xiaoyan Zhu"], "publication_date": "2012/7", "conference": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "pages": "410-419", "description": "Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment-and topic-lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.", "total_citations": {"2011": 1, "2012": 1, "2013": 10, "2014": 15, "2015": 16, "2016": 36, "2017": 17, "2018": 25, "2019": 19, "2020": 17, "2021": 15, "2022": 16, "2023": 14}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:OU6Ihb5iCvQC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/8961", "authors": ["Joey Tianyi Zhou", "Sinno Jialin Pan", "Ivor W Tsang", "Yan Yan"], "publication_date": "2014/6/21", "conference": "Twenty-eighth AAAI conference on artificial intelligence", "description": "Most previous heterogeneous transfer learning methods learn a cross-domain feature mapping between heterogeneous feature spaces based on a few cross-domain instance-correspondences, and these corresponding instances are assumed to be representative in the source and target domains respectively. However, in many real-world scenarios, this assumption may not hold. As a result, the constructed feature mapping may not be precisely due to the bias issue of the correspondences in the target or (and) source domain (s). In this case, a classifier trained on the labeled transformed-source-domain data may not be useful for the target domain. In this paper, we present a new transfer learning framework called Hybrid Heterogeneous Transfer Learning (HHTL), which allows the corresponding instances across domains to be biased in either the source or target domain. Specifically, we propose a deep learning approach to learn a feature mapping between cross-domain heterogeneous features as well as a better feature representation for mapped data to reduce the bias issue caused by the cross-domain correspondences. Extensive experiments on several multilingual sentiment classification tasks verify the effectiveness of our proposed approach compared with some baseline methods.", "total_citations": {"2014": 1, "2015": 6, "2016": 15, "2017": 25, "2018": 31, "2019": 30, "2020": 25, "2021": 19, "2022": 32, "2023": 9}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:P5F9QuxV20EC": {"external_link": "http://proceedings.mlr.press/v33/zhou14.html", "authors": ["Joey Tianyi Zhou", "Ivor W Tsang", "Sinno Jialin Pan", "Mingkui Tan"], "publication_date": "2014/4/2", "conference": "Artificial Intelligence and Statistics", "pages": "1095-1103", "description": "In this paper, we present an efficient Multi-class Heterogeneous Domain Adaptation (HDA) method, where data from the source and target domains are represented by heterogeneous features with different dimensions. Specifically, we propose to reconstruct a sparse feature transformation matrix to map the features of multiple classes from the source domain to the target domain. We cast this learning task as a compressed sensing problem, where each classifier can be deemed as a measurement sensor. Based on compressive sensing theory, the estimation error of the transformation matrix decreases with the increasing number of classifiers. Therefore, to guarantee the reconstruction performance, we construct sufficiently many binary classifiers based on the error correcting output correcting. Extensive experiments are conducted on both toy data and three real-world HDA applications to verify the superiority of our proposed method over existing state-of-the-art HDA methods in terms of prediction accuracy.", "total_citations": {"2014": 3, "2015": 9, "2016": 15, "2017": 14, "2018": 24, "2019": 33, "2020": 20, "2021": 20, "2022": 21, "2023": 12}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&citation_for_view=P6WcnfkAAAAJ:VL0QpB8kHFEC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7855802/", "authors": ["Yonghui Xu", "Sinno Jialin Pan", "Hui Xiong", "Qingyao Wu", "Ronghua Luo", "Huaqing Min", "Hengjie Song"], "publication_date": "2017/6/1", "journal": "IEEE Transactions on Knowledge and Data Engineering", "volume": "29", "issue": "6", "pages": "1158-1171", "publisher": "IEEE", "description": "Transfer learning has been proven to be effective for the problems where training data from a source domain and test data from a target domain are drawn from different distributions. To reduce the distribution divergence between the source domain and the target domain, many previous studies have been focused on designing and optimizing objective functions with the Euclidean distance to measure dissimilarity between instances. However, in some real-world applications, the Euclidean distance may be inappropriate to capture the intrinsic similarity or dissimilarity between instances. To deal with this issue, in this paper, we propose a metric transfer learning framework (MTLF) to encode metric learning in transfer learning. In MTLF, instance weights are learned and exploited to bridge the distributions of different domains, while Mahalanobis distance is learned simultaneously to maximize the intra-class distances\u00a0\u2026", "total_citations": {"2017": 1, "2018": 12, "2019": 23, "2020": 49, "2021": 30, "2022": 32, "2023": 20}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:qxL8FJ1GzNcC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5989824/", "authors": ["Jeffrey Junfeng Pan", "Sinno Jialin Pan", "Jie Yin", "Lionel M Ni", "Qiang Yang"], "publication_date": "2012/3", "journal": "IEEE transactions on pattern analysis and machine intelligence", "volume": "34", "issue": "3", "pages": "587-600", "publisher": "IEEE", "description": "Recent years have witnessed the growing popularity of sensor and sensor-network technologies, supporting important practical applications. One of the fundamental issues is how to accurately locate a user with few labeled data in a wireless sensor network, where a major difficulty arises from the need to label large quantities of user location data, which in turn requires knowledge about the locations of signal transmitters or access points. To solve this problem, we have developed a novel machine learning-based approach that combines collaborative filtering with graph-based semi-supervised learning to learn both mobile users' locations and the locations of access points. Our framework exploits both labeled and unlabeled data from mobile devices and access points. In our two-phase solution, we first build a manifold-based model from a batch of labeled and unlabeled data in an offline training phase and then\u00a0\u2026", "total_citations": {"2010": 1, "2011": 0, "2012": 6, "2013": 6, "2014": 10, "2015": 18, "2016": 17, "2017": 25, "2018": 14, "2019": 19, "2020": 10, "2021": 20, "2022": 11, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:Y0pCki6q_DkC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/7682", "authors": ["Bin Cao", "Sinno Jialin Pan", "Yu Zhang", "Dit-Yan Yeung", "Qiang Yang"], "publication_date": "2010/7/3", "conference": "Twenty-Fourth AAAI Conference on Artificial Intelligence", "description": "Transfer learning aims at reusing the knowledge in some source tasks to improve the learning of a target task. Many transfer learning methods assume that the source tasks and the target task be related, even though many tasks are not related in reality. However, when two tasks are unrelated, the knowledge extracted from a source task may not help, and even hurt, the performance of a target task. Thus, how to avoid negative transfer and then ensure a\" safe transfer\" of knowledge is crucial in transfer learning. In this paper, we propose an Adaptive Transfer learning algorithm based on Gaussian Processes (AT-GP), which can be used to adapt the transfer learning schemes by automatically estimating the similarity between a source and a target task. The main contribution of our work is that we propose a new semi-parametric transfer kernel for transfer learning from a Bayesian perspective, and propose to learn the model with respect to the target task, rather than all tasks as in multi-task learning. We can formulate the transfer learning problem as a unified Gaussian Process (GP) model. The adaptive transfer ability of our approach is verified on both synthetic and real-world datasets.", "total_citations": {"2010": 2, "2011": 7, "2012": 8, "2013": 12, "2014": 4, "2015": 5, "2016": 7, "2017": 6, "2018": 10, "2019": 10, "2020": 20, "2021": 14, "2022": 27, "2023": 22}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:W7OEmFMy1HYC": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=24d349dd944dd1842897578b59f1c19ea61da68b", "authors": ["Sinno Jialin Pan", "Vincent Wenchen Zheng", "Qiang Yang", "Derek Hao Hu"], "publication_date": "2008/7/14", "journal": "Association for the advancement of artificial intelligence (AAAI) workshop", "volume": "6", "publisher": "The Association for the Advancement of Artificial Intelligence", "description": "The WiFi-based indoor localization problem (WILP) aims to detect the location of a client device given the signals received from various access points. WILP is a complex and very important task for many AI and ubiquitous computing applications. A major approach to solving this task is through machine learning, where upto-date labeled training data are required in a large scale indoor environment. In this paper, we identify WILP as a transfer learning problem, because the WiFi data are highly dependent on contextual changes. We show that WILP can be modeled as a transfer learning problem for regression modeling, where we identify several important cases of knowledge transfer that range from transferring the localization models over time, across space and across client devices. We also share our working experience in WILP and transfer learning research in a realistic problem solving setting, and discuss a data set we have made public for advancing this research.", "total_citations": {"2009": 2, "2010": 1, "2011": 2, "2012": 5, "2013": 9, "2014": 4, "2015": 10, "2016": 13, "2017": 13, "2018": 15, "2019": 18, "2020": 24, "2021": 15, "2022": 12, "2023": 7}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:IjCSPb-OGe4C": {"external_link": "https://cdn.aaai.org/AAAI/2007/AAAI07-176.pdf", "authors": ["Sinno Jialin Pan", "James T Kwok", "Qiang Yang", "Jeffrey Junfeng Pan"], "publication_date": "2007/7/22", "conference": "AAAI", "pages": "1108-1113", "description": "Accurately locating users in a wireless environment is an important task for many pervasive computing and AI applications, such as activity recognition. In a WiFi environment, a mobile device can be localized using signals received from various transmitters, such as access points (APs). Most localization approaches build a map between the signal space and the physical location space in a offline phase, and then using the received-signal-strength (RSS) map to estimate the location in an online phase. However, the map can be outdated when the signal-strength values change with time due to environmental dynamics. It is infeasible or expensive to repeat data calibration for reconstructing the RSS map. In such a case, it is important to adapt the model learnt in one time period to another time period without too much recalibration. In this paper, we present a location-estimation approach based on Manifold co-Regularization, which is a machine learning technique for building a mapping function between data. We describe LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization. We show that LeManCoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort. We illustrate LeMan-CoR\u2019s effectiveness in a real 802.11 WiFi environment.", "total_citations": {"2006": 1, "2007": 0, "2008": 10, "2009": 4, "2010": 5, "2011": 13, "2012": 6, "2013": 10, "2014": 13, "2015": 14, "2016": 9, "2017": 8, "2018": 11, "2019": 14, "2020": 16, "2021": 4, "2022": 4, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:9yKSN-GCB0IC": {"external_link": "https://cse.hkust.edu.hk/faculty/qyang/Docs/2008/intsys08.pdf", "authors": ["Qiang Yang", "Sinno Jialin Pan", "Vincent Wenchen Zheng"], "publication_date": "2008", "publisher": "IEEE Computer Society", "description": "Recent advances in pervasive computing and mobile technology have enabled accurate location and activity tracking of users wearing wireless devices indoors, where GPS isn\u2019t available. A practical way to do this is by leveraging the Wi-Fi signals that a mobile client receives from various access points. For example, many indoor location estimation techniques use received radio signal strength (RSS) values and radio signal propagation models to track users. Machine learning-based methods have proven among the most accurate. However, Wi-Fi data is noisy owing to the indoor environment\u2019s multipath and shadow fading effects. The data distribution changes constantly as people move and as temperature and humidity change. 1\u20133 Moreover, it can be expensive to collect and label RSS training data in a large building because it requires a human to walk with a mobile device, collecting RSS values and recording ground locations. 4, 5Despite intense research in indoor location estimation and activity recognition, the field lacks benchmark data that researchers and practitioners can use to compare their solutions. The 2007 Data Mining Contest (www. ist. unomaha. edu/icdm2007/contest), sponsored by the IEEE International Conference on Data Mining, provided the first realistic public benchmark data for indoor location estimation using RSS that a client device received from Wi-Fi access points. We collected the data sets in a 145.5 m\u00d7 37.5 m academic building at the Hong Kong University of Science and Technology. We divided the location into a grid of 247 units, each about 1.5 m\u00d7 1.5 m. We focused on discrete classification as well as\u00a0\u2026", "total_citations": {"2008": 4, "2009": 6, "2010": 10, "2011": 11, "2012": 9, "2013": 16, "2014": 13, "2015": 17, "2016": 15, "2017": 11, "2018": 8, "2019": 9, "2020": 5, "2021": 3, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:HoB7MX3m0LUC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/8458", "authors": ["Lili Zhao", "Sinno Jialin Pan", "Evan Wei Xiang", "Erheng Zhong", "Zhongqi Lu", "Qiang Yang"], "publication_date": "2013/6/29", "conference": "Twenty-Seventh AAAI Conference on Artificial Intelligence", "description": "Recommender systems, especially the newly launched ones, have to deal with the data-sparsity issue, where little existing rating information is available. Recently, transfer learning has been proposed to address this problem by leveraging the knowledge from related recommender systems where rich collaborative data are available. However, most previous transfer learning models assume that entity-correspondences across different systems are given as input, which means that for any entity (eg, a user or an item) in a target system, its corresponding entity in a source system is known. This assumption can hardly be satisfied in real-world scenarios where entity-correspondences across systems are usually unknown, and the cost of identifying them can be expensive. For example, it is extremely difficult to identify whether a user A from Facebook and a user B from Twitter are the same person. In this paper, we propose a framework to construct entity correspondence with limited budget by using active learning to facilitate knowledge transfer across recommender systems. Specifically, for the purpose of maximizing knowledge transfer, we first iteratively select entities in the target system based on our proposed criterion to query their correspondences in the source system. We then plug the actively constructed entity-correspondence mapping into a general transferred collaborative-filtering model to improve recommendation quality. We perform extensive experiments on real world datasets to verify the effectiveness of our proposed framework for this cross-system recommendation problem.", "total_citations": {"2012": 1, "2013": 0, "2014": 7, "2015": 11, "2016": 18, "2017": 17, "2018": 15, "2019": 9, "2020": 16, "2021": 11, "2022": 15, "2023": 13}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:zYLM7Y9cAGgC": {"external_link": "https://cdn.aaai.org/AAAI/2008/AAAI08-226.pdf", "authors": ["Vincent Wenchen Zheng", "Sinno Jialin Pan", "Qiang Yang", "Jeffrey Junfeng Pan"], "publication_date": "2008/7/13", "journal": "AAAI", "volume": "8", "pages": "1427-1432", "description": "In this paper, we propose a latent multi-task learning algorithm to solve the multi-device indoor localization problem. Traditional indoor localization systems often assume that the collected signal data distributions are fixed, and thus the localization model learned on one device can be used on other devices without adaptation. However, by empirically studying the signal variation over different devices, we found this assumption to be invalid in practice. To solve this problem, we treat multiple devices as multiple learning tasks, and propose a multi-task learning algorithm. Different from algorithms assuming that the hypotheses learned from the original data space for related tasks can be similar, we only require the hypotheses learned in a latent feature space are similar. To establish our algorithm, we employ an alternating optimization approach to iteratively learn feature mappings and multi-task regression models for the devices. We apply our latent multi-task learning algorithm to real-world indoor localization data and demonstrate its effectiveness.", "total_citations": {"2008": 1, "2009": 5, "2010": 5, "2011": 9, "2012": 11, "2013": 9, "2014": 10, "2015": 5, "2016": 9, "2017": 13, "2018": 6, "2019": 6, "2020": 13, "2021": 5, "2022": 7, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:PoWvk5oyLR8C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3459637.3482315", "authors": ["Yuntao Du", "Jindong Wang", "Wenjie Feng", "Sinno Pan", "Tao Qin", "Renjun Xu", "Chongjun Wang"], "publication_date": "2021/10/26", "book": "Proceedings of the 30th ACM International Conference on Information & Knowledge Management", "pages": "402-411", "description": "Time series has wide applications in the real world and is known to be difficult to forecast. Since its statistical properties change over time, its distribution also changes temporally, which will cause severe distribution shift problem to existing methods. However, it remains unexplored to model the time series in the distribution perspective. In this paper, we term this as Temporal Covariate Shift (TCS). This paper proposes Adaptive RNNs (AdaRNN) to tackle the TCS problem by building an adaptive model that generalizes well on the unseen test data. AdaRNN is sequentially composed of two novel algorithms. First, we propose Temporal Distribution Characterization to better characterize the distribution information in the TS. Second, we propose Temporal Distribution Matching to reduce the distribution mismatch in TS to learn the adaptive TS model. AdaRNN is a general framework with flexible distribution distances\u00a0\u2026", "total_citations": {"2021": 3, "2022": 34, "2023": 65}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:UeHWp8X0CEIC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1409635.1409640", "authors": ["Derek Hao Hu", "Sinno Jialin Pan", "Vincent Wenchen Zheng", "Nathan Nan Liu", "Qiang Yang"], "publication_date": "2008/9/21", "conference": "Proceedings of the 10th international conference on Ubiquitous computing", "pages": "30-39", "publisher": "ACM", "description": "Recognizing and understanding the activities of people from sensor readings is an important task in ubiquitous computing. Activity recognition is also a particularly difficult task because of the inherent uncertainty and complexity of the data collected by the sensors. Many researchers have tackled this problem in an overly simplistic setting by assuming that users often carry out single activities one at a time or multiple activities consecutively, one after another. However, so far there has been no formal exploration on the degree in which humans perform concurrent or interleaving activities, and no thorough study on how to detect multiple goals in a real world scenario. In this article, we ask the fundamental questions of whether users often carry out multiple concurrent and interleaving activities or single activities in their daily life, and if so, whether such complex behavior can be detected accurately using sensors. We\u00a0\u2026", "total_citations": {"2008": 1, "2009": 8, "2010": 9, "2011": 15, "2012": 11, "2013": 4, "2014": 10, "2015": 6, "2016": 6, "2017": 7, "2018": 8, "2019": 8, "2020": 4, "2021": 0, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:1yQoGdGgb4wC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/10733", "authors": ["Haiyan Yin", "Sinno Pan"], "publication_date": "2017/2/12", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "31", "issue": "1", "description": "The process for transferring knowledge of multiple reinforcement learning policies into a single multi-task policy via distillation technique is known as policy distillation. When policy distillation is under a deep reinforcement learning setting, due to the giant parameter size and the huge state space for each task domain, it requires extensive computational efforts to train the multi-task policy network. In this paper, we propose a new policy distillation architecture for deep reinforcement learning, where we assume that each task uses its task-specific high-level convolutional features as the inputs to the multi-task policy network. Furthermore, we propose a new sampling framework termed hierarchical prioritized experience replay to selectively choose experiences from the replay memories of each task domain to perform learning on the network. With the above two attempts, we aim to accelerate the learning of the multi-task policy network while guaranteeing a good performance. We use Atari 2600 games as testing environment to demonstrate the efficiency and effectiveness of our proposed solution for policy distillation", "total_citations": {"2017": 5, "2018": 9, "2019": 12, "2020": 18, "2021": 16, "2022": 17, "2023": 20}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:738O_yMBCRsC": {"external_link": "https://aclanthology.org/D14-1120.pdf", "authors": ["Jianfeng Si", "Arjun Mukherjee", "Bing Liu", "Sinno Jialin Pan", "Qing Li", "Huayi Li"], "publication_date": "2014", "journal": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "pages": "1139-1145", "description": "In this paper we first exploit cash-tags (\u201c$\u201d followed by stocks\u2019 ticker symbols) in Twitter to build a stock network, where nodes are stocks connected by edges when two stocks co-occur frequently in tweets. We then employ a labeled topic model to jointly model both the tweets and the network structure to assign each node and each edge a topic respectively. This Semantic Stock Network (SSN) summarizes discussion topics about stocks and stock relations. We further show that social sentiment about stock (node) topics and stock relationship (edge) topics are predictive of each stock\u2019s market. For prediction, we propose to regress the topic-sentiment time-series and the stock\u2019s price time series. Experimental results demonstrate that topic sentiments from close neighbors are able to help improve the prediction of a stock markedly.", "total_citations": {"2015": 9, "2016": 4, "2017": 16, "2018": 10, "2019": 12, "2020": 15, "2021": 10, "2022": 6, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:WqliGbK-hY8C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7917871/", "authors": ["Yanbing Yang", "Jie Hao", "Jun Luo", "Sinno Jialin Pan"], "publication_date": "2017/3/13", "conference": "2017 IEEE International Conference on Pervasive Computing and Communications (PerCom)", "pages": "247-256", "publisher": "IEEE", "description": "As a key component of building management and security, occupancy inference through smart sensing has attracted a lot of research attentions for nearly two decades. Nevertheless, existing solutions mostly rely on either pre-deployed infrastructures or user device participation, thus hampering their wide adoption. This paper presents CeilingSee, a dedicated occupancy inference system free of heavy infrastructure deployments and user involvements. Building upon existing LED lighting systems, CeilingSee converts part of the ceiling-mounted LED luminaires to act as sensors, sensing the variances in diffuse reflection caused by occupants. In realizing CeilingSee, we first re-design the LED driver to leverage LED's photoelectric effect so as to transform a light emitter to a light sensor. In order to produce accurate occupancy inference, we then engineer efficient learning algorithms to fuse sensing information\u00a0\u2026", "total_citations": {"2017": 4, "2018": 19, "2019": 17, "2020": 17, "2021": 11, "2022": 5, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:5awf1xo2G04C": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0004370216301540", "authors": ["Lili Zhao", "Sinno Jialin Pan", "Qiang Yang"], "publication_date": "2017/4/1", "journal": "Artificial Intelligence", "volume": "245", "pages": "38-55", "publisher": "Elsevier", "description": "In the past decade, artificial intelligence (AI) techniques have been successfully applied to recommender systems employed in many e-commerce companies, such as Amazon, eBay, Netflix, etc., which aim to provide personalized recommendations on products or services. Among various AI-based recommendation techniques, collaborative filtering has proven to be one of the most promising methods. However, most collaborative-filtering-based recommender systems, especially the newly launched ones, have trouble making accurate recommendations for users. This is caused by the data sparsity issue in recommender systems, where little existing rating information is available. To address this issue, one of the most effective practices is applying transfer learning techniques by leveraging relatively rich collaborative data knowledge from related systems, which have been well running. Previous transfer learning\u00a0\u2026", "total_citations": {"2017": 2, "2018": 9, "2019": 14, "2020": 15, "2021": 15, "2022": 14, "2023": 8}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:hFOr9nPyWt4C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2339530.2339701", "authors": ["Lianghao Li", "Xiaoming Jin", "Sinno Jialin Pan", "Jian-Tao Sun"], "publication_date": "2012", "description": "Active learning has been proven to be effective in reducing labeling efforts for supervised learning. However, existing active learning work has mainly focused on training models for a single domain. In practical applications, it is common to simultaneously train classifiers for multiple domains. For example, some merchant web sites (like Amazon.com) may need a set of classifiers to predict the sentiment polarity of product reviews collected from various domains (e.g., electronics, books, shoes). Though different domains have their own unique features, they may share some common latent features. If we apply active learning on each domain separately, some data instances selected from different domains may contain duplicate knowledge due to the common features. Therefore, how to choose the data from multiple domains to label is crucial to further reducing the human labeling efforts in multi-domain learning. In\u00a0\u2026", "total_citations": {"2012": 1, "2013": 3, "2014": 6, "2015": 7, "2016": 8, "2017": 9, "2018": 8, "2019": 6, "2020": 12, "2021": 5, "2022": 5, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:XiVPGOgt02cC": {"external_link": "http://www.cse.cuhk.edu.hk/~sinnopan/publications/[IJCAI16]Matrix%20Factorization+%20for%20Movie%20Recommendation.pdf", "authors": ["Lili Zhao", "Zhongqi Lu", "Sinno Jialin Pan", "Qiang Yang"], "publication_date": "2016/7/9", "conference": "IJCAI", "pages": "3945-3951", "description": "We present a novel model for movie recommendations using additional visual features extracted from pictural data like posters and still frames, to better understand movies. In particular, several context-based methods for recommendation are shown to be special cases of our proposed framework. Unlike existing context-based approaches, our method can be used to incorporate visual features\u2013features that are lacking in existing contextbased approaches for movie recommendations. In reality, movie posters and still frames provide us with rich knowledge for understanding movies as well as users\u2019 preferences. For instance, user may want to watch a movie at the minute when she/he finds some released posters or still frames attractive. Unfortunately, such unique features cannot be revealed from rating data or other forms of context being used in most of existing methods. In this paper, we take a step forward in this direction and investigate both low-level and high-level visual features from the movie posters and still frames for further improvement of recommendation methods. Extensive experiments on real world datasets show that our approach leads to significant improvement over several state-of-the-art methods.", "total_citations": {"2016": 2, "2017": 5, "2018": 10, "2019": 16, "2020": 12, "2021": 10, "2022": 10, "2023": 9}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:p2g8aNsByqUC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6774431/", "authors": ["Li Cheng", "Sinno Jialin Pan"], "publication_date": "2014/12", "journal": "IEEE transactions on neural networks and learning systems", "volume": "25", "issue": "12", "pages": "2240-2249", "publisher": "IEEE", "description": "In real-life problems, the following semi-supervised domain adaptation scenario is often encountered: we have full access to some source data, which is usually very large; the target data distribution is under certain unknown transformation of the source data distribution; meanwhile, only a small fraction of the target instances come with labels. The goal is to learn a prediction model by incorporating information from the source domain that is able to generalize well on the target test instances. We consider an explicit form of transformation functions and especially linear transformations that maps examples from the source to the target domain, and we argue that by proper preprocessing of the data from both source and target domains, the feasible transformation functions can be characterized by a set of rotation matrices. This naturally leads to an optimization formulation under the special orthogonal group constraints\u00a0\u2026", "total_citations": {"2015": 2, "2016": 10, "2017": 7, "2018": 6, "2019": 11, "2020": 12, "2021": 7, "2022": 14, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:Tiz5es2fbqcC": {"external_link": "http://proceedings.mlr.press/v32/tan14.html", "authors": ["Mingkui Tan", "Ivor W. Tsang", "Li Wang", "Bart Vandereycken", "Sinno Jialin Pan"], "publication_date": "2014/6", "conference": "31st International Conference on Machine Learning", "description": "Low rank matrix recovery is a fundamental task in many real-world applications. The performance of existing methods, however, deteriorates significantly when applied to ill-conditioned or large-scale matrices. In this paper, we therefore propose an efficient method, called Riemannian Pursuit (RP), that aims to address these two problems simultaneously. Our method consists of a sequence of fixed-rank optimization problems. Each subproblem, solved by a nonlinear Riemannian conjugate gradient method, aims to correct the solution in the most important subspace of increasing size. Theoretically, RP converges linearly under mild conditions and experimental results show that it substantially outperforms existing methods when applied to large-scale and ill-conditioned matrices.", "total_citations": {"2014": 1, "2015": 13, "2016": 11, "2017": 6, "2018": 9, "2019": 7, "2020": 5, "2021": 7, "2022": 9, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:qjMakFHDy7sC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0004370207000938", "authors": ["Rong Pan", "Qiang Yang", "Sinno Jialin Pan"], "publication_date": "2007/11/1", "journal": "Artificial Intelligence", "volume": "171", "issue": "16-17", "pages": "1039-1068", "publisher": "Elsevier", "description": "Case-based reasoning relies heavily on the availability of a highly competent case base to make high-quality decisions. However, good case bases are difficult to come by. In this paper, we present a novel algorithm for automatically mining a high-quality case base from a raw case set that can preserve and sometimes even improve the competence of case-based reasoning. In this paper, we analyze two major problems in previous case-mining algorithms. The first problem is caused by noisy cases such that the nearest neighbor cases of a problem may not provide correct solutions. The second problem is caused by uneven case distribution, such that similar problems may have dissimilar solutions. To solve these problems, we develop a theoretical framework for the error bound in case-based reasoning, and propose a novel case-base mining algorithm guided by the theoretical results that returns a high-quality\u00a0\u2026", "total_citations": {"2008": 5, "2009": 9, "2010": 6, "2011": 10, "2012": 3, "2013": 5, "2014": 9, "2015": 4, "2016": 3, "2017": 3, "2018": 3, "2019": 2, "2020": 4, "2021": 2, "2022": 3, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:VLnqNzywnoUC": {"external_link": "https://aclanthology.org/P18-1202/", "authors": ["Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2018/7", "conference": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "pages": "2171-2181", "description": "Fine-grained opinion analysis aims to extract aspect and opinion terms from each sentence for opinion summarization. Supervised learning methods have proven to be effective for this task. However, in many domains, the lack of labeled data hinders the learning of a precise extraction model. In this case, unsupervised domain adaptation methods are desired to transfer knowledge from the source domain to any unlabeled target domain. In this paper, we develop a novel recursive neural network that could reduce domain shift effectively in word level through syntactic relations. We treat these relations as invariant \u201cpivot information\u201d across domains to build structural correspondences and generate an auxiliary task to predict the relation between any two adjacent words in the dependency tree. In the end, we demonstrate state-of-the-art results on three benchmark datasets.", "total_citations": {"2018": 1, "2019": 5, "2020": 12, "2021": 16, "2022": 20, "2023": 17}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:N5tVd3kTz84C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3097983.3098136", "authors": ["Sulin Liu", "Sinno Jialin Pan", "Qirong Ho"], "publication_date": "2017/8/13", "conference": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "pages": "937-946", "publisher": "ACM", "description": "Multi-task learning aims to learn multiple tasks jointly by exploiting their relatedness to improve the generalization performance for each task. Traditionally, to perform multi-task learning, one needs to centralize data from all the tasks to a single machine. However, in many real-world applications, data of different tasks may be geo-distributed over different local machines. Due to heavy communication caused by transmitting the data and the issue of data privacy and security, it is impossible to send data of different task to a master machine to perform multi-task learning. Therefore, in this paper, we propose a distributed multi-task learning framework that simultaneously learns predictive models for each task as well as task relationships between tasks alternatingly in the parameter server paradigm. In our framework, we first offer a general dual form for a family of regularized multi-task relationship learning methods\u00a0\u2026", "total_citations": {"2017": 4, "2018": 9, "2019": 8, "2020": 12, "2021": 11, "2022": 18, "2023": 9}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:J-pR_7NvFogC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/10211", "authors": ["Joey Tianyi Zhou", "Sinno Jialin Pan", "Ivor W Tsang", "Shen-Shyang Ho"], "publication_date": "2016/3/2", "conference": "Thirtieth AAAI Conference on Artificial Intelligence", "description": "Most existing heterogeneous transfer learning (HTL) methods for cross-language text classification rely on sufficient cross-domain instance correspondences to learn a mapping across heterogeneous feature spaces, and assume that such correspondences are given in advance. However, in practice, correspondences between domains are usually unknown. In this case, extensively manual efforts are required to establish accurate correspondences across multilingual documents based on their content and meta-information. In this paper, we present a general framework to integrate active learning to construct correspondences between heterogeneous domains for HTL, namely HTL through active correspondences construction (HTLA). Based on this framework, we develop a new HTL method. On top of the new HTL method, we further propose a strategy to actively construct correspondences between domains. Extensive experiments are conducted on various multilingual text classification tasks to verify the effectiveness of HTLA.", "total_citations": {"2016": 5, "2017": 4, "2018": 13, "2019": 16, "2020": 9, "2021": 10, "2022": 6, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:tzM49s52ZIMC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/11721", "authors": ["Joey Tianyi Zhou", "Kai Di", "Jiawei Du", "Xi Peng", "Hao Yang", "Sinno Jialin Pan", "Ivor W Tsang", "Yong Liu", "Zheng Qin", "Rick Siow Mong Goh"], "publication_date": "2018", "conference": "AAAI", "description": "The iterative hard-thresholding algorithm (ISTA) is one of the most popular optimization solvers to achieve sparse codes. However, ISTA suffers from following problems: 1) ISTA employs non-adaptive updating strategy to learn the parameters on each dimension with a fixed learning rate. Such a strategy may lead to inferior performance due to the scarcity of diversity; 2) ISTA does not incorporate the historical information into the updating rules, and the historical information has been proven helpful to speed up the convergence. To address these challenging issues, we propose a novel formulation of ISTA (named as adaptive ISTA) by introducing a novel\\textit {adaptive momentum vector}. To efficiently solve the proposed adaptive ISTA, we recast it as a recurrent neural network unit and show its connection with the well-known long short term memory (LSTM) model. With a new proposed unit, we present a neural network (termed SC2Net) to achieve sparse codes in an end-to-end manner. To the best of our knowledge, this is one of the first works to bridge the -solver and LSTM, and may provide novel insights in understanding model-based optimization and LSTM. Extensive experiments show the effectiveness of our method on both unsupervised and supervised tasks.", "total_citations": {"2018": 3, "2019": 17, "2020": 13, "2021": 14, "2022": 12, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:4OULZ7Gr8RgC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2505515.2505518", "authors": ["Yin Zhu", "Erheng Zhong", "Sinno Jialin Pan", "Xiao Wang", "Minzhe Zhou", "Qiang Yang"], "publication_date": "2013/10/27", "conference": "Proceedings of the 22nd ACM international conference on Information & Knowledge Management", "pages": "159-168", "publisher": "ACM", "description": "The study of users' social behaviors has gained much research attention since the advent of various social media such as Facebook, Renren and Twitter. A major kind of applications is to predict a user's future activities based on his/her historical social behaviors. In this paper, we focus on a fundamental task: to predict a user's future activity levels in a social network, e.g. weekly activeness, active or inactive. This problem is closely related to Social Customer Relationship Management (Social CRM). Compared to traditional CRM, the three properties: user diversity, social influence, and dynamic nature of social networks, raise new challenges and opportunities to Social CRM. Firstly, the user diversity property implies that a global predictive model may not be precise for all users. On the other hand, historical data of individual users are too sparse to build precisely personalized models. Secondly, the social influence\u00a0\u2026", "total_citations": {"2014": 7, "2015": 10, "2016": 8, "2017": 6, "2018": 6, "2019": 12, "2020": 3, "2021": 5, "2022": 3, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:Tyk-4Ss8FVUC": {"external_link": "https://cdn.aaai.org/AAAI/2008/AAAI08-219.pdf", "authors": ["Sinno Jialin Pan", "Dou Shen", "Qiang Yang", "James T Kwok"], "publication_date": "2008/7/13", "conference": "AAAI", "pages": "1383-1388", "description": "Machine learning approaches to indoor WiFi localization involve an offline phase and an online phase. In the offline phase, data are collected from an environment to build a localization model, which will be applied to new data collected in the online phase for location estimation. However, collecting the labeled data across an entire building would be too time consuming. In this paper, we present a novel approach to transferring the learning model trained on data from one area of a building to another. We learn a mapping function between the signal space and the location space by solving an optimization problem based on manifold learning techniques. A low-dimensional manifold is shared between data collected in different areas in an environment as a bridge to propagate the knowledge across the whole environment. With the help of the transferred knowledge, we can significantly reduce the amount of labeled data which are required for building the localization model. We test the effectiveness of our proposed solution in a real indoor WiFi environment.", "total_citations": {"2009": 3, "2010": 4, "2011": 4, "2012": 4, "2013": 2, "2014": 3, "2015": 4, "2016": 2, "2017": 6, "2018": 3, "2019": 7, "2020": 13, "2021": 2, "2022": 5, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:nb7KW1ujOQ8C": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/8721", "authors": ["Zhongqi Lu", "Yin Zhu", "Sinno Pan", "Evan Xiang", "Yujing Wang", "Qiang Yang"], "publication_date": "2014/6/19", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "28", "issue": "1", "description": "Transfer learning uses relevant auxiliary data to help the learning task in a target domain where labeled data is usually insufficient to train an accurate model. Given appropriate auxiliary data, researchers have proposed many transfer learning models. How to find such auxiliary data, however, is of little research so far. In this paper, we focus on the problem of auxiliary data retrieval, and propose a transfer learning framework that effectively selects helpful auxiliary data from an open knowledge space (eg the World Wide Web). Because there is no need of manually selecting auxiliary data for different target domain tasks, we call our framework Source Free Transfer Learning (SFTL). For each target domain task, SFTL framework iteratively queries for the helpful auxiliary data based on the learned model and then updates the model using the retrieved auxiliary data. We highlight the automatic constructions of queries and the robustness of the SFTL framework. Our experiments on 20NewsGroup dataset and a Google search snippets dataset suggest that the framework is capable of achieving comparable performance to those state-of-the-art methods with dedicated selections of auxiliary data.", "total_citations": {"2014": 1, "2015": 4, "2016": 6, "2017": 9, "2018": 4, "2019": 10, "2020": 8, "2021": 9, "2022": 4, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:LkGwnXOMwfcC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5453335/", "authors": ["Qian Xu", "Sinno Jialin Pan", "Hannah Hong Xue", "Qiang Yang"], "publication_date": "2011/5", "journal": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "volume": "8", "issue": "3", "pages": "748-759", "publisher": "IEEE", "description": "Protein subcellular localization is concerned with predicting the location of a protein within a cell using computational methods. The location information can indicate key functionalities of proteins. Thus, accurate prediction of subcellular localizations of proteins can help the prediction of protein functions and genome annotations, as well as the identification of drug targets. Machine learning methods such as Support Vector Machines (SVMs) have been used in the past for the problem of protein subcellular localization, but have been shown to suffer from a lack of annotated training data in each species under study. To overcome this data sparsity problem, we observe that because some of the organisms may be related to each other, there may be some commonalities across different organisms that can be discovered and used to help boost the data in each localization task. In this paper, we formulate protein\u00a0\u2026", "total_citations": {"2009": 1, "2010": 2, "2011": 4, "2012": 4, "2013": 10, "2014": 2, "2015": 1, "2016": 2, "2017": 4, "2018": 7, "2019": 3, "2020": 3, "2021": 5, "2022": 10, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:LjlpjdlvIbIC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8057096/", "authors": ["Jin Wang", "Nicholas Tan", "Jun Luo", "Sinno Jialin Pan"], "publication_date": "2017/5/1", "conference": "IEEE INFOCOM 2017-IEEE Conference on Computer Communications", "pages": "1-9", "publisher": "IEEE", "description": "Given the ever-expanding scale of WiFi deployments in metropolitan areas, we have reached the point where accurate GPS-free outdoor localization becomes possible by relying solely on the WiFi infrastructure. Nevertheless, the existing industrial practices do not seem to have the right implementation to achieve an adequate accuracy, while the academic researches that are mostly attracted by indoor localization have largely neglected this outdoor aspect. In this paper, we propose WOLoc (WiFi-only Outdoor Localization) as a solution that offers meter-level accuracy, by holistically treating the large number of WiFi hotspot labels gather by crowdsensing. On one hand, we do not take these labels as fingerprints as it is almost impossible to extend indoor localization mechanisms by fingerprinting metropolitan areas. On the other hand, we avoid the over-simplified local synthesis methods (e.g., centroid) that\u00a0\u2026", "total_citations": {"2017": 6, "2018": 9, "2019": 12, "2020": 7, "2021": 8, "2022": 9, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:tKAzc9rXhukC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3108257", "authors": ["Fuzhen Zhuang", "Xiaohu Cheng", "Ping Luo", "Sinno Jialin Pan", "Qing He"], "publication_date": "2018/1/18", "journal": "ACM Transactions on Intelligent Systems and Technology (TIST)", "volume": "9", "issue": "2", "pages": "16", "publisher": "ACM", "description": "Transfer learning has gained a lot of attention and interest in the past decade. One crucial research issue in transfer learning is how to find a good representation for instances of different domains such that the divergence between domains can be reduced with the new representation. Recently, deep learning has been proposed to learn more robust or higher-level features for transfer learning. In this article, we adapt the autoencoder technique to transfer learning and propose a supervised representation learning method based on double encoding-layer autoencoder. The proposed framework consists of two encoding layers: one for embedding and the other one for label encoding. In the embedding layer, the distribution distance of the embedded instances between the source and target domains is minimized in terms of KL-Divergence. In the label encoding layer, label information of the source domain is encoded\u00a0\u2026", "total_citations": {"2018": 1, "2019": 6, "2020": 9, "2021": 9, "2022": 14, "2023": 13}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:uWiczbcajpAC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0004370219301493", "authors": ["Joey Tianyi Zhou", "Sinno Jialin Pan", "Ivor W Tsang"], "publication_date": "2019/10/1", "journal": "Artificial Intelligence", "volume": "275", "pages": "310-328", "publisher": "Elsevier", "description": "Most previous methods in heterogeneous transfer learning learn a cross-domain feature mapping between different domains based on some cross-domain instance-correspondences. Such instance-correspondences are assumed to be representative in the source domain and the target domain, respectively. However, in many real-world scenarios, this assumption may not hold. As a result, the constructed feature mapping may not be precise, and thus the transformed source-domain labeled data using the feature mapping are not useful to build an accurate classifier for the target domain. In this paper, we offer a new heterogeneous transfer learning framework named Hybrid Heterogeneous Transfer Learning (HHTL), which allows the selection of corresponding instances across domains to be biased to the source or target domain. Our basic idea is that though the corresponding instances are biased in the original\u00a0\u2026", "total_citations": {"2019": 4, "2020": 15, "2021": 7, "2022": 14, "2023": 9}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:hqOjcs7Dif8C": {"external_link": "https://aclanthology.org/I11-1012.pdf", "authors": ["Bin Chen", "Jian Su", "Sinno Jialin Pan", "Chew Lim Tan"], "publication_date": "2011", "journal": "Proceedings of 5th International Joint Conference on Natural Language Processing", "pages": "102-110", "description": "Event coreference is an important and complicated task in cascaded event template extraction and other natural language processing tasks. Despite its importance, it was merely discussed in previous studies. In this paper, we present a globally optimized coreference resolution system dedicated to various sophisticated event coreference phenomena. Seven resolvers for both event and object coreference cases are utilized, which include three new resolvers for event coreference resolution. Three enhancements are further proposed at both mention pair detection and chain formation levels. First, the object coreference resolvers are used to effectively reduce the false positive cases for event coreference. Second, A revised instance selection scheme is proposed to improve link level mention-pair model performances. Last but not least, an efficient and globally optimized graph partitioning model is employed for coreference chain formation using spectral partitioning which allows the incorporation of pronoun coreference information. The three techniques contribute to a significant improvement of 8.54% in B3 F-score for event coreference resolution on OntoNotes 2.0 corpus.", "total_citations": {"2012": 3, "2013": 9, "2014": 4, "2015": 10, "2016": 7, "2017": 4, "2018": 4, "2019": 2, "2020": 1, "2021": 3, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:_Re3VWB3Y0AC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/11838", "authors": ["Mengchen Zhao", "Bo An", "Yaodong Yu", "Sulin Liu", "Sinno Jialin Pan"], "publication_date": "2018/4/26", "conference": "Thirty-Second AAAI Conference on Artificial Intelligence", "description": "Multi-task learning (MTL) is a machine learning paradigm that improves the performance of each task by exploiting useful information contained in multiple related tasks. However, the relatedness of tasks can be exploited by attackers to launch data poisoning attacks, which has been demonstrated a big threat to single-task learning. In this paper, we provide the first study on the vulnerability of MTL. Specifically, we focus on multi-task relationship learning (MTRL) models, a popular subclass of MTL models where task relationships are quantized and are learned directly from training data. We formulate the problem of computing optimal poisoning attacks on MTRL as a bilevel program that is adaptive to arbitrary choice of target tasks and attacking tasks. We propose an efficient algorithm called PATOM for computing optimal attack strategies. PATOM leverages the optimality conditions of the subproblem of MTRL to compute the implicit gradients of the upper level objective function. Experimental results on real-world datasets show that MTRL models are very sensitive to poisoning attacks and the attacker can significantly degrade the performance of target tasks, by either directly poisoning the target tasks or indirectly poisoning the related tasks exploiting the task relatedness. We also found that the tasks being attacked are always strongly correlated, which provides a clue for defending against such attacks.", "total_citations": {"2018": 5, "2019": 6, "2020": 9, "2021": 9, "2022": 10, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:epqYDVWIO7EC": {"external_link": "https://www.jmlr.org/papers/volume20/13-580/13-580.pdf", "authors": ["Joey Tianyi Zhou", "Ivor W Tsang", "Sinno Jialin Pan", "Mingkui Tan"], "publication_date": "2019", "journal": "Journal of Machine Learning Research", "volume": "20", "issue": "57", "pages": "1-31", "description": "A crucial issue in heterogeneous domain adaptation (HDA) is the ability to learn a feature mapping between different types of features across domains. Inspired by language translation, a word translated from one language corresponds to only a few words in another language, we present an efficient method named Sparse Heterogeneous Feature Representation (SHFR) in this paper for multi-class HDA to learn a sparse feature transformation between domains with multiple classes. Specifically, we formulate the problem of learning the feature transformation as a compressed sensing problem by building multiple binary classifiers in the target domain as various measurement sensors, which are decomposed from the target multi-class classification problem. We show that the estimation error of the learned transformation decreases with the increasing number of binary classifiers. In other words, for adaptation across heterogeneous domains to be successful, it is necessary to construct a sufficient number of incoherent binary classifiers from the original multi-class classification problem. To achieve this, we propose to apply the error correcting output correcting (ECOC) scheme to generate incoherent classifiers. To speed up the learning of the feature transformation across domains, we apply an efficient batch-mode algorithm to solve the resultant nonnegative sparse recovery problem. Theoretically, we present a generalization error bound of our proposed HDA method under a multi-class setting. Lastly, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate the superiority of our proposed method over existing\u00a0\u2026", "total_citations": {"2019": 8, "2020": 15, "2021": 13, "2022": 6, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:ILKRHgRFtOwC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/6460", "authors": ["Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2020/4/3", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "34", "issue": "05", "pages": "9225-9232", "description": "Information extraction (IE) aims to produce structured information from an input text, eg, Named Entity Recognition and Relation Extraction. Various attempts have been proposed for IE via feature engineering or deep learning. However, most of them fail to associate the complex relationships inherent in the task itself, which has proven to be especially crucial. For example, the relation between 2 entities is highly dependent on their entity types. These dependencies can be regarded as complex constraints that can be efficiently expressed as logical rules. To combine such logic reasoning capabilities with learning capabilities of deep neural networks, we propose to integrate logical knowledge in the form of first-order logic into a deep learning system, which can be trained jointly in an end-to-end manner. The integrated framework is able to enhance neural outputs with knowledge regularization via logic rules, and at the same time update the weights of logic rules to comply with the characteristics of the training data. We demonstrate the effectiveness and generalization of the proposed model on multiple IE tasks.", "total_citations": {"2020": 5, "2021": 14, "2022": 14, "2023": 10}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:EYYDruWGBe4C": {"external_link": "https://proceedings.neurips.cc/paper_files/paper/2019/hash/f8e59f4b2fe7c5705bf878bbd494ccdf-Abstract.html", "authors": ["Shangyu Chen", "Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2019", "conference": "Advances in Neural Information Processing Systems", "pages": "3916-3926", "description": "Tremendous amount of parameters make deep neural networks impractical to be deployed for edge-device-based real-world applications due to the limit of computational power and storage space. Existing studies have made progress on learning quantized deep models to reduce model size and energy consumption, ie converting full-precision weights ('s) into discrete values ('s) in a supervised training manner. However, the training process for quantization is non-differentiable, which leads to either infinite or zero gradients () wrt . To address this problem, most training-based quantization methods use the gradient wrt () with clipping to approximate  by Straight-Through-Estimator (STE) or manually design their computation. However, these methods only heuristically make training-based quantization applicable, without further analysis on how the approximated gradients can assist training of a quantized network. In this paper, we propose to learn  by a neural network. Specifically, a meta network is trained using  and  as inputs, and outputs  for subsequent weight updates. The meta network is updated together with the original quantized network. Our proposed method alleviates the problem of non-differentiability, and can be trained in an end-to-end manner. Extensive experiments are conducted with CIFAR10/100 and ImageNet on various deep networks to demonstrate the advantage of our proposed method in terms of a faster convergence rate and better performance. Codes are released at:\\texttt {https://github. com/csyhhu/MetaQuant}", "total_citations": {"2019": 1, "2020": 7, "2021": 10, "2022": 11, "2023": 14}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:t6usbXjVLHcC": {"external_link": "https://www.ijcai.org/Proceedings/16/Papers/535.pdf", "authors": ["Zhongqi Lu", "Sinno Jialin Pan", "Yong Li", "Jie Jiang", "Qiang Yang"], "publication_date": "2016/7/9", "conference": "IJCAI", "pages": "3804-3810", "description": "Accurate user profiling is important for an online recommender system to provide proper personalized recommendations to its users. In many realworld scenarios, the user\u2019s interests towards the items may change over time. Therefore, a dynamic and evolutionary user profile is needed. In this work, we come up with a novel evolutionary view of user\u2019s profile by proposing a Collaborative Evolution (CE) model, which learns the evolution of user\u2019s profiles through the sparse historical data in recommender systems and outputs the prospective user profile of the future. To verify the effectiveness of the proposed model, we conduct experiments on a real-world dataset, which is obtained from the online shopping website of Tencent Inc.\u2014www. 51buy. com and contains more than 1 million users\u2019 shopping records in a time span of more than 180 days. Experimental analyses demonstrate that our proposed CE model can be used to make better future recommendations compared to several stateof-the-art methods.", "total_citations": {"2016": 1, "2017": 3, "2018": 11, "2019": 7, "2020": 6, "2021": 5, "2022": 6, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:ldfaerwXgEUC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2457465.2457467", "authors": ["Sinno Jialin Pan", "Zhiqiang Toh", "Jian Su"], "publication_date": "2013/5/17", "journal": "ACM Transactions on Information Systems (TOIS)", "volume": "31", "issue": "2", "pages": "1-27", "publisher": "ACM", "description": "Named Entity Recognition (NER) is a fundamental task in information extraction from unstructured text. Most previous machine-learning-based NER systems are domain-specific, which implies that they may only perform well on some specific domains (e.g., Newswire) but tend to adapt poorly to other related but different domains (e.g., Weblog). Recently, transfer learning techniques have been proposed to NER. However, most transfer learning approaches to NER are developed for binary classification, while NER is a multiclass classification problem in nature. Therefore, one has to first reduce the NER task to multiple binary classification tasks and solve them independently. In this article, we propose a new transfer learning method, named Transfer Joint Embedding (TJE), for cross-domain multiclass classification, which can fully exploit the relationships between classes (labels), and reduce domain difference in\u00a0\u2026", "total_citations": {"2014": 2, "2015": 0, "2016": 4, "2017": 0, "2018": 3, "2019": 6, "2020": 9, "2021": 7, "2022": 7, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:Z5m8FVwuT1cC": {"external_link": "http://www.cse.cuhk.edu.hk/~sinnopan/publications/[IJCAI19]A%20Novel%20Distribution-Embedded%20Neural%20Network%20for%20Sensor-Based%20Activity%20Recognition.pdf", "authors": ["Hangwei Qian", "Sinno Jialin Pan", "Bingshui Da", "Chunyan Miao"], "publication_date": "2019/8/10", "journal": "IJCAI 2019", "pages": "5614-5620", "description": "Feature-engineering-based machine learning models and deep learning models have been explored for wearable-sensor-based human activity recognition. For both types of methods, one crucial research issue is how to extract proper features from the partitioned segments of multivariate sensor readings. Existing methods have different drawbacks: 1) feature-engineering-based methods are able to extract meaningful features, such as statistical or structural information underlying the segments, but usually require manual designs of features for different applications, which is time consuming, and 2) deep learning models are able to learn temporal and/or spatial features from the sensor data automatically, but fail to capture statistical information. In this paper, we propose a novel deep learning model to automatically learn meaningful features including statistical features, temporal features and spatial correlation features for activity recognition in a unified framework. Extensive experiments are conducted on four datasets to demonstrate the effectiveness of our proposed method compared with state-of-the-art baselines.", "total_citations": {"2019": 1, "2020": 2, "2021": 8, "2022": 14, "2023": 14}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:EkHepimYqZsC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/4880", "authors": ["Haoliang Li", "Sinno Jialin Pan", "Renjie Wan", "Alex C Kot"], "publication_date": "2019/7/17", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "33", "issue": "01", "pages": "8602-8609", "description": "Heterogeneous Transfer Learning (HTL) aims to solve transfer learning problems where a source domain and a target domain are of heterogeneous types of features. Most existing HTL approaches either explicitly learn feature mappings between the heterogeneous domains or implicitly reconstruct heterogeneous cross-domain features based on matrix completion techniques. In this paper, we propose a new HTL method based on a deep matrix completion framework, where kernel embedding of distributions is trained in an adversarial manner for learning heterogeneous features across domains. We conduct extensive experiments on two different vision tasks to demonstrate the effectiveness of our proposed method compared with a number of baseline methods.", "total_citations": {"2019": 4, "2020": 4, "2021": 13, "2022": 13, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:j8SEvjWlNXcC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8392372/", "authors": ["Jin Wang", "Jun Luo", "Sinno Jialin Pan", "Aixin Sun"], "publication_date": "2019/4/1", "journal": "IEEE Transactions on Mobile Computing", "volume": "18", "issue": "4", "pages": "896-909", "publisher": "IEEE", "description": "The ever-expanding scale of WiFi deployments in metropolitan areas has made accurate GPS-free outdoor localization possible by relying solely on the WiFi infrastructure. Nevertheless, neither academic researches nor existing industrial practices seem to provide a satisfactory solution or implementation. In this paper, we propose WOLoc (WiFi-only Outdoor Localization) as a learning-based outdoor localization solution using only WiFi hotspots labeled by crowdsensing. On one hand, we do not take these labels as fingerprints as it is almost impossible to extend indoor localization mechanisms by fingerprinting metropolitan areas. On the other hand, we avoid the over-simplified local synthesis methods (e.g., centroid) that significantly lose the information contained in the labels. Instead, WOLoc adopts a semi-supervised manifold learning approach that accommodates all the labeled and unlabeled data for a given\u00a0\u2026", "total_citations": {"2018": 1, "2019": 11, "2020": 6, "2021": 6, "2022": 4, "2023": 10}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:HE397vMXCloC": {"external_link": "https://arxiv.org/abs/1605.04034", "authors": ["Joey Tianyi Zhou", "Xinxing Xu", "Sinno Jialin Pan", "Ivor W Tsang", "Zheng Qin", "Rick Siow Mong Goh"], "publication_date": "2016", "conference": "IJCAI", "pages": "2414-2420", "description": "Most existing learning to hash methods assume that there are sufficient data, either labeled or unlabeled, on the domain of interest (i.e., the target domain) for training. However, this assumption cannot be satisfied in some real-world applications. To address this data sparsity issue in hashing, inspired by transfer learning, we propose a new framework named Transfer Hashing with Privileged Information (THPI). Specifically, we extend the standard learning to hash method, Iterative Quantization (ITQ), in a transfer learning manner, namely ITQ+. In ITQ+, a new slack function is learned from auxiliary data to approximate the quantization error in ITQ. We developed an alternating optimization approach to solve the resultant optimization problem for ITQ+. We further extend ITQ+ to LapITQ+ by utilizing the geometry structure among the auxiliary data for learning more precise binary codes in the target domain. Extensive experiments on several benchmark datasets verify the effectiveness of our proposed approaches through comparisons with several state-of-the-art baselines.", "total_citations": {"2016": 4, "2017": 4, "2018": 11, "2019": 4, "2020": 6, "2021": 5, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:M7yex6snE4oC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9458855/", "authors": ["Razvan-Gabriel Cirstea", "Tung Kieu", "Chenjuan Guo", "Bin Yang", "Sinno Jialin Pan"], "publication_date": "2021/4/19", "conference": "2021 IEEE 37th International Conference on Data Engineering (ICDE)", "pages": "1739-1750", "publisher": "IEEE", "description": "Correlated time series forecasting plays an essential role in many cyber-physical systems, where entities interact with each other over time. To enable accurate forecasting, it is essential to capture both the temporal dynamics and the correlations among different entities. To capture the former, two popular types of models, recurrent neural networks (RNNs) and temporal convolution networks (TCNs), are employed. To capture the latter, a graph is constructed to reflect certain relationships among entities and then graph convolution (GC) is applied upon the graph to capture the correlations among the entities. The state-of-the-art forecasting accuracy is achieved by models that combine RNNs or TCNs with GC. However, they neither capture distinct temporal dynamics that exist among different entities nor consider the entity correlations that evolve across time. In this paper, rather than proposing yet another new end-to\u00a0\u2026", "total_citations": {"2020": 1, "2021": 4, "2022": 18, "2023": 13}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:k8Z6L05lTy4C": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/17416", "authors": ["Hangwei Qian", "Sinno Jialin Pan", "Chunyan Miao"], "publication_date": "2021/5/18", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "35", "issue": "13", "pages": "11921-11929", "description": "In wearable-sensor-based activity recognition, it is often assumed that the training and test samples follow the same data distribution. This assumption neglects practical scenarios where the activity patterns inevitably vary from person to person. To solve this problem, transfer learning and domain adaptation approaches are often leveraged to reduce the gaps between different participants. Nevertheless, these approaches require additional information (ie, labeled or unlabeled data, meta-information) from the target domain during the training stage. In this paper, we introduce a novel method named Generalizable Independent Latent Excitation (GILE) for human activity recognition, which greatly enhances the cross-person generalization capability of the model. Our proposed method is superior to existing methods in the sense that it does not require any access to the target domain information. Besides, this novel model can be directly applied to various target domains without re-training or fine-tuning. Specifically, the proposed model learns to automatically disentangle domain-agnostic and domain-specific features, the former of which are expected to be invariant across various persons. To further remove correlations between the two types of features, a novel Independent Excitation mechanism is incorporated in the latent feature space. Comprehensive experimental evaluations are conducted on three benchmark datasets to demonstrate the superiority of the proposed method over the state-of-the-art solutions.", "total_citations": {"2022": 21, "2023": 13}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:g5m5HwL7SMYC": {"external_link": "http://proceedings.mlr.press/v25/zhou12.html", "authors": ["Joey Tianyi Zhou", "Sinno Jialin Pan", "Qi Mao", "Ivor W Tsang"], "publication_date": "2012/11/17", "conference": "Asian Conference on Machine Learning", "pages": "555-570", "description": "Learning with Positive and Unlabeled instances (PU learning) arises widely in information retrieval applications. To address the unavailability issue of negative instances, most existing PU learning approaches require to either identify a reliable set of negative instances from the unlabeled data or estimate probability densities as an intermediate step. However, inaccurate negative-instance identification or poor density estimation may severely degrade overall performance of the final predictive model. To this end, we propose a novel PU learning method based on density ratio estimation without constructing any sets of negative instances or estimating any intermediate densities. To further boost PU learning performance, we extend our proposed learning method in a multi-view manner by utilizing multiple heterogeneous sources. Extensive experimental studies demonstrate the effectiveness of our proposed methods, especially when positive labeled data are limited.", "total_citations": {"2013": 1, "2014": 0, "2015": 3, "2016": 3, "2017": 2, "2018": 4, "2019": 4, "2020": 5, "2021": 3, "2022": 3, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:YOwf2qJgpHMC": {"external_link": "https://repository.ust.hk/ir/Record/1783.1-64755", "authors": ["Evan Wei Xiang", "Sinno Jialin Pan", "Weike Pan", "Jian Su", "Qiang Yang"], "publication_date": "2011/6/28", "conference": "Twenty-Second International Joint Conference on Artificial Intelligence", "description": "Transfer learning addresses the problems that labeled training data are insufficient to produce a high-performance model. Typically, given a target learning task, most transfer learning approaches require to select one or more auxiliary tasks as sources by the designers. However, how to select the right source data to enable effective knowledge transfer automatically is still an unsolved problem, which limits the applicability of transfer learning. In this paper, we take one step ahead and propose a novel transfer learning framework, known as source-selection-free transfer learning (SSFTL), to free users from the need to select source domains. Instead of asking the users for source and target data pairs, as traditional transfer learning does, SSFTL turns to some online information sources such as World Wide Web or the Wikipedia for help. The source data for transfer learning can be hidden somewhere within this large online information source, but the users do not know where they are. Based on the online information sources, we train a large number of classifiers. Then, given a target task, a bridge is built for labels of the potential source candidates and the target domain data in SSFTL via some large online social media with tag cloud as a label translator. An added advantage of SSFTL is that, unlike many previous transfer learning approaches, which are difficult to scale up to the Web scale, SSFTL is highly scalable and can offset much of the training work to offline stage. We demonstrate the effectiveness and efficiency of SSFTL through extensive experiments on several real-world datasets in text classification.", "total_citations": {"2012": 3, "2013": 0, "2014": 1, "2015": 0, "2016": 1, "2017": 5, "2018": 4, "2019": 6, "2020": 4, "2021": 3, "2022": 4, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:URolC5Kub84C": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/4206", "authors": ["Shangyu Chen", "Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2019/7/17", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "33", "issue": "01", "pages": "3329-3336", "description": "The advancement of deep models poses great challenges to real-world deployment because of the limited computational ability and storage space on edge devices. To solve this problem, existing works have made progress to prune or quantize deep models. However, most existing methods rely heavily on a supervised training process to achieve satisfactory performance, acquiring large amount of labeled training data, which may not be practical for real deployment. In this paper, we propose a novel layer-wise quantization method for deep neural networks, which only requires limited training data (1% of original dataset). Specifically, we formulate parameters quantization for each layer as a discrete optimization problem, and solve it using Alternative Direction Method of Multipliers (ADMM), which gives an efficient closed-form solution. We prove that the final performance drop after quantization is bounded by a linear combination of the reconstructed errors caused at each layer. Based on the proved theorem, we propose an algorithm to quantize a deep neural network layer by layer with an additional weights update step to minimize the final error. Extensive experiments on benchmark deep models are conducted to demonstrate the effectiveness of our proposed method using 1% of CIFAR10 and ImageNet datasets. Codes are available in: https://github. com/csyhhu/L-DNQ", "total_citations": {"2019": 1, "2020": 5, "2021": 12, "2022": 11, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:vDijr-p_gm4C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8725935/", "authors": ["Haoliang Li", "Sinno Jialin Pan", "Shiqi Wang", "Alex C Kot"], "publication_date": "2020/3/1", "journal": "IEEE transactions on neural networks and learning systems", "volume": "31", "issue": "3", "pages": "984-996", "publisher": "IEEE", "description": "Heterogeneous domain adaptation (HDA) aims to solve the learning problems where the source- and the target-domain data are represented by heterogeneous types of features. The existing HDA approaches based on matrix completion or matrix factorization have proven to be effective to capture shareable information between heterogeneous domains. However, there are two limitations in the existing methods. First, a large number of corresponding data instances between the source domain and the target domain are required to bridge the gap between different domains for performing matrix completion. These corresponding data instances may be difficult to collect in real-world applications due to the limited size of data in the target domain. Second, most existing methods can only capture linear correlations between features and data instances while performing matrix completion for HDA. In this paper, we\u00a0\u2026", "total_citations": {"2019": 1, "2020": 8, "2021": 12, "2022": 6, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:XiSMed-E-HIC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-662-44845-8_27", "authors": ["Fuzhen Zhuang", "Xiaohu Cheng", "Sinno Jialin Pan", "Wenchao Yu", "Qing He", "Zhongzhi Shi"], "publication_date": "2014", "conference": "Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part III 14", "pages": "417-431", "publisher": "Springer Berlin Heidelberg", "description": "Knowledge transfer from multiple source domains to a target domain is crucial in transfer learning. Most existing methods are focused on learning weights for different domains based on the similarities between each source domain and the target domain or learning more precise classifiers from the source domain data jointly by maximizing their consensus of predictions on the target domain data. However, these methods only consider measuring similarities or building classifiers on the original data space, and fail to discover a more powerful feature representation of the data when transferring knowledge from multiple source domains to the target domain. In this paper, we propose a new framework for transfer learning with multiple source domains. Specifically, in the proposed framework, we adopt autoencoders to construct a feature mapping from an original instance to a hidden representation, and train\u00a0\u2026", "total_citations": {"2014": 1, "2015": 4, "2016": 2, "2017": 7, "2018": 4, "2019": 3, "2020": 7, "2021": 1, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:eQOLeE2rZwMC": {"external_link": "https://cdn.aaai.org/AAAI/2007/AAAI07-175.pdf", "authors": ["Jeffrey Junfeng Pan", "Qiang Yang", "Sinno Jialin Pan"], "publication_date": "2007/7/22", "journal": "PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE", "volume": "22", "issue": "2", "pages": "1102", "publisher": "Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999", "description": "This paper addresses the problem of recovering the locations of both mobile devices and access points from radio signals that come in a stream manner, a problem which we call online co-localization, by exploiting both labeled and unlabeled data from mobile devices and access points. Many tracking systems function in two phases: an offline training phase and an online localization phase. In the training phase, models are built from a batch of data that are collected offline. Many of them can not cope with a dynamic environment in which calibration data may come sequentially. In such case, these systems may gradually become inaccurate without a manually costly re-calibration. To solve this problem, we proposed an online co-localization method that can deal with labeled and unlabeled data stream based on semi-supervised manifold-learning techniques. Experiments conducted in wireless local area networks show that we can achieve high accuracy with less calibration effort as compared to several previous systems. Furthermore, our method can deal with online stream data relatively faster than its two-phase counterpart.", "total_citations": {"2007": 1, "2008": 2, "2009": 2, "2010": 1, "2011": 3, "2012": 1, "2013": 1, "2014": 0, "2015": 4, "2016": 2, "2017": 1, "2018": 3, "2019": 4, "2020": 2, "2021": 1, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:f2IySw72cVMC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2492517.2492651", "authors": ["Linhong Zhu", "Sheng Gao", "Sinno Jialin Pan", "Haizhou Li", "Dingxiong Deng", "Cyrus Shahabi"], "publication_date": "2013/8/25", "conference": "Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining", "pages": "408-412", "publisher": "ACM", "description": "In this paper, we propose a new framework for opinion summarization based on sentence selection. Our goal is to assist users to get helpful opinion suggestions from reviews by only reading a short summary with few informative sentences, where the quality of summary is evaluated in terms of both aspect coverage and viewpoints preservation. More specifically, we formulate the informative-sentence selection problem in opinion summarization as a community-leader detection problem, where a community consists of a cluster of sentences towards the same aspect of an entity. The detected leaders of the communities can be considered as the most informative sentences of the corresponding aspect, while informativeness of a sentence is defined by its informativeness within both its community and the document it belongs to. Review data from six product domains from Amazon.com are used to verify the\u00a0\u2026", "total_citations": {"2014": 2, "2015": 5, "2016": 3, "2017": 3, "2018": 6, "2019": 1, "2020": 2, "2021": 3, "2022": 1, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:zLWjf1WUPmwC": {"external_link": "https://aaai.org/ojs/index.php/AAAI/article/view/4703", "authors": ["Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2019/7/17", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "33", "issue": "01", "pages": "7192-7199", "description": "In fine-grained opinion mining, aspect and opinion terms extraction has become a fundamental task that provides key information for user-generated texts. Despite its importance, a lack of annotated resources in many domains impede the ability to train a precise model. Very few attempts have applied unsupervised domain adaptation methods to transfer fine-grained knowledge (in the word level) from some labeled source domain (s) to any unlabeled target domain. Existing methods depend on the construction of \u201cpivot\u201d knowledge, eg, common opinion terms or syntactic relations between aspect and opinion words. In this work, we propose an interactive memory network that consists of local and global memory units. The model could exploit both local and global memory interactions to capture intra-correlations among aspect words or opinion words themselves, as well as the interconnections between aspect and opinion words. The source space and the target space are aligned through these domaininvariant interactions by incorporating an auxiliary task and domain adversarial networks. The proposed model does not require any external resources and demonstrates promising results on 3 benchmark datasets.", "total_citations": {"2020": 4, "2021": 7, "2022": 6, "2023": 11}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:p__nRnzSRKYC": {"external_link": "https://direct.mit.edu/coli/article-abstract/45/4/705/93359", "authors": ["Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2020/1", "journal": "Computational Linguistics", "volume": "45", "issue": "4", "pages": "705-736", "publisher": "MIT Press", "description": "In fine-grained opinion mining, extracting aspect terms (a.k.a. opinion targets) and opinion terms (a.k.a. opinion expressions) from user-generated texts is the most fundamental task in order to generate structured opinion summarization. Existing studies have shown that the syntactic relations between aspect and opinion words play an important role for aspect and opinion terms extraction. However, most of the works either relied on predefined rules or separated relation mining with feature learning. Moreover, these works only focused on single-domain extraction, which failed to adapt well to other domains of interest where only unlabeled data are available. In real-world scenarios, annotated resources are extremely scarce for many domains, motivating knowledge transfer strategies from labeled source domain(s) to any unlabeled target domain. We observe that syntactic relations among target words to be\u00a0\u2026", "total_citations": {"2020": 3, "2021": 3, "2022": 10, "2023": 7}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:vbGhcppDl1QC": {"external_link": "http://openaccess.thecvf.com/content_ICCV_2019/html/Huang_Accelerate_Learning_of_Deep_Hashing_With_Gradient_Attention_ICCV_2019_paper.html", "authors": ["Long-Kai Huang", "Jianda Chen", "Sinno Jialin Pan"], "publication_date": "2019", "conference": "Proceedings of the IEEE/CVF International Conference on Computer Vision", "pages": "5271-5280", "description": "Recent years have witnessed the success of learning to hash in fast large-scale image retrieval. As deep learning has shown its superior performance on many computer vision applications, recent designs of learning-based hashing models have been moving from shallow ones to deep architectures. However, based on our analysis, we find that gradient descent based algorithms used in deep hashing models would potentially cause hash codes of a pair of training instances to be updated towards the directions of each other simultaneously during optimization. In the worst case, the paired hash codes switch their directions after update, and consequently, their corresponding distance in the Hamming space remain unchanged. This makes the overall learning process highly inefficient. To address this issue, we propose a new deep hashing model integrated with a novel gradient attention mechanism. Extensive experimental results on three benchmark datasets show that our proposed algorithm is able to accelerate the learning process and obtain competitive retrieval performance compared with state-of-the-art deep hashing models.", "total_citations": {"2020": 6, "2021": 8, "2022": 4, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:2KloaMYe4IUC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/12078", "authors": ["Hangwei Qian", "Sinno Jialin Pan", "Chunyan Miao"], "publication_date": "2018/5/25", "conference": "AAAI", "description": "Sensor-based activity recognition aims to predict users' activities from multi-dimensional streams of various sensor readings received from ubiquitous sensors. To use machine learning techniques for sensor-based activity recognition, previous approaches focused on composing a feature vector to represent sensor-reading streams received within a period of various lengths. With the constructed feature vectors, eg, using predefined orders of moments in statistics, and their corresponding labels of activities, standard classification algorithms can be applied to train a predictive model, which will be used to make predictions online. However, we argue that in this way some important information, eg, statistical information captured by higher-order moments, may be discarded when constructing features. Therefore, in this paper, we propose a new method, denoted by SMMAR, based on learning from distributions for sensor-based activity recognition. Specifically, we consider sensor readings received within a period as a sample, which can be represented by a feature vector of infinite dimensions in a Reproducing Kernel Hilbert Space (RKHS) using kernel embedding techniques. We then train a classifier in the RKHS. To scale-up the proposed method, we further offer an accelerated version by utilizing an explicit feature map instead of using a kernel function. We conduct experiments on four benchmark datasets to verify the effectiveness and scalability of our proposed method.", "total_citations": {"2019": 6, "2020": 0, "2021": 4, "2022": 3, "2023": 8}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:eJXPG6dFmWUC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2806416.2806644", "authors": ["Xin Jin", "Fuzhen Zhuang", "Sinno Jialin Pan", "Changying Du", "Ping Luo", "Qing He"], "publication_date": "2015/10/17", "conference": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "pages": "1847-1850", "publisher": "ACM", "description": "Multi-task Learning (MTL) aims to learn multiple related tasks simultaneously instead of separately to improve generalization performance of each task. Most existing MTL methods assumed that the multiple tasks to be learned have the same feature representation. However, this assumption may not hold for many real-world applications. In this paper, we study the problem of MTL with heterogeneous features for each task. To address this problem, we first construct an integrated graph of a set of bipartite graphs to build a connection among different tasks. We then propose a multi-task nonnegative matrix factorization (MTNMF) method to learn a common semantic feature space underlying different heterogeneous feature spaces of each task. Finally, based on the common semantic features and original heterogeneous features, we model the heterogenous MTL problem as a multi-task multi-view learning (MTMVL\u00a0\u2026", "total_citations": {"2016": 3, "2017": 7, "2018": 4, "2019": 2, "2020": 2, "2021": 2, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:AvfA0Oy_GE0C": {"external_link": "https://csyhhu.github.io/data/Co-Prune.pdf", "authors": ["Shangyu Chen", "Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2019/8/10", "conference": "IJCAI", "pages": "2102-2108", "description": "The advancement of deep models poses great challenges to real-world deployment because of the limited computational ability and storage space on edge devices. To solve this problem, existing works have made progress to compress deep models by pruning or quantization. However, most existing methods rely on a large amount of training data and a pre-trained model in the same domain. When only limited in-domain training data is available, these methods fail to perform well. This prompts the idea of transferring knowledge from a resource-rich source domain to a target domain with limited data to perform model compression. In this paper, we propose a method to perform cross-domain pruning by cooperatively training in both domains: taking advantage of data and a pre-trained model from the source domain to assist pruning in the target domain. Specifically, source and target pruned models are trained simultaneously and interactively, with source information transferred through the construction of a cooperative pruning mask. Our method significantly improves pruning quality in the target domain, and shed light to model compression in the cross-domain setting. Codes are available at https://github. com/csyhhu/Co-Prune.", "total_citations": {"2020": 4, "2021": 4, "2022": 8, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:xtRiw3GOFMkC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0031320314001101", "authors": ["Liyuan Li", "Weixun Goh", "Joo Hwee Lim", "Sinno Jialin Pan"], "publication_date": "2014/9/1", "journal": "Pattern Recognition", "volume": "47", "issue": "9", "pages": "2940-2951", "publisher": "Pergamon", "description": "This paper proposes a novel method based on Spectral Regression (SR) for efficient scene recognition. First, a new SR approach, called Extended Spectral Regression (ESR), is proposed to perform manifold learning on a huge number of data samples. Then, an efficient Bag-of-Words (BOW) based method is developed which employs ESR to encapsulate local visual features with their semantic, spatial, scale, and orientation information for scene recognition. In many applications, such as image classification and multimedia analysis, there are a huge number of low-level feature samples in a training set. It prohibits direct application of SR to perform manifold learning on such dataset. In ESR, we first group the samples into tiny clusters, and then devise an approach to reduce the size of the similarity matrix for graph learning. In this way, the subspace learning on graph Laplacian for a vast dataset is computationally\u00a0\u2026", "total_citations": {"2013": 1, "2014": 1, "2015": 4, "2016": 6, "2017": 2, "2018": 2, "2019": 3, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:SpbeaW3--B0C": {"external_link": "https://proceedings.neurips.cc/paper/2020/hash/a914ecef9c12ffdb9bede64bb703d877-Abstract.html", "authors": ["Jianda Chen", "Shangyu Chen", "Sinno Jialin Pan"], "publication_date": "2020/12", "conference": "Advances in Neural Information Processing Systems", "description": "In this paper, we propose a deep reinforcement learning (DRL) based framework to efficiently perform runtime channel pruning on convolutional neural networks (CNNs). Our DRL-based framework aims to learn a pruning strategy to determine how many and which channels to be pruned in each convolutional layer, depending on each individual input instance at runtime. Unlike existing runtime pruning methods which require to store all channels parameters for inference, our framework can reduce parameters storage consumption by introducing a static pruning component. Comparison experimental results with existing runtime and static pruning methods on state-of-the-art CNNs demonstrate that our proposed framework is able to provide a tradeoff between dynamic flexibility and storage efficiency in runtime channel pruning.", "total_citations": {"2021": 8, "2022": 5, "2023": 6}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:ufrVoPGSRksC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/1281192.1281304", "authors": ["Rong Pan", "Junhui Zhao", "Vincent Wenchen Zheng", "Jeffrey Junfeng Pan", "Dou Shen", "Sinno Jialin Pan", "Qiang Yang"], "publication_date": "2007/8/12", "conference": "Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining", "pages": "1023-1027", "publisher": "ACM", "description": "Accurate localization of mobile objects is a major research problem in sensor networks and an important data mining application. Specifically, the localization problem is to determine the location of a client device accurately given the radio signal strength values received at the client device from multiple beacon sensors or access points. Conventional data mining and machine learning methods can be applied to solve this problem. However, all of them require large amounts of labeled training data, which can be quite expensive. In this paper, we propose a probabilistic semi supervised learning approach to reduce the calibration effort and increase the tracking accuracy. Our method is based on semi-supervised conditional random fields which can enhance the learned model from a small set of training data with abundant unlabeled data effectively. To make our method more efficient, we exploit a Generalized EM\u00a0\u2026", "total_citations": {"2009": 1, "2010": 1, "2011": 2, "2012": 5, "2013": 1, "2014": 2, "2015": 2, "2016": 1, "2017": 0, "2018": 1, "2019": 0, "2020": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:xtoqd-5pKcoC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3534589", "authors": ["Wang Lu", "Jindong Wang", "Yiqiang Chen", "Sinno Jialin Pan", "Chunyu Hu", "Xin Qin"], "publication_date": "2022/7/7", "journal": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies", "volume": "6", "issue": "2", "pages": "1-19", "publisher": "ACM", "description": "It is expensive and time-consuming to collect sufficient labeled data to build human activity recognition (HAR) models. Training on existing data often makes the model biased towards the distribution of the training data, thus the model might perform terribly on test data with different distributions. Although existing efforts on transfer learning and domain adaptation try to solve the above problem, they still need access to unlabeled data on the target domain, which may not be possible in real scenarios. Few works pay attention to training a model that can generalize well to unseen target domains for HAR. In this paper, we propose a novel method called Semantic-Discriminative Mixup (SDMix) for generalizable cross-domain HAR. Firstly, we introduce semantic-aware Mixup that considers the activity semantic ranges to overcome the semantic inconsistency brought by domain differences. Secondly, we introduce the\u00a0\u2026", "total_citations": {"2022": 4, "2023": 14}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:uJ-U7cs_P_0C": {"external_link": "https://www.ijcai.org/proceedings/2018/0622.pdf", "authors": ["Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2018", "conference": "IJCAI", "pages": "3026-3032", "description": "In fine-grained opinion mining, the task of aspect extraction involves the identification of explicit product features in customer reviews. This task has been widely studied in some major languages, eg, English, but was seldom addressed in other minor languages due to the lack of annotated corpus. To solve it, we develop a novel deep model to transfer knowledge from a source language with labeled training data to a target language without any annotations. Different from cross-lingual sentiment classification, aspect extraction across languages requires more fine-grained adaptation. To this end, we utilize transition-based mechanism that reads a word each time and forms a series of configurations that represent the status of the whole sentence. We represent each configuration as a continuous feature vector and align these representations from different languages into a shared space through an adversarial network. In addition, syntactic structures are also integrated into the deep model to achieve more syntactically-sensitive adaptations. The proposed method is end-to-end and achieves state-ofthe-art performance on English, French and Spanish restaurant review datasets.", "total_citations": {"2019": 5, "2020": 4, "2021": 4, "2022": 2, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:aqlVkmm33-oC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/6091797/", "authors": ["Feng Zhang", "Mengling Feng", "Sinno Jialin Pan", "Liang Yu Loy", "Wenyuan Guo", "Zhuo Zhang", "Pei Loon Chin", "Cuntai Guan", "Nicolas Kon Kam King", "Beng Ti Ang"], "publication_date": "2011/8/30", "conference": "2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society", "pages": "7111-7114", "publisher": "IEEE", "description": "Although the future mean of intracranial pressure (ICP) is of critical concern of many clinicians for timely medical treatment, the problem of forecasting the future ICP mean has not been addressed yet. In this paper, we present a nonlinear autoregressive with exogenous input artificial neural network based mean forecast algorithm (ANN NARX -MFA) to predict the ICP mean of the future windows based on features extracted from past windows and segmented sub-windows. We compare its performance with nonlinear autoregressive artificial neural network algorithm (ANN NAR ) without features extracted from window segmentation. Experimental results showed that, ANN NARX -MFA algorithm outperforms ANN NAR  algorithm in prediction accuracy, because additional features extracted from finer segmented sub-windows help to catch the subtle changes of ICP trends. This verifies the effectiveness of decomposing\u00a0\u2026", "total_citations": {"2013": 1, "2014": 0, "2015": 2, "2016": 2, "2017": 0, "2018": 0, "2019": 3, "2020": 5, "2021": 1, "2022": 1, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:WF5omc3nYNoC": {"external_link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=6916e8f5220c210f97a44af7eaac15eca3396bd8", "authors": ["Qiang Yang", "Rong Pan", "Sinno Jialin Pan"], "publication_date": "2007", "journal": "ICAPS Workshop on AI Planning and Learning", "description": "HTN planning is one of the most effective planning methods in AI. However, designing the HTN-decomposition methods is a very difficult task which has been achieved mainly by humans. It would therefore be desirable to design automated learning methods to acquire these decomposition methods from observed action sequences. In this work, we explore how to apply model-based clustering in order to construct task decomposition hierarchies and summarize a database of action sequences. We present a probabilistic model for unsupervised learning of HTN methods from action sequences. Based on this model, we introduce a novel two-pronged approach by simultaneously learning a Markov model for action segment clusters from action sequences and then learning an action parameter model for recognizing tasks. These models are integrated together to construct action clusters. Then, an abstraction algorithm is applied to extract variables from the action parameters in each cluster to obtain succinct HTN methods. We introduce evaluation metrics for this approach, and test the algorithm in a logistics planning domain.", "total_citations": {"2008": 2, "2009": 3, "2010": 2, "2011": 0, "2012": 0, "2013": 1, "2014": 2, "2015": 1, "2016": 1, "2017": 2, "2018": 0, "2019": 1, "2020": 0, "2021": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:e_rmSamDkqQC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3460231.3474239", "authors": ["Danni Peng", "Sinno Jialin Pan", "Jie Zhang", "Anxiang Zeng"], "publication_date": "2021/9/13", "book": "Proceedings of the 15th ACM Conference on Recommender Systems", "pages": "411-421", "description": "Recommender Systems (RSs) in real-world applications often deal with billions of user interactions daily. To capture the most recent trends effectively, it is common to update the model incrementally using only the newly arrived data. However, this may impede the model\u2019s ability to retain long-term information due to the potential overfitting and forgetting issues. To address this problem, we propose a novel Adaptive Sequential Model Generation (ASMG) framework, which generates a better serving model from a sequence of historical models via a meta generator. For the design of the meta generator, we propose to employ Gated Recurrent Units (GRUs) to leverage its ability to capture the long-term dependencies. We further introduce some novel strategies to apply together with the GRU meta generator, which not only improve its computational efficiency but also enable more accurate sequential modeling. By\u00a0\u2026", "total_citations": {"2022": 7, "2023": 9}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:nrtMV_XWKgEC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S000437021830599X", "authors": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier"], "publication_date": "2018/12/1", "journal": "Artificial Intelligence", "volume": "265", "pages": "1-17", "publisher": "Elsevier", "description": "Fine-grained opinion mining has attracted increasing attention recently because of its benefits for providing richer information compared with coarse-grained sentiment analysis. Under this problem, there are several existing works focusing on aspect (or opinion) terms extraction which utilize the syntactic relations among the words given by a dependency parser. These approaches, however, require additional information and highly depend on the quality of the parsing results. As a result, they may perform poorly on user-generated texts, such as product reviews, tweets, etc., whose syntactic structure is not precise. In this work, we offer an end-to-end deep learning model without any preprocessing. The model consists of a memory network that automatically learns the complicated interactions among aspect words and opinion words. Moreover, we extend the network with a multi-task manner to solve a finer-grained\u00a0\u2026", "total_citations": {"2020": 6, "2021": 4, "2022": 5, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:edDO8Oi4QzsC": {"external_link": "https://arxiv.org/abs/2305.15005", "authors": ["Wenxuan Zhang", "Yue Deng", "Bing Liu", "Sinno Jialin Pan", "Lidong Bing"], "publication_date": "2023/5/24", "journal": "arXiv preprint arXiv:2305.15005", "description": "Sentiment analysis (SA) has been a long-standing research area in natural language processing. It can offer rich insights into human sentiments and opinions and has thus seen considerable interest from both academia and industry. With the advent of large language models (LLMs) such as ChatGPT, there is a great potential for their employment on SA problems. However, the extent to which existing LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts. We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets. Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring deeper understanding or structured sentiment information. However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited. We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, \\textsc{SentiEval}, for a more comprehensive and realistic evaluation. Data and code during our investigations are available at \\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}.", "total_citations": {"2023": 14}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:tuHXwOkdijsC": {"external_link": "https://aclanthology.org/2020.emnlp-main.453/", "authors": ["Meixi Wu", "Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2020/11", "conference": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "pages": "5618-5628", "description": "Though deep learning has achieved significant success in various NLP tasks, most deep learning models lack the capability of encoding explicit domain knowledge to model complex causal relationships among different types of variables. On the other hand, logic rules offer a compact expression to represent the causal relationships to guide the training process. Logic programs can be cast as a satisfiability problem which aims to find truth assignments to logic variables by maximizing the number of satisfiable clauses (MaxSAT). We adopt the MaxSAT semantics to model logic inference process and smoothly incorporate a weighted version of MaxSAT that connects deep neural networks and a graphical model in a joint framework. The joint model feeds deep learning outputs to a weighted MaxSAT layer to rectify the erroneous predictions and can be trained via end-to-end gradient descent. Our proposed model associates the benefits of high-level feature learning, knowledge reasoning, and structured learning with observable performance gain for the task of aspect-based opinion extraction.", "total_citations": {"2021": 1, "2022": 8, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:Fu2w8maKXqMC": {"external_link": "http://www.cse.cuhk.edu.hk/~sinnopan/publications/[IJCAI17]Adaptive%20Group%20Sparse%20Multi-task%20Learning%20via%20Trace%20Lasso.pdf", "authors": ["Sulin Liu", "Sinno Jialin Pan"], "publication_date": "2017/8/19", "conference": "IJCAI", "pages": "2358-2364", "description": "In multi-task learning (MTL), tasks are learned jointly so that information among related tasks is shared and utilized to help improve generalization for each individual task. A major challenge in MTL is how to selectively choose what to share among tasks. Ideally, only related tasks should share information with each other. In this paper, we propose a new MTL method that can adaptively group correlated tasks into clusters and share information among the correlated tasks only. Our method is based on the assumption that each task parameter is a linear combination of other tasks\u2019 and the coefficients of the linear combination are active only if there is relatedness between the two tasks. Through introducing trace Lasso penalty on these coefficients, our method is able to adaptively select the subset of coefficients with respect to the tasks that are correlated to the task. Our model frees the process of determining task clustering structure as used in the literature. Efficient optimization method based on alternating direction method of multipliers (ADMM) is developed to solve the problem. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of our method in terms of clustering related tasks and generalization performance.", "total_citations": {"2018": 2, "2019": 3, "2020": 6, "2021": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:i2xiXl-TujoC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9268191/", "authors": ["Fengmao Lv", "Guosheng Lin", "Peng Liu", "Guowu Yang", "Sinno Jialin Pan", "Lixin Duan"], "publication_date": "2021/9/1", "journal": "IEEE Transactions on Circuits and Systems for Video Technology", "publisher": "IEEE", "description": "Semantic segmentation, which aims to acquire pixel-level understanding about images, is among the key components in computer vision. To train a good segmentation model for real-world images, it usually requires a huge amount of time and labor effort to obtain sufficient pixel-level annotations of real-world images beforehand. To get rid of such a nontrivial burden, one can use simulators to automatically generate synthetic images that inherently contain full pixel-level annotations and use them to train a segmentation model for the real-world images. However, training with synthetic images usually cannot lead to good performance due to the domain difference between the synthetic images (i.e., source domain) and the real-world images (i.e., target domain). To deal with this issue, a number of unsupervised domain adaptation (UDA) approaches have been proposed, where no labeled real-world images are available\u00a0\u2026", "total_citations": {"2021": 1, "2022": 6, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:BUYA1_V_uYcC": {"external_link": "https://aaai.org/ojs/index.php/AAAI/article/view/4765/4643", "authors": ["Hangwei Qian", "Sinno Jialin Pan", "Chunyan Miao"], "publication_date": "2019/7/17", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "33", "pages": "7699-7706", "description": "Supervised learning methods have been widely applied to activity recognition. The prevalent success of existing methods, however, has two crucial prerequisites: proper feature extraction and sufficient labeled training data. The former is important to differentiate activities, while the latter is crucial to build a precise learning model. These two prerequisites have become bottlenecks to make existing methods more practical. Most existing feature extraction methods highly depend on domain knowledge, while labeled data requires intensive human annotation effort. Therefore, in this paper, we propose a novel method, named Distribution-based Semi-Supervised Learning, to tackle the aforementioned limitations. The proposed method is capable of automatically extracting powerful features with no domain knowledge required, meanwhile, alleviating the heavy annotation effort through semi-supervised learning. Specifically, we treat data stream of sensor readings received in a period as a distribution, and map all training distributions, including labeled and unlabeled, into a reproducing kernel Hilbert space (RKHS) using the kernel mean embedding technique. The RKHS is further altered by exploiting the underlying geometry structure of the unlabeled distributions. Finally, in the altered RKHS, a classifier is trained with the labeled distributions. We conduct extensive experiments on three public datasets to verify the effectiveness of our method compared with state-of-the-art baselines.", "total_citations": {"2019": 1, "2020": 3, "2021": 3, "2022": 3, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:eq2jaN3J8jMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/7743557/", "authors": ["Wei Chian Tan", "I-Ming Chen", "Sinno Jialin Pan", "Hoon Kiang Tan"], "publication_date": "2016/8/21", "conference": "2016 IEEE International Conference on Automation Science and Engineering (CASE)", "pages": "1295-1300", "publisher": "IEEE", "description": "An autonomous framework to evaluate layout of a Piping and Instrumentation Diagram (also known as P&ID or piping design) according to a set of standards of marine and offshore industry is proposed. The method starts with transforming layout of a P&ID into a vector x in R d . Transformation is done based on a novel concept developed for piping design known as Histogram of Connectivity (HoC). The proposed descriptor captures two essential properties of piping design: attributes of each component and connectivity among the components. Next, linear Support Vector Machine (SVM) is used to learn from existing compliant and non-compliant designs. Subsequently, the linear classifier can be used to check if an unseen design complies with the standards, hence achieving the aim of checking compliance of layout of a piping design. The method has demonstrated state of the art performance in a challenging\u00a0\u2026", "total_citations": {"2017": 2, "2018": 2, "2019": 4, "2020": 3, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:eMMeJKvmdy0C": {"external_link": "http://www.cse.cuhk.edu.hk/~sinnopan/publications/[IJCAI16]Class-wise%20Supervised%20Hashing%20with%20Label%20Embedding%20and%20Active%20Bits.pdf", "authors": ["Long-Kai Huang", "Sinno Jialin Pan"], "publication_date": "2016/7/9", "conference": "IJCAI", "pages": "1585-1591", "description": "Learning to hash has become a crucial technique for big data analytics. Among existing methods, supervised learning approaches play an important role as they can produce compact codes and enable semantic search. However, the size of an instancepairwise similarity matrix used in most supervised hashing methods is quadratic to the size of labeled training data, which is very expensive in terms of space, especially for a large-scale learning problem. This limitation hinders the full utilization of labeled instances for learning a more precise hashing model. To overcome this limitation, we propose a class-wise supervised hashing method that trains a model based on a class-pairwise similarity matrix, whose size is much smaller than the instance-pairwise similarity matrix in many applications. In addition, besides a set of hash functions, our proposed method learns a set of classwise code-prototypes with active bits for different classes. These class-wise code-prototypes can help to learn more precise compact codes for semantic information retrieval. Experimental results verify the superior effectiveness of our proposed method over other baseline hashing methods.", "total_citations": {"2017": 1, "2018": 2, "2019": 3, "2020": 2, "2021": 2, "2022": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:MLfJN-KU85MC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S0004370220301788", "authors": ["Hangwei Qian", "Sinno Jialin Pan", "Chunyan Miao"], "publication_date": "2021/3/1", "journal": "Artificial Intelligence", "volume": "292", "pages": "103429", "publisher": "Elsevier", "description": "Sensor-based activity recognition aims to recognize users' activities from multi-dimensional streams of sensor readings received from ubiquitous sensors. It has been shown that data segmentation and feature extraction are two crucial steps in developing machine learning-based models for sensor-based activity recognition. However, most previous studies were only focused on the latter step by assuming that data segmentation is done in advance. In practice, on the one hand, doing data segmentation on sensory streams is very challenging. On the other hand, if data segmentation is considered as a pre-process, the errors in data segmentation may be propagated to latter steps. Therefore, in this paper, we propose a unified weakly-supervised framework based on kernel embedding of distributions to jointly segment sensor streams, extract powerful features from each segment, and train a final classifier for activity\u00a0\u2026", "total_citations": {"2021": 2, "2022": 6, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:kuK5TVdYjLIC": {"external_link": "https://proceedings.mlr.press/v119/huang20e.html", "authors": ["Long-Kai Huang", "Sinno Jialin Pan"], "publication_date": "2020/11/21", "conference": "International Conference on Machine Learning", "pages": "4465-4474", "publisher": "PMLR", "description": "In this paper, we study the leading eigenvector problem in a statistically distributed setting and propose a communication-efficient algorithm based on Riemannian optimization, which trades local computation for global communication. Theoretical analysis shows that the proposed algorithm linearly converges to the centralized empirical risk minimization solution regarding the number of communication rounds. When the number of data points in local machines is sufficiently large, the proposed algorithm achieves a significant reduction of communication cost over existing distributed PCA algorithms. Superior performance in terms of communication cost of the proposed algorithm is verified on real-world and synthetic datasets.", "total_citations": {"2021": 2, "2022": 6, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:YsMSGLbcyi4C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/4517470/", "authors": ["Jeffrey Junfeng Pan", "Sinno Jialin Pan", "Vincent Wenchen Zheng", "Qiang Yang"], "publication_date": "2008/3/17", "conference": "2008 Sixth Annual IEEE International Conference on Pervasive Computing and Communications (PerCom)", "pages": "645-650", "publisher": "IEEE", "description": "With the proliferation of wireless and sensor techniques, data can be shared conveniently through the air. However, wireless communication is vulnerable since unauthorized machine may try to intrude a server without being physically connected. In this paper, we wish to control the communication between a wireless client and the infrastructure based on the client location. Our idea is to implement a digital wall, which is a user-defined boundary so that access is allowed within the boundary and denied outside the boundary. To do this, we need to do accurate location estimation since the decision around the boundary line is critical. Furthermore, computational efficiency is also important since we need to reduce computation cost so as to save power energy. In this paper, we propose k-nearest-neighbor (KNN) based method to determine the location of a mobile client based on received signal strength (RSS) values\u00a0\u2026", "total_citations": {"2009": 2, "2010": 1, "2011": 1, "2012": 2, "2013": 0, "2014": 0, "2015": 1, "2016": 0, "2017": 2, "2018": 0, "2019": 0, "2020": 0, "2021": 0, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:yB1At4FlUx8C": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8560550/", "authors": ["Wei Chian Tan", "I-Ming Chen", "Dimitrios Pantazis", "Sinno Jialin Pan"], "publication_date": "2018/8/20", "conference": "2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)", "pages": "1296-1301", "publisher": "IEEE", "description": "This paper presents an end-to-end learning approach based on latest CNN architectures and transfer learning to perform vision-based analysis of engineering designs. The specific application considered here is the design of pipe networks on-board ships or offshore platforms. Having a piping design in the form of an image, a framework known as Piping Net (PipNet) is introduced to understand the design and interpret if it complies with applicable engineering regulations. Designs and corresponding labels (compliant or non-compliant) are fed into an existing trained CNN in the form of images for transfer learning, with the subsequently obtained fine-tuned network called PipNet. Based on Regulation 12, Annex I Regulations for the Prevention of Pollution by Oil, International Convention for the Prevention of Pollution from Ships (MARPOL) and Rules for Classification of Ships of Lloyd's Register, two datasets\u00a0\u2026", "total_citations": {"2019": 1, "2020": 1, "2021": 3, "2022": 4, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:evX43VCCuoAC": {"external_link": "https://www.sciencedirect.com/science/article/pii/S1574119217303218", "authors": ["Yanbing Yang", "Jun Luo", "Jie Hao", "Sinno Jialin Pan"], "publication_date": "2018/4/30", "journal": "Pervasive and Mobile Computing", "volume": "45", "pages": "35-54", "publisher": "Elsevier", "description": "As a key component of building management and security, occupancy inference through smart sensing has attracted a lot of research attention for nearly two decades. Nevertheless, existing solutions mostly rely on either pre-deployed infrastructures or user device participation, thus hampering their wide adoption. This paper presents CeilingSee, a dedicated occupancy inference system free of heavy infrastructure deployments and user involvements. Building upon existing LED lighting systems, CeilingSee converts part of the ceiling-mounted LED luminaires to act as sensors, sensing the variances in diffuse reflection caused by occupants. In realizing CeilingSee, we first re-design the LED driver to leverage LED\u2019s photoelectric effect so as to transform a light emitter to a light sensor. In order to produce accurate occupancy inference, we then engineer efficient learning algorithms to fuse sensing information\u00a0\u2026", "total_citations": {"2018": 1, "2019": 3, "2020": 3, "2021": 1, "2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:0N-VGjzr574C": {"external_link": "https://arxiv.org/abs/2211.08892", "authors": ["Tianze Luo", "Zhanfeng Mo", "Sinno Jialin Pan"], "publication_date": "2022/11/16", "journal": "arXiv preprint arXiv:2211.08892", "description": "Generating graph-structured data is a challenging problem, which requires learning the underlying distribution of graphs. Various models such as graph VAE, graph GANs and graph diffusion models have been proposed to generate meaningful and reliable graphs, among which the diffusion models have achieved state-of-the-art performance. In this paper, we argue that running full-rank diffusion SDEs on the whole space hinders diffusion models from learning graph topology generation, and hence significantly deteriorates the quality of generated graph data. To address this limitation, we propose an efficient yet effective Graph Spectral Diffusion Model (GSDM), which is driven by low-rank diffusion SDEs on the graph spectrum space. Our spectral diffusion model is further proven to enjoy a substantially stronger theoretical guarantee than standard diffusion models. Extensive experiments across various datasets demonstrate that, our proposed GSDM turns out to be the SOTA model, by exhibiting either significantly higher generation quality or much less computational consumption than the baselines.", "total_citations": {"2022": 1, "2023": 8}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:HbR8gkJAVGIC": {"external_link": "https://arxiv.org/abs/2207.04564", "authors": ["Quanyu Long", "Tianze Luo", "Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2022/7/10", "journal": "arXiv preprint arXiv:2207.04564", "description": "In this work, we study Unsupervised Domain Adaptation (UDA) in a challenging self-supervised approach. One of the difficulties is how to learn task discrimination in the absence of target labels. Unlike previous literature which directly aligns cross-domain distributions or leverages reverse gradient, we propose Domain Confused Contrastive Learning (DCCL) to bridge the source and the target domains via domain puzzles, and retain discriminative representations after adaptation. Technically, DCCL searches for a most domain-challenging direction and exquisitely crafts domain confused augmentations as positive pairs, then it contrastively encourages the model to pull representations towards the other domain, thus learning more stable and effective domain invariances. We also investigate whether contrastive learning necessarily helps with UDA when performing other data augmentations. Extensive experiments demonstrate that DCCL significantly outperforms baselines.", "total_citations": {"2022": 3, "2023": 5}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:ZfRJV9d4-WMC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/8098602/", "authors": ["Wei Chian Tan", "I Chen", "Sinno Jialin Pan", "Hoon Kiang Tan"], "publication_date": "2018/1/1", "journal": "IEEE Transactions on Automation Science and Engineering", "volume": "15", "issue": "1", "pages": "381-392", "publisher": "IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC", "description": "An autonomous framework to evaluate layout of a piping design in the form of piping and instrumentation diagram (P&ID) according to a set of standards of marine and offshore industry is proposed. The method starts with transforming a P&ID into a vector x in Rd. Transformation is done based on a concept introduced for piping known as Histogram of Connectivity. The proposed descriptor captures two essential properties of P&ID: attributes of each component and connectivity among the components. Next, linear support vector machine (SVM) is used to learn a classifier from existing compliant and noncompliant designs. Subsequently, the linear classifier can be used to check if an unseen design complies with the standards. In addition, to enable follow up on noncompliant design including correction or modification, a method to analyze the reason of noncompliance prediction by the learned SVM model is\u00a0\u2026", "total_citations": {"2018": 2, "2019": 1, "2020": 1, "2021": 1, "2022": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=20&pagesize=80&citation_for_view=P6WcnfkAAAAJ:l7t_Zn2s7bgC": {"external_link": "https://link.springer.com/chapter/10.1007/978-3-319-14379-8_9", "authors": ["Linhong Zhu", "Sheng Gao", "Sinno Jialin Pan", "Haizhou Li", "Dingxiong Deng", "Cyrus Shahabi"], "publication_date": "2015", "book": "Recommendation and search in social networks", "pages": "165-187", "publisher": "Springer, Cham", "description": "Most previous works on opinion summarization focus on summarizing sentiment polarity distribution toward different aspects of an entity (e.g., battery life and screen of a mobile phone). However, users\u2019 demand may be more beyond this kind of opinion summarization. Besides such coarse-grained summarization on aspects, one may prefer to read detailed but concise text of the opinion data for more information. In this paper, we propose a new framework for opinion summarization. Our goal is to assist users to get helpful opinion suggestions from reviews by only reading a short summary with a few informative sentences, where the quality of summary is evaluated in terms of both aspect coverage and viewpoints preservation. More specifically, we formulate the informative sentence selection problem in opinion summarization as a community leader detection problem, where a community consists of a cluster\u00a0\u2026", "total_citations": {"2018": 3, "2019": 1, "2020": 1, "2021": 1, "2022": 0, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:PVjk1bu6vJQC": {"external_link": "https://arxiv.org/abs/2011.00825", "authors": ["Haiyan Yin", "Yingzhen Li", "Sinno Jialin Pan", "Cheng Zhang", "Sebastian Tschiatschek"], "publication_date": "2020/11/2", "journal": "arXiv preprint arXiv:2011.00825", "description": "Solving real-life sequential decision making problems under partial observability involves an exploration-exploitation problem. To be successful, an agent needs to efficiently gather valuable information about the state of the world for making rewarding decisions. However, in real-life, acquiring valuable information is often highly costly, e.g., in the medical domain, information acquisition might correspond to performing a medical test on a patient. This poses a significant challenge for the agent to perform optimally for the task while reducing the cost for information acquisition. In this paper, we propose a model-based reinforcement learning framework that learns an active feature acquisition policy to solve the exploration-exploitation problem during its execution. Key to the success is a novel sequential variational auto-encoder that learns high-quality representations from partially observed states, which are then used by the policy to maximize the task reward in a cost efficient manner. We demonstrate the efficacy of our proposed framework in a control domain as well as using a medical simulator. In both tasks, our proposed method outperforms conventional baselines and results in policies with greater cost efficiency.", "total_citations": {"2022": 3, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:JoZmwDi-zQgC": {"external_link": "https://dl.acm.org/doi/abs/10.1145/2983323.2983690", "authors": ["Fuzhen Zhuang", "Ping Luo", "Sinno Jialin Pan", "Hui Xiong", "Qing He"], "publication_date": "2016/10/24", "conference": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "pages": "2335-2340", "publisher": "ACM", "description": "In the past decade, there have been a large number of transfer learning algorithms proposed for various real-world applications. However, most of them are vulnerable to negative transfer since their performance is even worse than traditional supervised models. Aiming at more robust transfer learning models, we propose an ENsemble framework of anCHOR adapters (ENCHOR for short), in which an anchor adapter adapts the features of instances based on their similarities to a specific anchor (i.e., a selected instance). Specifically, the more similar to the anchor instance, the higher degree of the original feature of an instance remains unchanged in the adapted representation, and vice versa. This adapted representation for the data actually expresses the local structure around the corresponding anchor, and then any transfer learning method can be applied to this adapted representation for a prediction model\u00a0\u2026", "total_citations": {"2020": 1, "2021": 3, "2022": 1, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:ruyezt5ZtCIC": {"external_link": "https://arxiv.org/abs/2212.13088", "authors": ["Jianda Chen", "Sinno Jialin Pan"], "publication_date": "2022/12/26", "journal": "arXiv preprint arXiv:2212.13088", "description": "How to learn an effective reinforcement learning-based model for control tasks from high-level visual observations is a practical and challenging problem. A key to solving this problem is to learn low-dimensional state representations from observations, from which an effective policy can be learned. In order to boost the learning of state encoding, recent works are focused on capturing behavioral similarities between state representations or applying data augmentation on visual observations. In this paper, we propose a novel meta-learner-based framework for representation learning regarding behavioral similarities for reinforcement learning. Specifically, our framework encodes the high-dimensional observations into two decomposed embeddings regarding reward and dynamics in a Markov Decision Process (MDP). A pair of meta-learners are developed, one of which quantifies the reward similarity and the other quantifies dynamics similarity over the correspondingly decomposed embeddings. The meta-learners are self-learned to update the state embeddings by approximating two disjoint terms in on-policy bisimulation metric. To incorporate the reward and dynamics terms, we further develop a strategy to adaptively balance their impacts based on different tasks or environments. We empirically demonstrate that our proposed framework outperforms state-of-the-art baselines on several benchmarks, including conventional DM Control Suite, Distracting DM Control Suite and a self-driving task CARLA.", "total_citations": {"2022": 2, "2023": 4}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:L7CI7m0gUJcC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/6022", "authors": ["Junyi Shen", "Hankz Hankui Zhuo", "Jin Xu", "Bin Zhong", "Sinno Jialin Pan"], "publication_date": "2020", "conference": "AAAI", "pages": "5676-5683", "description": "Value iteration networks (VINs) have been demonstrated to have a good generalization ability for reinforcement learning tasks across similar domains. However, based on our experiments, a policy learned by VINs still fail to generalize well on the domain whose action space and feature space are not identical to those in the domain where it is trained. In this paper, we propose a transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such that a learned policy from a source domain can be generalized to a target domain with only limited training data, even if the source domain and the target domain have domain-specific actions and features. We empirically verify that our proposed TVINs outperform VINs when the source and the target domains have similar but not identical action and feature spaces. Furthermore, we show that the performance improvement is consistent across different environments, maze sizes, dataset sizes as well as different values of hyperparameters such as number of iteration and kernel size.", "total_citations": {"2021": 1, "2022": 2, "2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:_Ybze24A_UAC": {"external_link": "https://arxiv.org/abs/1707.00524", "authors": ["Haiyan Yin", "Jianda Chen", "Sinno Jialin Pan"], "publication_date": "2018", "conference": "IJCAI", "pages": "3026-3032", "description": "In deep reinforcement learning (RL) tasks, an efficient exploration mechanism should be able to encourage an agent to take actions that lead to less frequent states which may yield higher accumulative future return. However, both knowing about the future and evaluating the frequentness of states are non-trivial tasks, especially for deep RL domains, where a state is represented by high-dimensional image frames. In this paper, we propose a novel informed exploration framework for deep RL, where we build the capability for an RL agent to predict over the future transitions and evaluate the frequentness for the predicted future frames in a meaningful manner. To this end, we train a deep prediction model to predict future frames given a state-action pair, and a convolutional autoencoder model to hash over the seen frames. In addition, to utilize the counts derived from the seen frames to evaluate the frequentness for the predicted frames, we tackle the challenge of matching the predicted future frames and their corresponding seen frames at the latent feature level. In this way, we derive a reliable metric for evaluating the novelty of the future direction pointed by each action, and hence inform the agent to explore the least frequent one.", "total_citations": {"2018": 1, "2019": 4, "2020": 0, "2021": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:-FonjvnnhkoC": {"external_link": "https://direct.mit.edu/coli/article-abstract/47/4/775/106773", "authors": ["Wenya Wang", "Sinno Jialin Pan"], "publication_date": "2021/12/23", "journal": "Computational Linguistics", "volume": "47", "issue": "4", "pages": "775-812", "publisher": "MIT Press", "description": "Currently, deep learning models have been widely adopted and achieved promising results on various application domains. Despite their intriguing performance, most deep learning models function as black boxes, lacking explicit reasoning capabilities and explanations, which are usually essential for complex problems. Take joint inference in information extraction as an example. This task requires the identification of multiple structured knowledge from texts, which is inter-correlated, including entities, events, and the relationships between them. Various deep neural networks have been proposed to jointly perform entity extraction and relation prediction, which only propagate information implicitly via representation learning. However, they fail to encode the intensive correlations between entity types and relations to enforce their coexistence. On the other hand, some approaches adopt rules to explicitly\u00a0\u2026", "total_citations": {"2022": 3, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:VaXvl8Fpj5cC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/17279", "authors": ["Haiyan Yin", "Jianda Chen", "Sinno Jialin Pan", "Sebastian Tschiatschek"], "publication_date": "2021/5/18", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "35", "issue": "12", "pages": "10700-10708", "description": "Many challenging partially observable reinforcement learning problems have sparse rewards and most existing model-free algorithms struggle with such reward sparsity. In this paper, we propose a novel reward shaping approach to infer the intrinsic rewards for the agent from a sequential generative model. Specifically, the sequential generative model processes a sequence of partial observations and actions from the agent's historical transitions to compile a belief state for performing forward dynamics prediction. Then we utilize the error of the dynamics prediction task to infer the intrinsic rewards for the agent. Our proposed method is able to derive intrinsic rewards that could better reflect the agent's surprise or curiosity over its ground-truth state by taking a sequential inference procedure. Furthermore, we formulate the inference procedure for dynamics prediction as a multi-step forward prediction task, where the time abstraction that has been incorporated could effectively help to increase the expressiveness of the intrinsic reward signals. To evaluate our method, we conduct extensive experiments on challenging 3D navigation tasks in ViZDoom and DeepMind Lab. Empirical evaluation results show that our proposed exploration method could lead to significantly faster convergence than various state-of-the-art exploration approaches in the testified navigation domains.", "total_citations": {"2021": 2, "2022": 1, "2023": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:BwyfMAYsbu0C": {"external_link": "https://link.springer.com/article/10.1007/s10994-019-05847-6", "authors": ["Qiang Zhou", "Yu Chen", "Sinno Jialin Pan"], "publication_date": "2020/3", "journal": "Machine Learning", "volume": "109", "pages": "569-601", "publisher": "Springer US", "description": "This work focuses on distributed optimization for multi-task learning with matrix sparsity regularization. We propose a fast communication-efficient distributed optimization method for solving the problem. With the proposed method, training data of different tasks can be geo-distributed over different local machines, and the tasks can be learned jointly through the matrix sparsity regularization without a need to centralize the data. We theoretically prove that our proposed method enjoys a fast convergence rate for different types of loss functions in the distributed environment. To further reduce the communication cost during the distributed optimization procedure, we propose a data screening approach to safely filter inactive features or variables. Finally, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate the effectiveness of our proposed method.", "total_citations": {"2021": 1, "2022": 2, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:_kc_bZDykSQC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/5360443/", "authors": ["Evan Wei Xiang", "Nathan N Liu", "Sinno Jialin Pan", "Qiang Yang"], "publication_date": "2009/12/6", "conference": "2009 IEEE International Conference on Data Mining Workshops", "pages": "429-434", "publisher": "IEEE", "description": "Online recommendation systems are becoming more and more popular with the development of web. However, a critical problem of such system is that new users and items are always added to the system with time. How to overcome the data sparseness for such new incoming entities become an important issue. In this paper, we try to reduce the data sparseness in the link prediction problem via involving heterogeneous information network as auxiliary information sources. We developed two models based on the Collective Matrix Factorization (CMF) framework. We also provided a detailed empirical study on how effectively different information networks could help with two real world link prediction tasks. We will report some preliminary results of our current work and also point our several potential research issues.", "total_citations": {"2014": 1, "2015": 1, "2016": 0, "2017": 0, "2018": 0, "2019": 0, "2020": 2}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:Dip1O2bNi0gC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/9861164/", "authors": ["Kaijun Liu", "Sijie Ruan", "Qianxiong Xu", "Cheng Long", "Nan Xiao", "Nan Hu", "Liang Yu", "Sinno Jialin Pan"], "publication_date": "2022/6/1", "conference": "2022 23rd IEEE International Conference on Mobile Data Management (MDM)", "pages": "208-213", "publisher": "IEEE Computer Society", "description": "With the increasing popularity of GPS modules, there are various urban applications relying on trajectory data modeling. In this work, we study the problem to model the vehicle trajectories by predicting the next road segment given a partial trajectory. Existing methods that model trajectories with Markov chain or recurrent neural network suffer from issues of modeling, context and semantics. In this paper, we propose a new trajectory modeling framework called Multi-task Modeling for Trajectories (MMTraj), which avoids these issues. Specifically, MMTraj uses multi-head self-attention networks for sequential modeling, captures the overall road network as the context information for road segment embedding, and performs an auxiliary task of predicting the trajectory destination to better guide the main trajectory modeling task (controlled by a carefully designed gating mechanism). Extensive experiments conducted on\u00a0\u2026", "total_citations": {"2023": 3}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:S16KYo8Pm5AC": {"external_link": "http://openaccess.thecvf.com/content_eccv_2018_workshops/w8/html/Lv_Domain_Adaptive_Semantic_Segmentation_through_Structure_Enhancement_ECCVW_2018_paper.html", "authors": ["Fengmao Lv", "Qing Lian", "Guowu Yang", "Guosheng Lin", "Sinno Jialin Pan", "Lixin Duan"], "publication_date": "2018", "conference": "Proceedings of the European Conference on Computer Vision (ECCV) Workshops", "pages": "0-0", "description": "Although fully convolutional networks have recently achieved great advances in semantic segmentation, the performance leaps heavily rely on supervision with pixel-level annotations which are extremely expensive and time-consuming to collect. Training models on synthetic data is a feasible way to relieve the annotation burden. However, the domain shift between synthetic and real images usually lead to poor generalization performance. In this work, we propose an effective method to adapt the segmentation network trained on synthetic images to real scenarios in an unsupervised fashion. To improve the adaptation performance for semantic segmentation, we enhance the structure information of the target images at both the feature level and the output level. Specifically, we enforce the segmentation network to learn a representation that encodes the target images\u2019 visual cues through image reconstruction, which is beneficial to the structured prediction of the target images. Further more, we implement adversarial training at the output space of the segmentation network to align the structured prediction of the source and target images based on the similar spatial structure they share. To validate the performance of our method, we conduct comprehensive experiments on the\" GTA5 to Cityscapes\" dataset which is a standard domain adaptation benchmark for semantic segmentation. The experimental results clearly demonstrate that our method can effectively bridge the synthetic and real image domains and obtain better adaptation performance compared with the existing state-of-the-art methods.", "total_citations": {"2020": 2, "2021": 0, "2022": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:WZBGuue-350C": {"external_link": "https://dl.acm.org/doi/abs/10.1145/3447548.3467436", "authors": ["Tianbo Li", "Tianze Luo", "Yiping Ke", "Sinno Jialin Pan"], "publication_date": "2021/8/14", "book": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining", "pages": "986-994", "description": "Attributed event sequences are commonly encountered in practice. A recent research line focuses on incorporating neural networks with the statistical model--marked point processes, which is the conventional tool for dealing with attributed event sequences. Neural marked point processes possess good interpretability of probabilistic models as well as the representational power of neural networks. However, we find that performance of neural marked point processes is not always increasing as the network architecture becomes more complicated and larger, which is what we call the performance saturation phenomenon. This is due to the fact that the generalization error of neural marked point processes is determined by both the network representational ability and the model specification at the same time. Therefore we can draw two major conclusions: first, simple network structures can perform no worse than\u00a0\u2026", "total_citations": {"2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:LI9QrySNdTsC": {"external_link": "https://ojs.aaai.org/index.php/AAAI/article/view/16520", "authors": ["Yu Chen", "Sinno Jialin Pan"], "publication_date": "2021/5/18", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "35", "issue": "5", "pages": "4001-4009", "description": "For personalized recommendations, collaborative filtering (CF) methods aim to recommend items to users based on data of historical user-item interactions. Deep learning has indicated success in improving performance of CF methods in recent works. However, to generate an item recommendation list for each user, a lot of deep learning based CF methods require every pair of users and items to be passed through multiple neural layers. This requires intensive computation and makes real-time end-to-end neural recommendations very costly. To address this issue, in this paper, we propose a new deep learning-based hierarchical decision network to filter out irrelevant items to save computation cost while maintaining good recommendation accuracy of deep CF methods. We also develop a distillation-based training algorithm, which uses a well-trained CF model as a teacher network to guide the training of the decision network. We conducted extensive experiments on real-world benchmark datasets to verify the effectiveness of efficiency of our decision network for making recommendations. The experimental results indicate that the proposed decision network is able to maintain or even improve the recommendation quality in terms of various metrics and meanwhile enjoy lower computational cost.", "total_citations": {"2022": 1, "2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:kzcrU_BdoSEC": {"external_link": "http://www.cse.cuhk.edu.hk/~sinnopan/publications/[UAI17]Communication-Efficient%20Distributed%20Primal-Dual%20Algorithm%20for%20Saddle%20Point%20Problems.pdf", "authors": ["Yaodong Yu", "Sulin Liu", "Sinno Jialin Pan"], "publication_date": "2017", "conference": "UAI", "description": "Primal-dual algorithms, which are proposed to solve reformulated convex-concave saddle point problems, have been proven to be effective for solving a generic class of convex optimization problems, especially when the problems are ill-conditioned. However, the saddle point problem still lacks a distributed optimization framework where primal-dual algorithms can be employed. In this paper, we propose a novel communication-efficient distributed optimization framework to solve the convex-concave saddle point problem based on primal-dual methods. We carefully design local subproblems and a central problem such that our proposed distributed optimization framework is communication-efficient. We provide a convergence analysis of our proposed algorithm, and extend it to address non-smooth and non-strongly convex loss functions. We conduct extensive experiments on several real-world datasets to demonstrate competitive performance of the proposed method, especially on ill-conditioned problems.", "total_citations": {"2018": 1, "2019": 0, "2020": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:hCrLmN-GePgC": {"external_link": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/eda9523faa5e7191aee1c2eaff669716-Abstract-Conference.html", "authors": ["Jianda Chen", "Sinno Jialin Pan"], "publication_date": "2022/12/6", "journal": "Advances in Neural Information Processing Systems", "volume": "35", "pages": "36654-36666", "description": "Learning an informative representation with behavioral metrics is able to accelerate the deep reinforcement learning process. There are two key research issues on behavioral metric-based representation learning: 1) how to relax the computation of a specific behavioral metric, which is difficult or even intractable to compute, and 2) how to approximate the relaxed metric by learning an embedding space for states. In this paper, we analyze the potential relaxation and/or approximation gaps for existing behavioral metric-based representation learning methods. Based on the analysis, we propose a new behavioral distance, the RAP distance, and develop a practical representation learning algorithm on top of it with a theoretical analysis. We conduct extensive experiments on DeepMind Control Suite with distraction, Robosuite, and autonomous driving simulator CARLA to demonstrate new state-of-the-art results.", "total_citations": {"2023": 1}}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:rmuvC79q63oC": {"external_link": "https://arxiv.org/abs/2310.06474", "authors": ["Yue Deng", "Wenxuan Zhang", "Sinno Jialin Pan", "Lidong Bing"], "publication_date": "2023/10/10", "journal": "arXiv preprint arXiv:2310.06474", "description": "While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the ``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior. Although several preventive measures have been developed to mitigate the potential risks associated with LLMs, they have primarily focused on English data. In this study, we reveal the presence of multilingual jailbreak challenges within LLMs and consider two potential risk scenarios: unintentional and intentional. The unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, while the intentional scenario concerns malicious users combining malicious instructions with multilingual prompts to deliberately attack LLMs. The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases as the availability of languages decreases. Specifically, low-resource languages exhibit three times the likelihood of encountering harmful content compared to high-resource languages, with both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts can exacerbate the negative impact of malicious instructions, with astonishingly high rates of unsafe output: 80.92\\% for ChatGPT and 40.71\\% for GPT-4. To handle such a challenge in the multilingual context, we propose a novel \\textsc{Self-Defense} framework that automatically generates multilingual training data for safety fine-tuning. Experimental results show that ChatGPT fine-tuned with such data can achieve a substantial reduction in\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:ClCfbGk0d_YC": {"external_link": "https://openreview.net/forum?id=1CbGa6gxQr", "authors": ["Tianze Luo", "Zhanfeng Mo", "Sinno Jialin Pan"], "publication_date": "2023/7/28", "conference": "ICML 2023 Workshop on Structured Probabilistic Inference {\\&} Generative Modeling", "description": "Conditional graph generation is crucial and challenging since the conditional distribution of graph topology and feature is complicated and the semantic feature is hard to be captured by the generative model. In this work, we propose a novel graph conditional generative model, termed Graph Principal Flow Network (GPrinFlowNet), which enables us to progressively generate graphs from low- to high-frequency components. Our GPrinFlowNet effectively captures the subtle yet essential semantic features of graph topology, resulting in high-quality generated graph data."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:FPJr55Dyh1AC": {"external_link": "https://proceedings.mlr.press/v202/mo23c.html", "authors": ["Zhanfeng Mo", "Haosen Shi", "Sinno Jialin Pan"], "publication_date": "2023/7/3", "conference": "International Conference on Machine Learning", "pages": "25018-25036", "publisher": "PMLR", "description": "Neural pruning, which involves identifying the optimal sparse subnetwork, is a key technique for reducing the complexity and improving the efficiency of deep neural networks. To address the challenge of solving neural pruning at a specific sparsity level directly, we investigate the evolution of optimal subnetworks with continuously increasing sparsity, which can provide insight into how to transform an unpruned dense model into an optimal subnetwork with any desired level of sparsity. In this paper, we proposed a novel pruning framework, coined Sparsity-indexed ODE (SpODE) that provides explicit guidance on how to best preserve model performance while ensuring an infinitesimal increase in model sparsity. On top of this, we develop a pruning algorithm, termed Pruning via Sparsity-indexed ODE (PSO), that enables effective pruning via traveling along the SpODE path. Empirical experiments show that PSO achieves either better or comparable performance compared to state-of-the-art baselines across various pruning settings."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:Ug5p-4gJ2f0C": {"external_link": "https://arxiv.org/abs/2305.09509", "authors": ["Yue Deng", "Wenxuan Zhang", "Sinno Jialin Pan", "Lidong Bing"], "publication_date": "2023/5/16", "journal": "arXiv preprint arXiv:2305.09509", "description": "Cross-domain aspect-based sentiment analysis (ABSA) aims to perform various fine-grained sentiment analysis tasks on a target domain by transferring knowledge from a source domain. Since labeled data only exists in the source domain, a model is expected to bridge the domain gap for tackling cross-domain ABSA. Though domain adaptation methods have proven to be effective, most of them are based on a discriminative model, which needs to be specifically designed for different ABSA tasks. To offer a more general solution, we propose a unified bidirectional generative framework to tackle various cross-domain ABSA tasks. Specifically, our framework trains a generative model in both text-to-label and label-to-text directions. The former transforms each task into a unified format to learn domain-agnostic features, and the latter generates natural sentences from noisy labels for data augmentation, with which a more accurate model can be trained. To investigate the effectiveness and generality of our framework, we conduct extensive experiments on four cross-domain ABSA tasks and present new state-of-the-art results on all tasks. Our data and code are publicly available at \\url{https://github.com/DAMO-NLP-SG/BGCA}."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:5qfkUJPXOUwC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/10184650/", "authors": ["Yansheng Wang", "Yongxin Tong", "Zimu Zhou", "Ruisheng Zhang", "Sinno Jialin Pan", "Lixin Fan", "Qiang Yang"], "publication_date": "2023/4/3", "conference": "2023 IEEE 39th International Conference on Data Engineering (ICDE)", "pages": "2113-2125", "publisher": "IEEE", "description": "Federated learning (FL) has emerged as a popular machine learning paradigm recently. Compared with traditional distributed learning, its unique challenges mainly lie in communication efficiency and non-IID (heterogeneous data) problem. While the widely adopted framework FedAvg can reduce communication overhead significantly, its effectiveness on non-IID data still lacks exploration. In this paper, we study the non-IID problem of FL from the perspective of domain adaptation. We propose a distribution regularization for FL on non-IID data such that the discrepancy of data distributions between clients is reduced. To further reduce the communication cost, we devise two novel distributed learning algorithms, namely rFedAvg and rFedAvg+, for efficiently learning with the distribution regularization. More importantly, we theoretically establish their convergence for strongly convex objectives. Extensive experiments\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:XoXfffV-tXoC": {"external_link": "https://ieeexplore.ieee.org/abstract/document/10061493/", "authors": ["Danni Peng", "Sinno Jialin Pan"], "publication_date": "2023/3/6", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "publisher": "IEEE", "description": "To enable effective learning of new tasks with only a few examples, meta-learning acquires common knowledge from the existing tasks with a globally shared meta-learner. To further address the problem of task heterogeneity, recent developments balance between customization and generalization by incorporating task clustering to generate task-aware modulation to be applied to the global meta-learner. However, these methods learn task representation mostly from the features of input data, while the task-specific optimization process with respect to the base-learner is often neglected. In this work, we propose a  C lustered  T ask-Aware  M eta- L earning (CTML) framework with task representation learned from both features and learning paths. We first conduct rehearsed task learning from the common initialization, and collect a set of geometric quantities that adequately describes this learning path. By inputting\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:86PQX7AUzd4C": {"external_link": "https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.html", "authors": ["Haosen Shi", "Shen Ren", "Tianwei Zhang", "Sinno Jialin Pan"], "publication_date": "2023", "conference": "Proceedings of the IEEE/CVF International Conference on Computer Vision", "pages": "19924-19935", "description": "We propose a novel progressive parameter-sharing strategy (MPPS) in this paper for effectively training multitask learning models on diverse computer vision tasks simultaneously. Specifically, we propose to parameterize distributions for different tasks to control the sharings, based on the concept of Exclusive Capacity that we introduce. A scheduling mechanism following the concept of curriculum learning is also designed to progressively change the sharing strategy to increase the level of sharing during the learning process. We further propose a novel loss function to regularize the optimization of network parameters as well as the sharing probabilities of each neuron for each task. Our approach can be combined with many state-of-the-art multitask learning solutions to achieve better joint task performance. Comprehensive experiments show that it has competitive performance on three challenging datasets (Multi-CIFAR100, NYUv2, and Cityscapes) using various convolution neural network architectures."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:_axFR9aDTf0C": {"external_link": "https://patents.google.com/patent/US11527074B1/en", "inventors": "Shen Ren, Csaba Nemes, Regina Deak-Meszlenyi, Sinno Jialin Pan", "publication_date": "2022/12/13", "patent_office": "US", "patent_number": "11527074", "application_number": "17534845", "description": "A computer-implemented method includes receiving data generated using at least one sensor of a vehicle; and simultaneously performing multiple different prediction tasks on the data using a multi-task neural network, wherein the multi-task neural network comprises at least one shared parameter inference matrix comprising parameters shared between the multiple different prediction tasks, and the at least one shared parameter inference matrix was over-parameterized during training into at least one shared parameter matrix and multiple task-specific parameter matrices, each of the multiple task-specific parameter matrices being associated with a different one of the multiple different tasks."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:foquWX3nUaYC": {"external_link": "https://proceedings.mlr.press/v180/zhou22b.html", "authors": ["Qiang Zhou", "Sinno Jialin Pan"], "publication_date": "2022/8/17", "conference": "Uncertainty in Artificial Intelligence", "pages": "2394-2403", "publisher": "PMLR", "description": "Linear coupling is recently proposed to accelerate first-order algorithms by linking gradient descent and mirror descent together, which is able to achieve the accelerated convergence rate for first-order algorithms. This work focuses on the convergence analysis of linear coupling for convex composite minimization when the proximal operator cannot be exactly computed. It is of particular interest to study the convergence of linear coupling because it not only achieves the accelerated convergence rate for first-order algorithm but also works for generic norms. We present convergence analysis of linear coupling by allowing the proximal operator to be computed up to a certain precision. Our analysis illustrates that the accelerated convergence rate of linear coupling with inexact proximal operator can be preserved if the error sequence of inexact proximal operator decreases in a sufficiently fast rate. More importantly, our analysis leads to better bounds than existing works on inexact proximal operator. Experiment results on several real-world datasets verify our theoretical results."}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:q3CdL3IzO_QC": {"external_link": "https://dl.acm.org/doi/abs/10.5555/3586589.3586812", "authors": ["Qiang Zhou", "Sinno Jialin Pan"], "publication_date": "2022", "journal": "Journal of Machine Learning Research", "volume": "23", "issue": "223", "pages": "1-59", "description": "The accelerated proximal methods (APM) have become one of the most important optimization tools for large-scale convex composite minimization problems, due to their wide range of applications and the optimal convergence rate in first-order algorithms. However, most existing theoretical results of APM are obtained by assuming that the gradient oracle is exact and the proximal mapping must be exactly solved, which may not hold in practice. This work presents a theoretical study of APM by allowing to use inexact gradient oracle and approximate proximal mapping. Specifically, we analyze inexact APM by improving the approximate duality gap technique (ADGT) which was originally designed for convergence analysis for first-order methods with both exact gradient oracle and proximal mapping. Our approach has several advantages: 1) we provide a unified convergence analysis that allows both inexact gradient\u00a0\u2026"}, "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=P6WcnfkAAAAJ&cstart=100&pagesize=100&citation_for_view=P6WcnfkAAAAJ:tYavs44e6CUC": {"external_link": null, "authors": ["Sinno Jialin Pan"], "publication_date": "2014", "book": "Data Classification: Algorithms and Applications", "pages": "537--570}", "publisher": "CRC Press"}}